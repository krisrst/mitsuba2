//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31294372
// Cuda compilation tools, release 11.7, V11.7.64
// Based on NVVM 7.0.1
//

.version 7.7
.target sm_61
.address_size 64

	// .globl	__intersection__cylinder
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.const .align 8 .b8 params[368];
.global .align 1 .b8 $str[36] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 83, 84, 65, 67, 75, 95, 79, 86, 69, 82, 70, 76, 79, 87, 0};
.global .align 1 .b8 $str$1[42] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 67, 69, 95, 68, 69, 80, 84, 72, 95, 69, 88, 67, 69, 69, 68, 69, 68, 0};
.global .align 1 .b8 $str$2[46] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 86, 69, 82, 83, 65, 76, 95, 68, 69, 80, 84, 72, 95, 69, 88, 67, 69, 69, 68, 69, 68, 0};
.global .align 1 .b8 $str$3[51] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 86, 69, 82, 83, 65, 76, 95, 73, 78, 86, 65, 76, 73, 68, 95, 84, 82, 65, 86, 69, 82, 83, 65, 66, 76, 69, 0};
.global .align 1 .b8 $str$4[48] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 86, 69, 82, 83, 65, 76, 95, 73, 78, 86, 65, 76, 73, 68, 95, 77, 73, 83, 83, 95, 83, 66, 84, 0};
.global .align 1 .b8 $str$5[47] = {79, 80, 84, 73, 88, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 84, 82, 65, 86, 69, 82, 83, 65, 76, 95, 73, 78, 86, 65, 76, 73, 68, 95, 72, 73, 84, 95, 83, 66, 84, 0};
.const .align 8 .u64 exceptions[12] = {4294967295, generic($str), 4294967294, generic($str$1), 4294967293, generic($str$2), 4294967291, generic($str$3), 4294967290, generic($str$4), 4294967289, generic($str$5)};
.global .align 1 .b8 $str$6[24] = {79, 112, 116, 105, 120, 32, 69, 120, 99, 101, 112, 116, 105, 111, 110, 32, 37, 117, 58, 32, 37, 115, 10, 0};

.visible .entry __intersection__cylinder()
{
	.reg .pred 	%p<54>;
	.reg .b16 	%rs<8>;
	.reg .f32 	%f<1009>;
	.reg .b32 	%r<323>;
	.reg .b64 	%rd<259>;


	// begin inline asm
	call (%rd17), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd1, [%rd17+8];
	// begin inline asm
	call (%f945), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f946), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f947), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r9), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p2, %r9, 0;
	@%p2 bra 	$L__BB0_21;

	// begin inline asm
	call (%r10), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f359), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p3, %r10, 0;
	@%p3 bra 	$L__BB0_19;

	mov.u32 	%r321, 0;

$L__BB0_3:
	.pragma "nounroll";
	// begin inline asm
	call (%rd18), _optix_get_transform_list_handle, (%r321);
	// end inline asm
	// begin inline asm
	call (%r13), _optix_get_transform_type_from_handle, (%rd18);
	// end inline asm
	or.b32  	%r14, %r13, 1;
	setp.eq.s32 	%p4, %r14, 3;
	@%p4 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_4;

$L__BB0_9:
	setp.eq.s32 	%p7, %r13, 2;
	@%p7 bra 	$L__BB0_13;
	bra.uni 	$L__BB0_10;

$L__BB0_13:
	// begin inline asm
	call (%rd90), _optix_get_matrix_motion_transform_from_handle, (%rd18);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd92];
	// end inline asm
	add.s64 	%rd96, %rd90, 16;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd95];
	// end inline asm
	add.s64 	%rd99, %rd90, 32;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd98];
	// end inline asm
	add.s64 	%rd102, %rd90, 48;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd101];
	// end inline asm
	add.s64 	%rd105, %rd90, 64;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd104];
	// end inline asm
	add.s64 	%rd108, %rd90, 80;
	// begin inline asm
	cvta.to.global.u64 %rd107, %rd108;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd107];
	// end inline asm
	add.s64 	%rd111, %rd90, 96;
	// begin inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd110];
	// end inline asm
	add.s64 	%rd114, %rd90, 112;
	// begin inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd113];
	// end inline asm
	mov.b32 	%f487, %r105;
	mov.b32 	%f488, %r106;
	and.b32  	%r146, %r104, 65535;
	add.s32 	%r147, %r146, -1;
	cvt.rn.f32.s32 	%f489, %r147;
	sub.f32 	%f490, %f359, %f487;
	mul.f32 	%f491, %f490, %f489;
	sub.f32 	%f492, %f488, %f487;
	div.rn.f32 	%f493, %f491, %f492;
	min.f32 	%f494, %f489, %f493;
	mov.f32 	%f495, 0f00000000;
	max.f32 	%f496, %f495, %f494;
	cvt.rmi.f32.f32 	%f497, %f496;
	sub.f32 	%f90, %f496, %f497;
	cvt.rzi.s32.f32 	%r148, %f497;
	mul.wide.s32 	%rd125, %r148, 48;
	add.s64 	%rd117, %rd99, %rd125;
	// begin inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd116];
	// end inline asm
	mov.b32 	%f900, %r134;
	mov.b32 	%f899, %r135;
	mov.b32 	%f898, %r136;
	mov.b32 	%f897, %r137;
	add.s64 	%rd120, %rd117, 16;
	// begin inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd119];
	// end inline asm
	mov.b32 	%f904, %r138;
	mov.b32 	%f903, %r139;
	mov.b32 	%f902, %r140;
	mov.b32 	%f901, %r141;
	add.s64 	%rd123, %rd117, 32;
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd122];
	// end inline asm
	mov.b32 	%f908, %r142;
	mov.b32 	%f907, %r143;
	mov.b32 	%f906, %r144;
	mov.b32 	%f905, %r145;
	setp.leu.f32 	%p9, %f90, 0f00000000;
	@%p9 bra 	$L__BB0_15;

	cvt.rmi.f32.f32 	%f868, %f496;
	cvt.rzi.s32.f32 	%r320, %f868;
	cvt.s64.s32 	%rd256, %r320;
	mov.f32 	%f498, 0f3F800000;
	sub.f32 	%f499, %f498, %f90;
	mul.lo.s64 	%rd135, %rd256, 48;
	add.s64 	%rd136, %rd90, %rd135;
	add.s64 	%rd127, %rd136, 80;
	// begin inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd126];
	// end inline asm
	mov.b32 	%f500, %r149;
	mov.b32 	%f501, %r150;
	mov.b32 	%f502, %r151;
	mov.b32 	%f503, %r152;
	mul.f32 	%f504, %f90, %f500;
	mul.f32 	%f505, %f90, %f501;
	mul.f32 	%f506, %f90, %f502;
	mul.f32 	%f507, %f90, %f503;
	fma.rn.f32 	%f900, %f499, %f900, %f504;
	fma.rn.f32 	%f899, %f499, %f899, %f505;
	fma.rn.f32 	%f898, %f499, %f898, %f506;
	fma.rn.f32 	%f897, %f499, %f897, %f507;
	add.s64 	%rd130, %rd136, 96;
	// begin inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd129];
	// end inline asm
	mov.b32 	%f508, %r153;
	mov.b32 	%f509, %r154;
	mov.b32 	%f510, %r155;
	mov.b32 	%f511, %r156;
	mul.f32 	%f512, %f90, %f508;
	mul.f32 	%f513, %f90, %f509;
	mul.f32 	%f514, %f90, %f510;
	mul.f32 	%f515, %f90, %f511;
	fma.rn.f32 	%f904, %f499, %f904, %f512;
	fma.rn.f32 	%f903, %f499, %f903, %f513;
	fma.rn.f32 	%f902, %f499, %f902, %f514;
	fma.rn.f32 	%f901, %f499, %f901, %f515;
	add.s64 	%rd133, %rd136, 112;
	// begin inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd132];
	// end inline asm
	mov.b32 	%f516, %r157;
	mov.b32 	%f517, %r158;
	mov.b32 	%f518, %r159;
	mov.b32 	%f519, %r160;
	mul.f32 	%f520, %f90, %f516;
	mul.f32 	%f521, %f90, %f517;
	mul.f32 	%f522, %f90, %f518;
	mul.f32 	%f523, %f90, %f519;
	fma.rn.f32 	%f908, %f499, %f908, %f520;
	fma.rn.f32 	%f907, %f499, %f907, %f521;
	fma.rn.f32 	%f906, %f499, %f906, %f522;
	fma.rn.f32 	%f905, %f499, %f905, %f523;
	bra.uni 	$L__BB0_15;

$L__BB0_4:
	mov.f32 	%f909, 0f00000000;
	mov.f32 	%f912, 0f3F800000;
	setp.eq.s32 	%p5, %r13, 4;
	@%p5 bra 	$L__BB0_7;

	setp.ne.s32 	%p6, %r13, 1;
	mov.f32 	%f910, %f909;
	mov.f32 	%f911, %f909;
	mov.f32 	%f913, %f909;
	mov.f32 	%f914, %f909;
	mov.f32 	%f915, %f912;
	mov.f32 	%f916, %f909;
	mov.f32 	%f917, %f909;
	mov.f32 	%f918, %f912;
	mov.f32 	%f919, %f909;
	mov.f32 	%f920, %f909;
	@%p6 bra 	$L__BB0_16;

	// begin inline asm
	call (%rd20), _optix_get_static_transform_from_handle, (%rd18);
	// end inline asm
	add.s64 	%rd257, %rd20, 64;
	bra.uni 	$L__BB0_8;

$L__BB0_10:
	// begin inline asm
	call (%rd33), _optix_get_srt_motion_transform_from_handle, (%rd18);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd35, %rd33;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r27,%r28,%r29,%r30}, [%rd35];
	// end inline asm
	add.s64 	%rd39, %rd33, 16;
	// begin inline asm
	cvta.to.global.u64 %rd38, %rd39;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r31,%r32,%r33,%r34}, [%rd38];
	// end inline asm
	add.s64 	%rd42, %rd33, 32;
	// begin inline asm
	cvta.to.global.u64 %rd41, %rd42;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd41];
	// end inline asm
	add.s64 	%rd45, %rd33, 48;
	// begin inline asm
	cvta.to.global.u64 %rd44, %rd45;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd44];
	// end inline asm
	add.s64 	%rd48, %rd33, 64;
	// begin inline asm
	cvta.to.global.u64 %rd47, %rd48;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd47];
	// end inline asm
	add.s64 	%rd51, %rd33, 80;
	// begin inline asm
	cvta.to.global.u64 %rd50, %rd51;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd50];
	// end inline asm
	add.s64 	%rd54, %rd33, 96;
	// begin inline asm
	cvta.to.global.u64 %rd53, %rd54;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd53];
	// end inline asm
	add.s64 	%rd57, %rd33, 112;
	// begin inline asm
	cvta.to.global.u64 %rd56, %rd57;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd56];
	// end inline asm
	add.s64 	%rd60, %rd33, 128;
	// begin inline asm
	cvta.to.global.u64 %rd59, %rd60;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd59];
	// end inline asm
	add.s64 	%rd63, %rd33, 144;
	// begin inline asm
	cvta.to.global.u64 %rd62, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd62];
	// end inline asm
	mov.b32 	%f374, %r30;
	mov.b32 	%f375, %r31;
	and.b32  	%r83, %r29, 65535;
	add.s32 	%r84, %r83, -1;
	cvt.rn.f32.s32 	%f376, %r84;
	sub.f32 	%f377, %f359, %f374;
	mul.f32 	%f378, %f377, %f376;
	sub.f32 	%f379, %f375, %f374;
	div.rn.f32 	%f380, %f378, %f379;
	min.f32 	%f381, %f376, %f380;
	mov.f32 	%f382, 0f00000000;
	max.f32 	%f383, %f382, %f381;
	cvt.rmi.f32.f32 	%f384, %f383;
	sub.f32 	%f29, %f383, %f384;
	cvt.rzi.s32.f32 	%r85, %f384;
	mul.wide.s32 	%rd77, %r85, 64;
	add.s64 	%rd66, %rd42, %rd77;
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd66;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd65];
	// end inline asm
	mov.b32 	%f881, %r67;
	mov.b32 	%f882, %r68;
	mov.b32 	%f883, %r69;
	mov.b32 	%f884, %r70;
	add.s64 	%rd69, %rd66, 16;
	// begin inline asm
	cvta.to.global.u64 %rd68, %rd69;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd68];
	// end inline asm
	mov.b32 	%f885, %r71;
	mov.b32 	%f886, %r72;
	mov.b32 	%f887, %r73;
	mov.b32 	%f888, %r74;
	add.s64 	%rd72, %rd66, 32;
	// begin inline asm
	cvta.to.global.u64 %rd71, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd71];
	// end inline asm
	mov.b32 	%f889, %r75;
	mov.b32 	%f890, %r76;
	mov.b32 	%f891, %r77;
	mov.b32 	%f892, %r78;
	add.s64 	%rd75, %rd66, 48;
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd75;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd74];
	// end inline asm
	mov.b32 	%f893, %r79;
	mov.b32 	%f894, %r80;
	mov.b32 	%f895, %r81;
	mov.b32 	%f896, %r82;
	setp.leu.f32 	%p8, %f29, 0f00000000;
	@%p8 bra 	$L__BB0_12;

	mov.f32 	%f385, 0f3F800000;
	sub.f32 	%f386, %f385, %f29;
	add.s64 	%rd79, %rd66, 64;
	// begin inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r86,%r87,%r88,%r89}, [%rd78];
	// end inline asm
	mov.b32 	%f387, %r86;
	mov.b32 	%f388, %r87;
	mov.b32 	%f389, %r88;
	mov.b32 	%f390, %r89;
	mul.f32 	%f391, %f29, %f387;
	mul.f32 	%f392, %f29, %f388;
	mul.f32 	%f393, %f29, %f389;
	mul.f32 	%f394, %f29, %f390;
	fma.rn.f32 	%f881, %f386, %f881, %f391;
	fma.rn.f32 	%f882, %f386, %f882, %f392;
	fma.rn.f32 	%f883, %f386, %f883, %f393;
	fma.rn.f32 	%f884, %f386, %f884, %f394;
	add.s64 	%rd82, %rd66, 80;
	// begin inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd81];
	// end inline asm
	mov.b32 	%f395, %r90;
	mov.b32 	%f396, %r91;
	mov.b32 	%f397, %r92;
	mov.b32 	%f398, %r93;
	mul.f32 	%f399, %f29, %f395;
	mul.f32 	%f400, %f29, %f396;
	mul.f32 	%f401, %f29, %f397;
	mul.f32 	%f402, %f29, %f398;
	fma.rn.f32 	%f885, %f386, %f885, %f399;
	fma.rn.f32 	%f886, %f386, %f886, %f400;
	fma.rn.f32 	%f887, %f386, %f887, %f401;
	fma.rn.f32 	%f888, %f386, %f888, %f402;
	add.s64 	%rd85, %rd66, 96;
	// begin inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd84];
	// end inline asm
	mov.b32 	%f403, %r94;
	mov.b32 	%f404, %r95;
	mov.b32 	%f405, %r96;
	mov.b32 	%f406, %r97;
	mul.f32 	%f407, %f29, %f403;
	mul.f32 	%f408, %f29, %f404;
	mul.f32 	%f409, %f29, %f405;
	mul.f32 	%f410, %f29, %f406;
	fma.rn.f32 	%f889, %f386, %f889, %f407;
	fma.rn.f32 	%f411, %f386, %f890, %f408;
	fma.rn.f32 	%f412, %f386, %f891, %f409;
	fma.rn.f32 	%f413, %f386, %f892, %f410;
	add.s64 	%rd88, %rd66, 112;
	// begin inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd87];
	// end inline asm
	mov.b32 	%f414, %r98;
	mov.b32 	%f415, %r99;
	mov.b32 	%f416, %r100;
	mov.b32 	%f417, %r101;
	mul.f32 	%f418, %f29, %f414;
	mul.f32 	%f419, %f29, %f415;
	mul.f32 	%f420, %f29, %f416;
	mul.f32 	%f421, %f29, %f417;
	fma.rn.f32 	%f422, %f386, %f893, %f418;
	fma.rn.f32 	%f894, %f386, %f894, %f419;
	fma.rn.f32 	%f895, %f386, %f895, %f420;
	fma.rn.f32 	%f896, %f386, %f896, %f421;
	mul.f32 	%f423, %f412, %f412;
	fma.rn.f32 	%f424, %f411, %f411, %f423;
	fma.rn.f32 	%f425, %f413, %f413, %f424;
	fma.rn.f32 	%f426, %f422, %f422, %f425;
	sqrt.rn.f32 	%f427, %f426;
	rcp.rn.f32 	%f428, %f427;
	mul.f32 	%f890, %f411, %f428;
	mul.f32 	%f891, %f412, %f428;
	mul.f32 	%f892, %f413, %f428;
	mul.f32 	%f893, %f428, %f422;

$L__BB0_12:
	mul.f32 	%f429, %f891, %f891;
	fma.rn.f32 	%f430, %f890, %f890, %f429;
	fma.rn.f32 	%f431, %f892, %f892, %f430;
	fma.rn.f32 	%f432, %f893, %f893, %f431;
	rcp.rn.f32 	%f433, %f432;
	mul.f32 	%f434, %f890, %f433;
	mul.f32 	%f435, %f891, %f433;
	mul.f32 	%f436, %f892, %f433;
	mul.f32 	%f437, %f893, %f433;
	mul.f32 	%f438, %f890, %f434;
	mul.f32 	%f439, %f891, %f435;
	mul.f32 	%f440, %f892, %f436;
	mul.f32 	%f441, %f890, %f435;
	mul.f32 	%f442, %f892, %f437;
	mul.f32 	%f443, %f890, %f436;
	mul.f32 	%f444, %f891, %f437;
	mul.f32 	%f445, %f891, %f436;
	mul.f32 	%f446, %f890, %f437;
	sub.f32 	%f447, %f438, %f439;
	sub.f32 	%f448, %f447, %f440;
	fma.rn.f32 	%f449, %f893, %f437, %f448;
	sub.f32 	%f450, %f441, %f442;
	add.f32 	%f451, %f450, %f450;
	add.f32 	%f452, %f443, %f444;
	add.f32 	%f453, %f452, %f452;
	add.f32 	%f454, %f441, %f442;
	add.f32 	%f455, %f454, %f454;
	sub.f32 	%f456, %f439, %f438;
	sub.f32 	%f457, %f456, %f440;
	fma.rn.f32 	%f458, %f893, %f437, %f457;
	sub.f32 	%f459, %f445, %f446;
	add.f32 	%f460, %f459, %f459;
	sub.f32 	%f461, %f443, %f444;
	add.f32 	%f462, %f461, %f461;
	add.f32 	%f463, %f445, %f446;
	add.f32 	%f464, %f463, %f463;
	neg.f32 	%f465, %f438;
	sub.f32 	%f466, %f465, %f439;
	add.f32 	%f467, %f440, %f466;
	fma.rn.f32 	%f468, %f893, %f437, %f467;
	mul.f32 	%f469, %f884, %f449;
	fma.rn.f32 	%f470, %f887, %f451, %f469;
	fma.rn.f32 	%f471, %f889, %f453, %f470;
	sub.f32 	%f897, %f894, %f471;
	mul.f32 	%f472, %f887, %f458;
	fma.rn.f32 	%f473, %f884, %f455, %f472;
	fma.rn.f32 	%f474, %f889, %f460, %f473;
	sub.f32 	%f901, %f895, %f474;
	mul.f32 	%f475, %f887, %f464;
	fma.rn.f32 	%f476, %f884, %f462, %f475;
	fma.rn.f32 	%f477, %f889, %f468, %f476;
	sub.f32 	%f905, %f896, %f477;
	mul.f32 	%f478, %f883, %f449;
	fma.rn.f32 	%f479, %f886, %f451, %f478;
	fma.rn.f32 	%f898, %f888, %f453, %f479;
	mul.f32 	%f480, %f886, %f458;
	fma.rn.f32 	%f481, %f883, %f455, %f480;
	fma.rn.f32 	%f902, %f888, %f460, %f481;
	mul.f32 	%f482, %f886, %f464;
	fma.rn.f32 	%f483, %f883, %f462, %f482;
	fma.rn.f32 	%f906, %f888, %f468, %f483;
	mul.f32 	%f484, %f882, %f449;
	fma.rn.f32 	%f899, %f885, %f451, %f484;
	mul.f32 	%f485, %f885, %f458;
	fma.rn.f32 	%f903, %f882, %f455, %f485;
	mul.f32 	%f486, %f885, %f464;
	fma.rn.f32 	%f907, %f882, %f462, %f486;
	mul.f32 	%f900, %f881, %f449;
	mul.f32 	%f904, %f881, %f455;
	mul.f32 	%f908, %f881, %f462;

$L__BB0_15:
	mul.f32 	%f524, %f902, %f907;
	mul.f32 	%f525, %f903, %f906;
	sub.f32 	%f526, %f525, %f524;
	mul.f32 	%f527, %f900, %f526;
	mul.f32 	%f528, %f902, %f908;
	mul.f32 	%f529, %f904, %f906;
	sub.f32 	%f530, %f529, %f528;
	mul.f32 	%f531, %f899, %f530;
	sub.f32 	%f532, %f527, %f531;
	mul.f32 	%f533, %f903, %f908;
	mul.f32 	%f534, %f904, %f907;
	sub.f32 	%f535, %f534, %f533;
	fma.rn.f32 	%f536, %f898, %f535, %f532;
	rcp.rn.f32 	%f537, %f536;
	mul.f32 	%f912, %f526, %f537;
	mul.f32 	%f538, %f899, %f906;
	mul.f32 	%f539, %f898, %f907;
	sub.f32 	%f540, %f539, %f538;
	mul.f32 	%f911, %f540, %f537;
	mul.f32 	%f541, %f898, %f903;
	mul.f32 	%f542, %f899, %f902;
	sub.f32 	%f543, %f542, %f541;
	mul.f32 	%f910, %f543, %f537;
	sub.f32 	%f544, %f528, %f529;
	mul.f32 	%f916, %f544, %f537;
	mul.f32 	%f545, %f898, %f908;
	mul.f32 	%f546, %f900, %f906;
	sub.f32 	%f547, %f546, %f545;
	mul.f32 	%f915, %f547, %f537;
	mul.f32 	%f548, %f900, %f902;
	mul.f32 	%f549, %f898, %f904;
	sub.f32 	%f550, %f549, %f548;
	mul.f32 	%f914, %f550, %f537;
	mul.f32 	%f920, %f535, %f537;
	mul.f32 	%f551, %f900, %f907;
	mul.f32 	%f552, %f899, %f908;
	sub.f32 	%f553, %f552, %f551;
	mul.f32 	%f919, %f553, %f537;
	mul.f32 	%f554, %f899, %f904;
	mul.f32 	%f555, %f900, %f903;
	sub.f32 	%f556, %f555, %f554;
	mul.f32 	%f918, %f556, %f537;
	mul.f32 	%f557, %f897, %f912;
	neg.f32 	%f558, %f557;
	mul.f32 	%f559, %f901, %f911;
	sub.f32 	%f560, %f558, %f559;
	mul.f32 	%f561, %f905, %f910;
	sub.f32 	%f909, %f560, %f561;
	mul.f32 	%f562, %f897, %f916;
	neg.f32 	%f563, %f562;
	mul.f32 	%f564, %f901, %f915;
	sub.f32 	%f565, %f563, %f564;
	mul.f32 	%f566, %f905, %f914;
	sub.f32 	%f913, %f565, %f566;
	mul.f32 	%f567, %f897, %f920;
	neg.f32 	%f568, %f567;
	mul.f32 	%f569, %f901, %f919;
	sub.f32 	%f570, %f568, %f569;
	mul.f32 	%f571, %f905, %f918;
	sub.f32 	%f917, %f570, %f571;
	bra.uni 	$L__BB0_16;

$L__BB0_7:
	// begin inline asm
	call (%rd257), _optix_get_instance_inverse_transform_from_handle, (%rd18);
	// end inline asm

$L__BB0_8:
	// begin inline asm
	cvta.to.global.u64 %rd24, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r15,%r16,%r17,%r18}, [%rd24];
	// end inline asm
	mov.b32 	%f912, %r15;
	mov.b32 	%f911, %r16;
	mov.b32 	%f910, %r17;
	mov.b32 	%f909, %r18;
	add.s64 	%rd28, %rd257, 16;
	// begin inline asm
	cvta.to.global.u64 %rd27, %rd28;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r19,%r20,%r21,%r22}, [%rd27];
	// end inline asm
	mov.b32 	%f916, %r19;
	mov.b32 	%f915, %r20;
	mov.b32 	%f914, %r21;
	mov.b32 	%f913, %r22;
	add.s64 	%rd31, %rd257, 32;
	// begin inline asm
	cvta.to.global.u64 %rd30, %rd31;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r23,%r24,%r25,%r26}, [%rd30];
	// end inline asm
	mov.b32 	%f920, %r23;
	mov.b32 	%f919, %r24;
	mov.b32 	%f918, %r25;
	mov.b32 	%f917, %r26;

$L__BB0_16:
	setp.eq.s32 	%p10, %r321, 0;
	@%p10 bra 	$L__BB0_18;

	mul.f32 	%f572, %f877, %f912;
	fma.rn.f32 	%f573, %f873, %f911, %f572;
	fma.rn.f32 	%f151, %f869, %f910, %f573;
	mul.f32 	%f574, %f878, %f912;
	fma.rn.f32 	%f575, %f874, %f911, %f574;
	fma.rn.f32 	%f152, %f870, %f910, %f575;
	mul.f32 	%f576, %f879, %f912;
	fma.rn.f32 	%f577, %f875, %f911, %f576;
	fma.rn.f32 	%f153, %f871, %f910, %f577;
	mul.f32 	%f578, %f880, %f912;
	fma.rn.f32 	%f579, %f876, %f911, %f578;
	fma.rn.f32 	%f580, %f872, %f910, %f579;
	add.f32 	%f909, %f909, %f580;
	mul.f32 	%f581, %f877, %f916;
	fma.rn.f32 	%f582, %f873, %f915, %f581;
	fma.rn.f32 	%f155, %f869, %f914, %f582;
	mul.f32 	%f583, %f878, %f916;
	fma.rn.f32 	%f584, %f874, %f915, %f583;
	fma.rn.f32 	%f156, %f870, %f914, %f584;
	mul.f32 	%f585, %f879, %f916;
	fma.rn.f32 	%f586, %f875, %f915, %f585;
	fma.rn.f32 	%f157, %f871, %f914, %f586;
	mul.f32 	%f587, %f880, %f916;
	fma.rn.f32 	%f588, %f876, %f915, %f587;
	fma.rn.f32 	%f589, %f872, %f914, %f588;
	add.f32 	%f913, %f913, %f589;
	mul.f32 	%f590, %f877, %f920;
	fma.rn.f32 	%f591, %f873, %f919, %f590;
	fma.rn.f32 	%f159, %f869, %f918, %f591;
	mul.f32 	%f592, %f878, %f920;
	fma.rn.f32 	%f593, %f874, %f919, %f592;
	fma.rn.f32 	%f160, %f870, %f918, %f593;
	mul.f32 	%f594, %f879, %f920;
	fma.rn.f32 	%f595, %f875, %f919, %f594;
	fma.rn.f32 	%f161, %f871, %f918, %f595;
	mul.f32 	%f596, %f880, %f920;
	fma.rn.f32 	%f597, %f876, %f919, %f596;
	fma.rn.f32 	%f598, %f872, %f918, %f597;
	add.f32 	%f917, %f917, %f598;
	mov.f32 	%f910, %f153;
	mov.f32 	%f911, %f152;
	mov.f32 	%f912, %f151;
	mov.f32 	%f914, %f157;
	mov.f32 	%f915, %f156;
	mov.f32 	%f916, %f155;
	mov.f32 	%f918, %f161;
	mov.f32 	%f919, %f160;
	mov.f32 	%f920, %f159;

$L__BB0_18:
	add.s32 	%r321, %r321, 1;
	setp.lt.u32 	%p11, %r321, %r10;
	mov.f32 	%f869, %f920;
	mov.f32 	%f870, %f919;
	mov.f32 	%f871, %f918;
	mov.f32 	%f872, %f917;
	mov.f32 	%f873, %f916;
	mov.f32 	%f874, %f915;
	mov.f32 	%f875, %f914;
	mov.f32 	%f876, %f913;
	mov.f32 	%f877, %f912;
	mov.f32 	%f878, %f911;
	mov.f32 	%f879, %f910;
	mov.f32 	%f880, %f909;
	@%p11 bra 	$L__BB0_3;

$L__BB0_19:
	mul.f32 	%f599, %f945, %f912;
	fma.rn.f32 	%f600, %f946, %f911, %f599;
	fma.rn.f32 	%f601, %f947, %f910, %f600;
	mul.f32 	%f602, %f945, %f916;
	fma.rn.f32 	%f603, %f946, %f915, %f602;
	fma.rn.f32 	%f604, %f947, %f914, %f603;
	mul.f32 	%f605, %f945, %f920;
	fma.rn.f32 	%f606, %f946, %f919, %f605;
	fma.rn.f32 	%f607, %f947, %f918, %f606;
	add.f32 	%f947, %f917, %f607;
	add.f32 	%f946, %f913, %f604;
	add.f32 	%f945, %f909, %f601;

$L__BB0_21:
	// begin inline asm
	call (%f1003), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1004), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f610), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r161), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p12, %r161, 0;
	@%p12 bra 	$L__BB0_41;

	// begin inline asm
	call (%r162), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f611), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p13, %r162, 0;
	@%p13 bra 	$L__BB0_40;

	mov.u32 	%r322, 0;

$L__BB0_24:
	.pragma "nounroll";
	// begin inline asm
	call (%rd137), _optix_get_transform_list_handle, (%r322);
	// end inline asm
	// begin inline asm
	call (%r165), _optix_get_transform_type_from_handle, (%rd137);
	// end inline asm
	or.b32  	%r166, %r165, 1;
	setp.eq.s32 	%p14, %r166, 3;
	@%p14 bra 	$L__BB0_30;
	bra.uni 	$L__BB0_25;

$L__BB0_30:
	setp.eq.s32 	%p17, %r165, 2;
	@%p17 bra 	$L__BB0_34;
	bra.uni 	$L__BB0_31;

$L__BB0_34:
	// begin inline asm
	call (%rd209), _optix_get_matrix_motion_transform_from_handle, (%rd137);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd211];
	// end inline asm
	add.s64 	%rd215, %rd209, 16;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd214];
	// end inline asm
	add.s64 	%rd218, %rd209, 32;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd217];
	// end inline asm
	add.s64 	%rd221, %rd209, 48;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd220];
	// end inline asm
	add.s64 	%rd224, %rd209, 64;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd223];
	// end inline asm
	add.s64 	%rd227, %rd209, 80;
	// begin inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd226];
	// end inline asm
	add.s64 	%rd230, %rd209, 96;
	// begin inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd229];
	// end inline asm
	add.s64 	%rd233, %rd209, 112;
	// begin inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd232];
	// end inline asm
	mov.b32 	%f715, %r257;
	mov.b32 	%f716, %r258;
	and.b32  	%r298, %r256, 65535;
	add.s32 	%r299, %r298, -1;
	cvt.rn.f32.s32 	%f717, %r299;
	sub.f32 	%f718, %f611, %f715;
	mul.f32 	%f719, %f718, %f717;
	sub.f32 	%f720, %f716, %f715;
	div.rn.f32 	%f721, %f719, %f720;
	min.f32 	%f722, %f717, %f721;
	mov.f32 	%f723, 0f00000000;
	max.f32 	%f724, %f723, %f722;
	cvt.rmi.f32.f32 	%f725, %f724;
	sub.f32 	%f258, %f724, %f725;
	cvt.rzi.s32.f32 	%r300, %f725;
	cvt.s64.s32 	%rd15, %r300;
	mul.wide.s32 	%rd244, %r300, 48;
	add.s64 	%rd236, %rd218, %rd244;
	// begin inline asm
	cvta.to.global.u64 %rd235, %rd236;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd235];
	// end inline asm
	mov.b32 	%f973, %r286;
	mov.b32 	%f974, %r287;
	mov.b32 	%f975, %r288;
	add.s64 	%rd239, %rd236, 16;
	// begin inline asm
	cvta.to.global.u64 %rd238, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd238];
	// end inline asm
	mov.b32 	%f970, %r290;
	mov.b32 	%f971, %r291;
	mov.b32 	%f972, %r292;
	add.s64 	%rd242, %rd236, 32;
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd242;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r294,%r295,%r296,%r297}, [%rd241];
	// end inline asm
	mov.b32 	%f967, %r294;
	mov.b32 	%f968, %r295;
	mov.b32 	%f969, %r296;
	setp.leu.f32 	%p19, %f258, 0f00000000;
	@%p19 bra 	$L__BB0_36;

	mov.f32 	%f726, 0f3F800000;
	sub.f32 	%f727, %f726, %f258;
	mul.lo.s64 	%rd254, %rd15, 48;
	add.s64 	%rd255, %rd209, %rd254;
	add.s64 	%rd246, %rd255, 80;
	// begin inline asm
	cvta.to.global.u64 %rd245, %rd246;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd245];
	// end inline asm
	mov.b32 	%f728, %r301;
	mov.b32 	%f729, %r302;
	mov.b32 	%f730, %r303;
	mul.f32 	%f731, %f258, %f728;
	mul.f32 	%f732, %f258, %f729;
	mul.f32 	%f733, %f258, %f730;
	fma.rn.f32 	%f973, %f727, %f973, %f731;
	fma.rn.f32 	%f974, %f727, %f974, %f732;
	fma.rn.f32 	%f975, %f727, %f975, %f733;
	add.s64 	%rd249, %rd255, 96;
	// begin inline asm
	cvta.to.global.u64 %rd248, %rd249;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd248];
	// end inline asm
	mov.b32 	%f734, %r305;
	mov.b32 	%f735, %r306;
	mov.b32 	%f736, %r307;
	mul.f32 	%f737, %f258, %f734;
	mul.f32 	%f738, %f258, %f735;
	mul.f32 	%f739, %f258, %f736;
	fma.rn.f32 	%f970, %f727, %f970, %f737;
	fma.rn.f32 	%f971, %f727, %f971, %f738;
	fma.rn.f32 	%f972, %f727, %f972, %f739;
	add.s64 	%rd252, %rd255, 112;
	// begin inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r309,%r310,%r311,%r312}, [%rd251];
	// end inline asm
	mov.b32 	%f740, %r309;
	mov.b32 	%f741, %r310;
	mov.b32 	%f742, %r311;
	mul.f32 	%f743, %f258, %f740;
	mul.f32 	%f744, %f258, %f741;
	mul.f32 	%f745, %f258, %f742;
	fma.rn.f32 	%f967, %f727, %f967, %f743;
	fma.rn.f32 	%f968, %f727, %f968, %f744;
	fma.rn.f32 	%f969, %f727, %f969, %f745;
	bra.uni 	$L__BB0_36;

$L__BB0_25:
	mov.f32 	%f976, 0f00000000;
	mov.f32 	%f978, 0f3F800000;
	setp.eq.s32 	%p15, %r165, 4;
	@%p15 bra 	$L__BB0_28;

	setp.ne.s32 	%p16, %r165, 1;
	mov.f32 	%f977, %f976;
	mov.f32 	%f979, %f976;
	mov.f32 	%f980, %f978;
	mov.f32 	%f981, %f976;
	mov.f32 	%f982, %f978;
	mov.f32 	%f983, %f976;
	mov.f32 	%f984, %f976;
	@%p16 bra 	$L__BB0_37;

	// begin inline asm
	call (%rd139), _optix_get_static_transform_from_handle, (%rd137);
	// end inline asm
	add.s64 	%rd258, %rd139, 64;
	bra.uni 	$L__BB0_29;

$L__BB0_31:
	// begin inline asm
	call (%rd152), _optix_get_srt_motion_transform_from_handle, (%rd137);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd154, %rd152;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd154];
	// end inline asm
	add.s64 	%rd158, %rd152, 16;
	// begin inline asm
	cvta.to.global.u64 %rd157, %rd158;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd157];
	// end inline asm
	add.s64 	%rd161, %rd152, 32;
	// begin inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd160];
	// end inline asm
	add.s64 	%rd164, %rd152, 48;
	// begin inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd163];
	// end inline asm
	add.s64 	%rd167, %rd152, 64;
	// begin inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd166];
	// end inline asm
	add.s64 	%rd170, %rd152, 80;
	// begin inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd169];
	// end inline asm
	add.s64 	%rd173, %rd152, 96;
	// begin inline asm
	cvta.to.global.u64 %rd172, %rd173;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd172];
	// end inline asm
	add.s64 	%rd176, %rd152, 112;
	// begin inline asm
	cvta.to.global.u64 %rd175, %rd176;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd175];
	// end inline asm
	add.s64 	%rd179, %rd152, 128;
	// begin inline asm
	cvta.to.global.u64 %rd178, %rd179;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd178];
	// end inline asm
	add.s64 	%rd182, %rd152, 144;
	// begin inline asm
	cvta.to.global.u64 %rd181, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd181];
	// end inline asm
	mov.b32 	%f623, %r182;
	mov.b32 	%f624, %r183;
	and.b32  	%r235, %r181, 65535;
	add.s32 	%r236, %r235, -1;
	cvt.rn.f32.s32 	%f625, %r236;
	sub.f32 	%f626, %f611, %f623;
	mul.f32 	%f627, %f626, %f625;
	sub.f32 	%f628, %f624, %f623;
	div.rn.f32 	%f629, %f627, %f628;
	min.f32 	%f630, %f625, %f629;
	mov.f32 	%f631, 0f00000000;
	max.f32 	%f632, %f631, %f630;
	cvt.rmi.f32.f32 	%f633, %f632;
	sub.f32 	%f218, %f632, %f633;
	cvt.rzi.s32.f32 	%r237, %f633;
	mul.wide.s32 	%rd196, %r237, 64;
	add.s64 	%rd185, %rd161, %rd196;
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd185;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd184];
	// end inline asm
	mov.b32 	%f957, %r219;
	mov.b32 	%f958, %r220;
	mov.b32 	%f959, %r221;
	add.s64 	%rd188, %rd185, 16;
	// begin inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd187];
	// end inline asm
	mov.b32 	%f960, %r223;
	mov.b32 	%f961, %r224;
	mov.b32 	%f962, %r226;
	add.s64 	%rd191, %rd185, 32;
	// begin inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd190];
	// end inline asm
	mov.b32 	%f963, %r228;
	mov.b32 	%f964, %r229;
	mov.b32 	%f965, %r230;
	add.s64 	%rd194, %rd185, 48;
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r231,%r232,%r233,%r234}, [%rd193];
	// end inline asm
	mov.b32 	%f966, %r231;
	setp.leu.f32 	%p18, %f218, 0f00000000;
	@%p18 bra 	$L__BB0_33;

	mov.f32 	%f634, 0f3F800000;
	sub.f32 	%f635, %f634, %f218;
	add.s64 	%rd198, %rd185, 64;
	// begin inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd197];
	// end inline asm
	mov.b32 	%f636, %r238;
	mov.b32 	%f637, %r239;
	mov.b32 	%f638, %r240;
	mul.f32 	%f639, %f218, %f636;
	mul.f32 	%f640, %f218, %f637;
	mul.f32 	%f641, %f218, %f638;
	fma.rn.f32 	%f957, %f635, %f957, %f639;
	fma.rn.f32 	%f958, %f635, %f958, %f640;
	fma.rn.f32 	%f959, %f635, %f959, %f641;
	add.s64 	%rd201, %rd185, 80;
	// begin inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd200];
	// end inline asm
	mov.b32 	%f642, %r242;
	mov.b32 	%f643, %r243;
	mov.b32 	%f644, %r245;
	mul.f32 	%f645, %f218, %f642;
	mul.f32 	%f646, %f218, %f643;
	mul.f32 	%f647, %f218, %f644;
	fma.rn.f32 	%f960, %f635, %f960, %f645;
	fma.rn.f32 	%f961, %f635, %f961, %f646;
	fma.rn.f32 	%f962, %f635, %f962, %f647;
	add.s64 	%rd204, %rd185, 96;
	// begin inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd203];
	// end inline asm
	mov.b32 	%f648, %r247;
	mov.b32 	%f649, %r248;
	mov.b32 	%f650, %r249;
	mul.f32 	%f651, %f218, %f648;
	mul.f32 	%f652, %f218, %f649;
	mul.f32 	%f653, %f218, %f650;
	fma.rn.f32 	%f654, %f635, %f963, %f651;
	fma.rn.f32 	%f655, %f635, %f964, %f652;
	fma.rn.f32 	%f656, %f635, %f965, %f653;
	add.s64 	%rd207, %rd185, 112;
	// begin inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd206];
	// end inline asm
	mov.b32 	%f657, %r250;
	mul.f32 	%f658, %f218, %f657;
	fma.rn.f32 	%f659, %f635, %f966, %f658;
	mul.f32 	%f660, %f655, %f655;
	fma.rn.f32 	%f661, %f654, %f654, %f660;
	fma.rn.f32 	%f662, %f656, %f656, %f661;
	fma.rn.f32 	%f663, %f659, %f659, %f662;
	sqrt.rn.f32 	%f664, %f663;
	rcp.rn.f32 	%f665, %f664;
	mul.f32 	%f963, %f654, %f665;
	mul.f32 	%f964, %f655, %f665;
	mul.f32 	%f965, %f656, %f665;
	mul.f32 	%f966, %f665, %f659;

$L__BB0_33:
	mul.f32 	%f666, %f964, %f964;
	fma.rn.f32 	%f667, %f963, %f963, %f666;
	fma.rn.f32 	%f668, %f965, %f965, %f667;
	fma.rn.f32 	%f669, %f966, %f966, %f668;
	rcp.rn.f32 	%f670, %f669;
	mul.f32 	%f671, %f963, %f670;
	mul.f32 	%f672, %f964, %f670;
	mul.f32 	%f673, %f965, %f670;
	mul.f32 	%f674, %f966, %f670;
	mul.f32 	%f675, %f963, %f671;
	mul.f32 	%f676, %f964, %f672;
	mul.f32 	%f677, %f965, %f673;
	mul.f32 	%f678, %f963, %f672;
	mul.f32 	%f679, %f965, %f674;
	mul.f32 	%f680, %f963, %f673;
	mul.f32 	%f681, %f964, %f674;
	mul.f32 	%f682, %f964, %f673;
	mul.f32 	%f683, %f963, %f674;
	sub.f32 	%f684, %f675, %f676;
	sub.f32 	%f685, %f684, %f677;
	fma.rn.f32 	%f686, %f966, %f674, %f685;
	sub.f32 	%f687, %f678, %f679;
	add.f32 	%f688, %f687, %f687;
	add.f32 	%f689, %f680, %f681;
	add.f32 	%f690, %f689, %f689;
	add.f32 	%f691, %f678, %f679;
	add.f32 	%f692, %f691, %f691;
	sub.f32 	%f693, %f676, %f675;
	sub.f32 	%f694, %f693, %f677;
	fma.rn.f32 	%f695, %f966, %f674, %f694;
	sub.f32 	%f696, %f682, %f683;
	add.f32 	%f697, %f696, %f696;
	sub.f32 	%f698, %f680, %f681;
	add.f32 	%f699, %f698, %f698;
	add.f32 	%f700, %f682, %f683;
	add.f32 	%f701, %f700, %f700;
	neg.f32 	%f702, %f675;
	sub.f32 	%f703, %f702, %f676;
	add.f32 	%f704, %f677, %f703;
	fma.rn.f32 	%f705, %f966, %f674, %f704;
	mul.f32 	%f706, %f959, %f686;
	fma.rn.f32 	%f707, %f961, %f688, %f706;
	fma.rn.f32 	%f975, %f962, %f690, %f707;
	mul.f32 	%f708, %f961, %f695;
	fma.rn.f32 	%f709, %f959, %f692, %f708;
	fma.rn.f32 	%f972, %f962, %f697, %f709;
	mul.f32 	%f710, %f961, %f701;
	fma.rn.f32 	%f711, %f959, %f699, %f710;
	fma.rn.f32 	%f969, %f962, %f705, %f711;
	mul.f32 	%f712, %f958, %f686;
	fma.rn.f32 	%f974, %f960, %f688, %f712;
	mul.f32 	%f713, %f960, %f695;
	fma.rn.f32 	%f971, %f958, %f692, %f713;
	mul.f32 	%f714, %f960, %f701;
	fma.rn.f32 	%f968, %f958, %f699, %f714;
	mul.f32 	%f973, %f957, %f686;
	mul.f32 	%f970, %f957, %f692;
	mul.f32 	%f967, %f957, %f699;

$L__BB0_36:
	mul.f32 	%f746, %f968, %f972;
	mul.f32 	%f747, %f969, %f971;
	sub.f32 	%f748, %f747, %f746;
	mul.f32 	%f749, %f973, %f748;
	mul.f32 	%f750, %f967, %f972;
	mul.f32 	%f751, %f969, %f970;
	sub.f32 	%f752, %f751, %f750;
	mul.f32 	%f753, %f752, %f974;
	sub.f32 	%f754, %f749, %f753;
	mul.f32 	%f755, %f967, %f971;
	mul.f32 	%f756, %f968, %f970;
	sub.f32 	%f757, %f756, %f755;
	fma.rn.f32 	%f758, %f757, %f975, %f754;
	rcp.rn.f32 	%f759, %f758;
	mul.f32 	%f982, %f748, %f759;
	mul.f32 	%f760, %f969, %f974;
	mul.f32 	%f761, %f968, %f975;
	sub.f32 	%f762, %f761, %f760;
	mul.f32 	%f983, %f762, %f759;
	mul.f32 	%f763, %f971, %f975;
	mul.f32 	%f764, %f972, %f974;
	sub.f32 	%f765, %f764, %f763;
	mul.f32 	%f984, %f765, %f759;
	sub.f32 	%f766, %f750, %f751;
	mul.f32 	%f979, %f766, %f759;
	mul.f32 	%f767, %f967, %f975;
	mul.f32 	%f768, %f969, %f973;
	sub.f32 	%f769, %f768, %f767;
	mul.f32 	%f980, %f769, %f759;
	mul.f32 	%f770, %f972, %f973;
	mul.f32 	%f771, %f970, %f975;
	sub.f32 	%f772, %f771, %f770;
	mul.f32 	%f981, %f772, %f759;
	mul.f32 	%f976, %f757, %f759;
	mul.f32 	%f773, %f968, %f973;
	mul.f32 	%f774, %f967, %f974;
	sub.f32 	%f775, %f774, %f773;
	mul.f32 	%f977, %f775, %f759;
	mul.f32 	%f776, %f970, %f974;
	mul.f32 	%f777, %f971, %f973;
	sub.f32 	%f778, %f777, %f776;
	mul.f32 	%f978, %f778, %f759;
	bra.uni 	$L__BB0_37;

$L__BB0_28:
	// begin inline asm
	call (%rd258), _optix_get_instance_inverse_transform_from_handle, (%rd137);
	// end inline asm

$L__BB0_29:
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd258;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd143];
	// end inline asm
	mov.b32 	%f982, %r167;
	mov.b32 	%f983, %r168;
	mov.b32 	%f984, %r169;
	add.s64 	%rd147, %rd258, 16;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd146];
	// end inline asm
	mov.b32 	%f979, %r171;
	mov.b32 	%f980, %r172;
	mov.b32 	%f981, %r173;
	add.s64 	%rd150, %rd258, 32;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd149];
	// end inline asm
	mov.b32 	%f976, %r175;
	mov.b32 	%f977, %r176;
	mov.b32 	%f978, %r177;

$L__BB0_37:
	setp.eq.s32 	%p20, %r322, 0;
	@%p20 bra 	$L__BB0_39;

	mul.f32 	%f779, %f953, %f983;
	fma.rn.f32 	%f780, %f950, %f982, %f779;
	fma.rn.f32 	%f304, %f956, %f984, %f780;
	mul.f32 	%f781, %f952, %f983;
	fma.rn.f32 	%f782, %f949, %f982, %f781;
	fma.rn.f32 	%f305, %f955, %f984, %f782;
	mul.f32 	%f783, %f951, %f983;
	fma.rn.f32 	%f784, %f948, %f982, %f783;
	fma.rn.f32 	%f984, %f954, %f984, %f784;
	mul.f32 	%f785, %f953, %f980;
	fma.rn.f32 	%f786, %f950, %f979, %f785;
	fma.rn.f32 	%f307, %f956, %f981, %f786;
	mul.f32 	%f787, %f952, %f980;
	fma.rn.f32 	%f788, %f949, %f979, %f787;
	fma.rn.f32 	%f308, %f955, %f981, %f788;
	mul.f32 	%f789, %f951, %f980;
	fma.rn.f32 	%f790, %f948, %f979, %f789;
	fma.rn.f32 	%f981, %f954, %f981, %f790;
	mul.f32 	%f791, %f953, %f977;
	fma.rn.f32 	%f792, %f950, %f976, %f791;
	fma.rn.f32 	%f310, %f956, %f978, %f792;
	mul.f32 	%f793, %f952, %f977;
	fma.rn.f32 	%f794, %f949, %f976, %f793;
	fma.rn.f32 	%f311, %f955, %f978, %f794;
	mul.f32 	%f795, %f951, %f977;
	fma.rn.f32 	%f796, %f948, %f976, %f795;
	fma.rn.f32 	%f978, %f954, %f978, %f796;
	mov.f32 	%f976, %f310;
	mov.f32 	%f977, %f311;
	mov.f32 	%f979, %f307;
	mov.f32 	%f980, %f308;
	mov.f32 	%f982, %f304;
	mov.f32 	%f983, %f305;

$L__BB0_39:
	add.s32 	%r322, %r322, 1;
	setp.lt.u32 	%p21, %r322, %r162;
	mov.f32 	%f948, %f984;
	mov.f32 	%f949, %f983;
	mov.f32 	%f950, %f982;
	mov.f32 	%f951, %f981;
	mov.f32 	%f952, %f980;
	mov.f32 	%f953, %f979;
	mov.f32 	%f954, %f978;
	mov.f32 	%f955, %f977;
	mov.f32 	%f956, %f976;
	@%p21 bra 	$L__BB0_24;

$L__BB0_40:
	mul.f32 	%f797, %f1004, %f983;
	fma.rn.f32 	%f798, %f1003, %f982, %f797;
	mul.f32 	%f799, %f1004, %f980;
	fma.rn.f32 	%f800, %f1003, %f979, %f799;
	mul.f32 	%f801, %f1004, %f977;
	fma.rn.f32 	%f802, %f1003, %f976, %f801;
	fma.rn.f32 	%f1005, %f610, %f978, %f802;
	fma.rn.f32 	%f1004, %f610, %f981, %f800;
	fma.rn.f32 	%f1003, %f610, %f984, %f798;
	bra.uni 	$L__BB0_42;

$L__BB0_41:
	mov.f32 	%f1005, %f610;

$L__BB0_42:
	// begin inline asm
	call (%f803), _optix_get_ray_tmin, ();
	// end inline asm
	// begin inline asm
	call (%f804), _optix_get_ray_tmax, ();
	// end inline asm
	add.s64 	%rd16, %rd1, 208;
	ld.v4.f32 	{%f807, %f808, %f809, %f810}, [%rd1+208];
	ld.f32 	%f814, [%rd1+160];
	fma.rn.f32 	%f815, %f945, %f814, %f807;
	ld.f32 	%f816, [%rd1+164];
	fma.rn.f32 	%f817, %f945, %f816, %f808;
	ld.f32 	%f818, [%rd1+168];
	fma.rn.f32 	%f819, %f945, %f818, %f809;
	ld.f32 	%f820, [%rd1+176];
	fma.rn.f32 	%f821, %f946, %f820, %f815;
	ld.f32 	%f822, [%rd1+180];
	fma.rn.f32 	%f823, %f946, %f822, %f817;
	ld.f32 	%f824, [%rd1+184];
	fma.rn.f32 	%f825, %f946, %f824, %f819;
	ld.f32 	%f826, [%rd1+192];
	fma.rn.f32 	%f827, %f947, %f826, %f821;
	ld.f32 	%f828, [%rd1+196];
	fma.rn.f32 	%f829, %f947, %f828, %f823;
	ld.f32 	%f830, [%rd1+200];
	fma.rn.f32 	%f342, %f947, %f830, %f825;
	ld.v4.f32 	{%f831, %f832, %f833, %f834}, [%rd1+160];
	mul.f32 	%f838, %f1003, %f831;
	mul.f32 	%f839, %f1003, %f832;
	mul.f32 	%f840, %f1003, %f833;
	fma.rn.f32 	%f841, %f1004, %f820, %f838;
	fma.rn.f32 	%f842, %f1004, %f822, %f839;
	fma.rn.f32 	%f843, %f1004, %f824, %f840;
	fma.rn.f32 	%f844, %f1005, %f826, %f841;
	fma.rn.f32 	%f845, %f1005, %f828, %f842;
	fma.rn.f32 	%f343, %f1005, %f830, %f843;
	mul.f32 	%f846, %f845, %f845;
	fma.rn.f32 	%f344, %f844, %f844, %f846;
	mul.f32 	%f847, %f829, %f845;
	fma.rn.f32 	%f848, %f827, %f844, %f847;
	add.f32 	%f345, %f848, %f848;
	mul.f32 	%f849, %f829, %f829;
	fma.rn.f32 	%f850, %f827, %f827, %f849;
	ld.f32 	%f851, [%rd1+292];
	mul.f32 	%f852, %f851, %f851;
	sub.f32 	%f346, %f850, %f852;
	setp.eq.f32 	%p23, %f344, 0f00000000;
	setp.eq.f32 	%p24, %f345, 0f00000000;
	and.pred  	%p25, %p23, %p24;
	mov.pred 	%p53, 0;
	@%p25 bra 	$L__BB0_45;

	neg.f32 	%f853, %f346;
	div.rn.f32 	%f1006, %f853, %f345;
	mul.f32 	%f854, %f344, 0fC0800000;
	mul.f32 	%f855, %f854, %f346;
	fma.rn.f32 	%f348, %f345, %f345, %f855;
	setp.neu.f32 	%p27, %f344, 0f00000000;
	setp.lt.f32 	%p28, %f348, 0f00000000;
	and.pred  	%p29, %p28, %p27;
	mov.f32 	%f1007, %f1006;
	@%p29 bra 	$L__BB0_45;

	mov.b32 	%r313, %f345;
	and.b32  	%r314, %r313, -2147483648;
	sqrt.rn.f32 	%f856, %f348;
	mov.b32 	%r315, %f856;
	and.b32  	%r316, %r315, 2147483647;
	or.b32  	%r317, %r316, %r314;
	mov.b32 	%f857, %r317;
	add.f32 	%f858, %f345, %f857;
	mul.f32 	%f859, %f858, 0fBF000000;
	div.rn.f32 	%f860, %f859, %f344;
	div.rn.f32 	%f861, %f346, %f859;
	min.f32 	%f862, %f860, %f861;
	max.f32 	%f863, %f860, %f861;
	selp.f32 	%f349, %f1006, %f862, %p23;
	selp.f32 	%f1007, %f1006, %f863, %p23;
	mov.pred 	%p53, -1;
	mov.f32 	%f1006, %f349;

$L__BB0_45:
	fma.rn.f32 	%f353, %f343, %f1006, %f342;
	fma.rn.f32 	%f354, %f343, %f1007, %f342;
	setp.ge.f32 	%p32, %f1007, %f803;
	setp.le.f32 	%p33, %f1006, %f804;
	and.pred  	%p34, %p33, %p32;
	and.pred  	%p35, %p53, %p34;
	setp.leu.f32 	%p36, %f1007, %f804;
	setp.geu.f32 	%p37, %f1006, %f803;
	or.pred  	%p38, %p37, %p36;
	and.pred  	%p39, %p35, %p38;
	mov.u16 	%rs3, 0;
	not.pred 	%p40, %p39;
	mov.u16 	%rs7, %rs3;
	@%p40 bra 	$L__BB0_51;

	setp.ltu.f32 	%p41, %f353, 0f00000000;
	@%p41 bra 	$L__BB0_48;

	ld.f32 	%f864, [%rd16+80];
	setp.le.f32 	%p42, %f353, %f864;
	setp.ge.f32 	%p43, %f1006, %f803;
	mov.u16 	%rs7, 1;
	and.pred  	%p44, %p42, %p43;
	@%p44 bra 	$L__BB0_51;

$L__BB0_48:
	setp.ltu.f32 	%p45, %f354, 0f00000000;
	mov.u16 	%rs7, %rs3;
	@%p45 bra 	$L__BB0_51;

	ld.f32 	%f865, [%rd16+80];
	setp.gtu.f32 	%p46, %f354, %f865;
	mov.u16 	%rs7, %rs3;
	@%p46 bra 	$L__BB0_51;

	setp.le.f32 	%p47, %f1007, %f804;
	selp.u16 	%rs7, 1, 0, %p47;

$L__BB0_51:
	setp.ltu.f32 	%p48, %f353, 0f00000000;
	@%p48 bra 	$L__BB0_53;

	ld.f32 	%f866, [%rd16+80];
	setp.le.f32 	%p49, %f353, %f866;
	setp.ge.f32 	%p50, %f1006, %f803;
	and.pred  	%p51, %p49, %p50;
	@%p51 bra 	$L__BB0_54;

$L__BB0_53:
	mov.f32 	%f1006, %f1007;

$L__BB0_54:
	setp.eq.s16 	%p52, %rs7, 0;
	@%p52 bra 	$L__BB0_56;

	mov.u32 	%r319, 254;
	// begin inline asm
	call (%r318), _optix_report_intersection_0, (%f1006, %r319);
	// end inline asm

$L__BB0_56:
	ret;

}
	// .globl	__closesthit__cylinder
.visible .entry __closesthit__cylinder()
{
	.reg .pred 	%p<69>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<2103>;
	.reg .b32 	%r<660>;
	.reg .b64 	%rd<652>;


	// begin inline asm
	call (%r27), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r28), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r30), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r31), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r32), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r33, %r32, %r28, %r31;
	mad.lo.s32 	%r1, %r33, %r27, %r30;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64 	%p1, %rd1, 0;
	@%p1 bra 	$L__BB1_2;

	cvta.to.global.u64 	%rd44, %rd1;
	cvt.u64.u32 	%rd45, %r1;
	add.s64 	%rd46, %rd44, %rd45;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd46], %rs1;
	bra.uni 	$L__BB1_113;

$L__BB1_2:
	// begin inline asm
	call (%rd47), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd3, [%rd47+8];
	// begin inline asm
	call (%f1883), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1884), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1885), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r34), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p2, %r34, 0;
	@%p2 bra 	$L__BB1_22;

	// begin inline asm
	call (%r35), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f724), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p3, %r35, 0;
	@%p3 bra 	$L__BB1_21;

	mov.u32 	%r655, 0;

$L__BB1_5:
	.pragma "nounroll";
	// begin inline asm
	call (%rd48), _optix_get_transform_list_handle, (%r655);
	// end inline asm
	// begin inline asm
	call (%r38), _optix_get_transform_type_from_handle, (%rd48);
	// end inline asm
	or.b32  	%r39, %r38, 1;
	setp.eq.s32 	%p4, %r39, 3;
	@%p4 bra 	$L__BB1_11;
	bra.uni 	$L__BB1_6;

$L__BB1_11:
	setp.eq.s32 	%p7, %r38, 2;
	@%p7 bra 	$L__BB1_15;
	bra.uni 	$L__BB1_12;

$L__BB1_15:
	// begin inline asm
	call (%rd120), _optix_get_matrix_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r127,%r128,%r129,%r130}, [%rd122];
	// end inline asm
	add.s64 	%rd126, %rd120, 16;
	// begin inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r131,%r132,%r133,%r134}, [%rd125];
	// end inline asm
	add.s64 	%rd129, %rd120, 32;
	// begin inline asm
	cvta.to.global.u64 %rd128, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r135,%r136,%r137,%r138}, [%rd128];
	// end inline asm
	add.s64 	%rd132, %rd120, 48;
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r139,%r140,%r141,%r142}, [%rd131];
	// end inline asm
	add.s64 	%rd135, %rd120, 64;
	// begin inline asm
	cvta.to.global.u64 %rd134, %rd135;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r143,%r144,%r145,%r146}, [%rd134];
	// end inline asm
	add.s64 	%rd138, %rd120, 80;
	// begin inline asm
	cvta.to.global.u64 %rd137, %rd138;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd137];
	// end inline asm
	add.s64 	%rd141, %rd120, 96;
	// begin inline asm
	cvta.to.global.u64 %rd140, %rd141;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd140];
	// end inline asm
	add.s64 	%rd144, %rd120, 112;
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd144;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd143];
	// end inline asm
	mov.b32 	%f852, %r130;
	mov.b32 	%f853, %r131;
	and.b32  	%r171, %r129, 65535;
	add.s32 	%r172, %r171, -1;
	cvt.rn.f32.s32 	%f854, %r172;
	sub.f32 	%f855, %f724, %f852;
	mul.f32 	%f856, %f855, %f854;
	sub.f32 	%f857, %f853, %f852;
	div.rn.f32 	%f858, %f856, %f857;
	min.f32 	%f859, %f854, %f858;
	mov.f32 	%f860, 0f00000000;
	max.f32 	%f861, %f860, %f859;
	cvt.rmi.f32.f32 	%f862, %f861;
	sub.f32 	%f90, %f861, %f862;
	cvt.rzi.s32.f32 	%r173, %f862;
	mul.wide.s32 	%rd155, %r173, 48;
	add.s64 	%rd147, %rd129, %rd155;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r159,%r160,%r161,%r162}, [%rd146];
	// end inline asm
	mov.b32 	%f1838, %r159;
	mov.b32 	%f1837, %r160;
	mov.b32 	%f1836, %r161;
	mov.b32 	%f1835, %r162;
	add.s64 	%rd150, %rd147, 16;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd149];
	// end inline asm
	mov.b32 	%f1842, %r163;
	mov.b32 	%f1841, %r164;
	mov.b32 	%f1840, %r165;
	mov.b32 	%f1839, %r166;
	add.s64 	%rd153, %rd147, 32;
	// begin inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd152];
	// end inline asm
	mov.b32 	%f1846, %r167;
	mov.b32 	%f1845, %r168;
	mov.b32 	%f1844, %r169;
	mov.b32 	%f1843, %r170;
	setp.leu.f32 	%p9, %f90, 0f00000000;
	@%p9 bra 	$L__BB1_17;

	cvt.rmi.f32.f32 	%f1806, %f861;
	cvt.rzi.s32.f32 	%r654, %f1806;
	cvt.s64.s32 	%rd647, %r654;
	mov.f32 	%f863, 0f3F800000;
	sub.f32 	%f864, %f863, %f90;
	mul.lo.s64 	%rd165, %rd647, 48;
	add.s64 	%rd166, %rd120, %rd165;
	add.s64 	%rd157, %rd166, 80;
	// begin inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r174,%r175,%r176,%r177}, [%rd156];
	// end inline asm
	mov.b32 	%f865, %r174;
	mov.b32 	%f866, %r175;
	mov.b32 	%f867, %r176;
	mov.b32 	%f868, %r177;
	mul.f32 	%f869, %f90, %f865;
	mul.f32 	%f870, %f90, %f866;
	mul.f32 	%f871, %f90, %f867;
	mul.f32 	%f872, %f90, %f868;
	fma.rn.f32 	%f1838, %f864, %f1838, %f869;
	fma.rn.f32 	%f1837, %f864, %f1837, %f870;
	fma.rn.f32 	%f1836, %f864, %f1836, %f871;
	fma.rn.f32 	%f1835, %f864, %f1835, %f872;
	add.s64 	%rd160, %rd166, 96;
	// begin inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r178,%r179,%r180,%r181}, [%rd159];
	// end inline asm
	mov.b32 	%f873, %r178;
	mov.b32 	%f874, %r179;
	mov.b32 	%f875, %r180;
	mov.b32 	%f876, %r181;
	mul.f32 	%f877, %f90, %f873;
	mul.f32 	%f878, %f90, %f874;
	mul.f32 	%f879, %f90, %f875;
	mul.f32 	%f880, %f90, %f876;
	fma.rn.f32 	%f1842, %f864, %f1842, %f877;
	fma.rn.f32 	%f1841, %f864, %f1841, %f878;
	fma.rn.f32 	%f1840, %f864, %f1840, %f879;
	fma.rn.f32 	%f1839, %f864, %f1839, %f880;
	add.s64 	%rd163, %rd166, 112;
	// begin inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r182,%r183,%r184,%r185}, [%rd162];
	// end inline asm
	mov.b32 	%f881, %r182;
	mov.b32 	%f882, %r183;
	mov.b32 	%f883, %r184;
	mov.b32 	%f884, %r185;
	mul.f32 	%f885, %f90, %f881;
	mul.f32 	%f886, %f90, %f882;
	mul.f32 	%f887, %f90, %f883;
	mul.f32 	%f888, %f90, %f884;
	fma.rn.f32 	%f1846, %f864, %f1846, %f885;
	fma.rn.f32 	%f1845, %f864, %f1845, %f886;
	fma.rn.f32 	%f1844, %f864, %f1844, %f887;
	fma.rn.f32 	%f1843, %f864, %f1843, %f888;
	bra.uni 	$L__BB1_17;

$L__BB1_6:
	mov.f32 	%f1847, 0f00000000;
	mov.f32 	%f1850, 0f3F800000;
	setp.eq.s32 	%p5, %r38, 4;
	@%p5 bra 	$L__BB1_9;

	setp.ne.s32 	%p6, %r38, 1;
	mov.f32 	%f1848, %f1847;
	mov.f32 	%f1849, %f1847;
	mov.f32 	%f1851, %f1847;
	mov.f32 	%f1852, %f1847;
	mov.f32 	%f1853, %f1850;
	mov.f32 	%f1854, %f1847;
	mov.f32 	%f1855, %f1847;
	mov.f32 	%f1856, %f1850;
	mov.f32 	%f1857, %f1847;
	mov.f32 	%f1858, %f1847;
	@%p6 bra 	$L__BB1_18;

	// begin inline asm
	call (%rd50), _optix_get_static_transform_from_handle, (%rd48);
	// end inline asm
	add.s64 	%rd648, %rd50, 64;
	bra.uni 	$L__BB1_10;

$L__BB1_12:
	// begin inline asm
	call (%rd63), _optix_get_srt_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r52,%r53,%r54,%r55}, [%rd65];
	// end inline asm
	add.s64 	%rd69, %rd63, 16;
	// begin inline asm
	cvta.to.global.u64 %rd68, %rd69;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r56,%r57,%r58,%r59}, [%rd68];
	// end inline asm
	add.s64 	%rd72, %rd63, 32;
	// begin inline asm
	cvta.to.global.u64 %rd71, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r60,%r61,%r62,%r63}, [%rd71];
	// end inline asm
	add.s64 	%rd75, %rd63, 48;
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd75;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r64,%r65,%r66,%r67}, [%rd74];
	// end inline asm
	add.s64 	%rd78, %rd63, 64;
	// begin inline asm
	cvta.to.global.u64 %rd77, %rd78;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r68,%r69,%r70,%r71}, [%rd77];
	// end inline asm
	add.s64 	%rd81, %rd63, 80;
	// begin inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r72,%r73,%r74,%r75}, [%rd80];
	// end inline asm
	add.s64 	%rd84, %rd63, 96;
	// begin inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r76,%r77,%r78,%r79}, [%rd83];
	// end inline asm
	add.s64 	%rd87, %rd63, 112;
	// begin inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r80,%r81,%r82,%r83}, [%rd86];
	// end inline asm
	add.s64 	%rd90, %rd63, 128;
	// begin inline asm
	cvta.to.global.u64 %rd89, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd89];
	// end inline asm
	add.s64 	%rd93, %rd63, 144;
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd93;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd92];
	// end inline asm
	mov.b32 	%f739, %r55;
	mov.b32 	%f740, %r56;
	and.b32  	%r108, %r54, 65535;
	add.s32 	%r109, %r108, -1;
	cvt.rn.f32.s32 	%f741, %r109;
	sub.f32 	%f742, %f724, %f739;
	mul.f32 	%f743, %f742, %f741;
	sub.f32 	%f744, %f740, %f739;
	div.rn.f32 	%f745, %f743, %f744;
	min.f32 	%f746, %f741, %f745;
	mov.f32 	%f747, 0f00000000;
	max.f32 	%f748, %f747, %f746;
	cvt.rmi.f32.f32 	%f749, %f748;
	sub.f32 	%f29, %f748, %f749;
	cvt.rzi.s32.f32 	%r110, %f749;
	mul.wide.s32 	%rd107, %r110, 64;
	add.s64 	%rd96, %rd72, %rd107;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd95];
	// end inline asm
	mov.b32 	%f1819, %r92;
	mov.b32 	%f1820, %r93;
	mov.b32 	%f1821, %r94;
	mov.b32 	%f1822, %r95;
	add.s64 	%rd99, %rd96, 16;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd98];
	// end inline asm
	mov.b32 	%f1823, %r96;
	mov.b32 	%f1824, %r97;
	mov.b32 	%f1825, %r98;
	mov.b32 	%f1826, %r99;
	add.s64 	%rd102, %rd96, 32;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd101];
	// end inline asm
	mov.b32 	%f1827, %r100;
	mov.b32 	%f1828, %r101;
	mov.b32 	%f1829, %r102;
	mov.b32 	%f1830, %r103;
	add.s64 	%rd105, %rd96, 48;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd104];
	// end inline asm
	mov.b32 	%f1831, %r104;
	mov.b32 	%f1832, %r105;
	mov.b32 	%f1833, %r106;
	mov.b32 	%f1834, %r107;
	setp.leu.f32 	%p8, %f29, 0f00000000;
	@%p8 bra 	$L__BB1_14;

	mov.f32 	%f750, 0f3F800000;
	sub.f32 	%f751, %f750, %f29;
	add.s64 	%rd109, %rd96, 64;
	// begin inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r111,%r112,%r113,%r114}, [%rd108];
	// end inline asm
	mov.b32 	%f752, %r111;
	mov.b32 	%f753, %r112;
	mov.b32 	%f754, %r113;
	mov.b32 	%f755, %r114;
	mul.f32 	%f756, %f29, %f752;
	mul.f32 	%f757, %f29, %f753;
	mul.f32 	%f758, %f29, %f754;
	mul.f32 	%f759, %f29, %f755;
	fma.rn.f32 	%f1819, %f751, %f1819, %f756;
	fma.rn.f32 	%f1820, %f751, %f1820, %f757;
	fma.rn.f32 	%f1821, %f751, %f1821, %f758;
	fma.rn.f32 	%f1822, %f751, %f1822, %f759;
	add.s64 	%rd112, %rd96, 80;
	// begin inline asm
	cvta.to.global.u64 %rd111, %rd112;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r115,%r116,%r117,%r118}, [%rd111];
	// end inline asm
	mov.b32 	%f760, %r115;
	mov.b32 	%f761, %r116;
	mov.b32 	%f762, %r117;
	mov.b32 	%f763, %r118;
	mul.f32 	%f764, %f29, %f760;
	mul.f32 	%f765, %f29, %f761;
	mul.f32 	%f766, %f29, %f762;
	mul.f32 	%f767, %f29, %f763;
	fma.rn.f32 	%f1823, %f751, %f1823, %f764;
	fma.rn.f32 	%f1824, %f751, %f1824, %f765;
	fma.rn.f32 	%f1825, %f751, %f1825, %f766;
	fma.rn.f32 	%f1826, %f751, %f1826, %f767;
	add.s64 	%rd115, %rd96, 96;
	// begin inline asm
	cvta.to.global.u64 %rd114, %rd115;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r119,%r120,%r121,%r122}, [%rd114];
	// end inline asm
	mov.b32 	%f768, %r119;
	mov.b32 	%f769, %r120;
	mov.b32 	%f770, %r121;
	mov.b32 	%f771, %r122;
	mul.f32 	%f772, %f29, %f768;
	mul.f32 	%f773, %f29, %f769;
	mul.f32 	%f774, %f29, %f770;
	mul.f32 	%f775, %f29, %f771;
	fma.rn.f32 	%f1827, %f751, %f1827, %f772;
	fma.rn.f32 	%f776, %f751, %f1828, %f773;
	fma.rn.f32 	%f777, %f751, %f1829, %f774;
	fma.rn.f32 	%f778, %f751, %f1830, %f775;
	add.s64 	%rd118, %rd96, 112;
	// begin inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r123,%r124,%r125,%r126}, [%rd117];
	// end inline asm
	mov.b32 	%f779, %r123;
	mov.b32 	%f780, %r124;
	mov.b32 	%f781, %r125;
	mov.b32 	%f782, %r126;
	mul.f32 	%f783, %f29, %f779;
	mul.f32 	%f784, %f29, %f780;
	mul.f32 	%f785, %f29, %f781;
	mul.f32 	%f786, %f29, %f782;
	fma.rn.f32 	%f787, %f751, %f1831, %f783;
	fma.rn.f32 	%f1832, %f751, %f1832, %f784;
	fma.rn.f32 	%f1833, %f751, %f1833, %f785;
	fma.rn.f32 	%f1834, %f751, %f1834, %f786;
	mul.f32 	%f788, %f777, %f777;
	fma.rn.f32 	%f789, %f776, %f776, %f788;
	fma.rn.f32 	%f790, %f778, %f778, %f789;
	fma.rn.f32 	%f791, %f787, %f787, %f790;
	sqrt.rn.f32 	%f792, %f791;
	rcp.rn.f32 	%f793, %f792;
	mul.f32 	%f1828, %f776, %f793;
	mul.f32 	%f1829, %f777, %f793;
	mul.f32 	%f1830, %f778, %f793;
	mul.f32 	%f1831, %f793, %f787;

$L__BB1_14:
	mul.f32 	%f794, %f1829, %f1829;
	fma.rn.f32 	%f795, %f1828, %f1828, %f794;
	fma.rn.f32 	%f796, %f1830, %f1830, %f795;
	fma.rn.f32 	%f797, %f1831, %f1831, %f796;
	rcp.rn.f32 	%f798, %f797;
	mul.f32 	%f799, %f1828, %f798;
	mul.f32 	%f800, %f1829, %f798;
	mul.f32 	%f801, %f1830, %f798;
	mul.f32 	%f802, %f1831, %f798;
	mul.f32 	%f803, %f1828, %f799;
	mul.f32 	%f804, %f1829, %f800;
	mul.f32 	%f805, %f1830, %f801;
	mul.f32 	%f806, %f1828, %f800;
	mul.f32 	%f807, %f1830, %f802;
	mul.f32 	%f808, %f1828, %f801;
	mul.f32 	%f809, %f1829, %f802;
	mul.f32 	%f810, %f1829, %f801;
	mul.f32 	%f811, %f1828, %f802;
	sub.f32 	%f812, %f803, %f804;
	sub.f32 	%f813, %f812, %f805;
	fma.rn.f32 	%f814, %f1831, %f802, %f813;
	sub.f32 	%f815, %f806, %f807;
	add.f32 	%f816, %f815, %f815;
	add.f32 	%f817, %f808, %f809;
	add.f32 	%f818, %f817, %f817;
	add.f32 	%f819, %f806, %f807;
	add.f32 	%f820, %f819, %f819;
	sub.f32 	%f821, %f804, %f803;
	sub.f32 	%f822, %f821, %f805;
	fma.rn.f32 	%f823, %f1831, %f802, %f822;
	sub.f32 	%f824, %f810, %f811;
	add.f32 	%f825, %f824, %f824;
	sub.f32 	%f826, %f808, %f809;
	add.f32 	%f827, %f826, %f826;
	add.f32 	%f828, %f810, %f811;
	add.f32 	%f829, %f828, %f828;
	neg.f32 	%f830, %f803;
	sub.f32 	%f831, %f830, %f804;
	add.f32 	%f832, %f805, %f831;
	fma.rn.f32 	%f833, %f1831, %f802, %f832;
	mul.f32 	%f834, %f1822, %f814;
	fma.rn.f32 	%f835, %f1825, %f816, %f834;
	fma.rn.f32 	%f836, %f1827, %f818, %f835;
	sub.f32 	%f1835, %f1832, %f836;
	mul.f32 	%f837, %f1825, %f823;
	fma.rn.f32 	%f838, %f1822, %f820, %f837;
	fma.rn.f32 	%f839, %f1827, %f825, %f838;
	sub.f32 	%f1839, %f1833, %f839;
	mul.f32 	%f840, %f1825, %f829;
	fma.rn.f32 	%f841, %f1822, %f827, %f840;
	fma.rn.f32 	%f842, %f1827, %f833, %f841;
	sub.f32 	%f1843, %f1834, %f842;
	mul.f32 	%f843, %f1821, %f814;
	fma.rn.f32 	%f844, %f1824, %f816, %f843;
	fma.rn.f32 	%f1836, %f1826, %f818, %f844;
	mul.f32 	%f845, %f1824, %f823;
	fma.rn.f32 	%f846, %f1821, %f820, %f845;
	fma.rn.f32 	%f1840, %f1826, %f825, %f846;
	mul.f32 	%f847, %f1824, %f829;
	fma.rn.f32 	%f848, %f1821, %f827, %f847;
	fma.rn.f32 	%f1844, %f1826, %f833, %f848;
	mul.f32 	%f849, %f1820, %f814;
	fma.rn.f32 	%f1837, %f1823, %f816, %f849;
	mul.f32 	%f850, %f1823, %f823;
	fma.rn.f32 	%f1841, %f1820, %f820, %f850;
	mul.f32 	%f851, %f1823, %f829;
	fma.rn.f32 	%f1845, %f1820, %f827, %f851;
	mul.f32 	%f1838, %f1819, %f814;
	mul.f32 	%f1842, %f1819, %f820;
	mul.f32 	%f1846, %f1819, %f827;

$L__BB1_17:
	mul.f32 	%f889, %f1840, %f1845;
	mul.f32 	%f890, %f1841, %f1844;
	sub.f32 	%f891, %f890, %f889;
	mul.f32 	%f892, %f1838, %f891;
	mul.f32 	%f893, %f1840, %f1846;
	mul.f32 	%f894, %f1842, %f1844;
	sub.f32 	%f895, %f894, %f893;
	mul.f32 	%f896, %f1837, %f895;
	sub.f32 	%f897, %f892, %f896;
	mul.f32 	%f898, %f1841, %f1846;
	mul.f32 	%f899, %f1842, %f1845;
	sub.f32 	%f900, %f899, %f898;
	fma.rn.f32 	%f901, %f1836, %f900, %f897;
	rcp.rn.f32 	%f902, %f901;
	mul.f32 	%f1850, %f891, %f902;
	mul.f32 	%f903, %f1837, %f1844;
	mul.f32 	%f904, %f1836, %f1845;
	sub.f32 	%f905, %f904, %f903;
	mul.f32 	%f1849, %f905, %f902;
	mul.f32 	%f906, %f1836, %f1841;
	mul.f32 	%f907, %f1837, %f1840;
	sub.f32 	%f908, %f907, %f906;
	mul.f32 	%f1848, %f908, %f902;
	sub.f32 	%f909, %f893, %f894;
	mul.f32 	%f1854, %f909, %f902;
	mul.f32 	%f910, %f1836, %f1846;
	mul.f32 	%f911, %f1838, %f1844;
	sub.f32 	%f912, %f911, %f910;
	mul.f32 	%f1853, %f912, %f902;
	mul.f32 	%f913, %f1838, %f1840;
	mul.f32 	%f914, %f1836, %f1842;
	sub.f32 	%f915, %f914, %f913;
	mul.f32 	%f1852, %f915, %f902;
	mul.f32 	%f1858, %f900, %f902;
	mul.f32 	%f916, %f1838, %f1845;
	mul.f32 	%f917, %f1837, %f1846;
	sub.f32 	%f918, %f917, %f916;
	mul.f32 	%f1857, %f918, %f902;
	mul.f32 	%f919, %f1837, %f1842;
	mul.f32 	%f920, %f1838, %f1841;
	sub.f32 	%f921, %f920, %f919;
	mul.f32 	%f1856, %f921, %f902;
	mul.f32 	%f922, %f1835, %f1850;
	neg.f32 	%f923, %f922;
	mul.f32 	%f924, %f1839, %f1849;
	sub.f32 	%f925, %f923, %f924;
	mul.f32 	%f926, %f1843, %f1848;
	sub.f32 	%f1847, %f925, %f926;
	mul.f32 	%f927, %f1835, %f1854;
	neg.f32 	%f928, %f927;
	mul.f32 	%f929, %f1839, %f1853;
	sub.f32 	%f930, %f928, %f929;
	mul.f32 	%f931, %f1843, %f1852;
	sub.f32 	%f1851, %f930, %f931;
	mul.f32 	%f932, %f1835, %f1858;
	neg.f32 	%f933, %f932;
	mul.f32 	%f934, %f1839, %f1857;
	sub.f32 	%f935, %f933, %f934;
	mul.f32 	%f936, %f1843, %f1856;
	sub.f32 	%f1855, %f935, %f936;
	bra.uni 	$L__BB1_18;

$L__BB1_9:
	// begin inline asm
	call (%rd648), _optix_get_instance_inverse_transform_from_handle, (%rd48);
	// end inline asm

$L__BB1_10:
	// begin inline asm
	cvta.to.global.u64 %rd54, %rd648;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r40,%r41,%r42,%r43}, [%rd54];
	// end inline asm
	mov.b32 	%f1850, %r40;
	mov.b32 	%f1849, %r41;
	mov.b32 	%f1848, %r42;
	mov.b32 	%f1847, %r43;
	add.s64 	%rd58, %rd648, 16;
	// begin inline asm
	cvta.to.global.u64 %rd57, %rd58;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r44,%r45,%r46,%r47}, [%rd57];
	// end inline asm
	mov.b32 	%f1854, %r44;
	mov.b32 	%f1853, %r45;
	mov.b32 	%f1852, %r46;
	mov.b32 	%f1851, %r47;
	add.s64 	%rd61, %rd648, 32;
	// begin inline asm
	cvta.to.global.u64 %rd60, %rd61;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r48,%r49,%r50,%r51}, [%rd60];
	// end inline asm
	mov.b32 	%f1858, %r48;
	mov.b32 	%f1857, %r49;
	mov.b32 	%f1856, %r50;
	mov.b32 	%f1855, %r51;

$L__BB1_18:
	setp.eq.s32 	%p10, %r655, 0;
	@%p10 bra 	$L__BB1_20;

	mul.f32 	%f937, %f1815, %f1850;
	fma.rn.f32 	%f938, %f1811, %f1849, %f937;
	fma.rn.f32 	%f151, %f1807, %f1848, %f938;
	mul.f32 	%f939, %f1816, %f1850;
	fma.rn.f32 	%f940, %f1812, %f1849, %f939;
	fma.rn.f32 	%f152, %f1808, %f1848, %f940;
	mul.f32 	%f941, %f1817, %f1850;
	fma.rn.f32 	%f942, %f1813, %f1849, %f941;
	fma.rn.f32 	%f153, %f1809, %f1848, %f942;
	mul.f32 	%f943, %f1818, %f1850;
	fma.rn.f32 	%f944, %f1814, %f1849, %f943;
	fma.rn.f32 	%f945, %f1810, %f1848, %f944;
	add.f32 	%f1847, %f1847, %f945;
	mul.f32 	%f946, %f1815, %f1854;
	fma.rn.f32 	%f947, %f1811, %f1853, %f946;
	fma.rn.f32 	%f155, %f1807, %f1852, %f947;
	mul.f32 	%f948, %f1816, %f1854;
	fma.rn.f32 	%f949, %f1812, %f1853, %f948;
	fma.rn.f32 	%f156, %f1808, %f1852, %f949;
	mul.f32 	%f950, %f1817, %f1854;
	fma.rn.f32 	%f951, %f1813, %f1853, %f950;
	fma.rn.f32 	%f157, %f1809, %f1852, %f951;
	mul.f32 	%f952, %f1818, %f1854;
	fma.rn.f32 	%f953, %f1814, %f1853, %f952;
	fma.rn.f32 	%f954, %f1810, %f1852, %f953;
	add.f32 	%f1851, %f1851, %f954;
	mul.f32 	%f955, %f1815, %f1858;
	fma.rn.f32 	%f956, %f1811, %f1857, %f955;
	fma.rn.f32 	%f159, %f1807, %f1856, %f956;
	mul.f32 	%f957, %f1816, %f1858;
	fma.rn.f32 	%f958, %f1812, %f1857, %f957;
	fma.rn.f32 	%f160, %f1808, %f1856, %f958;
	mul.f32 	%f959, %f1817, %f1858;
	fma.rn.f32 	%f960, %f1813, %f1857, %f959;
	fma.rn.f32 	%f161, %f1809, %f1856, %f960;
	mul.f32 	%f961, %f1818, %f1858;
	fma.rn.f32 	%f962, %f1814, %f1857, %f961;
	fma.rn.f32 	%f963, %f1810, %f1856, %f962;
	add.f32 	%f1855, %f1855, %f963;
	mov.f32 	%f1848, %f153;
	mov.f32 	%f1849, %f152;
	mov.f32 	%f1850, %f151;
	mov.f32 	%f1852, %f157;
	mov.f32 	%f1853, %f156;
	mov.f32 	%f1854, %f155;
	mov.f32 	%f1856, %f161;
	mov.f32 	%f1857, %f160;
	mov.f32 	%f1858, %f159;

$L__BB1_20:
	add.s32 	%r655, %r655, 1;
	setp.lt.u32 	%p11, %r655, %r35;
	mov.f32 	%f1807, %f1858;
	mov.f32 	%f1808, %f1857;
	mov.f32 	%f1809, %f1856;
	mov.f32 	%f1810, %f1855;
	mov.f32 	%f1811, %f1854;
	mov.f32 	%f1812, %f1853;
	mov.f32 	%f1813, %f1852;
	mov.f32 	%f1814, %f1851;
	mov.f32 	%f1815, %f1850;
	mov.f32 	%f1816, %f1849;
	mov.f32 	%f1817, %f1848;
	mov.f32 	%f1818, %f1847;
	@%p11 bra 	$L__BB1_5;

$L__BB1_21:
	mul.f32 	%f964, %f1883, %f1850;
	fma.rn.f32 	%f965, %f1884, %f1849, %f964;
	fma.rn.f32 	%f966, %f1885, %f1848, %f965;
	mul.f32 	%f967, %f1883, %f1854;
	fma.rn.f32 	%f968, %f1884, %f1853, %f967;
	fma.rn.f32 	%f969, %f1885, %f1852, %f968;
	mul.f32 	%f970, %f1883, %f1858;
	fma.rn.f32 	%f971, %f1884, %f1857, %f970;
	fma.rn.f32 	%f972, %f1885, %f1856, %f971;
	add.f32 	%f1885, %f1855, %f972;
	add.f32 	%f1884, %f1851, %f969;
	add.f32 	%f1883, %f1847, %f966;

$L__BB1_22:
	// begin inline asm
	call (%f1941), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1942), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f975), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r186), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p12, %r186, 0;
	@%p12 bra 	$L__BB1_42;

	// begin inline asm
	call (%r187), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f976), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p13, %r187, 0;
	@%p13 bra 	$L__BB1_41;

	mov.u32 	%r656, 0;

$L__BB1_25:
	.pragma "nounroll";
	// begin inline asm
	call (%rd167), _optix_get_transform_list_handle, (%r656);
	// end inline asm
	// begin inline asm
	call (%r190), _optix_get_transform_type_from_handle, (%rd167);
	// end inline asm
	or.b32  	%r191, %r190, 1;
	setp.eq.s32 	%p14, %r191, 3;
	@%p14 bra 	$L__BB1_31;
	bra.uni 	$L__BB1_26;

$L__BB1_31:
	setp.eq.s32 	%p17, %r190, 2;
	@%p17 bra 	$L__BB1_35;
	bra.uni 	$L__BB1_32;

$L__BB1_35:
	// begin inline asm
	call (%rd239), _optix_get_matrix_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r279,%r280,%r281,%r282}, [%rd241];
	// end inline asm
	add.s64 	%rd245, %rd239, 16;
	// begin inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r283,%r284,%r285,%r286}, [%rd244];
	// end inline asm
	add.s64 	%rd248, %rd239, 32;
	// begin inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r287,%r288,%r289,%r290}, [%rd247];
	// end inline asm
	add.s64 	%rd251, %rd239, 48;
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r291,%r292,%r293,%r294}, [%rd250];
	// end inline asm
	add.s64 	%rd254, %rd239, 64;
	// begin inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r295,%r296,%r297,%r298}, [%rd253];
	// end inline asm
	add.s64 	%rd257, %rd239, 80;
	// begin inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r299,%r300,%r301,%r302}, [%rd256];
	// end inline asm
	add.s64 	%rd260, %rd239, 96;
	// begin inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd259];
	// end inline asm
	add.s64 	%rd263, %rd239, 112;
	// begin inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd262];
	// end inline asm
	mov.b32 	%f1080, %r282;
	mov.b32 	%f1081, %r283;
	and.b32  	%r323, %r281, 65535;
	add.s32 	%r324, %r323, -1;
	cvt.rn.f32.s32 	%f1082, %r324;
	sub.f32 	%f1083, %f976, %f1080;
	mul.f32 	%f1084, %f1083, %f1082;
	sub.f32 	%f1085, %f1081, %f1080;
	div.rn.f32 	%f1086, %f1084, %f1085;
	min.f32 	%f1087, %f1082, %f1086;
	mov.f32 	%f1088, 0f00000000;
	max.f32 	%f1089, %f1088, %f1087;
	cvt.rmi.f32.f32 	%f1090, %f1089;
	sub.f32 	%f258, %f1089, %f1090;
	cvt.rzi.s32.f32 	%r325, %f1090;
	cvt.s64.s32 	%rd17, %r325;
	mul.wide.s32 	%rd274, %r325, 48;
	add.s64 	%rd266, %rd248, %rd274;
	// begin inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd265];
	// end inline asm
	mov.b32 	%f1911, %r311;
	mov.b32 	%f1912, %r312;
	mov.b32 	%f1913, %r313;
	add.s64 	%rd269, %rd266, 16;
	// begin inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r315,%r316,%r317,%r318}, [%rd268];
	// end inline asm
	mov.b32 	%f1908, %r315;
	mov.b32 	%f1909, %r316;
	mov.b32 	%f1910, %r317;
	add.s64 	%rd272, %rd266, 32;
	// begin inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r319,%r320,%r321,%r322}, [%rd271];
	// end inline asm
	mov.b32 	%f1905, %r319;
	mov.b32 	%f1906, %r320;
	mov.b32 	%f1907, %r321;
	setp.leu.f32 	%p19, %f258, 0f00000000;
	@%p19 bra 	$L__BB1_37;

	mov.f32 	%f1091, 0f3F800000;
	sub.f32 	%f1092, %f1091, %f258;
	mul.lo.s64 	%rd284, %rd17, 48;
	add.s64 	%rd285, %rd239, %rd284;
	add.s64 	%rd276, %rd285, 80;
	// begin inline asm
	cvta.to.global.u64 %rd275, %rd276;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r326,%r327,%r328,%r329}, [%rd275];
	// end inline asm
	mov.b32 	%f1093, %r326;
	mov.b32 	%f1094, %r327;
	mov.b32 	%f1095, %r328;
	mul.f32 	%f1096, %f258, %f1093;
	mul.f32 	%f1097, %f258, %f1094;
	mul.f32 	%f1098, %f258, %f1095;
	fma.rn.f32 	%f1911, %f1092, %f1911, %f1096;
	fma.rn.f32 	%f1912, %f1092, %f1912, %f1097;
	fma.rn.f32 	%f1913, %f1092, %f1913, %f1098;
	add.s64 	%rd279, %rd285, 96;
	// begin inline asm
	cvta.to.global.u64 %rd278, %rd279;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r330,%r331,%r332,%r333}, [%rd278];
	// end inline asm
	mov.b32 	%f1099, %r330;
	mov.b32 	%f1100, %r331;
	mov.b32 	%f1101, %r332;
	mul.f32 	%f1102, %f258, %f1099;
	mul.f32 	%f1103, %f258, %f1100;
	mul.f32 	%f1104, %f258, %f1101;
	fma.rn.f32 	%f1908, %f1092, %f1908, %f1102;
	fma.rn.f32 	%f1909, %f1092, %f1909, %f1103;
	fma.rn.f32 	%f1910, %f1092, %f1910, %f1104;
	add.s64 	%rd282, %rd285, 112;
	// begin inline asm
	cvta.to.global.u64 %rd281, %rd282;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r334,%r335,%r336,%r337}, [%rd281];
	// end inline asm
	mov.b32 	%f1105, %r334;
	mov.b32 	%f1106, %r335;
	mov.b32 	%f1107, %r336;
	mul.f32 	%f1108, %f258, %f1105;
	mul.f32 	%f1109, %f258, %f1106;
	mul.f32 	%f1110, %f258, %f1107;
	fma.rn.f32 	%f1905, %f1092, %f1905, %f1108;
	fma.rn.f32 	%f1906, %f1092, %f1906, %f1109;
	fma.rn.f32 	%f1907, %f1092, %f1907, %f1110;
	bra.uni 	$L__BB1_37;

$L__BB1_26:
	mov.f32 	%f1914, 0f00000000;
	mov.f32 	%f1916, 0f3F800000;
	setp.eq.s32 	%p15, %r190, 4;
	@%p15 bra 	$L__BB1_29;

	setp.ne.s32 	%p16, %r190, 1;
	mov.f32 	%f1915, %f1914;
	mov.f32 	%f1917, %f1914;
	mov.f32 	%f1918, %f1916;
	mov.f32 	%f1919, %f1914;
	mov.f32 	%f1920, %f1916;
	mov.f32 	%f1921, %f1914;
	mov.f32 	%f1922, %f1914;
	@%p16 bra 	$L__BB1_38;

	// begin inline asm
	call (%rd169), _optix_get_static_transform_from_handle, (%rd167);
	// end inline asm
	add.s64 	%rd649, %rd169, 64;
	bra.uni 	$L__BB1_30;

$L__BB1_32:
	// begin inline asm
	call (%rd182), _optix_get_srt_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r204,%r205,%r206,%r207}, [%rd184];
	// end inline asm
	add.s64 	%rd188, %rd182, 16;
	// begin inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r208,%r209,%r210,%r211}, [%rd187];
	// end inline asm
	add.s64 	%rd191, %rd182, 32;
	// begin inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r212,%r213,%r214,%r215}, [%rd190];
	// end inline asm
	add.s64 	%rd194, %rd182, 48;
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r216,%r217,%r218,%r219}, [%rd193];
	// end inline asm
	add.s64 	%rd197, %rd182, 64;
	// begin inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r220,%r221,%r222,%r223}, [%rd196];
	// end inline asm
	add.s64 	%rd200, %rd182, 80;
	// begin inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r224,%r225,%r226,%r227}, [%rd199];
	// end inline asm
	add.s64 	%rd203, %rd182, 96;
	// begin inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r228,%r229,%r230,%r231}, [%rd202];
	// end inline asm
	add.s64 	%rd206, %rd182, 112;
	// begin inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r232,%r233,%r234,%r235}, [%rd205];
	// end inline asm
	add.s64 	%rd209, %rd182, 128;
	// begin inline asm
	cvta.to.global.u64 %rd208, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r236,%r237,%r238,%r239}, [%rd208];
	// end inline asm
	add.s64 	%rd212, %rd182, 144;
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd212;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd211];
	// end inline asm
	mov.b32 	%f988, %r207;
	mov.b32 	%f989, %r208;
	and.b32  	%r260, %r206, 65535;
	add.s32 	%r261, %r260, -1;
	cvt.rn.f32.s32 	%f990, %r261;
	sub.f32 	%f991, %f976, %f988;
	mul.f32 	%f992, %f991, %f990;
	sub.f32 	%f993, %f989, %f988;
	div.rn.f32 	%f994, %f992, %f993;
	min.f32 	%f995, %f990, %f994;
	mov.f32 	%f996, 0f00000000;
	max.f32 	%f997, %f996, %f995;
	cvt.rmi.f32.f32 	%f998, %f997;
	sub.f32 	%f218, %f997, %f998;
	cvt.rzi.s32.f32 	%r262, %f998;
	mul.wide.s32 	%rd226, %r262, 64;
	add.s64 	%rd215, %rd191, %rd226;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd214];
	// end inline asm
	mov.b32 	%f1895, %r244;
	mov.b32 	%f1896, %r245;
	mov.b32 	%f1897, %r246;
	add.s64 	%rd218, %rd215, 16;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd217];
	// end inline asm
	mov.b32 	%f1898, %r248;
	mov.b32 	%f1899, %r249;
	mov.b32 	%f1900, %r251;
	add.s64 	%rd221, %rd215, 32;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd220];
	// end inline asm
	mov.b32 	%f1901, %r253;
	mov.b32 	%f1902, %r254;
	mov.b32 	%f1903, %r255;
	add.s64 	%rd224, %rd215, 48;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd223];
	// end inline asm
	mov.b32 	%f1904, %r256;
	setp.leu.f32 	%p18, %f218, 0f00000000;
	@%p18 bra 	$L__BB1_34;

	mov.f32 	%f999, 0f3F800000;
	sub.f32 	%f1000, %f999, %f218;
	add.s64 	%rd228, %rd215, 64;
	// begin inline asm
	cvta.to.global.u64 %rd227, %rd228;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r263,%r264,%r265,%r266}, [%rd227];
	// end inline asm
	mov.b32 	%f1001, %r263;
	mov.b32 	%f1002, %r264;
	mov.b32 	%f1003, %r265;
	mul.f32 	%f1004, %f218, %f1001;
	mul.f32 	%f1005, %f218, %f1002;
	mul.f32 	%f1006, %f218, %f1003;
	fma.rn.f32 	%f1895, %f1000, %f1895, %f1004;
	fma.rn.f32 	%f1896, %f1000, %f1896, %f1005;
	fma.rn.f32 	%f1897, %f1000, %f1897, %f1006;
	add.s64 	%rd231, %rd215, 80;
	// begin inline asm
	cvta.to.global.u64 %rd230, %rd231;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r267,%r268,%r269,%r270}, [%rd230];
	// end inline asm
	mov.b32 	%f1007, %r267;
	mov.b32 	%f1008, %r268;
	mov.b32 	%f1009, %r270;
	mul.f32 	%f1010, %f218, %f1007;
	mul.f32 	%f1011, %f218, %f1008;
	mul.f32 	%f1012, %f218, %f1009;
	fma.rn.f32 	%f1898, %f1000, %f1898, %f1010;
	fma.rn.f32 	%f1899, %f1000, %f1899, %f1011;
	fma.rn.f32 	%f1900, %f1000, %f1900, %f1012;
	add.s64 	%rd234, %rd215, 96;
	// begin inline asm
	cvta.to.global.u64 %rd233, %rd234;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r271,%r272,%r273,%r274}, [%rd233];
	// end inline asm
	mov.b32 	%f1013, %r272;
	mov.b32 	%f1014, %r273;
	mov.b32 	%f1015, %r274;
	mul.f32 	%f1016, %f218, %f1013;
	mul.f32 	%f1017, %f218, %f1014;
	mul.f32 	%f1018, %f218, %f1015;
	fma.rn.f32 	%f1019, %f1000, %f1901, %f1016;
	fma.rn.f32 	%f1020, %f1000, %f1902, %f1017;
	fma.rn.f32 	%f1021, %f1000, %f1903, %f1018;
	add.s64 	%rd237, %rd215, 112;
	// begin inline asm
	cvta.to.global.u64 %rd236, %rd237;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r275,%r276,%r277,%r278}, [%rd236];
	// end inline asm
	mov.b32 	%f1022, %r275;
	mul.f32 	%f1023, %f218, %f1022;
	fma.rn.f32 	%f1024, %f1000, %f1904, %f1023;
	mul.f32 	%f1025, %f1020, %f1020;
	fma.rn.f32 	%f1026, %f1019, %f1019, %f1025;
	fma.rn.f32 	%f1027, %f1021, %f1021, %f1026;
	fma.rn.f32 	%f1028, %f1024, %f1024, %f1027;
	sqrt.rn.f32 	%f1029, %f1028;
	rcp.rn.f32 	%f1030, %f1029;
	mul.f32 	%f1901, %f1019, %f1030;
	mul.f32 	%f1902, %f1020, %f1030;
	mul.f32 	%f1903, %f1021, %f1030;
	mul.f32 	%f1904, %f1030, %f1024;

$L__BB1_34:
	mul.f32 	%f1031, %f1902, %f1902;
	fma.rn.f32 	%f1032, %f1901, %f1901, %f1031;
	fma.rn.f32 	%f1033, %f1903, %f1903, %f1032;
	fma.rn.f32 	%f1034, %f1904, %f1904, %f1033;
	rcp.rn.f32 	%f1035, %f1034;
	mul.f32 	%f1036, %f1901, %f1035;
	mul.f32 	%f1037, %f1902, %f1035;
	mul.f32 	%f1038, %f1903, %f1035;
	mul.f32 	%f1039, %f1904, %f1035;
	mul.f32 	%f1040, %f1901, %f1036;
	mul.f32 	%f1041, %f1902, %f1037;
	mul.f32 	%f1042, %f1903, %f1038;
	mul.f32 	%f1043, %f1901, %f1037;
	mul.f32 	%f1044, %f1903, %f1039;
	mul.f32 	%f1045, %f1901, %f1038;
	mul.f32 	%f1046, %f1902, %f1039;
	mul.f32 	%f1047, %f1902, %f1038;
	mul.f32 	%f1048, %f1901, %f1039;
	sub.f32 	%f1049, %f1040, %f1041;
	sub.f32 	%f1050, %f1049, %f1042;
	fma.rn.f32 	%f1051, %f1904, %f1039, %f1050;
	sub.f32 	%f1052, %f1043, %f1044;
	add.f32 	%f1053, %f1052, %f1052;
	add.f32 	%f1054, %f1045, %f1046;
	add.f32 	%f1055, %f1054, %f1054;
	add.f32 	%f1056, %f1043, %f1044;
	add.f32 	%f1057, %f1056, %f1056;
	sub.f32 	%f1058, %f1041, %f1040;
	sub.f32 	%f1059, %f1058, %f1042;
	fma.rn.f32 	%f1060, %f1904, %f1039, %f1059;
	sub.f32 	%f1061, %f1047, %f1048;
	add.f32 	%f1062, %f1061, %f1061;
	sub.f32 	%f1063, %f1045, %f1046;
	add.f32 	%f1064, %f1063, %f1063;
	add.f32 	%f1065, %f1047, %f1048;
	add.f32 	%f1066, %f1065, %f1065;
	neg.f32 	%f1067, %f1040;
	sub.f32 	%f1068, %f1067, %f1041;
	add.f32 	%f1069, %f1042, %f1068;
	fma.rn.f32 	%f1070, %f1904, %f1039, %f1069;
	mul.f32 	%f1071, %f1897, %f1051;
	fma.rn.f32 	%f1072, %f1899, %f1053, %f1071;
	fma.rn.f32 	%f1913, %f1900, %f1055, %f1072;
	mul.f32 	%f1073, %f1899, %f1060;
	fma.rn.f32 	%f1074, %f1897, %f1057, %f1073;
	fma.rn.f32 	%f1910, %f1900, %f1062, %f1074;
	mul.f32 	%f1075, %f1899, %f1066;
	fma.rn.f32 	%f1076, %f1897, %f1064, %f1075;
	fma.rn.f32 	%f1907, %f1900, %f1070, %f1076;
	mul.f32 	%f1077, %f1896, %f1051;
	fma.rn.f32 	%f1912, %f1898, %f1053, %f1077;
	mul.f32 	%f1078, %f1898, %f1060;
	fma.rn.f32 	%f1909, %f1896, %f1057, %f1078;
	mul.f32 	%f1079, %f1898, %f1066;
	fma.rn.f32 	%f1906, %f1896, %f1064, %f1079;
	mul.f32 	%f1911, %f1895, %f1051;
	mul.f32 	%f1908, %f1895, %f1057;
	mul.f32 	%f1905, %f1895, %f1064;

$L__BB1_37:
	mul.f32 	%f1111, %f1906, %f1910;
	mul.f32 	%f1112, %f1907, %f1909;
	sub.f32 	%f1113, %f1112, %f1111;
	mul.f32 	%f1114, %f1911, %f1113;
	mul.f32 	%f1115, %f1905, %f1910;
	mul.f32 	%f1116, %f1907, %f1908;
	sub.f32 	%f1117, %f1116, %f1115;
	mul.f32 	%f1118, %f1117, %f1912;
	sub.f32 	%f1119, %f1114, %f1118;
	mul.f32 	%f1120, %f1905, %f1909;
	mul.f32 	%f1121, %f1906, %f1908;
	sub.f32 	%f1122, %f1121, %f1120;
	fma.rn.f32 	%f1123, %f1122, %f1913, %f1119;
	rcp.rn.f32 	%f1124, %f1123;
	mul.f32 	%f1920, %f1113, %f1124;
	mul.f32 	%f1125, %f1907, %f1912;
	mul.f32 	%f1126, %f1906, %f1913;
	sub.f32 	%f1127, %f1126, %f1125;
	mul.f32 	%f1921, %f1127, %f1124;
	mul.f32 	%f1128, %f1909, %f1913;
	mul.f32 	%f1129, %f1910, %f1912;
	sub.f32 	%f1130, %f1129, %f1128;
	mul.f32 	%f1922, %f1130, %f1124;
	sub.f32 	%f1131, %f1115, %f1116;
	mul.f32 	%f1917, %f1131, %f1124;
	mul.f32 	%f1132, %f1905, %f1913;
	mul.f32 	%f1133, %f1907, %f1911;
	sub.f32 	%f1134, %f1133, %f1132;
	mul.f32 	%f1918, %f1134, %f1124;
	mul.f32 	%f1135, %f1910, %f1911;
	mul.f32 	%f1136, %f1908, %f1913;
	sub.f32 	%f1137, %f1136, %f1135;
	mul.f32 	%f1919, %f1137, %f1124;
	mul.f32 	%f1914, %f1122, %f1124;
	mul.f32 	%f1138, %f1906, %f1911;
	mul.f32 	%f1139, %f1905, %f1912;
	sub.f32 	%f1140, %f1139, %f1138;
	mul.f32 	%f1915, %f1140, %f1124;
	mul.f32 	%f1141, %f1908, %f1912;
	mul.f32 	%f1142, %f1909, %f1911;
	sub.f32 	%f1143, %f1142, %f1141;
	mul.f32 	%f1916, %f1143, %f1124;
	bra.uni 	$L__BB1_38;

$L__BB1_29:
	// begin inline asm
	call (%rd649), _optix_get_instance_inverse_transform_from_handle, (%rd167);
	// end inline asm

$L__BB1_30:
	// begin inline asm
	cvta.to.global.u64 %rd173, %rd649;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r192,%r193,%r194,%r195}, [%rd173];
	// end inline asm
	mov.b32 	%f1920, %r192;
	mov.b32 	%f1921, %r193;
	mov.b32 	%f1922, %r194;
	add.s64 	%rd177, %rd649, 16;
	// begin inline asm
	cvta.to.global.u64 %rd176, %rd177;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r196,%r197,%r198,%r199}, [%rd176];
	// end inline asm
	mov.b32 	%f1917, %r196;
	mov.b32 	%f1918, %r197;
	mov.b32 	%f1919, %r198;
	add.s64 	%rd180, %rd649, 32;
	// begin inline asm
	cvta.to.global.u64 %rd179, %rd180;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r200,%r201,%r202,%r203}, [%rd179];
	// end inline asm
	mov.b32 	%f1914, %r200;
	mov.b32 	%f1915, %r201;
	mov.b32 	%f1916, %r202;

$L__BB1_38:
	setp.eq.s32 	%p20, %r656, 0;
	@%p20 bra 	$L__BB1_40;

	mul.f32 	%f1144, %f1891, %f1921;
	fma.rn.f32 	%f1145, %f1888, %f1920, %f1144;
	fma.rn.f32 	%f304, %f1894, %f1922, %f1145;
	mul.f32 	%f1146, %f1890, %f1921;
	fma.rn.f32 	%f1147, %f1887, %f1920, %f1146;
	fma.rn.f32 	%f305, %f1893, %f1922, %f1147;
	mul.f32 	%f1148, %f1889, %f1921;
	fma.rn.f32 	%f1149, %f1886, %f1920, %f1148;
	fma.rn.f32 	%f1922, %f1892, %f1922, %f1149;
	mul.f32 	%f1150, %f1891, %f1918;
	fma.rn.f32 	%f1151, %f1888, %f1917, %f1150;
	fma.rn.f32 	%f307, %f1894, %f1919, %f1151;
	mul.f32 	%f1152, %f1890, %f1918;
	fma.rn.f32 	%f1153, %f1887, %f1917, %f1152;
	fma.rn.f32 	%f308, %f1893, %f1919, %f1153;
	mul.f32 	%f1154, %f1889, %f1918;
	fma.rn.f32 	%f1155, %f1886, %f1917, %f1154;
	fma.rn.f32 	%f1919, %f1892, %f1919, %f1155;
	mul.f32 	%f1156, %f1891, %f1915;
	fma.rn.f32 	%f1157, %f1888, %f1914, %f1156;
	fma.rn.f32 	%f310, %f1894, %f1916, %f1157;
	mul.f32 	%f1158, %f1890, %f1915;
	fma.rn.f32 	%f1159, %f1887, %f1914, %f1158;
	fma.rn.f32 	%f311, %f1893, %f1916, %f1159;
	mul.f32 	%f1160, %f1889, %f1915;
	fma.rn.f32 	%f1161, %f1886, %f1914, %f1160;
	fma.rn.f32 	%f1916, %f1892, %f1916, %f1161;
	mov.f32 	%f1914, %f310;
	mov.f32 	%f1915, %f311;
	mov.f32 	%f1917, %f307;
	mov.f32 	%f1918, %f308;
	mov.f32 	%f1920, %f304;
	mov.f32 	%f1921, %f305;

$L__BB1_40:
	add.s32 	%r656, %r656, 1;
	setp.lt.u32 	%p21, %r656, %r187;
	mov.f32 	%f1886, %f1922;
	mov.f32 	%f1887, %f1921;
	mov.f32 	%f1888, %f1920;
	mov.f32 	%f1889, %f1919;
	mov.f32 	%f1890, %f1918;
	mov.f32 	%f1891, %f1917;
	mov.f32 	%f1892, %f1916;
	mov.f32 	%f1893, %f1915;
	mov.f32 	%f1894, %f1914;
	@%p21 bra 	$L__BB1_25;

$L__BB1_41:
	mul.f32 	%f1162, %f1942, %f1921;
	fma.rn.f32 	%f1163, %f1941, %f1920, %f1162;
	mul.f32 	%f1164, %f1942, %f1918;
	fma.rn.f32 	%f1165, %f1941, %f1917, %f1164;
	mul.f32 	%f1166, %f1942, %f1915;
	fma.rn.f32 	%f1167, %f1941, %f1914, %f1166;
	fma.rn.f32 	%f1943, %f975, %f1916, %f1167;
	fma.rn.f32 	%f1942, %f975, %f1919, %f1165;
	fma.rn.f32 	%f1941, %f975, %f1922, %f1163;
	bra.uni 	$L__BB1_43;

$L__BB1_42:
	mov.f32 	%f1943, %f975;

$L__BB1_43:
	// begin inline asm
	call (%f1169), _optix_get_ray_tmax, ();
	// end inline asm
	ld.const.u64 	%rd286, [params+80];
	setp.eq.s64 	%p22, %rd286, 0;
	@%p22 bra 	$L__BB1_48;

	ld.u64 	%rd287, [%rd47];
	ld.const.u64 	%rd288, [params+328];
	cvta.to.global.u64 	%rd289, %rd288;
	cvt.u64.u32 	%rd18, %r1;
	mul.wide.u32 	%rd290, %r1, 8;
	add.s64 	%rd291, %rd289, %rd290;
	st.global.u64 	[%rd291], %rd287;
	ld.const.u64 	%rd292, [params+336];
	cvta.to.global.u64 	%rd293, %rd292;
	mul.wide.u32 	%rd294, %r1, 4;
	add.s64 	%rd295, %rd293, %rd294;
	mov.u32 	%r338, 0;
	st.global.u32 	[%rd295], %r338;
	ld.const.u64 	%rd296, [params+344];
	cvta.to.global.u64 	%rd297, %rd296;
	add.s64 	%rd19, %rd297, %rd294;
	ld.global.u32 	%r10, [%rd19];
	setp.eq.s32 	%p23, %r10, 0;
	@%p23 bra 	$L__BB1_47;

	// begin inline asm
	call (%r339), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p24, %r339, %r10;
	@%p24 bra 	$L__BB1_47;

	st.global.u32 	[%rd19], %r339;

$L__BB1_47:
	ld.const.u64 	%rd298, [params+72];
	cvta.to.global.u64 	%rd299, %rd298;
	shl.b64 	%rd300, %rd18, 2;
	add.s64 	%rd301, %rd299, %rd300;
	st.global.f32 	[%rd301], %f1169;
	bra.uni 	$L__BB1_113;

$L__BB1_48:
	fma.rn.f32 	%f341, %f1169, %f1941, %f1883;
	fma.rn.f32 	%f342, %f1169, %f1942, %f1884;
	fma.rn.f32 	%f343, %f1169, %f1943, %f1885;
	add.s64 	%rd20, %rd3, 208;
	ld.v4.f32 	{%f1171, %f1172, %f1173, %f1174}, [%rd3+208];
	ld.f32 	%f1178, [%rd3+160];
	fma.rn.f32 	%f1179, %f341, %f1178, %f1171;
	ld.f32 	%f1180, [%rd3+164];
	fma.rn.f32 	%f1181, %f341, %f1180, %f1172;
	ld.f32 	%f1182, [%rd3+168];
	fma.rn.f32 	%f1183, %f341, %f1182, %f1173;
	ld.f32 	%f1184, [%rd3+176];
	fma.rn.f32 	%f1185, %f342, %f1184, %f1179;
	ld.f32 	%f1186, [%rd3+180];
	fma.rn.f32 	%f1187, %f342, %f1186, %f1181;
	ld.f32 	%f1188, [%rd3+184];
	fma.rn.f32 	%f1189, %f342, %f1188, %f1183;
	ld.f32 	%f1190, [%rd3+192];
	fma.rn.f32 	%f344, %f343, %f1190, %f1185;
	ld.f32 	%f1191, [%rd3+196];
	fma.rn.f32 	%f345, %f343, %f1191, %f1187;
	ld.f32 	%f1192, [%rd3+200];
	fma.rn.f32 	%f346, %f343, %f1192, %f1189;
	abs.f32 	%f347, %f344;
	abs.f32 	%f348, %f345;
	setp.eq.f32 	%p25, %f347, 0f00000000;
	setp.eq.f32 	%p26, %f348, 0f00000000;
	and.pred  	%p27, %p25, %p26;
	mov.b32 	%r12, %f344;
	mov.b32 	%r340, %f345;
	and.b32  	%r13, %r340, -2147483648;
	@%p27 bra 	$L__BB1_52;
	bra.uni 	$L__BB1_49;

$L__BB1_52:
	shr.s32 	%r345, %r12, 31;
	and.b32  	%r346, %r345, 1078530011;
	or.b32  	%r347, %r346, %r13;
	mov.b32 	%f1944, %r347;
	bra.uni 	$L__BB1_53;

$L__BB1_49:
	setp.eq.f32 	%p28, %f347, 0f7F800000;
	setp.eq.f32 	%p29, %f348, 0f7F800000;
	and.pred  	%p30, %p28, %p29;
	@%p30 bra 	$L__BB1_51;
	bra.uni 	$L__BB1_50;

$L__BB1_51:
	setp.lt.s32 	%p34, %r12, 0;
	selp.b32 	%r343, 1075235812, 1061752795, %p34;
	or.b32  	%r344, %r343, %r13;
	mov.b32 	%f1944, %r344;
	bra.uni 	$L__BB1_53;

$L__BB1_50:
	setp.lt.s32 	%p31, %r12, 0;
	min.f32 	%f1193, %f348, %f347;
	max.f32 	%f1194, %f348, %f347;
	div.rn.f32 	%f1195, %f1193, %f1194;
	mul.rn.f32 	%f1196, %f1195, %f1195;
	mov.f32 	%f1197, 0fC0B59883;
	mov.f32 	%f1198, 0fBF52C7EA;
	fma.rn.f32 	%f1199, %f1196, %f1198, %f1197;
	mov.f32 	%f1200, 0fC0D21907;
	fma.rn.f32 	%f1201, %f1199, %f1196, %f1200;
	mul.f32 	%f1202, %f1196, %f1201;
	mul.f32 	%f1203, %f1195, %f1202;
	add.f32 	%f1204, %f1196, 0f41355DC0;
	mov.f32 	%f1205, 0f41E6BD60;
	fma.rn.f32 	%f1206, %f1204, %f1196, %f1205;
	mov.f32 	%f1207, 0f419D92C8;
	fma.rn.f32 	%f1208, %f1206, %f1196, %f1207;
	rcp.rn.f32 	%f1209, %f1208;
	fma.rn.f32 	%f1210, %f1203, %f1209, %f1195;
	mov.f32 	%f1211, 0f3FC90FDB;
	sub.f32 	%f1212, %f1211, %f1210;
	setp.gt.f32 	%p32, %f348, %f347;
	selp.f32 	%f1213, %f1212, %f1210, %p32;
	mov.f32 	%f1214, 0f40490FDB;
	sub.f32 	%f1215, %f1214, %f1213;
	selp.f32 	%f1216, %f1215, %f1213, %p31;
	mov.b32 	%r341, %f1216;
	or.b32  	%r342, %r13, %r341;
	mov.b32 	%f1217, %r342;
	add.f32 	%f1218, %f347, %f348;
	setp.le.f32 	%p33, %f1218, 0f7F800000;
	selp.f32 	%f1944, %f1217, %f1218, %p33;

$L__BB1_53:
	add.f32 	%f1222, %f1944, 0f40C90FDB;
	setp.lt.f32 	%p35, %f1944, 0f00000000;
	mov.f32 	%f2082, 0f00000000;
	selp.f32 	%f353, %f1222, %f1944, %p35;
	ld.v2.f32 	{%f1223, %f1224}, [%rd20+80];
	div.rn.f32 	%f354, %f346, %f1223;
	ld.v4.f32 	{%f1227, %f1228, %f1229, %f1230}, [%rd20+-176];
	mul.f32 	%f1234, %f345, 0fC0C90FDB;
	mul.f32 	%f1235, %f1234, %f1227;
	mul.f32 	%f1236, %f1234, %f1228;
	mul.f32 	%f1237, %f1234, %f1229;
	ld.v4.f32 	{%f1238, %f1239, %f1240, %f1241}, [%rd20+-160];
	mul.f32 	%f1245, %f344, 0f40C90FDB;
	fma.rn.f32 	%f1246, %f1245, %f1238, %f1235;
	fma.rn.f32 	%f1247, %f1245, %f1239, %f1236;
	fma.rn.f32 	%f1248, %f1245, %f1240, %f1237;
	ld.f32 	%f1249, [%rd20+-144];
	fma.rn.f32 	%f2073, %f2082, %f1249, %f1246;
	ld.f32 	%f1250, [%rd20+-140];
	fma.rn.f32 	%f2074, %f2082, %f1250, %f1247;
	ld.f32 	%f1251, [%rd20+-136];
	fma.rn.f32 	%f2075, %f2082, %f1251, %f1248;
	mul.f32 	%f1252, %f1227, 0f00000000;
	mul.f32 	%f1253, %f1228, 0f00000000;
	mul.f32 	%f1254, %f1229, 0f00000000;
	fma.rn.f32 	%f1255, %f2082, %f1238, %f1252;
	fma.rn.f32 	%f1256, %f2082, %f1239, %f1253;
	fma.rn.f32 	%f1257, %f2082, %f1240, %f1254;
	fma.rn.f32 	%f2070, %f1223, %f1249, %f1255;
	fma.rn.f32 	%f2071, %f1223, %f1250, %f1256;
	fma.rn.f32 	%f2072, %f1223, %f1251, %f1257;
	mul.f32 	%f1258, %f2074, %f2072;
	mul.f32 	%f1259, %f2075, %f2071;
	sub.f32 	%f1260, %f1258, %f1259;
	mul.f32 	%f1261, %f2075, %f2070;
	mul.f32 	%f1262, %f2073, %f2072;
	sub.f32 	%f1263, %f1261, %f1262;
	mul.f32 	%f1264, %f2073, %f2071;
	mul.f32 	%f1265, %f2074, %f2070;
	sub.f32 	%f1266, %f1264, %f1265;
	mul.f32 	%f1267, %f1260, %f1260;
	fma.rn.f32 	%f1268, %f1263, %f1263, %f1267;
	fma.rn.f32 	%f1269, %f1266, %f1266, %f1268;
	sqrt.rn.f32 	%f1270, %f1269;
	div.rn.f32 	%f1271, %f1260, %f1270;
	div.rn.f32 	%f1272, %f1263, %f1270;
	div.rn.f32 	%f1273, %f1266, %f1270;
	mul.f32 	%f1274, %f344, %f344;
	fma.rn.f32 	%f1275, %f345, %f345, %f1274;
	sqrt.rn.f32 	%f1276, %f1275;
	sub.f32 	%f1277, %f1224, %f1276;
	fma.rn.f32 	%f2100, %f1271, %f1277, %f341;
	fma.rn.f32 	%f2101, %f1272, %f1277, %f342;
	fma.rn.f32 	%f2102, %f1273, %f1277, %f343;
	ld.u8 	%rs2, [%rd20+88];
	setp.eq.s16 	%p36, %rs2, 0;
	neg.f32 	%f1278, %f1271;
	neg.f32 	%f1279, %f1272;
	neg.f32 	%f1280, %f1273;
	selp.f32 	%f2069, %f1273, %f1280, %p36;
	selp.f32 	%f2068, %f1272, %f1279, %p36;
	selp.f32 	%f2067, %f1271, %f1278, %p36;
	selp.f32 	%f1281, 0f3F800000, 0fBF800000, %p36;
	mul.f32 	%f1282, %f1224, %f1281;
	div.rn.f32 	%f2079, %f2073, %f1282;
	div.rn.f32 	%f2080, %f2074, %f1282;
	div.rn.f32 	%f2081, %f2075, %f1282;
	ld.u64 	%rd21, [%rd47];
	ld.const.u64 	%rd302, [params+344];
	cvta.to.global.u64 	%rd303, %rd302;
	cvt.u64.u32 	%rd22, %r1;
	mul.wide.u32 	%rd304, %r1, 4;
	add.s64 	%rd23, %rd303, %rd304;
	ld.global.u32 	%r14, [%rd23];
	setp.eq.s32 	%p37, %r14, 0;
	mov.f32 	%f2083, %f2082;
	mov.f32 	%f2084, %f2082;
	mov.f32 	%f2097, %f2067;
	mov.f32 	%f2098, %f2068;
	mov.f32 	%f2099, %f2069;
	@%p37 bra 	$L__BB1_101;

	// begin inline asm
	call (%r348), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p38, %r348, %r14;
	mov.f32 	%f2097, %f2067;
	mov.f32 	%f2098, %f2068;
	mov.f32 	%f2099, %f2069;
	@%p38 bra 	$L__BB1_101;

	// begin inline asm
	call (%r349), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p39, %r349, 0;
	mov.f32 	%f2044, 0f00000000;
	mov.f32 	%f2043, 0f3F800000;
	mov.f32 	%f1981, %f2043;
	mov.f32 	%f1982, %f2044;
	mov.f32 	%f1983, %f2044;
	mov.f32 	%f1984, %f2044;
	mov.f32 	%f1977, %f2044;
	mov.f32 	%f1978, %f2043;
	mov.f32 	%f1979, %f2044;
	mov.f32 	%f1980, %f2044;
	mov.f32 	%f1973, %f2044;
	mov.f32 	%f1974, %f2044;
	mov.f32 	%f1975, %f2043;
	mov.f32 	%f1976, %f2044;
	@%p39 bra 	$L__BB1_73;

	// begin inline asm
	call (%r350), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1298), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p40, %r350, 1;
	@%p40 bra 	$L__BB1_73;

	add.s32 	%r657, %r350, 1;
	mov.u32 	%r658, 1;

$L__BB1_58:
	.pragma "nounroll";
	add.s32 	%r352, %r657, -2;
	// begin inline asm
	call (%rd305), _optix_get_transform_list_handle, (%r352);
	// end inline asm
	// begin inline asm
	call (%r353), _optix_get_transform_type_from_handle, (%rd305);
	// end inline asm
	or.b32  	%r354, %r353, 1;
	setp.eq.s32 	%p41, %r354, 3;
	@%p41 bra 	$L__BB1_64;
	bra.uni 	$L__BB1_59;

$L__BB1_64:
	setp.eq.s32 	%p44, %r353, 2;
	@%p44 bra 	$L__BB1_68;
	bra.uni 	$L__BB1_65;

$L__BB1_68:
	// begin inline asm
	call (%rd377), _optix_get_matrix_motion_transform_from_handle, (%rd305);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd379, %rd377;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r442,%r443,%r444,%r445}, [%rd379];
	// end inline asm
	add.s64 	%rd383, %rd377, 16;
	// begin inline asm
	cvta.to.global.u64 %rd382, %rd383;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd382];
	// end inline asm
	add.s64 	%rd386, %rd377, 32;
	// begin inline asm
	cvta.to.global.u64 %rd385, %rd386;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd385];
	// end inline asm
	add.s64 	%rd389, %rd377, 48;
	// begin inline asm
	cvta.to.global.u64 %rd388, %rd389;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd388];
	// end inline asm
	add.s64 	%rd392, %rd377, 64;
	// begin inline asm
	cvta.to.global.u64 %rd391, %rd392;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r458,%r459,%r460,%r461}, [%rd391];
	// end inline asm
	add.s64 	%rd395, %rd377, 80;
	// begin inline asm
	cvta.to.global.u64 %rd394, %rd395;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r462,%r463,%r464,%r465}, [%rd394];
	// end inline asm
	add.s64 	%rd398, %rd377, 96;
	// begin inline asm
	cvta.to.global.u64 %rd397, %rd398;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r466,%r467,%r468,%r469}, [%rd397];
	// end inline asm
	add.s64 	%rd401, %rd377, 112;
	// begin inline asm
	cvta.to.global.u64 %rd400, %rd401;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r470,%r471,%r472,%r473}, [%rd400];
	// end inline asm
	mov.b32 	%f1426, %r445;
	mov.b32 	%f1427, %r446;
	and.b32  	%r486, %r444, 65535;
	add.s32 	%r487, %r486, -1;
	cvt.rn.f32.s32 	%f1428, %r487;
	sub.f32 	%f1429, %f1298, %f1426;
	mul.f32 	%f1430, %f1429, %f1428;
	sub.f32 	%f1431, %f1427, %f1426;
	div.rn.f32 	%f1432, %f1430, %f1431;
	min.f32 	%f1433, %f1428, %f1432;
	mov.f32 	%f1434, 0f00000000;
	max.f32 	%f1435, %f1434, %f1433;
	cvt.rmi.f32.f32 	%f1436, %f1435;
	sub.f32 	%f456, %f1435, %f1436;
	cvt.rzi.s32.f32 	%r488, %f1436;
	cvt.s64.s32 	%rd30, %r488;
	mul.wide.s32 	%rd412, %r488, 48;
	add.s64 	%rd404, %rd386, %rd412;
	// begin inline asm
	cvta.to.global.u64 %rd403, %rd404;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r474,%r475,%r476,%r477}, [%rd403];
	// end inline asm
	mov.b32 	%f1981, %r474;
	mov.b32 	%f1982, %r475;
	mov.b32 	%f1983, %r476;
	mov.b32 	%f1984, %r477;
	add.s64 	%rd407, %rd404, 16;
	// begin inline asm
	cvta.to.global.u64 %rd406, %rd407;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r478,%r479,%r480,%r481}, [%rd406];
	// end inline asm
	mov.b32 	%f1977, %r478;
	mov.b32 	%f1978, %r479;
	mov.b32 	%f1979, %r480;
	mov.b32 	%f1980, %r481;
	add.s64 	%rd410, %rd404, 32;
	// begin inline asm
	cvta.to.global.u64 %rd409, %rd410;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r482,%r483,%r484,%r485}, [%rd409];
	// end inline asm
	mov.b32 	%f1973, %r482;
	mov.b32 	%f1974, %r483;
	mov.b32 	%f1975, %r484;
	mov.b32 	%f1976, %r485;
	setp.leu.f32 	%p46, %f456, 0f00000000;
	@%p46 bra 	$L__BB1_70;

	mov.f32 	%f1437, 0f3F800000;
	sub.f32 	%f1438, %f1437, %f456;
	mul.lo.s64 	%rd422, %rd30, 48;
	add.s64 	%rd423, %rd377, %rd422;
	add.s64 	%rd414, %rd423, 80;
	// begin inline asm
	cvta.to.global.u64 %rd413, %rd414;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r489,%r490,%r491,%r492}, [%rd413];
	// end inline asm
	mov.b32 	%f1439, %r489;
	mov.b32 	%f1440, %r490;
	mov.b32 	%f1441, %r491;
	mov.b32 	%f1442, %r492;
	mul.f32 	%f1443, %f456, %f1439;
	mul.f32 	%f1444, %f456, %f1440;
	mul.f32 	%f1445, %f456, %f1441;
	mul.f32 	%f1446, %f456, %f1442;
	fma.rn.f32 	%f1981, %f1438, %f1981, %f1443;
	fma.rn.f32 	%f1982, %f1438, %f1982, %f1444;
	fma.rn.f32 	%f1983, %f1438, %f1983, %f1445;
	fma.rn.f32 	%f1984, %f1438, %f1984, %f1446;
	add.s64 	%rd417, %rd423, 96;
	// begin inline asm
	cvta.to.global.u64 %rd416, %rd417;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r493,%r494,%r495,%r496}, [%rd416];
	// end inline asm
	mov.b32 	%f1447, %r493;
	mov.b32 	%f1448, %r494;
	mov.b32 	%f1449, %r495;
	mov.b32 	%f1450, %r496;
	mul.f32 	%f1451, %f456, %f1447;
	mul.f32 	%f1452, %f456, %f1448;
	mul.f32 	%f1453, %f456, %f1449;
	mul.f32 	%f1454, %f456, %f1450;
	fma.rn.f32 	%f1977, %f1438, %f1977, %f1451;
	fma.rn.f32 	%f1978, %f1438, %f1978, %f1452;
	fma.rn.f32 	%f1979, %f1438, %f1979, %f1453;
	fma.rn.f32 	%f1980, %f1438, %f1980, %f1454;
	add.s64 	%rd420, %rd423, 112;
	// begin inline asm
	cvta.to.global.u64 %rd419, %rd420;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd419];
	// end inline asm
	mov.b32 	%f1455, %r497;
	mov.b32 	%f1456, %r498;
	mov.b32 	%f1457, %r499;
	mov.b32 	%f1458, %r500;
	mul.f32 	%f1459, %f456, %f1455;
	mul.f32 	%f1460, %f456, %f1456;
	mul.f32 	%f1461, %f456, %f1457;
	mul.f32 	%f1462, %f456, %f1458;
	fma.rn.f32 	%f1973, %f1438, %f1973, %f1459;
	fma.rn.f32 	%f1974, %f1438, %f1974, %f1460;
	fma.rn.f32 	%f1975, %f1438, %f1975, %f1461;
	fma.rn.f32 	%f1976, %f1438, %f1976, %f1462;
	bra.uni 	$L__BB1_70;

$L__BB1_59:
	mov.f32 	%f1973, 0f00000000;
	mov.f32 	%f1975, 0f3F800000;
	setp.eq.s32 	%p42, %r353, 4;
	@%p42 bra 	$L__BB1_62;

	setp.ne.s32 	%p43, %r353, 1;
	mov.f32 	%f1974, %f1973;
	mov.f32 	%f1976, %f1973;
	mov.f32 	%f1977, %f1973;
	mov.f32 	%f1978, %f1975;
	mov.f32 	%f1979, %f1973;
	mov.f32 	%f1980, %f1973;
	mov.f32 	%f1981, %f1975;
	mov.f32 	%f1982, %f1973;
	mov.f32 	%f1983, %f1973;
	mov.f32 	%f1984, %f1973;
	@%p43 bra 	$L__BB1_70;

	// begin inline asm
	call (%rd307), _optix_get_static_transform_from_handle, (%rd305);
	// end inline asm
	add.s64 	%rd650, %rd307, 16;
	bra.uni 	$L__BB1_63;

$L__BB1_65:
	// begin inline asm
	call (%rd320), _optix_get_srt_motion_transform_from_handle, (%rd305);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd322, %rd320;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd322];
	// end inline asm
	add.s64 	%rd326, %rd320, 16;
	// begin inline asm
	cvta.to.global.u64 %rd325, %rd326;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd325];
	// end inline asm
	add.s64 	%rd329, %rd320, 32;
	// begin inline asm
	cvta.to.global.u64 %rd328, %rd329;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd328];
	// end inline asm
	add.s64 	%rd332, %rd320, 48;
	// begin inline asm
	cvta.to.global.u64 %rd331, %rd332;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd331];
	// end inline asm
	add.s64 	%rd335, %rd320, 64;
	// begin inline asm
	cvta.to.global.u64 %rd334, %rd335;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd334];
	// end inline asm
	add.s64 	%rd338, %rd320, 80;
	// begin inline asm
	cvta.to.global.u64 %rd337, %rd338;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd337];
	// end inline asm
	add.s64 	%rd341, %rd320, 96;
	// begin inline asm
	cvta.to.global.u64 %rd340, %rd341;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd340];
	// end inline asm
	add.s64 	%rd344, %rd320, 112;
	// begin inline asm
	cvta.to.global.u64 %rd343, %rd344;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd343];
	// end inline asm
	add.s64 	%rd347, %rd320, 128;
	// begin inline asm
	cvta.to.global.u64 %rd346, %rd347;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd346];
	// end inline asm
	add.s64 	%rd350, %rd320, 144;
	// begin inline asm
	cvta.to.global.u64 %rd349, %rd350;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r403,%r404,%r405,%r406}, [%rd349];
	// end inline asm
	mov.b32 	%f1313, %r370;
	mov.b32 	%f1314, %r371;
	and.b32  	%r423, %r369, 65535;
	add.s32 	%r424, %r423, -1;
	cvt.rn.f32.s32 	%f1315, %r424;
	sub.f32 	%f1316, %f1298, %f1313;
	mul.f32 	%f1317, %f1316, %f1315;
	sub.f32 	%f1318, %f1314, %f1313;
	div.rn.f32 	%f1319, %f1317, %f1318;
	min.f32 	%f1320, %f1315, %f1319;
	mov.f32 	%f1321, 0f00000000;
	max.f32 	%f1322, %f1321, %f1320;
	cvt.rmi.f32.f32 	%f1323, %f1322;
	sub.f32 	%f395, %f1322, %f1323;
	cvt.rzi.s32.f32 	%r425, %f1323;
	mul.wide.s32 	%rd364, %r425, 64;
	add.s64 	%rd353, %rd329, %rd364;
	// begin inline asm
	cvta.to.global.u64 %rd352, %rd353;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r407,%r408,%r409,%r410}, [%rd352];
	// end inline asm
	mov.b32 	%f1957, %r407;
	mov.b32 	%f1958, %r408;
	mov.b32 	%f1959, %r409;
	mov.b32 	%f1960, %r410;
	add.s64 	%rd356, %rd353, 16;
	// begin inline asm
	cvta.to.global.u64 %rd355, %rd356;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r411,%r412,%r413,%r414}, [%rd355];
	// end inline asm
	mov.b32 	%f1961, %r411;
	mov.b32 	%f1962, %r412;
	mov.b32 	%f1963, %r413;
	mov.b32 	%f1964, %r414;
	add.s64 	%rd359, %rd353, 32;
	// begin inline asm
	cvta.to.global.u64 %rd358, %rd359;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r415,%r416,%r417,%r418}, [%rd358];
	// end inline asm
	mov.b32 	%f1965, %r415;
	mov.b32 	%f1966, %r416;
	mov.b32 	%f1967, %r417;
	mov.b32 	%f1968, %r418;
	add.s64 	%rd362, %rd353, 48;
	// begin inline asm
	cvta.to.global.u64 %rd361, %rd362;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r419,%r420,%r421,%r422}, [%rd361];
	// end inline asm
	mov.b32 	%f1969, %r419;
	mov.b32 	%f1970, %r420;
	mov.b32 	%f1971, %r421;
	mov.b32 	%f1972, %r422;
	setp.leu.f32 	%p45, %f395, 0f00000000;
	@%p45 bra 	$L__BB1_67;

	mov.f32 	%f1324, 0f3F800000;
	sub.f32 	%f1325, %f1324, %f395;
	add.s64 	%rd366, %rd353, 64;
	// begin inline asm
	cvta.to.global.u64 %rd365, %rd366;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r426,%r427,%r428,%r429}, [%rd365];
	// end inline asm
	mov.b32 	%f1326, %r426;
	mov.b32 	%f1327, %r427;
	mov.b32 	%f1328, %r428;
	mov.b32 	%f1329, %r429;
	mul.f32 	%f1330, %f395, %f1326;
	mul.f32 	%f1331, %f395, %f1327;
	mul.f32 	%f1332, %f395, %f1328;
	mul.f32 	%f1333, %f395, %f1329;
	fma.rn.f32 	%f1957, %f1325, %f1957, %f1330;
	fma.rn.f32 	%f1958, %f1325, %f1958, %f1331;
	fma.rn.f32 	%f1959, %f1325, %f1959, %f1332;
	fma.rn.f32 	%f1960, %f1325, %f1960, %f1333;
	add.s64 	%rd369, %rd353, 80;
	// begin inline asm
	cvta.to.global.u64 %rd368, %rd369;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r430,%r431,%r432,%r433}, [%rd368];
	// end inline asm
	mov.b32 	%f1334, %r430;
	mov.b32 	%f1335, %r431;
	mov.b32 	%f1336, %r432;
	mov.b32 	%f1337, %r433;
	mul.f32 	%f1338, %f395, %f1334;
	mul.f32 	%f1339, %f395, %f1335;
	mul.f32 	%f1340, %f395, %f1336;
	mul.f32 	%f1341, %f395, %f1337;
	fma.rn.f32 	%f1961, %f1325, %f1961, %f1338;
	fma.rn.f32 	%f1962, %f1325, %f1962, %f1339;
	fma.rn.f32 	%f1963, %f1325, %f1963, %f1340;
	fma.rn.f32 	%f1964, %f1325, %f1964, %f1341;
	add.s64 	%rd372, %rd353, 96;
	// begin inline asm
	cvta.to.global.u64 %rd371, %rd372;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r434,%r435,%r436,%r437}, [%rd371];
	// end inline asm
	mov.b32 	%f1342, %r434;
	mov.b32 	%f1343, %r435;
	mov.b32 	%f1344, %r436;
	mov.b32 	%f1345, %r437;
	mul.f32 	%f1346, %f395, %f1342;
	mul.f32 	%f1347, %f395, %f1343;
	mul.f32 	%f1348, %f395, %f1344;
	mul.f32 	%f1349, %f395, %f1345;
	fma.rn.f32 	%f1965, %f1325, %f1965, %f1346;
	fma.rn.f32 	%f1350, %f1325, %f1966, %f1347;
	fma.rn.f32 	%f1351, %f1325, %f1967, %f1348;
	fma.rn.f32 	%f1352, %f1325, %f1968, %f1349;
	add.s64 	%rd375, %rd353, 112;
	// begin inline asm
	cvta.to.global.u64 %rd374, %rd375;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r438,%r439,%r440,%r441}, [%rd374];
	// end inline asm
	mov.b32 	%f1353, %r438;
	mov.b32 	%f1354, %r439;
	mov.b32 	%f1355, %r440;
	mov.b32 	%f1356, %r441;
	mul.f32 	%f1357, %f395, %f1353;
	mul.f32 	%f1358, %f395, %f1354;
	mul.f32 	%f1359, %f395, %f1355;
	mul.f32 	%f1360, %f395, %f1356;
	fma.rn.f32 	%f1361, %f1325, %f1969, %f1357;
	fma.rn.f32 	%f1970, %f1325, %f1970, %f1358;
	fma.rn.f32 	%f1971, %f1325, %f1971, %f1359;
	fma.rn.f32 	%f1972, %f1325, %f1972, %f1360;
	mul.f32 	%f1362, %f1351, %f1351;
	fma.rn.f32 	%f1363, %f1350, %f1350, %f1362;
	fma.rn.f32 	%f1364, %f1352, %f1352, %f1363;
	fma.rn.f32 	%f1365, %f1361, %f1361, %f1364;
	sqrt.rn.f32 	%f1366, %f1365;
	rcp.rn.f32 	%f1367, %f1366;
	mul.f32 	%f1966, %f1350, %f1367;
	mul.f32 	%f1967, %f1351, %f1367;
	mul.f32 	%f1968, %f1352, %f1367;
	mul.f32 	%f1969, %f1367, %f1361;

$L__BB1_67:
	mul.f32 	%f1368, %f1967, %f1967;
	fma.rn.f32 	%f1369, %f1966, %f1966, %f1368;
	fma.rn.f32 	%f1370, %f1968, %f1968, %f1369;
	fma.rn.f32 	%f1371, %f1969, %f1969, %f1370;
	rcp.rn.f32 	%f1372, %f1371;
	mul.f32 	%f1373, %f1966, %f1372;
	mul.f32 	%f1374, %f1967, %f1372;
	mul.f32 	%f1375, %f1968, %f1372;
	mul.f32 	%f1376, %f1969, %f1372;
	mul.f32 	%f1377, %f1966, %f1373;
	mul.f32 	%f1378, %f1967, %f1374;
	mul.f32 	%f1379, %f1968, %f1375;
	mul.f32 	%f1380, %f1966, %f1374;
	mul.f32 	%f1381, %f1968, %f1376;
	mul.f32 	%f1382, %f1966, %f1375;
	mul.f32 	%f1383, %f1967, %f1376;
	mul.f32 	%f1384, %f1967, %f1375;
	mul.f32 	%f1385, %f1966, %f1376;
	sub.f32 	%f1386, %f1377, %f1378;
	sub.f32 	%f1387, %f1386, %f1379;
	fma.rn.f32 	%f1388, %f1969, %f1376, %f1387;
	sub.f32 	%f1389, %f1380, %f1381;
	add.f32 	%f1390, %f1389, %f1389;
	add.f32 	%f1391, %f1382, %f1383;
	add.f32 	%f1392, %f1391, %f1391;
	add.f32 	%f1393, %f1380, %f1381;
	add.f32 	%f1394, %f1393, %f1393;
	sub.f32 	%f1395, %f1378, %f1377;
	sub.f32 	%f1396, %f1395, %f1379;
	fma.rn.f32 	%f1397, %f1969, %f1376, %f1396;
	sub.f32 	%f1398, %f1384, %f1385;
	add.f32 	%f1399, %f1398, %f1398;
	sub.f32 	%f1400, %f1382, %f1383;
	add.f32 	%f1401, %f1400, %f1400;
	add.f32 	%f1402, %f1384, %f1385;
	add.f32 	%f1403, %f1402, %f1402;
	neg.f32 	%f1404, %f1377;
	sub.f32 	%f1405, %f1404, %f1378;
	add.f32 	%f1406, %f1379, %f1405;
	fma.rn.f32 	%f1407, %f1969, %f1376, %f1406;
	mul.f32 	%f1408, %f1960, %f1388;
	fma.rn.f32 	%f1409, %f1963, %f1390, %f1408;
	fma.rn.f32 	%f1410, %f1965, %f1392, %f1409;
	sub.f32 	%f1984, %f1970, %f1410;
	mul.f32 	%f1411, %f1963, %f1397;
	fma.rn.f32 	%f1412, %f1960, %f1394, %f1411;
	fma.rn.f32 	%f1413, %f1965, %f1399, %f1412;
	sub.f32 	%f1980, %f1971, %f1413;
	mul.f32 	%f1414, %f1963, %f1403;
	fma.rn.f32 	%f1415, %f1960, %f1401, %f1414;
	fma.rn.f32 	%f1416, %f1965, %f1407, %f1415;
	sub.f32 	%f1976, %f1972, %f1416;
	mul.f32 	%f1417, %f1959, %f1388;
	fma.rn.f32 	%f1418, %f1962, %f1390, %f1417;
	fma.rn.f32 	%f1983, %f1964, %f1392, %f1418;
	mul.f32 	%f1419, %f1962, %f1397;
	fma.rn.f32 	%f1420, %f1959, %f1394, %f1419;
	fma.rn.f32 	%f1979, %f1964, %f1399, %f1420;
	mul.f32 	%f1421, %f1962, %f1403;
	fma.rn.f32 	%f1422, %f1959, %f1401, %f1421;
	fma.rn.f32 	%f1975, %f1964, %f1407, %f1422;
	mul.f32 	%f1423, %f1958, %f1388;
	fma.rn.f32 	%f1982, %f1961, %f1390, %f1423;
	mul.f32 	%f1424, %f1961, %f1397;
	fma.rn.f32 	%f1978, %f1958, %f1394, %f1424;
	mul.f32 	%f1425, %f1961, %f1403;
	fma.rn.f32 	%f1974, %f1958, %f1401, %f1425;
	mul.f32 	%f1981, %f1957, %f1388;
	mul.f32 	%f1977, %f1957, %f1394;
	mul.f32 	%f1973, %f1957, %f1401;
	bra.uni 	$L__BB1_70;

$L__BB1_62:
	// begin inline asm
	call (%rd650), _optix_get_instance_transform_from_handle, (%rd305);
	// end inline asm

$L__BB1_63:
	// begin inline asm
	cvta.to.global.u64 %rd311, %rd650;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r355,%r356,%r357,%r358}, [%rd311];
	// end inline asm
	mov.b32 	%f1981, %r355;
	mov.b32 	%f1982, %r356;
	mov.b32 	%f1983, %r357;
	mov.b32 	%f1984, %r358;
	add.s64 	%rd315, %rd650, 16;
	// begin inline asm
	cvta.to.global.u64 %rd314, %rd315;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r359,%r360,%r361,%r362}, [%rd314];
	// end inline asm
	mov.b32 	%f1977, %r359;
	mov.b32 	%f1978, %r360;
	mov.b32 	%f1979, %r361;
	mov.b32 	%f1980, %r362;
	add.s64 	%rd318, %rd650, 32;
	// begin inline asm
	cvta.to.global.u64 %rd317, %rd318;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r363,%r364,%r365,%r366}, [%rd317];
	// end inline asm
	mov.b32 	%f1973, %r363;
	mov.b32 	%f1974, %r364;
	mov.b32 	%f1975, %r365;
	mov.b32 	%f1976, %r366;

$L__BB1_70:
	setp.eq.s32 	%p47, %r658, 1;
	@%p47 bra 	$L__BB1_72;

	mul.f32 	%f1463, %f1952, %f1982;
	fma.rn.f32 	%f1464, %f1948, %f1981, %f1463;
	fma.rn.f32 	%f493, %f1956, %f1983, %f1464;
	mul.f32 	%f1465, %f1951, %f1982;
	fma.rn.f32 	%f1466, %f1947, %f1981, %f1465;
	fma.rn.f32 	%f494, %f1955, %f1983, %f1466;
	mul.f32 	%f1467, %f1950, %f1982;
	fma.rn.f32 	%f1468, %f1946, %f1981, %f1467;
	fma.rn.f32 	%f495, %f1954, %f1983, %f1468;
	mul.f32 	%f1469, %f1949, %f1982;
	fma.rn.f32 	%f1470, %f1945, %f1981, %f1469;
	fma.rn.f32 	%f1471, %f1953, %f1983, %f1470;
	add.f32 	%f1984, %f1984, %f1471;
	mul.f32 	%f1472, %f1952, %f1978;
	fma.rn.f32 	%f1473, %f1948, %f1977, %f1472;
	fma.rn.f32 	%f497, %f1956, %f1979, %f1473;
	mul.f32 	%f1474, %f1951, %f1978;
	fma.rn.f32 	%f1475, %f1947, %f1977, %f1474;
	fma.rn.f32 	%f498, %f1955, %f1979, %f1475;
	mul.f32 	%f1476, %f1950, %f1978;
	fma.rn.f32 	%f1477, %f1946, %f1977, %f1476;
	fma.rn.f32 	%f499, %f1954, %f1979, %f1477;
	mul.f32 	%f1478, %f1949, %f1978;
	fma.rn.f32 	%f1479, %f1945, %f1977, %f1478;
	fma.rn.f32 	%f1480, %f1953, %f1979, %f1479;
	add.f32 	%f1980, %f1980, %f1480;
	mul.f32 	%f1481, %f1952, %f1974;
	fma.rn.f32 	%f1482, %f1948, %f1973, %f1481;
	fma.rn.f32 	%f501, %f1956, %f1975, %f1482;
	mul.f32 	%f1483, %f1951, %f1974;
	fma.rn.f32 	%f1484, %f1947, %f1973, %f1483;
	fma.rn.f32 	%f502, %f1955, %f1975, %f1484;
	mul.f32 	%f1485, %f1950, %f1974;
	fma.rn.f32 	%f1486, %f1946, %f1973, %f1485;
	fma.rn.f32 	%f503, %f1954, %f1975, %f1486;
	mul.f32 	%f1487, %f1949, %f1974;
	fma.rn.f32 	%f1488, %f1945, %f1973, %f1487;
	fma.rn.f32 	%f1489, %f1953, %f1975, %f1488;
	add.f32 	%f1976, %f1976, %f1489;
	mov.f32 	%f1973, %f501;
	mov.f32 	%f1974, %f502;
	mov.f32 	%f1975, %f503;
	mov.f32 	%f1977, %f497;
	mov.f32 	%f1978, %f498;
	mov.f32 	%f1979, %f499;
	mov.f32 	%f1981, %f493;
	mov.f32 	%f1982, %f494;
	mov.f32 	%f1983, %f495;

$L__BB1_72:
	add.s32 	%r658, %r658, -1;
	add.s32 	%r657, %r657, -1;
	setp.gt.s32 	%p48, %r657, 1;
	mov.f32 	%f1945, %f1984;
	mov.f32 	%f1946, %f1983;
	mov.f32 	%f1947, %f1982;
	mov.f32 	%f1948, %f1981;
	mov.f32 	%f1949, %f1980;
	mov.f32 	%f1950, %f1979;
	mov.f32 	%f1951, %f1978;
	mov.f32 	%f1952, %f1977;
	mov.f32 	%f1953, %f1976;
	mov.f32 	%f1954, %f1975;
	mov.f32 	%f1955, %f1974;
	mov.f32 	%f1956, %f1973;
	@%p48 bra 	$L__BB1_58;

$L__BB1_73:
	// begin inline asm
	call (%r501), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p49, %r501, 0;
	mov.f32 	%f2045, %f2044;
	mov.f32 	%f2040, %f2044;
	mov.f32 	%f2041, %f2043;
	mov.f32 	%f2042, %f2044;
	mov.f32 	%f2037, %f2044;
	mov.f32 	%f2038, %f2044;
	mov.f32 	%f2039, %f2043;
	@%p49 bra 	$L__BB1_92;

	// begin inline asm
	call (%r502), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1499), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p50, %r502, 0;
	@%p50 bra 	$L__BB1_92;

	mov.u32 	%r659, 0;

$L__BB1_76:
	.pragma "nounroll";
	// begin inline asm
	call (%rd424), _optix_get_transform_list_handle, (%r659);
	// end inline asm
	// begin inline asm
	call (%r505), _optix_get_transform_type_from_handle, (%rd424);
	// end inline asm
	or.b32  	%r506, %r505, 1;
	setp.eq.s32 	%p51, %r506, 3;
	@%p51 bra 	$L__BB1_82;
	bra.uni 	$L__BB1_77;

$L__BB1_82:
	setp.eq.s32 	%p54, %r505, 2;
	@%p54 bra 	$L__BB1_86;
	bra.uni 	$L__BB1_83;

$L__BB1_86:
	// begin inline asm
	call (%rd496), _optix_get_matrix_motion_transform_from_handle, (%rd424);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd498, %rd496;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r594,%r595,%r596,%r597}, [%rd498];
	// end inline asm
	add.s64 	%rd502, %rd496, 16;
	// begin inline asm
	cvta.to.global.u64 %rd501, %rd502;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r598,%r599,%r600,%r601}, [%rd501];
	// end inline asm
	add.s64 	%rd505, %rd496, 32;
	// begin inline asm
	cvta.to.global.u64 %rd504, %rd505;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r602,%r603,%r604,%r605}, [%rd504];
	// end inline asm
	add.s64 	%rd508, %rd496, 48;
	// begin inline asm
	cvta.to.global.u64 %rd507, %rd508;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r606,%r607,%r608,%r609}, [%rd507];
	// end inline asm
	add.s64 	%rd511, %rd496, 64;
	// begin inline asm
	cvta.to.global.u64 %rd510, %rd511;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r610,%r611,%r612,%r613}, [%rd510];
	// end inline asm
	add.s64 	%rd514, %rd496, 80;
	// begin inline asm
	cvta.to.global.u64 %rd513, %rd514;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r614,%r615,%r616,%r617}, [%rd513];
	// end inline asm
	add.s64 	%rd517, %rd496, 96;
	// begin inline asm
	cvta.to.global.u64 %rd516, %rd517;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r618,%r619,%r620,%r621}, [%rd516];
	// end inline asm
	add.s64 	%rd520, %rd496, 112;
	// begin inline asm
	cvta.to.global.u64 %rd519, %rd520;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r622,%r623,%r624,%r625}, [%rd519];
	// end inline asm
	mov.b32 	%f1603, %r597;
	mov.b32 	%f1604, %r598;
	and.b32  	%r638, %r596, 65535;
	add.s32 	%r639, %r638, -1;
	cvt.rn.f32.s32 	%f1605, %r639;
	sub.f32 	%f1606, %f1499, %f1603;
	mul.f32 	%f1607, %f1606, %f1605;
	sub.f32 	%f1608, %f1604, %f1603;
	div.rn.f32 	%f1609, %f1607, %f1608;
	min.f32 	%f1610, %f1605, %f1609;
	mov.f32 	%f1611, 0f00000000;
	max.f32 	%f1612, %f1611, %f1610;
	cvt.rmi.f32.f32 	%f1613, %f1612;
	sub.f32 	%f588, %f1612, %f1613;
	cvt.rzi.s32.f32 	%r640, %f1613;
	cvt.s64.s32 	%rd37, %r640;
	mul.wide.s32 	%rd531, %r640, 48;
	add.s64 	%rd523, %rd505, %rd531;
	// begin inline asm
	cvta.to.global.u64 %rd522, %rd523;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r626,%r627,%r628,%r629}, [%rd522];
	// end inline asm
	mov.b32 	%f2034, %r626;
	mov.b32 	%f2035, %r627;
	mov.b32 	%f2036, %r628;
	add.s64 	%rd526, %rd523, 16;
	// begin inline asm
	cvta.to.global.u64 %rd525, %rd526;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r630,%r631,%r632,%r633}, [%rd525];
	// end inline asm
	mov.b32 	%f2031, %r630;
	mov.b32 	%f2032, %r631;
	mov.b32 	%f2033, %r632;
	add.s64 	%rd529, %rd523, 32;
	// begin inline asm
	cvta.to.global.u64 %rd528, %rd529;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r634,%r635,%r636,%r637}, [%rd528];
	// end inline asm
	mov.b32 	%f2028, %r634;
	mov.b32 	%f2029, %r635;
	mov.b32 	%f2030, %r636;
	setp.leu.f32 	%p56, %f588, 0f00000000;
	@%p56 bra 	$L__BB1_88;

	mov.f32 	%f1614, 0f3F800000;
	sub.f32 	%f1615, %f1614, %f588;
	mul.lo.s64 	%rd541, %rd37, 48;
	add.s64 	%rd542, %rd496, %rd541;
	add.s64 	%rd533, %rd542, 80;
	// begin inline asm
	cvta.to.global.u64 %rd532, %rd533;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r641,%r642,%r643,%r644}, [%rd532];
	// end inline asm
	mov.b32 	%f1616, %r641;
	mov.b32 	%f1617, %r642;
	mov.b32 	%f1618, %r643;
	mul.f32 	%f1619, %f588, %f1616;
	mul.f32 	%f1620, %f588, %f1617;
	mul.f32 	%f1621, %f588, %f1618;
	fma.rn.f32 	%f2034, %f1615, %f2034, %f1619;
	fma.rn.f32 	%f2035, %f1615, %f2035, %f1620;
	fma.rn.f32 	%f2036, %f1615, %f2036, %f1621;
	add.s64 	%rd536, %rd542, 96;
	// begin inline asm
	cvta.to.global.u64 %rd535, %rd536;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r645,%r646,%r647,%r648}, [%rd535];
	// end inline asm
	mov.b32 	%f1622, %r645;
	mov.b32 	%f1623, %r646;
	mov.b32 	%f1624, %r647;
	mul.f32 	%f1625, %f588, %f1622;
	mul.f32 	%f1626, %f588, %f1623;
	mul.f32 	%f1627, %f588, %f1624;
	fma.rn.f32 	%f2031, %f1615, %f2031, %f1625;
	fma.rn.f32 	%f2032, %f1615, %f2032, %f1626;
	fma.rn.f32 	%f2033, %f1615, %f2033, %f1627;
	add.s64 	%rd539, %rd542, 112;
	// begin inline asm
	cvta.to.global.u64 %rd538, %rd539;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r649,%r650,%r651,%r652}, [%rd538];
	// end inline asm
	mov.b32 	%f1628, %r649;
	mov.b32 	%f1629, %r650;
	mov.b32 	%f1630, %r651;
	mul.f32 	%f1631, %f588, %f1628;
	mul.f32 	%f1632, %f588, %f1629;
	mul.f32 	%f1633, %f588, %f1630;
	fma.rn.f32 	%f2028, %f1615, %f2028, %f1631;
	fma.rn.f32 	%f2029, %f1615, %f2029, %f1632;
	fma.rn.f32 	%f2030, %f1615, %f2030, %f1633;
	bra.uni 	$L__BB1_88;

$L__BB1_77:
	mov.f32 	%f2037, 0f00000000;
	mov.f32 	%f2039, 0f3F800000;
	setp.eq.s32 	%p52, %r505, 4;
	@%p52 bra 	$L__BB1_80;

	setp.ne.s32 	%p53, %r505, 1;
	mov.f32 	%f2038, %f2037;
	mov.f32 	%f2040, %f2037;
	mov.f32 	%f2041, %f2039;
	mov.f32 	%f2042, %f2037;
	mov.f32 	%f2043, %f2039;
	mov.f32 	%f2044, %f2037;
	mov.f32 	%f2045, %f2037;
	@%p53 bra 	$L__BB1_89;

	// begin inline asm
	call (%rd426), _optix_get_static_transform_from_handle, (%rd424);
	// end inline asm
	add.s64 	%rd651, %rd426, 64;
	bra.uni 	$L__BB1_81;

$L__BB1_83:
	// begin inline asm
	call (%rd439), _optix_get_srt_motion_transform_from_handle, (%rd424);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd441, %rd439;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r519,%r520,%r521,%r522}, [%rd441];
	// end inline asm
	add.s64 	%rd445, %rd439, 16;
	// begin inline asm
	cvta.to.global.u64 %rd444, %rd445;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r523,%r524,%r525,%r526}, [%rd444];
	// end inline asm
	add.s64 	%rd448, %rd439, 32;
	// begin inline asm
	cvta.to.global.u64 %rd447, %rd448;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r527,%r528,%r529,%r530}, [%rd447];
	// end inline asm
	add.s64 	%rd451, %rd439, 48;
	// begin inline asm
	cvta.to.global.u64 %rd450, %rd451;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r531,%r532,%r533,%r534}, [%rd450];
	// end inline asm
	add.s64 	%rd454, %rd439, 64;
	// begin inline asm
	cvta.to.global.u64 %rd453, %rd454;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r535,%r536,%r537,%r538}, [%rd453];
	// end inline asm
	add.s64 	%rd457, %rd439, 80;
	// begin inline asm
	cvta.to.global.u64 %rd456, %rd457;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r539,%r540,%r541,%r542}, [%rd456];
	// end inline asm
	add.s64 	%rd460, %rd439, 96;
	// begin inline asm
	cvta.to.global.u64 %rd459, %rd460;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r543,%r544,%r545,%r546}, [%rd459];
	// end inline asm
	add.s64 	%rd463, %rd439, 112;
	// begin inline asm
	cvta.to.global.u64 %rd462, %rd463;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r547,%r548,%r549,%r550}, [%rd462];
	// end inline asm
	add.s64 	%rd466, %rd439, 128;
	// begin inline asm
	cvta.to.global.u64 %rd465, %rd466;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r551,%r552,%r553,%r554}, [%rd465];
	// end inline asm
	add.s64 	%rd469, %rd439, 144;
	// begin inline asm
	cvta.to.global.u64 %rd468, %rd469;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r555,%r556,%r557,%r558}, [%rd468];
	// end inline asm
	mov.b32 	%f1511, %r522;
	mov.b32 	%f1512, %r523;
	and.b32  	%r575, %r521, 65535;
	add.s32 	%r576, %r575, -1;
	cvt.rn.f32.s32 	%f1513, %r576;
	sub.f32 	%f1514, %f1499, %f1511;
	mul.f32 	%f1515, %f1514, %f1513;
	sub.f32 	%f1516, %f1512, %f1511;
	div.rn.f32 	%f1517, %f1515, %f1516;
	min.f32 	%f1518, %f1513, %f1517;
	mov.f32 	%f1519, 0f00000000;
	max.f32 	%f1520, %f1519, %f1518;
	cvt.rmi.f32.f32 	%f1521, %f1520;
	sub.f32 	%f548, %f1520, %f1521;
	cvt.rzi.s32.f32 	%r577, %f1521;
	mul.wide.s32 	%rd483, %r577, 64;
	add.s64 	%rd472, %rd448, %rd483;
	// begin inline asm
	cvta.to.global.u64 %rd471, %rd472;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r559,%r560,%r561,%r562}, [%rd471];
	// end inline asm
	mov.b32 	%f2018, %r559;
	mov.b32 	%f2019, %r560;
	mov.b32 	%f2020, %r561;
	add.s64 	%rd475, %rd472, 16;
	// begin inline asm
	cvta.to.global.u64 %rd474, %rd475;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r563,%r564,%r565,%r566}, [%rd474];
	// end inline asm
	mov.b32 	%f2021, %r563;
	mov.b32 	%f2022, %r564;
	mov.b32 	%f2023, %r566;
	add.s64 	%rd478, %rd472, 32;
	// begin inline asm
	cvta.to.global.u64 %rd477, %rd478;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r567,%r568,%r569,%r570}, [%rd477];
	// end inline asm
	mov.b32 	%f2024, %r568;
	mov.b32 	%f2025, %r569;
	mov.b32 	%f2026, %r570;
	add.s64 	%rd481, %rd472, 48;
	// begin inline asm
	cvta.to.global.u64 %rd480, %rd481;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r571,%r572,%r573,%r574}, [%rd480];
	// end inline asm
	mov.b32 	%f2027, %r571;
	setp.leu.f32 	%p55, %f548, 0f00000000;
	@%p55 bra 	$L__BB1_85;

	mov.f32 	%f1522, 0f3F800000;
	sub.f32 	%f1523, %f1522, %f548;
	add.s64 	%rd485, %rd472, 64;
	// begin inline asm
	cvta.to.global.u64 %rd484, %rd485;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r578,%r579,%r580,%r581}, [%rd484];
	// end inline asm
	mov.b32 	%f1524, %r578;
	mov.b32 	%f1525, %r579;
	mov.b32 	%f1526, %r580;
	mul.f32 	%f1527, %f548, %f1524;
	mul.f32 	%f1528, %f548, %f1525;
	mul.f32 	%f1529, %f548, %f1526;
	fma.rn.f32 	%f2018, %f1523, %f2018, %f1527;
	fma.rn.f32 	%f2019, %f1523, %f2019, %f1528;
	fma.rn.f32 	%f2020, %f1523, %f2020, %f1529;
	add.s64 	%rd488, %rd472, 80;
	// begin inline asm
	cvta.to.global.u64 %rd487, %rd488;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r582,%r583,%r584,%r585}, [%rd487];
	// end inline asm
	mov.b32 	%f1530, %r582;
	mov.b32 	%f1531, %r583;
	mov.b32 	%f1532, %r585;
	mul.f32 	%f1533, %f548, %f1530;
	mul.f32 	%f1534, %f548, %f1531;
	mul.f32 	%f1535, %f548, %f1532;
	fma.rn.f32 	%f2021, %f1523, %f2021, %f1533;
	fma.rn.f32 	%f2022, %f1523, %f2022, %f1534;
	fma.rn.f32 	%f2023, %f1523, %f2023, %f1535;
	add.s64 	%rd491, %rd472, 96;
	// begin inline asm
	cvta.to.global.u64 %rd490, %rd491;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r586,%r587,%r588,%r589}, [%rd490];
	// end inline asm
	mov.b32 	%f1536, %r587;
	mov.b32 	%f1537, %r588;
	mov.b32 	%f1538, %r589;
	mul.f32 	%f1539, %f548, %f1536;
	mul.f32 	%f1540, %f548, %f1537;
	mul.f32 	%f1541, %f548, %f1538;
	fma.rn.f32 	%f1542, %f1523, %f2024, %f1539;
	fma.rn.f32 	%f1543, %f1523, %f2025, %f1540;
	fma.rn.f32 	%f1544, %f1523, %f2026, %f1541;
	add.s64 	%rd494, %rd472, 112;
	// begin inline asm
	cvta.to.global.u64 %rd493, %rd494;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r590,%r591,%r592,%r593}, [%rd493];
	// end inline asm
	mov.b32 	%f1545, %r590;
	mul.f32 	%f1546, %f548, %f1545;
	fma.rn.f32 	%f1547, %f1523, %f2027, %f1546;
	mul.f32 	%f1548, %f1543, %f1543;
	fma.rn.f32 	%f1549, %f1542, %f1542, %f1548;
	fma.rn.f32 	%f1550, %f1544, %f1544, %f1549;
	fma.rn.f32 	%f1551, %f1547, %f1547, %f1550;
	sqrt.rn.f32 	%f1552, %f1551;
	rcp.rn.f32 	%f1553, %f1552;
	mul.f32 	%f2024, %f1542, %f1553;
	mul.f32 	%f2025, %f1543, %f1553;
	mul.f32 	%f2026, %f1544, %f1553;
	mul.f32 	%f2027, %f1553, %f1547;

$L__BB1_85:
	mul.f32 	%f1554, %f2025, %f2025;
	fma.rn.f32 	%f1555, %f2024, %f2024, %f1554;
	fma.rn.f32 	%f1556, %f2026, %f2026, %f1555;
	fma.rn.f32 	%f1557, %f2027, %f2027, %f1556;
	rcp.rn.f32 	%f1558, %f1557;
	mul.f32 	%f1559, %f2024, %f1558;
	mul.f32 	%f1560, %f2025, %f1558;
	mul.f32 	%f1561, %f2026, %f1558;
	mul.f32 	%f1562, %f2027, %f1558;
	mul.f32 	%f1563, %f2024, %f1559;
	mul.f32 	%f1564, %f2025, %f1560;
	mul.f32 	%f1565, %f2026, %f1561;
	mul.f32 	%f1566, %f2024, %f1560;
	mul.f32 	%f1567, %f2026, %f1562;
	mul.f32 	%f1568, %f2024, %f1561;
	mul.f32 	%f1569, %f2025, %f1562;
	mul.f32 	%f1570, %f2025, %f1561;
	mul.f32 	%f1571, %f2024, %f1562;
	sub.f32 	%f1572, %f1563, %f1564;
	sub.f32 	%f1573, %f1572, %f1565;
	fma.rn.f32 	%f1574, %f2027, %f1562, %f1573;
	sub.f32 	%f1575, %f1566, %f1567;
	add.f32 	%f1576, %f1575, %f1575;
	add.f32 	%f1577, %f1568, %f1569;
	add.f32 	%f1578, %f1577, %f1577;
	add.f32 	%f1579, %f1566, %f1567;
	add.f32 	%f1580, %f1579, %f1579;
	sub.f32 	%f1581, %f1564, %f1563;
	sub.f32 	%f1582, %f1581, %f1565;
	fma.rn.f32 	%f1583, %f2027, %f1562, %f1582;
	sub.f32 	%f1584, %f1570, %f1571;
	add.f32 	%f1585, %f1584, %f1584;
	sub.f32 	%f1586, %f1568, %f1569;
	add.f32 	%f1587, %f1586, %f1586;
	add.f32 	%f1588, %f1570, %f1571;
	add.f32 	%f1589, %f1588, %f1588;
	neg.f32 	%f1590, %f1563;
	sub.f32 	%f1591, %f1590, %f1564;
	add.f32 	%f1592, %f1565, %f1591;
	fma.rn.f32 	%f1593, %f2027, %f1562, %f1592;
	mul.f32 	%f1594, %f2020, %f1574;
	fma.rn.f32 	%f1595, %f2022, %f1576, %f1594;
	fma.rn.f32 	%f2036, %f2023, %f1578, %f1595;
	mul.f32 	%f1596, %f2022, %f1583;
	fma.rn.f32 	%f1597, %f2020, %f1580, %f1596;
	fma.rn.f32 	%f2033, %f2023, %f1585, %f1597;
	mul.f32 	%f1598, %f2022, %f1589;
	fma.rn.f32 	%f1599, %f2020, %f1587, %f1598;
	fma.rn.f32 	%f2030, %f2023, %f1593, %f1599;
	mul.f32 	%f1600, %f2019, %f1574;
	fma.rn.f32 	%f2035, %f2021, %f1576, %f1600;
	mul.f32 	%f1601, %f2021, %f1583;
	fma.rn.f32 	%f2032, %f2019, %f1580, %f1601;
	mul.f32 	%f1602, %f2021, %f1589;
	fma.rn.f32 	%f2029, %f2019, %f1587, %f1602;
	mul.f32 	%f2034, %f2018, %f1574;
	mul.f32 	%f2031, %f2018, %f1580;
	mul.f32 	%f2028, %f2018, %f1587;

$L__BB1_88:
	mul.f32 	%f1634, %f2029, %f2033;
	mul.f32 	%f1635, %f2030, %f2032;
	sub.f32 	%f1636, %f1635, %f1634;
	mul.f32 	%f1637, %f2034, %f1636;
	mul.f32 	%f1638, %f2028, %f2033;
	mul.f32 	%f1639, %f2030, %f2031;
	sub.f32 	%f1640, %f1639, %f1638;
	mul.f32 	%f1641, %f1640, %f2035;
	sub.f32 	%f1642, %f1637, %f1641;
	mul.f32 	%f1643, %f2028, %f2032;
	mul.f32 	%f1644, %f2029, %f2031;
	sub.f32 	%f1645, %f1644, %f1643;
	fma.rn.f32 	%f1646, %f1645, %f2036, %f1642;
	rcp.rn.f32 	%f1647, %f1646;
	mul.f32 	%f2043, %f1636, %f1647;
	mul.f32 	%f1648, %f2030, %f2035;
	mul.f32 	%f1649, %f2029, %f2036;
	sub.f32 	%f1650, %f1649, %f1648;
	mul.f32 	%f2044, %f1650, %f1647;
	mul.f32 	%f1651, %f2032, %f2036;
	mul.f32 	%f1652, %f2033, %f2035;
	sub.f32 	%f1653, %f1652, %f1651;
	mul.f32 	%f2045, %f1653, %f1647;
	sub.f32 	%f1654, %f1638, %f1639;
	mul.f32 	%f2040, %f1654, %f1647;
	mul.f32 	%f1655, %f2028, %f2036;
	mul.f32 	%f1656, %f2030, %f2034;
	sub.f32 	%f1657, %f1656, %f1655;
	mul.f32 	%f2041, %f1657, %f1647;
	mul.f32 	%f1658, %f2033, %f2034;
	mul.f32 	%f1659, %f2031, %f2036;
	sub.f32 	%f1660, %f1659, %f1658;
	mul.f32 	%f2042, %f1660, %f1647;
	mul.f32 	%f2037, %f1645, %f1647;
	mul.f32 	%f1661, %f2029, %f2034;
	mul.f32 	%f1662, %f2028, %f2035;
	sub.f32 	%f1663, %f1662, %f1661;
	mul.f32 	%f2038, %f1663, %f1647;
	mul.f32 	%f1664, %f2031, %f2035;
	mul.f32 	%f1665, %f2032, %f2034;
	sub.f32 	%f1666, %f1665, %f1664;
	mul.f32 	%f2039, %f1666, %f1647;
	bra.uni 	$L__BB1_89;

$L__BB1_80:
	// begin inline asm
	call (%rd651), _optix_get_instance_inverse_transform_from_handle, (%rd424);
	// end inline asm

$L__BB1_81:
	// begin inline asm
	cvta.to.global.u64 %rd430, %rd651;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r507,%r508,%r509,%r510}, [%rd430];
	// end inline asm
	mov.b32 	%f2043, %r507;
	mov.b32 	%f2044, %r508;
	mov.b32 	%f2045, %r509;
	add.s64 	%rd434, %rd651, 16;
	// begin inline asm
	cvta.to.global.u64 %rd433, %rd434;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r511,%r512,%r513,%r514}, [%rd433];
	// end inline asm
	mov.b32 	%f2040, %r511;
	mov.b32 	%f2041, %r512;
	mov.b32 	%f2042, %r513;
	add.s64 	%rd437, %rd651, 32;
	// begin inline asm
	cvta.to.global.u64 %rd436, %rd437;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r515,%r516,%r517,%r518}, [%rd436];
	// end inline asm
	mov.b32 	%f2037, %r515;
	mov.b32 	%f2038, %r516;
	mov.b32 	%f2039, %r517;

$L__BB1_89:
	setp.eq.s32 	%p57, %r659, 0;
	@%p57 bra 	$L__BB1_91;

	mul.f32 	%f1667, %f2014, %f2044;
	fma.rn.f32 	%f1668, %f2011, %f2043, %f1667;
	fma.rn.f32 	%f634, %f2017, %f2045, %f1668;
	mul.f32 	%f1669, %f2013, %f2044;
	fma.rn.f32 	%f1670, %f2010, %f2043, %f1669;
	fma.rn.f32 	%f635, %f2016, %f2045, %f1670;
	mul.f32 	%f1671, %f2012, %f2044;
	fma.rn.f32 	%f1672, %f2009, %f2043, %f1671;
	fma.rn.f32 	%f2045, %f2015, %f2045, %f1672;
	mul.f32 	%f1673, %f2014, %f2041;
	fma.rn.f32 	%f1674, %f2011, %f2040, %f1673;
	fma.rn.f32 	%f637, %f2017, %f2042, %f1674;
	mul.f32 	%f1675, %f2013, %f2041;
	fma.rn.f32 	%f1676, %f2010, %f2040, %f1675;
	fma.rn.f32 	%f638, %f2016, %f2042, %f1676;
	mul.f32 	%f1677, %f2012, %f2041;
	fma.rn.f32 	%f1678, %f2009, %f2040, %f1677;
	fma.rn.f32 	%f2042, %f2015, %f2042, %f1678;
	mul.f32 	%f1679, %f2014, %f2038;
	fma.rn.f32 	%f1680, %f2011, %f2037, %f1679;
	fma.rn.f32 	%f640, %f2017, %f2039, %f1680;
	mul.f32 	%f1681, %f2013, %f2038;
	fma.rn.f32 	%f1682, %f2010, %f2037, %f1681;
	fma.rn.f32 	%f641, %f2016, %f2039, %f1682;
	mul.f32 	%f1683, %f2012, %f2038;
	fma.rn.f32 	%f1684, %f2009, %f2037, %f1683;
	fma.rn.f32 	%f2039, %f2015, %f2039, %f1684;
	mov.f32 	%f2037, %f640;
	mov.f32 	%f2038, %f641;
	mov.f32 	%f2040, %f637;
	mov.f32 	%f2041, %f638;
	mov.f32 	%f2043, %f634;
	mov.f32 	%f2044, %f635;

$L__BB1_91:
	add.s32 	%r659, %r659, 1;
	setp.lt.u32 	%p58, %r659, %r502;
	mov.f32 	%f2009, %f2045;
	mov.f32 	%f2010, %f2044;
	mov.f32 	%f2011, %f2043;
	mov.f32 	%f2012, %f2042;
	mov.f32 	%f2013, %f2041;
	mov.f32 	%f2014, %f2040;
	mov.f32 	%f2015, %f2039;
	mov.f32 	%f2016, %f2038;
	mov.f32 	%f2017, %f2037;
	@%p58 bra 	$L__BB1_76;

$L__BB1_92:
	fma.rn.f32 	%f1685, %f2100, %f1981, %f1984;
	fma.rn.f32 	%f1686, %f2101, %f1982, %f1685;
	fma.rn.f32 	%f1687, %f2100, %f1977, %f1980;
	fma.rn.f32 	%f1688, %f2101, %f1978, %f1687;
	fma.rn.f32 	%f1689, %f2100, %f1973, %f1976;
	fma.rn.f32 	%f1690, %f2101, %f1974, %f1689;
	fma.rn.f32 	%f2100, %f2102, %f1983, %f1686;
	fma.rn.f32 	%f2101, %f2102, %f1979, %f1688;
	fma.rn.f32 	%f2102, %f2102, %f1975, %f1690;
	ld.const.u64 	%rd543, [params+112];
	setp.eq.s64 	%p59, %rd543, 0;
	mov.f32 	%f2064, %f2067;
	mov.f32 	%f2065, %f2068;
	mov.f32 	%f2066, %f2069;
	@%p59 bra 	$L__BB1_94;

	mul.f32 	%f1691, %f2067, %f2043;
	fma.rn.f32 	%f1692, %f2068, %f2040, %f1691;
	mul.f32 	%f1693, %f2067, %f2044;
	fma.rn.f32 	%f1694, %f2068, %f2041, %f1693;
	mul.f32 	%f1695, %f2067, %f2045;
	fma.rn.f32 	%f1696, %f2068, %f2042, %f1695;
	fma.rn.f32 	%f1697, %f2069, %f2037, %f1692;
	fma.rn.f32 	%f1698, %f2069, %f2038, %f1694;
	fma.rn.f32 	%f1699, %f2069, %f2039, %f1696;
	mul.f32 	%f1700, %f1697, %f1697;
	fma.rn.f32 	%f1701, %f1698, %f1698, %f1700;
	fma.rn.f32 	%f1702, %f1699, %f1699, %f1701;
	sqrt.rn.f32 	%f1703, %f1702;
	div.rn.f32 	%f2064, %f1697, %f1703;
	div.rn.f32 	%f2065, %f1698, %f1703;
	div.rn.f32 	%f2066, %f1699, %f1703;

$L__BB1_94:
	ld.const.u64 	%rd544, [params+136];
	setp.eq.s64 	%p60, %rd544, 0;
	@%p60 bra 	$L__BB1_96;

	mul.f32 	%f1704, %f2067, %f2043;
	fma.rn.f32 	%f1705, %f2068, %f2040, %f1704;
	mul.f32 	%f1706, %f2067, %f2044;
	fma.rn.f32 	%f1707, %f2068, %f2041, %f1706;
	mul.f32 	%f1708, %f2067, %f2045;
	fma.rn.f32 	%f1709, %f2068, %f2042, %f1708;
	fma.rn.f32 	%f1710, %f2069, %f2037, %f1705;
	fma.rn.f32 	%f1711, %f2069, %f2038, %f1707;
	fma.rn.f32 	%f1712, %f2069, %f2039, %f1709;
	mul.f32 	%f1713, %f1710, %f1710;
	fma.rn.f32 	%f1714, %f1711, %f1711, %f1713;
	fma.rn.f32 	%f1715, %f1712, %f1712, %f1714;
	sqrt.rn.f32 	%f1716, %f1715;
	div.rn.f32 	%f2067, %f1710, %f1716;
	div.rn.f32 	%f2068, %f1711, %f1716;
	div.rn.f32 	%f2069, %f1712, %f1716;

$L__BB1_96:
	mov.f32 	%f2099, %f2069;
	mov.f32 	%f2098, %f2068;
	mov.f32 	%f2097, %f2067;
	ld.const.u64 	%rd545, [params+184];
	setp.eq.s64 	%p61, %rd545, 0;
	@%p61 bra 	$L__BB1_98;

	mul.f32 	%f1717, %f2073, %f1981;
	fma.rn.f32 	%f1718, %f2074, %f1982, %f1717;
	mul.f32 	%f1719, %f2073, %f1977;
	fma.rn.f32 	%f1720, %f2074, %f1978, %f1719;
	mul.f32 	%f1721, %f2073, %f1973;
	fma.rn.f32 	%f1722, %f2074, %f1974, %f1721;
	fma.rn.f32 	%f2073, %f2075, %f1983, %f1718;
	fma.rn.f32 	%f2074, %f2075, %f1979, %f1720;
	fma.rn.f32 	%f2075, %f2075, %f1975, %f1722;
	mul.f32 	%f1723, %f2070, %f1981;
	fma.rn.f32 	%f1724, %f2071, %f1982, %f1723;
	mul.f32 	%f1725, %f2070, %f1977;
	fma.rn.f32 	%f1726, %f2071, %f1978, %f1725;
	mul.f32 	%f1727, %f2070, %f1973;
	fma.rn.f32 	%f1728, %f2071, %f1974, %f1727;
	fma.rn.f32 	%f2070, %f2072, %f1983, %f1724;
	fma.rn.f32 	%f2071, %f2072, %f1979, %f1726;
	fma.rn.f32 	%f2072, %f2072, %f1975, %f1728;

$L__BB1_98:
	ld.const.u64 	%rd546, [params+232];
	ld.const.u64 	%rd547, [params+280];
	or.b64  	%rd548, %rd546, %rd547;
	setp.eq.s64 	%p62, %rd548, 0;
	mov.f32 	%f2082, 0f00000000;
	mov.f32 	%f2083, %f2082;
	mov.f32 	%f2084, %f2082;
	@%p62 bra 	$L__BB1_100;

	mul.f32 	%f1732, %f2097, %f1981;
	fma.rn.f32 	%f1733, %f2098, %f1977, %f1732;
	mul.f32 	%f1734, %f2097, %f1982;
	fma.rn.f32 	%f1735, %f2098, %f1978, %f1734;
	mul.f32 	%f1736, %f2097, %f1983;
	fma.rn.f32 	%f1737, %f2098, %f1979, %f1736;
	fma.rn.f32 	%f1738, %f2099, %f1973, %f1733;
	fma.rn.f32 	%f1739, %f2099, %f1974, %f1735;
	fma.rn.f32 	%f1740, %f2099, %f1975, %f1737;
	mul.f32 	%f1741, %f1738, %f1738;
	fma.rn.f32 	%f1742, %f1739, %f1739, %f1741;
	fma.rn.f32 	%f1743, %f1740, %f1740, %f1742;
	sqrt.rn.f32 	%f1744, %f1743;
	div.rn.f32 	%f1745, %f1738, %f1744;
	div.rn.f32 	%f1746, %f1739, %f1744;
	div.rn.f32 	%f1747, %f1740, %f1744;
	mul.f32 	%f1748, %f1745, %f2043;
	mul.f32 	%f1749, %f1745, %f2044;
	mul.f32 	%f1750, %f1745, %f2045;
	fma.rn.f32 	%f1751, %f1746, %f2040, %f1748;
	fma.rn.f32 	%f1752, %f1746, %f2041, %f1749;
	fma.rn.f32 	%f1753, %f1746, %f2042, %f1750;
	fma.rn.f32 	%f1754, %f1747, %f2037, %f1751;
	fma.rn.f32 	%f1755, %f1747, %f2038, %f1752;
	fma.rn.f32 	%f1756, %f1747, %f2039, %f1753;
	mul.f32 	%f1757, %f1754, %f1754;
	fma.rn.f32 	%f1758, %f1755, %f1755, %f1757;
	fma.rn.f32 	%f1759, %f1756, %f1756, %f1758;
	sqrt.rn.f32 	%f1760, %f1759;
	rcp.rn.f32 	%f1761, %f1760;
	mul.f32 	%f1762, %f1761, %f1754;
	mul.f32 	%f1763, %f1761, %f1755;
	mul.f32 	%f1764, %f1761, %f1756;
	mul.f32 	%f1765, %f2079, %f2043;
	fma.rn.f32 	%f1766, %f2080, %f2040, %f1765;
	mul.f32 	%f1767, %f2079, %f2044;
	fma.rn.f32 	%f1768, %f2080, %f2041, %f1767;
	mul.f32 	%f1769, %f2079, %f2045;
	fma.rn.f32 	%f1770, %f2080, %f2042, %f1769;
	fma.rn.f32 	%f1771, %f2081, %f2037, %f1766;
	fma.rn.f32 	%f1772, %f2081, %f2038, %f1768;
	fma.rn.f32 	%f1773, %f2081, %f2039, %f1770;
	mul.f32 	%f1774, %f1771, %f1761;
	mul.f32 	%f1775, %f1772, %f1761;
	mul.f32 	%f1776, %f1773, %f1761;
	mul.f32 	%f1777, %f2043, 0f00000000;
	mov.f32 	%f1778, 0f00000000;
	fma.rn.f32 	%f1779, %f1778, %f2040, %f1777;
	mul.f32 	%f1780, %f2044, 0f00000000;
	fma.rn.f32 	%f1781, %f1778, %f2041, %f1780;
	mul.f32 	%f1782, %f2045, 0f00000000;
	fma.rn.f32 	%f1783, %f1778, %f2042, %f1782;
	fma.rn.f32 	%f1784, %f1778, %f2037, %f1779;
	fma.rn.f32 	%f1785, %f1778, %f2038, %f1781;
	fma.rn.f32 	%f1786, %f1778, %f2039, %f1783;
	mul.f32 	%f1787, %f1784, %f1761;
	mul.f32 	%f1788, %f1785, %f1761;
	mul.f32 	%f1789, %f1786, %f1761;
	mul.f32 	%f1790, %f1762, %f1774;
	fma.rn.f32 	%f1791, %f1763, %f1775, %f1790;
	fma.rn.f32 	%f1792, %f1764, %f1776, %f1791;
	mul.f32 	%f1793, %f1762, %f1792;
	mul.f32 	%f1794, %f1763, %f1792;
	mul.f32 	%f1795, %f1764, %f1792;
	sub.f32 	%f2079, %f1774, %f1793;
	sub.f32 	%f2080, %f1775, %f1794;
	sub.f32 	%f2081, %f1776, %f1795;
	mul.f32 	%f1796, %f1762, %f1787;
	fma.rn.f32 	%f1797, %f1763, %f1788, %f1796;
	fma.rn.f32 	%f1798, %f1764, %f1789, %f1797;
	mul.f32 	%f1799, %f1762, %f1798;
	mul.f32 	%f1800, %f1763, %f1798;
	mul.f32 	%f1801, %f1764, %f1798;
	sub.f32 	%f2082, %f1787, %f1799;
	sub.f32 	%f2083, %f1788, %f1800;
	sub.f32 	%f2084, %f1789, %f1801;

$L__BB1_100:
	st.global.u32 	[%rd23], %r348;
	mov.f32 	%f2067, %f2064;
	mov.f32 	%f2068, %f2065;
	mov.f32 	%f2069, %f2066;

$L__BB1_101:
	ld.const.u64 	%rd549, [params+328];
	cvta.to.global.u64 	%rd550, %rd549;
	shl.b64 	%rd551, %rd22, 3;
	add.s64 	%rd552, %rd550, %rd551;
	st.global.u64 	[%rd552], %rd21;
	ld.const.u64 	%rd553, [params+336];
	cvta.to.global.u64 	%rd554, %rd553;
	shl.b64 	%rd555, %rd22, 2;
	add.s64 	%rd556, %rd554, %rd555;
	mov.u32 	%r653, 0;
	st.global.u32 	[%rd556], %r653;
	ld.const.u64 	%rd557, [params+160];
	cvta.to.global.u64 	%rd558, %rd557;
	add.s64 	%rd559, %rd558, %rd555;
	st.global.f32 	[%rd559], %f2100;
	ld.const.u64 	%rd560, [params+168];
	cvta.to.global.u64 	%rd561, %rd560;
	add.s64 	%rd562, %rd561, %rd555;
	st.global.f32 	[%rd562], %f2101;
	ld.const.u64 	%rd563, [params+176];
	cvta.to.global.u64 	%rd564, %rd563;
	add.s64 	%rd565, %rd564, %rd555;
	st.global.f32 	[%rd565], %f2102;
	ld.const.u64 	%rd566, [params+72];
	cvta.to.global.u64 	%rd567, %rd566;
	add.s64 	%rd568, %rd567, %rd555;
	st.global.f32 	[%rd568], %f1169;
	ld.const.u64 	%rd38, [params+96];
	setp.eq.s64 	%p63, %rd38, 0;
	@%p63 bra 	$L__BB1_103;

	cvta.to.global.u64 	%rd569, %rd38;
	add.s64 	%rd571, %rd569, %rd555;
	mul.f32 	%f1802, %f353, 0f3E22F983;
	st.global.f32 	[%rd571], %f1802;
	ld.const.u64 	%rd572, [params+104];
	cvta.to.global.u64 	%rd573, %rd572;
	add.s64 	%rd574, %rd573, %rd555;
	st.global.f32 	[%rd574], %f354;

$L__BB1_103:
	ld.const.u64 	%rd39, [params+112];
	setp.eq.s64 	%p64, %rd39, 0;
	@%p64 bra 	$L__BB1_105;

	cvta.to.global.u64 	%rd575, %rd39;
	add.s64 	%rd577, %rd575, %rd555;
	st.global.f32 	[%rd577], %f2067;
	ld.const.u64 	%rd578, [params+120];
	cvta.to.global.u64 	%rd579, %rd578;
	add.s64 	%rd580, %rd579, %rd555;
	st.global.f32 	[%rd580], %f2068;
	ld.const.u64 	%rd581, [params+128];
	cvta.to.global.u64 	%rd582, %rd581;
	add.s64 	%rd583, %rd582, %rd555;
	st.global.f32 	[%rd583], %f2069;

$L__BB1_105:
	ld.const.u64 	%rd40, [params+136];
	setp.eq.s64 	%p65, %rd40, 0;
	@%p65 bra 	$L__BB1_107;

	cvta.to.global.u64 	%rd584, %rd40;
	add.s64 	%rd586, %rd584, %rd555;
	st.global.f32 	[%rd586], %f2097;
	ld.const.u64 	%rd587, [params+144];
	cvta.to.global.u64 	%rd588, %rd587;
	add.s64 	%rd589, %rd588, %rd555;
	st.global.f32 	[%rd589], %f2098;
	ld.const.u64 	%rd590, [params+152];
	cvta.to.global.u64 	%rd591, %rd590;
	add.s64 	%rd592, %rd591, %rd555;
	st.global.f32 	[%rd592], %f2099;

$L__BB1_107:
	ld.const.u64 	%rd41, [params+184];
	setp.eq.s64 	%p66, %rd41, 0;
	@%p66 bra 	$L__BB1_109;

	cvta.to.global.u64 	%rd593, %rd41;
	add.s64 	%rd595, %rd593, %rd555;
	st.global.f32 	[%rd595], %f2073;
	ld.const.u64 	%rd596, [params+192];
	cvta.to.global.u64 	%rd597, %rd596;
	add.s64 	%rd598, %rd597, %rd555;
	st.global.f32 	[%rd598], %f2074;
	ld.const.u64 	%rd599, [params+200];
	cvta.to.global.u64 	%rd600, %rd599;
	add.s64 	%rd601, %rd600, %rd555;
	st.global.f32 	[%rd601], %f2075;
	ld.const.u64 	%rd602, [params+208];
	cvta.to.global.u64 	%rd603, %rd602;
	add.s64 	%rd604, %rd603, %rd555;
	st.global.f32 	[%rd604], %f2070;
	ld.const.u64 	%rd605, [params+216];
	cvta.to.global.u64 	%rd606, %rd605;
	add.s64 	%rd607, %rd606, %rd555;
	st.global.f32 	[%rd607], %f2071;
	ld.const.u64 	%rd608, [params+224];
	cvta.to.global.u64 	%rd609, %rd608;
	add.s64 	%rd610, %rd609, %rd555;
	st.global.f32 	[%rd610], %f2072;

$L__BB1_109:
	ld.const.u64 	%rd42, [params+232];
	setp.eq.s64 	%p67, %rd42, 0;
	@%p67 bra 	$L__BB1_111;

	cvta.to.global.u64 	%rd611, %rd42;
	add.s64 	%rd613, %rd611, %rd555;
	st.global.f32 	[%rd613], %f2079;
	ld.const.u64 	%rd614, [params+240];
	cvta.to.global.u64 	%rd615, %rd614;
	add.s64 	%rd616, %rd615, %rd555;
	st.global.f32 	[%rd616], %f2080;
	ld.const.u64 	%rd617, [params+248];
	cvta.to.global.u64 	%rd618, %rd617;
	add.s64 	%rd619, %rd618, %rd555;
	st.global.f32 	[%rd619], %f2081;
	ld.const.u64 	%rd620, [params+256];
	cvta.to.global.u64 	%rd621, %rd620;
	add.s64 	%rd622, %rd621, %rd555;
	st.global.f32 	[%rd622], %f2082;
	ld.const.u64 	%rd623, [params+264];
	cvta.to.global.u64 	%rd624, %rd623;
	add.s64 	%rd625, %rd624, %rd555;
	st.global.f32 	[%rd625], %f2083;
	ld.const.u64 	%rd626, [params+272];
	cvta.to.global.u64 	%rd627, %rd626;
	add.s64 	%rd628, %rd627, %rd555;
	st.global.f32 	[%rd628], %f2084;

$L__BB1_111:
	ld.const.u64 	%rd43, [params+280];
	setp.eq.s64 	%p68, %rd43, 0;
	@%p68 bra 	$L__BB1_113;

	cvta.to.global.u64 	%rd629, %rd43;
	add.s64 	%rd631, %rd629, %rd555;
	st.global.f32 	[%rd631], %f2079;
	ld.const.u64 	%rd632, [params+288];
	cvta.to.global.u64 	%rd633, %rd632;
	add.s64 	%rd634, %rd633, %rd555;
	st.global.f32 	[%rd634], %f2080;
	ld.const.u64 	%rd635, [params+296];
	cvta.to.global.u64 	%rd636, %rd635;
	add.s64 	%rd637, %rd636, %rd555;
	st.global.f32 	[%rd637], %f2081;
	ld.const.u64 	%rd638, [params+304];
	cvta.to.global.u64 	%rd639, %rd638;
	add.s64 	%rd640, %rd639, %rd555;
	st.global.f32 	[%rd640], %f2082;
	ld.const.u64 	%rd641, [params+312];
	cvta.to.global.u64 	%rd642, %rd641;
	add.s64 	%rd643, %rd642, %rd555;
	st.global.f32 	[%rd643], %f2083;
	ld.const.u64 	%rd644, [params+320];
	cvta.to.global.u64 	%rd645, %rd644;
	add.s64 	%rd646, %rd645, %rd555;
	st.global.f32 	[%rd646], %f2084;

$L__BB1_113:
	ret;

}
	// .globl	__intersection__disk
.visible .entry __intersection__disk()
{
	.reg .pred 	%p<22>;
	.reg .f32 	%f<977>;
	.reg .b32 	%r<318>;
	.reg .b64 	%rd<258>;


	// begin inline asm
	call (%rd16), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd1, [%rd16+8];
	// begin inline asm
	call (%f916), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f917), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f918), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r9), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p1, %r9, 0;
	@%p1 bra 	$L__BB2_21;

	// begin inline asm
	call (%r10), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f344), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p2, %r10, 0;
	@%p2 bra 	$L__BB2_19;

	mov.u32 	%r316, 0;

$L__BB2_3:
	.pragma "nounroll";
	// begin inline asm
	call (%rd17), _optix_get_transform_list_handle, (%r316);
	// end inline asm
	// begin inline asm
	call (%r13), _optix_get_transform_type_from_handle, (%rd17);
	// end inline asm
	or.b32  	%r14, %r13, 1;
	setp.eq.s32 	%p3, %r14, 3;
	@%p3 bra 	$L__BB2_9;
	bra.uni 	$L__BB2_4;

$L__BB2_9:
	setp.eq.s32 	%p6, %r13, 2;
	@%p6 bra 	$L__BB2_13;
	bra.uni 	$L__BB2_10;

$L__BB2_13:
	// begin inline asm
	call (%rd89), _optix_get_matrix_motion_transform_from_handle, (%rd17);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd91, %rd89;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd91];
	// end inline asm
	add.s64 	%rd95, %rd89, 16;
	// begin inline asm
	cvta.to.global.u64 %rd94, %rd95;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd94];
	// end inline asm
	add.s64 	%rd98, %rd89, 32;
	// begin inline asm
	cvta.to.global.u64 %rd97, %rd98;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd97];
	// end inline asm
	add.s64 	%rd101, %rd89, 48;
	// begin inline asm
	cvta.to.global.u64 %rd100, %rd101;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd100];
	// end inline asm
	add.s64 	%rd104, %rd89, 64;
	// begin inline asm
	cvta.to.global.u64 %rd103, %rd104;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd103];
	// end inline asm
	add.s64 	%rd107, %rd89, 80;
	// begin inline asm
	cvta.to.global.u64 %rd106, %rd107;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd106];
	// end inline asm
	add.s64 	%rd110, %rd89, 96;
	// begin inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd109];
	// end inline asm
	add.s64 	%rd113, %rd89, 112;
	// begin inline asm
	cvta.to.global.u64 %rd112, %rd113;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd112];
	// end inline asm
	mov.b32 	%f472, %r105;
	mov.b32 	%f473, %r106;
	and.b32  	%r146, %r104, 65535;
	add.s32 	%r147, %r146, -1;
	cvt.rn.f32.s32 	%f474, %r147;
	sub.f32 	%f475, %f344, %f472;
	mul.f32 	%f476, %f475, %f474;
	sub.f32 	%f477, %f473, %f472;
	div.rn.f32 	%f478, %f476, %f477;
	min.f32 	%f479, %f474, %f478;
	mov.f32 	%f480, 0f00000000;
	max.f32 	%f481, %f480, %f479;
	cvt.rmi.f32.f32 	%f482, %f481;
	sub.f32 	%f90, %f481, %f482;
	cvt.rzi.s32.f32 	%r148, %f482;
	mul.wide.s32 	%rd124, %r148, 48;
	add.s64 	%rd116, %rd98, %rd124;
	// begin inline asm
	cvta.to.global.u64 %rd115, %rd116;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd115];
	// end inline asm
	mov.b32 	%f871, %r134;
	mov.b32 	%f870, %r135;
	mov.b32 	%f869, %r136;
	mov.b32 	%f868, %r137;
	add.s64 	%rd119, %rd116, 16;
	// begin inline asm
	cvta.to.global.u64 %rd118, %rd119;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd118];
	// end inline asm
	mov.b32 	%f875, %r138;
	mov.b32 	%f874, %r139;
	mov.b32 	%f873, %r140;
	mov.b32 	%f872, %r141;
	add.s64 	%rd122, %rd116, 32;
	// begin inline asm
	cvta.to.global.u64 %rd121, %rd122;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd121];
	// end inline asm
	mov.b32 	%f879, %r142;
	mov.b32 	%f878, %r143;
	mov.b32 	%f877, %r144;
	mov.b32 	%f876, %r145;
	setp.leu.f32 	%p8, %f90, 0f00000000;
	@%p8 bra 	$L__BB2_15;

	cvt.rmi.f32.f32 	%f839, %f481;
	cvt.rzi.s32.f32 	%r315, %f839;
	cvt.s64.s32 	%rd255, %r315;
	mov.f32 	%f483, 0f3F800000;
	sub.f32 	%f484, %f483, %f90;
	mul.lo.s64 	%rd134, %rd255, 48;
	add.s64 	%rd135, %rd89, %rd134;
	add.s64 	%rd126, %rd135, 80;
	// begin inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd125];
	// end inline asm
	mov.b32 	%f485, %r149;
	mov.b32 	%f486, %r150;
	mov.b32 	%f487, %r151;
	mov.b32 	%f488, %r152;
	mul.f32 	%f489, %f90, %f485;
	mul.f32 	%f490, %f90, %f486;
	mul.f32 	%f491, %f90, %f487;
	mul.f32 	%f492, %f90, %f488;
	fma.rn.f32 	%f871, %f484, %f871, %f489;
	fma.rn.f32 	%f870, %f484, %f870, %f490;
	fma.rn.f32 	%f869, %f484, %f869, %f491;
	fma.rn.f32 	%f868, %f484, %f868, %f492;
	add.s64 	%rd129, %rd135, 96;
	// begin inline asm
	cvta.to.global.u64 %rd128, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd128];
	// end inline asm
	mov.b32 	%f493, %r153;
	mov.b32 	%f494, %r154;
	mov.b32 	%f495, %r155;
	mov.b32 	%f496, %r156;
	mul.f32 	%f497, %f90, %f493;
	mul.f32 	%f498, %f90, %f494;
	mul.f32 	%f499, %f90, %f495;
	mul.f32 	%f500, %f90, %f496;
	fma.rn.f32 	%f875, %f484, %f875, %f497;
	fma.rn.f32 	%f874, %f484, %f874, %f498;
	fma.rn.f32 	%f873, %f484, %f873, %f499;
	fma.rn.f32 	%f872, %f484, %f872, %f500;
	add.s64 	%rd132, %rd135, 112;
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd131];
	// end inline asm
	mov.b32 	%f501, %r157;
	mov.b32 	%f502, %r158;
	mov.b32 	%f503, %r159;
	mov.b32 	%f504, %r160;
	mul.f32 	%f505, %f90, %f501;
	mul.f32 	%f506, %f90, %f502;
	mul.f32 	%f507, %f90, %f503;
	mul.f32 	%f508, %f90, %f504;
	fma.rn.f32 	%f879, %f484, %f879, %f505;
	fma.rn.f32 	%f878, %f484, %f878, %f506;
	fma.rn.f32 	%f877, %f484, %f877, %f507;
	fma.rn.f32 	%f876, %f484, %f876, %f508;
	bra.uni 	$L__BB2_15;

$L__BB2_4:
	mov.f32 	%f880, 0f00000000;
	mov.f32 	%f883, 0f3F800000;
	setp.eq.s32 	%p4, %r13, 4;
	@%p4 bra 	$L__BB2_7;

	setp.ne.s32 	%p5, %r13, 1;
	mov.f32 	%f881, %f880;
	mov.f32 	%f882, %f880;
	mov.f32 	%f884, %f880;
	mov.f32 	%f885, %f880;
	mov.f32 	%f886, %f883;
	mov.f32 	%f887, %f880;
	mov.f32 	%f888, %f880;
	mov.f32 	%f889, %f883;
	mov.f32 	%f890, %f880;
	mov.f32 	%f891, %f880;
	@%p5 bra 	$L__BB2_16;

	// begin inline asm
	call (%rd19), _optix_get_static_transform_from_handle, (%rd17);
	// end inline asm
	add.s64 	%rd256, %rd19, 64;
	bra.uni 	$L__BB2_8;

$L__BB2_10:
	// begin inline asm
	call (%rd32), _optix_get_srt_motion_transform_from_handle, (%rd17);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd34, %rd32;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r27,%r28,%r29,%r30}, [%rd34];
	// end inline asm
	add.s64 	%rd38, %rd32, 16;
	// begin inline asm
	cvta.to.global.u64 %rd37, %rd38;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r31,%r32,%r33,%r34}, [%rd37];
	// end inline asm
	add.s64 	%rd41, %rd32, 32;
	// begin inline asm
	cvta.to.global.u64 %rd40, %rd41;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd40];
	// end inline asm
	add.s64 	%rd44, %rd32, 48;
	// begin inline asm
	cvta.to.global.u64 %rd43, %rd44;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd43];
	// end inline asm
	add.s64 	%rd47, %rd32, 64;
	// begin inline asm
	cvta.to.global.u64 %rd46, %rd47;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd46];
	// end inline asm
	add.s64 	%rd50, %rd32, 80;
	// begin inline asm
	cvta.to.global.u64 %rd49, %rd50;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd49];
	// end inline asm
	add.s64 	%rd53, %rd32, 96;
	// begin inline asm
	cvta.to.global.u64 %rd52, %rd53;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd52];
	// end inline asm
	add.s64 	%rd56, %rd32, 112;
	// begin inline asm
	cvta.to.global.u64 %rd55, %rd56;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd55];
	// end inline asm
	add.s64 	%rd59, %rd32, 128;
	// begin inline asm
	cvta.to.global.u64 %rd58, %rd59;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd58];
	// end inline asm
	add.s64 	%rd62, %rd32, 144;
	// begin inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd61];
	// end inline asm
	mov.b32 	%f359, %r30;
	mov.b32 	%f360, %r31;
	and.b32  	%r83, %r29, 65535;
	add.s32 	%r84, %r83, -1;
	cvt.rn.f32.s32 	%f361, %r84;
	sub.f32 	%f362, %f344, %f359;
	mul.f32 	%f363, %f362, %f361;
	sub.f32 	%f364, %f360, %f359;
	div.rn.f32 	%f365, %f363, %f364;
	min.f32 	%f366, %f361, %f365;
	mov.f32 	%f367, 0f00000000;
	max.f32 	%f368, %f367, %f366;
	cvt.rmi.f32.f32 	%f369, %f368;
	sub.f32 	%f29, %f368, %f369;
	cvt.rzi.s32.f32 	%r85, %f369;
	mul.wide.s32 	%rd76, %r85, 64;
	add.s64 	%rd65, %rd41, %rd76;
	// begin inline asm
	cvta.to.global.u64 %rd64, %rd65;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd64];
	// end inline asm
	mov.b32 	%f852, %r67;
	mov.b32 	%f853, %r68;
	mov.b32 	%f854, %r69;
	mov.b32 	%f855, %r70;
	add.s64 	%rd68, %rd65, 16;
	// begin inline asm
	cvta.to.global.u64 %rd67, %rd68;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd67];
	// end inline asm
	mov.b32 	%f856, %r71;
	mov.b32 	%f857, %r72;
	mov.b32 	%f858, %r73;
	mov.b32 	%f859, %r74;
	add.s64 	%rd71, %rd65, 32;
	// begin inline asm
	cvta.to.global.u64 %rd70, %rd71;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd70];
	// end inline asm
	mov.b32 	%f860, %r75;
	mov.b32 	%f861, %r76;
	mov.b32 	%f862, %r77;
	mov.b32 	%f863, %r78;
	add.s64 	%rd74, %rd65, 48;
	// begin inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd73];
	// end inline asm
	mov.b32 	%f864, %r79;
	mov.b32 	%f865, %r80;
	mov.b32 	%f866, %r81;
	mov.b32 	%f867, %r82;
	setp.leu.f32 	%p7, %f29, 0f00000000;
	@%p7 bra 	$L__BB2_12;

	mov.f32 	%f370, 0f3F800000;
	sub.f32 	%f371, %f370, %f29;
	add.s64 	%rd78, %rd65, 64;
	// begin inline asm
	cvta.to.global.u64 %rd77, %rd78;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r86,%r87,%r88,%r89}, [%rd77];
	// end inline asm
	mov.b32 	%f372, %r86;
	mov.b32 	%f373, %r87;
	mov.b32 	%f374, %r88;
	mov.b32 	%f375, %r89;
	mul.f32 	%f376, %f29, %f372;
	mul.f32 	%f377, %f29, %f373;
	mul.f32 	%f378, %f29, %f374;
	mul.f32 	%f379, %f29, %f375;
	fma.rn.f32 	%f852, %f371, %f852, %f376;
	fma.rn.f32 	%f853, %f371, %f853, %f377;
	fma.rn.f32 	%f854, %f371, %f854, %f378;
	fma.rn.f32 	%f855, %f371, %f855, %f379;
	add.s64 	%rd81, %rd65, 80;
	// begin inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd80];
	// end inline asm
	mov.b32 	%f380, %r90;
	mov.b32 	%f381, %r91;
	mov.b32 	%f382, %r92;
	mov.b32 	%f383, %r93;
	mul.f32 	%f384, %f29, %f380;
	mul.f32 	%f385, %f29, %f381;
	mul.f32 	%f386, %f29, %f382;
	mul.f32 	%f387, %f29, %f383;
	fma.rn.f32 	%f856, %f371, %f856, %f384;
	fma.rn.f32 	%f857, %f371, %f857, %f385;
	fma.rn.f32 	%f858, %f371, %f858, %f386;
	fma.rn.f32 	%f859, %f371, %f859, %f387;
	add.s64 	%rd84, %rd65, 96;
	// begin inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd83];
	// end inline asm
	mov.b32 	%f388, %r94;
	mov.b32 	%f389, %r95;
	mov.b32 	%f390, %r96;
	mov.b32 	%f391, %r97;
	mul.f32 	%f392, %f29, %f388;
	mul.f32 	%f393, %f29, %f389;
	mul.f32 	%f394, %f29, %f390;
	mul.f32 	%f395, %f29, %f391;
	fma.rn.f32 	%f860, %f371, %f860, %f392;
	fma.rn.f32 	%f396, %f371, %f861, %f393;
	fma.rn.f32 	%f397, %f371, %f862, %f394;
	fma.rn.f32 	%f398, %f371, %f863, %f395;
	add.s64 	%rd87, %rd65, 112;
	// begin inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd86];
	// end inline asm
	mov.b32 	%f399, %r98;
	mov.b32 	%f400, %r99;
	mov.b32 	%f401, %r100;
	mov.b32 	%f402, %r101;
	mul.f32 	%f403, %f29, %f399;
	mul.f32 	%f404, %f29, %f400;
	mul.f32 	%f405, %f29, %f401;
	mul.f32 	%f406, %f29, %f402;
	fma.rn.f32 	%f407, %f371, %f864, %f403;
	fma.rn.f32 	%f865, %f371, %f865, %f404;
	fma.rn.f32 	%f866, %f371, %f866, %f405;
	fma.rn.f32 	%f867, %f371, %f867, %f406;
	mul.f32 	%f408, %f397, %f397;
	fma.rn.f32 	%f409, %f396, %f396, %f408;
	fma.rn.f32 	%f410, %f398, %f398, %f409;
	fma.rn.f32 	%f411, %f407, %f407, %f410;
	sqrt.rn.f32 	%f412, %f411;
	rcp.rn.f32 	%f413, %f412;
	mul.f32 	%f861, %f396, %f413;
	mul.f32 	%f862, %f397, %f413;
	mul.f32 	%f863, %f398, %f413;
	mul.f32 	%f864, %f413, %f407;

$L__BB2_12:
	mul.f32 	%f414, %f862, %f862;
	fma.rn.f32 	%f415, %f861, %f861, %f414;
	fma.rn.f32 	%f416, %f863, %f863, %f415;
	fma.rn.f32 	%f417, %f864, %f864, %f416;
	rcp.rn.f32 	%f418, %f417;
	mul.f32 	%f419, %f861, %f418;
	mul.f32 	%f420, %f862, %f418;
	mul.f32 	%f421, %f863, %f418;
	mul.f32 	%f422, %f864, %f418;
	mul.f32 	%f423, %f861, %f419;
	mul.f32 	%f424, %f862, %f420;
	mul.f32 	%f425, %f863, %f421;
	mul.f32 	%f426, %f861, %f420;
	mul.f32 	%f427, %f863, %f422;
	mul.f32 	%f428, %f861, %f421;
	mul.f32 	%f429, %f862, %f422;
	mul.f32 	%f430, %f862, %f421;
	mul.f32 	%f431, %f861, %f422;
	sub.f32 	%f432, %f423, %f424;
	sub.f32 	%f433, %f432, %f425;
	fma.rn.f32 	%f434, %f864, %f422, %f433;
	sub.f32 	%f435, %f426, %f427;
	add.f32 	%f436, %f435, %f435;
	add.f32 	%f437, %f428, %f429;
	add.f32 	%f438, %f437, %f437;
	add.f32 	%f439, %f426, %f427;
	add.f32 	%f440, %f439, %f439;
	sub.f32 	%f441, %f424, %f423;
	sub.f32 	%f442, %f441, %f425;
	fma.rn.f32 	%f443, %f864, %f422, %f442;
	sub.f32 	%f444, %f430, %f431;
	add.f32 	%f445, %f444, %f444;
	sub.f32 	%f446, %f428, %f429;
	add.f32 	%f447, %f446, %f446;
	add.f32 	%f448, %f430, %f431;
	add.f32 	%f449, %f448, %f448;
	neg.f32 	%f450, %f423;
	sub.f32 	%f451, %f450, %f424;
	add.f32 	%f452, %f425, %f451;
	fma.rn.f32 	%f453, %f864, %f422, %f452;
	mul.f32 	%f454, %f855, %f434;
	fma.rn.f32 	%f455, %f858, %f436, %f454;
	fma.rn.f32 	%f456, %f860, %f438, %f455;
	sub.f32 	%f868, %f865, %f456;
	mul.f32 	%f457, %f858, %f443;
	fma.rn.f32 	%f458, %f855, %f440, %f457;
	fma.rn.f32 	%f459, %f860, %f445, %f458;
	sub.f32 	%f872, %f866, %f459;
	mul.f32 	%f460, %f858, %f449;
	fma.rn.f32 	%f461, %f855, %f447, %f460;
	fma.rn.f32 	%f462, %f860, %f453, %f461;
	sub.f32 	%f876, %f867, %f462;
	mul.f32 	%f463, %f854, %f434;
	fma.rn.f32 	%f464, %f857, %f436, %f463;
	fma.rn.f32 	%f869, %f859, %f438, %f464;
	mul.f32 	%f465, %f857, %f443;
	fma.rn.f32 	%f466, %f854, %f440, %f465;
	fma.rn.f32 	%f873, %f859, %f445, %f466;
	mul.f32 	%f467, %f857, %f449;
	fma.rn.f32 	%f468, %f854, %f447, %f467;
	fma.rn.f32 	%f877, %f859, %f453, %f468;
	mul.f32 	%f469, %f853, %f434;
	fma.rn.f32 	%f870, %f856, %f436, %f469;
	mul.f32 	%f470, %f856, %f443;
	fma.rn.f32 	%f874, %f853, %f440, %f470;
	mul.f32 	%f471, %f856, %f449;
	fma.rn.f32 	%f878, %f853, %f447, %f471;
	mul.f32 	%f871, %f852, %f434;
	mul.f32 	%f875, %f852, %f440;
	mul.f32 	%f879, %f852, %f447;

$L__BB2_15:
	mul.f32 	%f509, %f873, %f878;
	mul.f32 	%f510, %f874, %f877;
	sub.f32 	%f511, %f510, %f509;
	mul.f32 	%f512, %f871, %f511;
	mul.f32 	%f513, %f873, %f879;
	mul.f32 	%f514, %f875, %f877;
	sub.f32 	%f515, %f514, %f513;
	mul.f32 	%f516, %f870, %f515;
	sub.f32 	%f517, %f512, %f516;
	mul.f32 	%f518, %f874, %f879;
	mul.f32 	%f519, %f875, %f878;
	sub.f32 	%f520, %f519, %f518;
	fma.rn.f32 	%f521, %f869, %f520, %f517;
	rcp.rn.f32 	%f522, %f521;
	mul.f32 	%f883, %f511, %f522;
	mul.f32 	%f523, %f870, %f877;
	mul.f32 	%f524, %f869, %f878;
	sub.f32 	%f525, %f524, %f523;
	mul.f32 	%f882, %f525, %f522;
	mul.f32 	%f526, %f869, %f874;
	mul.f32 	%f527, %f870, %f873;
	sub.f32 	%f528, %f527, %f526;
	mul.f32 	%f881, %f528, %f522;
	sub.f32 	%f529, %f513, %f514;
	mul.f32 	%f887, %f529, %f522;
	mul.f32 	%f530, %f869, %f879;
	mul.f32 	%f531, %f871, %f877;
	sub.f32 	%f532, %f531, %f530;
	mul.f32 	%f886, %f532, %f522;
	mul.f32 	%f533, %f871, %f873;
	mul.f32 	%f534, %f869, %f875;
	sub.f32 	%f535, %f534, %f533;
	mul.f32 	%f885, %f535, %f522;
	mul.f32 	%f891, %f520, %f522;
	mul.f32 	%f536, %f871, %f878;
	mul.f32 	%f537, %f870, %f879;
	sub.f32 	%f538, %f537, %f536;
	mul.f32 	%f890, %f538, %f522;
	mul.f32 	%f539, %f870, %f875;
	mul.f32 	%f540, %f871, %f874;
	sub.f32 	%f541, %f540, %f539;
	mul.f32 	%f889, %f541, %f522;
	mul.f32 	%f542, %f868, %f883;
	neg.f32 	%f543, %f542;
	mul.f32 	%f544, %f872, %f882;
	sub.f32 	%f545, %f543, %f544;
	mul.f32 	%f546, %f876, %f881;
	sub.f32 	%f880, %f545, %f546;
	mul.f32 	%f547, %f868, %f887;
	neg.f32 	%f548, %f547;
	mul.f32 	%f549, %f872, %f886;
	sub.f32 	%f550, %f548, %f549;
	mul.f32 	%f551, %f876, %f885;
	sub.f32 	%f884, %f550, %f551;
	mul.f32 	%f552, %f868, %f891;
	neg.f32 	%f553, %f552;
	mul.f32 	%f554, %f872, %f890;
	sub.f32 	%f555, %f553, %f554;
	mul.f32 	%f556, %f876, %f889;
	sub.f32 	%f888, %f555, %f556;
	bra.uni 	$L__BB2_16;

$L__BB2_7:
	// begin inline asm
	call (%rd256), _optix_get_instance_inverse_transform_from_handle, (%rd17);
	// end inline asm

$L__BB2_8:
	// begin inline asm
	cvta.to.global.u64 %rd23, %rd256;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r15,%r16,%r17,%r18}, [%rd23];
	// end inline asm
	mov.b32 	%f883, %r15;
	mov.b32 	%f882, %r16;
	mov.b32 	%f881, %r17;
	mov.b32 	%f880, %r18;
	add.s64 	%rd27, %rd256, 16;
	// begin inline asm
	cvta.to.global.u64 %rd26, %rd27;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r19,%r20,%r21,%r22}, [%rd26];
	// end inline asm
	mov.b32 	%f887, %r19;
	mov.b32 	%f886, %r20;
	mov.b32 	%f885, %r21;
	mov.b32 	%f884, %r22;
	add.s64 	%rd30, %rd256, 32;
	// begin inline asm
	cvta.to.global.u64 %rd29, %rd30;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r23,%r24,%r25,%r26}, [%rd29];
	// end inline asm
	mov.b32 	%f891, %r23;
	mov.b32 	%f890, %r24;
	mov.b32 	%f889, %r25;
	mov.b32 	%f888, %r26;

$L__BB2_16:
	setp.eq.s32 	%p9, %r316, 0;
	@%p9 bra 	$L__BB2_18;

	mul.f32 	%f557, %f848, %f883;
	fma.rn.f32 	%f558, %f844, %f882, %f557;
	fma.rn.f32 	%f151, %f840, %f881, %f558;
	mul.f32 	%f559, %f849, %f883;
	fma.rn.f32 	%f560, %f845, %f882, %f559;
	fma.rn.f32 	%f152, %f841, %f881, %f560;
	mul.f32 	%f561, %f850, %f883;
	fma.rn.f32 	%f562, %f846, %f882, %f561;
	fma.rn.f32 	%f153, %f842, %f881, %f562;
	mul.f32 	%f563, %f851, %f883;
	fma.rn.f32 	%f564, %f847, %f882, %f563;
	fma.rn.f32 	%f565, %f843, %f881, %f564;
	add.f32 	%f880, %f880, %f565;
	mul.f32 	%f566, %f848, %f887;
	fma.rn.f32 	%f567, %f844, %f886, %f566;
	fma.rn.f32 	%f155, %f840, %f885, %f567;
	mul.f32 	%f568, %f849, %f887;
	fma.rn.f32 	%f569, %f845, %f886, %f568;
	fma.rn.f32 	%f156, %f841, %f885, %f569;
	mul.f32 	%f570, %f850, %f887;
	fma.rn.f32 	%f571, %f846, %f886, %f570;
	fma.rn.f32 	%f157, %f842, %f885, %f571;
	mul.f32 	%f572, %f851, %f887;
	fma.rn.f32 	%f573, %f847, %f886, %f572;
	fma.rn.f32 	%f574, %f843, %f885, %f573;
	add.f32 	%f884, %f884, %f574;
	mul.f32 	%f575, %f848, %f891;
	fma.rn.f32 	%f576, %f844, %f890, %f575;
	fma.rn.f32 	%f159, %f840, %f889, %f576;
	mul.f32 	%f577, %f849, %f891;
	fma.rn.f32 	%f578, %f845, %f890, %f577;
	fma.rn.f32 	%f160, %f841, %f889, %f578;
	mul.f32 	%f579, %f850, %f891;
	fma.rn.f32 	%f580, %f846, %f890, %f579;
	fma.rn.f32 	%f161, %f842, %f889, %f580;
	mul.f32 	%f581, %f851, %f891;
	fma.rn.f32 	%f582, %f847, %f890, %f581;
	fma.rn.f32 	%f583, %f843, %f889, %f582;
	add.f32 	%f888, %f888, %f583;
	mov.f32 	%f881, %f153;
	mov.f32 	%f882, %f152;
	mov.f32 	%f883, %f151;
	mov.f32 	%f885, %f157;
	mov.f32 	%f886, %f156;
	mov.f32 	%f887, %f155;
	mov.f32 	%f889, %f161;
	mov.f32 	%f890, %f160;
	mov.f32 	%f891, %f159;

$L__BB2_18:
	add.s32 	%r316, %r316, 1;
	setp.lt.u32 	%p10, %r316, %r10;
	mov.f32 	%f840, %f891;
	mov.f32 	%f841, %f890;
	mov.f32 	%f842, %f889;
	mov.f32 	%f843, %f888;
	mov.f32 	%f844, %f887;
	mov.f32 	%f845, %f886;
	mov.f32 	%f846, %f885;
	mov.f32 	%f847, %f884;
	mov.f32 	%f848, %f883;
	mov.f32 	%f849, %f882;
	mov.f32 	%f850, %f881;
	mov.f32 	%f851, %f880;
	@%p10 bra 	$L__BB2_3;

$L__BB2_19:
	mul.f32 	%f584, %f916, %f883;
	fma.rn.f32 	%f585, %f917, %f882, %f584;
	fma.rn.f32 	%f586, %f918, %f881, %f585;
	mul.f32 	%f587, %f916, %f887;
	fma.rn.f32 	%f588, %f917, %f886, %f587;
	fma.rn.f32 	%f589, %f918, %f885, %f588;
	mul.f32 	%f590, %f916, %f891;
	fma.rn.f32 	%f591, %f917, %f890, %f590;
	fma.rn.f32 	%f592, %f918, %f889, %f591;
	add.f32 	%f918, %f888, %f592;
	add.f32 	%f917, %f884, %f589;
	add.f32 	%f916, %f880, %f586;

$L__BB2_21:
	// begin inline asm
	call (%f974), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f975), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f595), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r161), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p11, %r161, 0;
	@%p11 bra 	$L__BB2_41;

	// begin inline asm
	call (%r162), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f596), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p12, %r162, 0;
	@%p12 bra 	$L__BB2_40;

	mov.u32 	%r317, 0;

$L__BB2_24:
	.pragma "nounroll";
	// begin inline asm
	call (%rd136), _optix_get_transform_list_handle, (%r317);
	// end inline asm
	// begin inline asm
	call (%r165), _optix_get_transform_type_from_handle, (%rd136);
	// end inline asm
	or.b32  	%r166, %r165, 1;
	setp.eq.s32 	%p13, %r166, 3;
	@%p13 bra 	$L__BB2_30;
	bra.uni 	$L__BB2_25;

$L__BB2_30:
	setp.eq.s32 	%p16, %r165, 2;
	@%p16 bra 	$L__BB2_34;
	bra.uni 	$L__BB2_31;

$L__BB2_34:
	// begin inline asm
	call (%rd208), _optix_get_matrix_motion_transform_from_handle, (%rd136);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd210, %rd208;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd210];
	// end inline asm
	add.s64 	%rd214, %rd208, 16;
	// begin inline asm
	cvta.to.global.u64 %rd213, %rd214;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd213];
	// end inline asm
	add.s64 	%rd217, %rd208, 32;
	// begin inline asm
	cvta.to.global.u64 %rd216, %rd217;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd216];
	// end inline asm
	add.s64 	%rd220, %rd208, 48;
	// begin inline asm
	cvta.to.global.u64 %rd219, %rd220;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd219];
	// end inline asm
	add.s64 	%rd223, %rd208, 64;
	// begin inline asm
	cvta.to.global.u64 %rd222, %rd223;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd222];
	// end inline asm
	add.s64 	%rd226, %rd208, 80;
	// begin inline asm
	cvta.to.global.u64 %rd225, %rd226;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd225];
	// end inline asm
	add.s64 	%rd229, %rd208, 96;
	// begin inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd228];
	// end inline asm
	add.s64 	%rd232, %rd208, 112;
	// begin inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd231];
	// end inline asm
	mov.b32 	%f700, %r257;
	mov.b32 	%f701, %r258;
	and.b32  	%r298, %r256, 65535;
	add.s32 	%r299, %r298, -1;
	cvt.rn.f32.s32 	%f702, %r299;
	sub.f32 	%f703, %f596, %f700;
	mul.f32 	%f704, %f703, %f702;
	sub.f32 	%f705, %f701, %f700;
	div.rn.f32 	%f706, %f704, %f705;
	min.f32 	%f707, %f702, %f706;
	mov.f32 	%f708, 0f00000000;
	max.f32 	%f709, %f708, %f707;
	cvt.rmi.f32.f32 	%f710, %f709;
	sub.f32 	%f258, %f709, %f710;
	cvt.rzi.s32.f32 	%r300, %f710;
	cvt.s64.s32 	%rd15, %r300;
	mul.wide.s32 	%rd243, %r300, 48;
	add.s64 	%rd235, %rd217, %rd243;
	// begin inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd234];
	// end inline asm
	mov.b32 	%f944, %r286;
	mov.b32 	%f945, %r287;
	mov.b32 	%f946, %r288;
	add.s64 	%rd238, %rd235, 16;
	// begin inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd237];
	// end inline asm
	mov.b32 	%f941, %r290;
	mov.b32 	%f942, %r291;
	mov.b32 	%f943, %r292;
	add.s64 	%rd241, %rd235, 32;
	// begin inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r294,%r295,%r296,%r297}, [%rd240];
	// end inline asm
	mov.b32 	%f938, %r294;
	mov.b32 	%f939, %r295;
	mov.b32 	%f940, %r296;
	setp.leu.f32 	%p18, %f258, 0f00000000;
	@%p18 bra 	$L__BB2_36;

	mov.f32 	%f711, 0f3F800000;
	sub.f32 	%f712, %f711, %f258;
	mul.lo.s64 	%rd253, %rd15, 48;
	add.s64 	%rd254, %rd208, %rd253;
	add.s64 	%rd245, %rd254, 80;
	// begin inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd244];
	// end inline asm
	mov.b32 	%f713, %r301;
	mov.b32 	%f714, %r302;
	mov.b32 	%f715, %r303;
	mul.f32 	%f716, %f258, %f713;
	mul.f32 	%f717, %f258, %f714;
	mul.f32 	%f718, %f258, %f715;
	fma.rn.f32 	%f944, %f712, %f944, %f716;
	fma.rn.f32 	%f945, %f712, %f945, %f717;
	fma.rn.f32 	%f946, %f712, %f946, %f718;
	add.s64 	%rd248, %rd254, 96;
	// begin inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd247];
	// end inline asm
	mov.b32 	%f719, %r305;
	mov.b32 	%f720, %r306;
	mov.b32 	%f721, %r307;
	mul.f32 	%f722, %f258, %f719;
	mul.f32 	%f723, %f258, %f720;
	mul.f32 	%f724, %f258, %f721;
	fma.rn.f32 	%f941, %f712, %f941, %f722;
	fma.rn.f32 	%f942, %f712, %f942, %f723;
	fma.rn.f32 	%f943, %f712, %f943, %f724;
	add.s64 	%rd251, %rd254, 112;
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r309,%r310,%r311,%r312}, [%rd250];
	// end inline asm
	mov.b32 	%f725, %r309;
	mov.b32 	%f726, %r310;
	mov.b32 	%f727, %r311;
	mul.f32 	%f728, %f258, %f725;
	mul.f32 	%f729, %f258, %f726;
	mul.f32 	%f730, %f258, %f727;
	fma.rn.f32 	%f938, %f712, %f938, %f728;
	fma.rn.f32 	%f939, %f712, %f939, %f729;
	fma.rn.f32 	%f940, %f712, %f940, %f730;
	bra.uni 	$L__BB2_36;

$L__BB2_25:
	mov.f32 	%f947, 0f00000000;
	mov.f32 	%f949, 0f3F800000;
	setp.eq.s32 	%p14, %r165, 4;
	@%p14 bra 	$L__BB2_28;

	setp.ne.s32 	%p15, %r165, 1;
	mov.f32 	%f948, %f947;
	mov.f32 	%f950, %f947;
	mov.f32 	%f951, %f949;
	mov.f32 	%f952, %f947;
	mov.f32 	%f953, %f949;
	mov.f32 	%f954, %f947;
	mov.f32 	%f955, %f947;
	@%p15 bra 	$L__BB2_37;

	// begin inline asm
	call (%rd138), _optix_get_static_transform_from_handle, (%rd136);
	// end inline asm
	add.s64 	%rd257, %rd138, 64;
	bra.uni 	$L__BB2_29;

$L__BB2_31:
	// begin inline asm
	call (%rd151), _optix_get_srt_motion_transform_from_handle, (%rd136);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd153, %rd151;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd153];
	// end inline asm
	add.s64 	%rd157, %rd151, 16;
	// begin inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd156];
	// end inline asm
	add.s64 	%rd160, %rd151, 32;
	// begin inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd159];
	// end inline asm
	add.s64 	%rd163, %rd151, 48;
	// begin inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd162];
	// end inline asm
	add.s64 	%rd166, %rd151, 64;
	// begin inline asm
	cvta.to.global.u64 %rd165, %rd166;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd165];
	// end inline asm
	add.s64 	%rd169, %rd151, 80;
	// begin inline asm
	cvta.to.global.u64 %rd168, %rd169;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd168];
	// end inline asm
	add.s64 	%rd172, %rd151, 96;
	// begin inline asm
	cvta.to.global.u64 %rd171, %rd172;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd171];
	// end inline asm
	add.s64 	%rd175, %rd151, 112;
	// begin inline asm
	cvta.to.global.u64 %rd174, %rd175;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd174];
	// end inline asm
	add.s64 	%rd178, %rd151, 128;
	// begin inline asm
	cvta.to.global.u64 %rd177, %rd178;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd177];
	// end inline asm
	add.s64 	%rd181, %rd151, 144;
	// begin inline asm
	cvta.to.global.u64 %rd180, %rd181;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd180];
	// end inline asm
	mov.b32 	%f608, %r182;
	mov.b32 	%f609, %r183;
	and.b32  	%r235, %r181, 65535;
	add.s32 	%r236, %r235, -1;
	cvt.rn.f32.s32 	%f610, %r236;
	sub.f32 	%f611, %f596, %f608;
	mul.f32 	%f612, %f611, %f610;
	sub.f32 	%f613, %f609, %f608;
	div.rn.f32 	%f614, %f612, %f613;
	min.f32 	%f615, %f610, %f614;
	mov.f32 	%f616, 0f00000000;
	max.f32 	%f617, %f616, %f615;
	cvt.rmi.f32.f32 	%f618, %f617;
	sub.f32 	%f218, %f617, %f618;
	cvt.rzi.s32.f32 	%r237, %f618;
	mul.wide.s32 	%rd195, %r237, 64;
	add.s64 	%rd184, %rd160, %rd195;
	// begin inline asm
	cvta.to.global.u64 %rd183, %rd184;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd183];
	// end inline asm
	mov.b32 	%f928, %r219;
	mov.b32 	%f929, %r220;
	mov.b32 	%f930, %r221;
	add.s64 	%rd187, %rd184, 16;
	// begin inline asm
	cvta.to.global.u64 %rd186, %rd187;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd186];
	// end inline asm
	mov.b32 	%f931, %r223;
	mov.b32 	%f932, %r224;
	mov.b32 	%f933, %r226;
	add.s64 	%rd190, %rd184, 32;
	// begin inline asm
	cvta.to.global.u64 %rd189, %rd190;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd189];
	// end inline asm
	mov.b32 	%f934, %r228;
	mov.b32 	%f935, %r229;
	mov.b32 	%f936, %r230;
	add.s64 	%rd193, %rd184, 48;
	// begin inline asm
	cvta.to.global.u64 %rd192, %rd193;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r231,%r232,%r233,%r234}, [%rd192];
	// end inline asm
	mov.b32 	%f937, %r231;
	setp.leu.f32 	%p17, %f218, 0f00000000;
	@%p17 bra 	$L__BB2_33;

	mov.f32 	%f619, 0f3F800000;
	sub.f32 	%f620, %f619, %f218;
	add.s64 	%rd197, %rd184, 64;
	// begin inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd196];
	// end inline asm
	mov.b32 	%f621, %r238;
	mov.b32 	%f622, %r239;
	mov.b32 	%f623, %r240;
	mul.f32 	%f624, %f218, %f621;
	mul.f32 	%f625, %f218, %f622;
	mul.f32 	%f626, %f218, %f623;
	fma.rn.f32 	%f928, %f620, %f928, %f624;
	fma.rn.f32 	%f929, %f620, %f929, %f625;
	fma.rn.f32 	%f930, %f620, %f930, %f626;
	add.s64 	%rd200, %rd184, 80;
	// begin inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd199];
	// end inline asm
	mov.b32 	%f627, %r242;
	mov.b32 	%f628, %r243;
	mov.b32 	%f629, %r245;
	mul.f32 	%f630, %f218, %f627;
	mul.f32 	%f631, %f218, %f628;
	mul.f32 	%f632, %f218, %f629;
	fma.rn.f32 	%f931, %f620, %f931, %f630;
	fma.rn.f32 	%f932, %f620, %f932, %f631;
	fma.rn.f32 	%f933, %f620, %f933, %f632;
	add.s64 	%rd203, %rd184, 96;
	// begin inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd202];
	// end inline asm
	mov.b32 	%f633, %r247;
	mov.b32 	%f634, %r248;
	mov.b32 	%f635, %r249;
	mul.f32 	%f636, %f218, %f633;
	mul.f32 	%f637, %f218, %f634;
	mul.f32 	%f638, %f218, %f635;
	fma.rn.f32 	%f639, %f620, %f934, %f636;
	fma.rn.f32 	%f640, %f620, %f935, %f637;
	fma.rn.f32 	%f641, %f620, %f936, %f638;
	add.s64 	%rd206, %rd184, 112;
	// begin inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd205];
	// end inline asm
	mov.b32 	%f642, %r250;
	mul.f32 	%f643, %f218, %f642;
	fma.rn.f32 	%f644, %f620, %f937, %f643;
	mul.f32 	%f645, %f640, %f640;
	fma.rn.f32 	%f646, %f639, %f639, %f645;
	fma.rn.f32 	%f647, %f641, %f641, %f646;
	fma.rn.f32 	%f648, %f644, %f644, %f647;
	sqrt.rn.f32 	%f649, %f648;
	rcp.rn.f32 	%f650, %f649;
	mul.f32 	%f934, %f639, %f650;
	mul.f32 	%f935, %f640, %f650;
	mul.f32 	%f936, %f641, %f650;
	mul.f32 	%f937, %f650, %f644;

$L__BB2_33:
	mul.f32 	%f651, %f935, %f935;
	fma.rn.f32 	%f652, %f934, %f934, %f651;
	fma.rn.f32 	%f653, %f936, %f936, %f652;
	fma.rn.f32 	%f654, %f937, %f937, %f653;
	rcp.rn.f32 	%f655, %f654;
	mul.f32 	%f656, %f934, %f655;
	mul.f32 	%f657, %f935, %f655;
	mul.f32 	%f658, %f936, %f655;
	mul.f32 	%f659, %f937, %f655;
	mul.f32 	%f660, %f934, %f656;
	mul.f32 	%f661, %f935, %f657;
	mul.f32 	%f662, %f936, %f658;
	mul.f32 	%f663, %f934, %f657;
	mul.f32 	%f664, %f936, %f659;
	mul.f32 	%f665, %f934, %f658;
	mul.f32 	%f666, %f935, %f659;
	mul.f32 	%f667, %f935, %f658;
	mul.f32 	%f668, %f934, %f659;
	sub.f32 	%f669, %f660, %f661;
	sub.f32 	%f670, %f669, %f662;
	fma.rn.f32 	%f671, %f937, %f659, %f670;
	sub.f32 	%f672, %f663, %f664;
	add.f32 	%f673, %f672, %f672;
	add.f32 	%f674, %f665, %f666;
	add.f32 	%f675, %f674, %f674;
	add.f32 	%f676, %f663, %f664;
	add.f32 	%f677, %f676, %f676;
	sub.f32 	%f678, %f661, %f660;
	sub.f32 	%f679, %f678, %f662;
	fma.rn.f32 	%f680, %f937, %f659, %f679;
	sub.f32 	%f681, %f667, %f668;
	add.f32 	%f682, %f681, %f681;
	sub.f32 	%f683, %f665, %f666;
	add.f32 	%f684, %f683, %f683;
	add.f32 	%f685, %f667, %f668;
	add.f32 	%f686, %f685, %f685;
	neg.f32 	%f687, %f660;
	sub.f32 	%f688, %f687, %f661;
	add.f32 	%f689, %f662, %f688;
	fma.rn.f32 	%f690, %f937, %f659, %f689;
	mul.f32 	%f691, %f930, %f671;
	fma.rn.f32 	%f692, %f932, %f673, %f691;
	fma.rn.f32 	%f946, %f933, %f675, %f692;
	mul.f32 	%f693, %f932, %f680;
	fma.rn.f32 	%f694, %f930, %f677, %f693;
	fma.rn.f32 	%f943, %f933, %f682, %f694;
	mul.f32 	%f695, %f932, %f686;
	fma.rn.f32 	%f696, %f930, %f684, %f695;
	fma.rn.f32 	%f940, %f933, %f690, %f696;
	mul.f32 	%f697, %f929, %f671;
	fma.rn.f32 	%f945, %f931, %f673, %f697;
	mul.f32 	%f698, %f931, %f680;
	fma.rn.f32 	%f942, %f929, %f677, %f698;
	mul.f32 	%f699, %f931, %f686;
	fma.rn.f32 	%f939, %f929, %f684, %f699;
	mul.f32 	%f944, %f928, %f671;
	mul.f32 	%f941, %f928, %f677;
	mul.f32 	%f938, %f928, %f684;

$L__BB2_36:
	mul.f32 	%f731, %f939, %f943;
	mul.f32 	%f732, %f940, %f942;
	sub.f32 	%f733, %f732, %f731;
	mul.f32 	%f734, %f944, %f733;
	mul.f32 	%f735, %f938, %f943;
	mul.f32 	%f736, %f940, %f941;
	sub.f32 	%f737, %f736, %f735;
	mul.f32 	%f738, %f737, %f945;
	sub.f32 	%f739, %f734, %f738;
	mul.f32 	%f740, %f938, %f942;
	mul.f32 	%f741, %f939, %f941;
	sub.f32 	%f742, %f741, %f740;
	fma.rn.f32 	%f743, %f742, %f946, %f739;
	rcp.rn.f32 	%f744, %f743;
	mul.f32 	%f953, %f733, %f744;
	mul.f32 	%f745, %f940, %f945;
	mul.f32 	%f746, %f939, %f946;
	sub.f32 	%f747, %f746, %f745;
	mul.f32 	%f954, %f747, %f744;
	mul.f32 	%f748, %f942, %f946;
	mul.f32 	%f749, %f943, %f945;
	sub.f32 	%f750, %f749, %f748;
	mul.f32 	%f955, %f750, %f744;
	sub.f32 	%f751, %f735, %f736;
	mul.f32 	%f950, %f751, %f744;
	mul.f32 	%f752, %f938, %f946;
	mul.f32 	%f753, %f940, %f944;
	sub.f32 	%f754, %f753, %f752;
	mul.f32 	%f951, %f754, %f744;
	mul.f32 	%f755, %f943, %f944;
	mul.f32 	%f756, %f941, %f946;
	sub.f32 	%f757, %f756, %f755;
	mul.f32 	%f952, %f757, %f744;
	mul.f32 	%f947, %f742, %f744;
	mul.f32 	%f758, %f939, %f944;
	mul.f32 	%f759, %f938, %f945;
	sub.f32 	%f760, %f759, %f758;
	mul.f32 	%f948, %f760, %f744;
	mul.f32 	%f761, %f941, %f945;
	mul.f32 	%f762, %f942, %f944;
	sub.f32 	%f763, %f762, %f761;
	mul.f32 	%f949, %f763, %f744;
	bra.uni 	$L__BB2_37;

$L__BB2_28:
	// begin inline asm
	call (%rd257), _optix_get_instance_inverse_transform_from_handle, (%rd136);
	// end inline asm

$L__BB2_29:
	// begin inline asm
	cvta.to.global.u64 %rd142, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd142];
	// end inline asm
	mov.b32 	%f953, %r167;
	mov.b32 	%f954, %r168;
	mov.b32 	%f955, %r169;
	add.s64 	%rd146, %rd257, 16;
	// begin inline asm
	cvta.to.global.u64 %rd145, %rd146;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd145];
	// end inline asm
	mov.b32 	%f950, %r171;
	mov.b32 	%f951, %r172;
	mov.b32 	%f952, %r173;
	add.s64 	%rd149, %rd257, 32;
	// begin inline asm
	cvta.to.global.u64 %rd148, %rd149;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd148];
	// end inline asm
	mov.b32 	%f947, %r175;
	mov.b32 	%f948, %r176;
	mov.b32 	%f949, %r177;

$L__BB2_37:
	setp.eq.s32 	%p19, %r317, 0;
	@%p19 bra 	$L__BB2_39;

	mul.f32 	%f764, %f924, %f954;
	fma.rn.f32 	%f765, %f921, %f953, %f764;
	fma.rn.f32 	%f304, %f927, %f955, %f765;
	mul.f32 	%f766, %f923, %f954;
	fma.rn.f32 	%f767, %f920, %f953, %f766;
	fma.rn.f32 	%f305, %f926, %f955, %f767;
	mul.f32 	%f768, %f922, %f954;
	fma.rn.f32 	%f769, %f919, %f953, %f768;
	fma.rn.f32 	%f955, %f925, %f955, %f769;
	mul.f32 	%f770, %f924, %f951;
	fma.rn.f32 	%f771, %f921, %f950, %f770;
	fma.rn.f32 	%f307, %f927, %f952, %f771;
	mul.f32 	%f772, %f923, %f951;
	fma.rn.f32 	%f773, %f920, %f950, %f772;
	fma.rn.f32 	%f308, %f926, %f952, %f773;
	mul.f32 	%f774, %f922, %f951;
	fma.rn.f32 	%f775, %f919, %f950, %f774;
	fma.rn.f32 	%f952, %f925, %f952, %f775;
	mul.f32 	%f776, %f924, %f948;
	fma.rn.f32 	%f777, %f921, %f947, %f776;
	fma.rn.f32 	%f310, %f927, %f949, %f777;
	mul.f32 	%f778, %f923, %f948;
	fma.rn.f32 	%f779, %f920, %f947, %f778;
	fma.rn.f32 	%f311, %f926, %f949, %f779;
	mul.f32 	%f780, %f922, %f948;
	fma.rn.f32 	%f781, %f919, %f947, %f780;
	fma.rn.f32 	%f949, %f925, %f949, %f781;
	mov.f32 	%f947, %f310;
	mov.f32 	%f948, %f311;
	mov.f32 	%f950, %f307;
	mov.f32 	%f951, %f308;
	mov.f32 	%f953, %f304;
	mov.f32 	%f954, %f305;

$L__BB2_39:
	add.s32 	%r317, %r317, 1;
	setp.lt.u32 	%p20, %r317, %r162;
	mov.f32 	%f919, %f955;
	mov.f32 	%f920, %f954;
	mov.f32 	%f921, %f953;
	mov.f32 	%f922, %f952;
	mov.f32 	%f923, %f951;
	mov.f32 	%f924, %f950;
	mov.f32 	%f925, %f949;
	mov.f32 	%f926, %f948;
	mov.f32 	%f927, %f947;
	@%p20 bra 	$L__BB2_24;

$L__BB2_40:
	mul.f32 	%f782, %f975, %f954;
	fma.rn.f32 	%f783, %f974, %f953, %f782;
	mul.f32 	%f784, %f975, %f951;
	fma.rn.f32 	%f785, %f974, %f950, %f784;
	mul.f32 	%f786, %f975, %f948;
	fma.rn.f32 	%f787, %f974, %f947, %f786;
	fma.rn.f32 	%f976, %f595, %f949, %f787;
	fma.rn.f32 	%f975, %f595, %f952, %f785;
	fma.rn.f32 	%f974, %f595, %f955, %f783;
	bra.uni 	$L__BB2_42;

$L__BB2_41:
	mov.f32 	%f976, %f595;

$L__BB2_42:
	ld.v4.f32 	{%f791, %f792, %f793, %f794}, [%rd1+208];
	ld.f32 	%f798, [%rd1+160];
	fma.rn.f32 	%f799, %f916, %f798, %f791;
	ld.f32 	%f800, [%rd1+164];
	fma.rn.f32 	%f801, %f916, %f800, %f792;
	ld.f32 	%f802, [%rd1+168];
	fma.rn.f32 	%f803, %f916, %f802, %f793;
	ld.f32 	%f804, [%rd1+176];
	fma.rn.f32 	%f805, %f917, %f804, %f799;
	ld.f32 	%f806, [%rd1+180];
	fma.rn.f32 	%f807, %f917, %f806, %f801;
	ld.f32 	%f808, [%rd1+184];
	fma.rn.f32 	%f809, %f917, %f808, %f803;
	ld.f32 	%f810, [%rd1+192];
	fma.rn.f32 	%f811, %f918, %f810, %f805;
	ld.f32 	%f812, [%rd1+196];
	fma.rn.f32 	%f813, %f918, %f812, %f807;
	ld.f32 	%f814, [%rd1+200];
	fma.rn.f32 	%f815, %f918, %f814, %f809;
	ld.v4.f32 	{%f816, %f817, %f818, %f819}, [%rd1+160];
	mul.f32 	%f823, %f974, %f816;
	mul.f32 	%f824, %f974, %f817;
	mul.f32 	%f825, %f974, %f818;
	fma.rn.f32 	%f826, %f975, %f804, %f823;
	fma.rn.f32 	%f827, %f975, %f806, %f824;
	fma.rn.f32 	%f828, %f975, %f808, %f825;
	fma.rn.f32 	%f829, %f976, %f810, %f826;
	fma.rn.f32 	%f830, %f976, %f812, %f827;
	fma.rn.f32 	%f831, %f976, %f814, %f828;
	rcp.rn.f32 	%f832, %f831;
	mul.f32 	%f833, %f815, %f832;
	neg.f32 	%f340, %f833;
	fma.rn.f32 	%f834, %f340, %f829, %f811;
	fma.rn.f32 	%f835, %f340, %f830, %f813;
	mul.f32 	%f836, %f835, %f835;
	fma.rn.f32 	%f837, %f834, %f834, %f836;
	setp.gtu.f32 	%p21, %f837, 0f3F800000;
	@%p21 bra 	$L__BB2_44;

	mov.u32 	%r314, 254;
	// begin inline asm
	call (%r313), _optix_report_intersection_0, (%f340, %r314);
	// end inline asm

$L__BB2_44:
	ret;

}
	// .globl	__closesthit__disk
.visible .entry __closesthit__disk()
{
	.reg .pred 	%p<71>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<2118>;
	.reg .b32 	%r<660>;
	.reg .b64 	%rd<658>;


	// begin inline asm
	call (%r27), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r28), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r30), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r31), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r32), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r33, %r32, %r28, %r31;
	mad.lo.s32 	%r1, %r33, %r27, %r30;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64 	%p1, %rd1, 0;
	@%p1 bra 	$L__BB3_2;

	cvta.to.global.u64 	%rd45, %rd1;
	cvt.u64.u32 	%rd46, %r1;
	add.s64 	%rd47, %rd45, %rd46;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd47], %rs1;
	bra.uni 	$L__BB3_117;

$L__BB3_2:
	// begin inline asm
	call (%rd48), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd3, [%rd48+8];
	// begin inline asm
	call (%f1896), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1897), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1898), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r34), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p2, %r34, 0;
	@%p2 bra 	$L__BB3_23;

	// begin inline asm
	call (%r35), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f722), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p3, %r35, 0;
	@%p3 bra 	$L__BB3_21;

	mov.u32 	%r655, 0;

$L__BB3_5:
	.pragma "nounroll";
	// begin inline asm
	call (%rd49), _optix_get_transform_list_handle, (%r655);
	// end inline asm
	// begin inline asm
	call (%r38), _optix_get_transform_type_from_handle, (%rd49);
	// end inline asm
	or.b32  	%r39, %r38, 1;
	setp.eq.s32 	%p4, %r39, 3;
	@%p4 bra 	$L__BB3_11;
	bra.uni 	$L__BB3_6;

$L__BB3_11:
	setp.eq.s32 	%p7, %r38, 2;
	@%p7 bra 	$L__BB3_15;
	bra.uni 	$L__BB3_12;

$L__BB3_15:
	// begin inline asm
	call (%rd121), _optix_get_matrix_motion_transform_from_handle, (%rd49);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd123, %rd121;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r127,%r128,%r129,%r130}, [%rd123];
	// end inline asm
	add.s64 	%rd127, %rd121, 16;
	// begin inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r131,%r132,%r133,%r134}, [%rd126];
	// end inline asm
	add.s64 	%rd130, %rd121, 32;
	// begin inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r135,%r136,%r137,%r138}, [%rd129];
	// end inline asm
	add.s64 	%rd133, %rd121, 48;
	// begin inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r139,%r140,%r141,%r142}, [%rd132];
	// end inline asm
	add.s64 	%rd136, %rd121, 64;
	// begin inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r143,%r144,%r145,%r146}, [%rd135];
	// end inline asm
	add.s64 	%rd139, %rd121, 80;
	// begin inline asm
	cvta.to.global.u64 %rd138, %rd139;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd138];
	// end inline asm
	add.s64 	%rd142, %rd121, 96;
	// begin inline asm
	cvta.to.global.u64 %rd141, %rd142;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd141];
	// end inline asm
	add.s64 	%rd145, %rd121, 112;
	// begin inline asm
	cvta.to.global.u64 %rd144, %rd145;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd144];
	// end inline asm
	mov.b32 	%f850, %r130;
	mov.b32 	%f851, %r131;
	and.b32  	%r171, %r129, 65535;
	add.s32 	%r172, %r171, -1;
	cvt.rn.f32.s32 	%f852, %r172;
	sub.f32 	%f853, %f722, %f850;
	mul.f32 	%f854, %f853, %f852;
	sub.f32 	%f855, %f851, %f850;
	div.rn.f32 	%f856, %f854, %f855;
	min.f32 	%f857, %f852, %f856;
	mov.f32 	%f858, 0f00000000;
	max.f32 	%f859, %f858, %f857;
	cvt.rmi.f32.f32 	%f860, %f859;
	sub.f32 	%f90, %f859, %f860;
	cvt.rzi.s32.f32 	%r173, %f860;
	mul.wide.s32 	%rd156, %r173, 48;
	add.s64 	%rd148, %rd130, %rd156;
	// begin inline asm
	cvta.to.global.u64 %rd147, %rd148;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r159,%r160,%r161,%r162}, [%rd147];
	// end inline asm
	mov.b32 	%f1851, %r159;
	mov.b32 	%f1850, %r160;
	mov.b32 	%f1849, %r161;
	mov.b32 	%f1848, %r162;
	add.s64 	%rd151, %rd148, 16;
	// begin inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd150];
	// end inline asm
	mov.b32 	%f1855, %r163;
	mov.b32 	%f1854, %r164;
	mov.b32 	%f1853, %r165;
	mov.b32 	%f1852, %r166;
	add.s64 	%rd154, %rd148, 32;
	// begin inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd153];
	// end inline asm
	mov.b32 	%f1859, %r167;
	mov.b32 	%f1858, %r168;
	mov.b32 	%f1857, %r169;
	mov.b32 	%f1856, %r170;
	setp.leu.f32 	%p9, %f90, 0f00000000;
	@%p9 bra 	$L__BB3_17;

	cvt.rmi.f32.f32 	%f1819, %f859;
	cvt.rzi.s32.f32 	%r654, %f1819;
	cvt.s64.s32 	%rd653, %r654;
	mov.f32 	%f861, 0f3F800000;
	sub.f32 	%f862, %f861, %f90;
	mul.lo.s64 	%rd166, %rd653, 48;
	add.s64 	%rd167, %rd121, %rd166;
	add.s64 	%rd158, %rd167, 80;
	// begin inline asm
	cvta.to.global.u64 %rd157, %rd158;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r174,%r175,%r176,%r177}, [%rd157];
	// end inline asm
	mov.b32 	%f863, %r174;
	mov.b32 	%f864, %r175;
	mov.b32 	%f865, %r176;
	mov.b32 	%f866, %r177;
	mul.f32 	%f867, %f90, %f863;
	mul.f32 	%f868, %f90, %f864;
	mul.f32 	%f869, %f90, %f865;
	mul.f32 	%f870, %f90, %f866;
	fma.rn.f32 	%f1851, %f862, %f1851, %f867;
	fma.rn.f32 	%f1850, %f862, %f1850, %f868;
	fma.rn.f32 	%f1849, %f862, %f1849, %f869;
	fma.rn.f32 	%f1848, %f862, %f1848, %f870;
	add.s64 	%rd161, %rd167, 96;
	// begin inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r178,%r179,%r180,%r181}, [%rd160];
	// end inline asm
	mov.b32 	%f871, %r178;
	mov.b32 	%f872, %r179;
	mov.b32 	%f873, %r180;
	mov.b32 	%f874, %r181;
	mul.f32 	%f875, %f90, %f871;
	mul.f32 	%f876, %f90, %f872;
	mul.f32 	%f877, %f90, %f873;
	mul.f32 	%f878, %f90, %f874;
	fma.rn.f32 	%f1855, %f862, %f1855, %f875;
	fma.rn.f32 	%f1854, %f862, %f1854, %f876;
	fma.rn.f32 	%f1853, %f862, %f1853, %f877;
	fma.rn.f32 	%f1852, %f862, %f1852, %f878;
	add.s64 	%rd164, %rd167, 112;
	// begin inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r182,%r183,%r184,%r185}, [%rd163];
	// end inline asm
	mov.b32 	%f879, %r182;
	mov.b32 	%f880, %r183;
	mov.b32 	%f881, %r184;
	mov.b32 	%f882, %r185;
	mul.f32 	%f883, %f90, %f879;
	mul.f32 	%f884, %f90, %f880;
	mul.f32 	%f885, %f90, %f881;
	mul.f32 	%f886, %f90, %f882;
	fma.rn.f32 	%f1859, %f862, %f1859, %f883;
	fma.rn.f32 	%f1858, %f862, %f1858, %f884;
	fma.rn.f32 	%f1857, %f862, %f1857, %f885;
	fma.rn.f32 	%f1856, %f862, %f1856, %f886;
	bra.uni 	$L__BB3_17;

$L__BB3_6:
	mov.f32 	%f1860, 0f00000000;
	mov.f32 	%f1863, 0f3F800000;
	setp.eq.s32 	%p5, %r38, 4;
	@%p5 bra 	$L__BB3_9;

	setp.ne.s32 	%p6, %r38, 1;
	mov.f32 	%f1861, %f1860;
	mov.f32 	%f1862, %f1860;
	mov.f32 	%f1864, %f1860;
	mov.f32 	%f1865, %f1860;
	mov.f32 	%f1866, %f1863;
	mov.f32 	%f1867, %f1860;
	mov.f32 	%f1868, %f1860;
	mov.f32 	%f1869, %f1863;
	mov.f32 	%f1870, %f1860;
	mov.f32 	%f1871, %f1860;
	@%p6 bra 	$L__BB3_18;

	// begin inline asm
	call (%rd51), _optix_get_static_transform_from_handle, (%rd49);
	// end inline asm
	add.s64 	%rd654, %rd51, 64;
	bra.uni 	$L__BB3_10;

$L__BB3_12:
	// begin inline asm
	call (%rd64), _optix_get_srt_motion_transform_from_handle, (%rd49);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd66, %rd64;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r52,%r53,%r54,%r55}, [%rd66];
	// end inline asm
	add.s64 	%rd70, %rd64, 16;
	// begin inline asm
	cvta.to.global.u64 %rd69, %rd70;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r56,%r57,%r58,%r59}, [%rd69];
	// end inline asm
	add.s64 	%rd73, %rd64, 32;
	// begin inline asm
	cvta.to.global.u64 %rd72, %rd73;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r60,%r61,%r62,%r63}, [%rd72];
	// end inline asm
	add.s64 	%rd76, %rd64, 48;
	// begin inline asm
	cvta.to.global.u64 %rd75, %rd76;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r64,%r65,%r66,%r67}, [%rd75];
	// end inline asm
	add.s64 	%rd79, %rd64, 64;
	// begin inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r68,%r69,%r70,%r71}, [%rd78];
	// end inline asm
	add.s64 	%rd82, %rd64, 80;
	// begin inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r72,%r73,%r74,%r75}, [%rd81];
	// end inline asm
	add.s64 	%rd85, %rd64, 96;
	// begin inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r76,%r77,%r78,%r79}, [%rd84];
	// end inline asm
	add.s64 	%rd88, %rd64, 112;
	// begin inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r80,%r81,%r82,%r83}, [%rd87];
	// end inline asm
	add.s64 	%rd91, %rd64, 128;
	// begin inline asm
	cvta.to.global.u64 %rd90, %rd91;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd90];
	// end inline asm
	add.s64 	%rd94, %rd64, 144;
	// begin inline asm
	cvta.to.global.u64 %rd93, %rd94;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd93];
	// end inline asm
	mov.b32 	%f737, %r55;
	mov.b32 	%f738, %r56;
	and.b32  	%r108, %r54, 65535;
	add.s32 	%r109, %r108, -1;
	cvt.rn.f32.s32 	%f739, %r109;
	sub.f32 	%f740, %f722, %f737;
	mul.f32 	%f741, %f740, %f739;
	sub.f32 	%f742, %f738, %f737;
	div.rn.f32 	%f743, %f741, %f742;
	min.f32 	%f744, %f739, %f743;
	mov.f32 	%f745, 0f00000000;
	max.f32 	%f746, %f745, %f744;
	cvt.rmi.f32.f32 	%f747, %f746;
	sub.f32 	%f29, %f746, %f747;
	cvt.rzi.s32.f32 	%r110, %f747;
	mul.wide.s32 	%rd108, %r110, 64;
	add.s64 	%rd97, %rd73, %rd108;
	// begin inline asm
	cvta.to.global.u64 %rd96, %rd97;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd96];
	// end inline asm
	mov.b32 	%f1832, %r92;
	mov.b32 	%f1833, %r93;
	mov.b32 	%f1834, %r94;
	mov.b32 	%f1835, %r95;
	add.s64 	%rd100, %rd97, 16;
	// begin inline asm
	cvta.to.global.u64 %rd99, %rd100;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd99];
	// end inline asm
	mov.b32 	%f1836, %r96;
	mov.b32 	%f1837, %r97;
	mov.b32 	%f1838, %r98;
	mov.b32 	%f1839, %r99;
	add.s64 	%rd103, %rd97, 32;
	// begin inline asm
	cvta.to.global.u64 %rd102, %rd103;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd102];
	// end inline asm
	mov.b32 	%f1840, %r100;
	mov.b32 	%f1841, %r101;
	mov.b32 	%f1842, %r102;
	mov.b32 	%f1843, %r103;
	add.s64 	%rd106, %rd97, 48;
	// begin inline asm
	cvta.to.global.u64 %rd105, %rd106;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd105];
	// end inline asm
	mov.b32 	%f1844, %r104;
	mov.b32 	%f1845, %r105;
	mov.b32 	%f1846, %r106;
	mov.b32 	%f1847, %r107;
	setp.leu.f32 	%p8, %f29, 0f00000000;
	@%p8 bra 	$L__BB3_14;

	mov.f32 	%f748, 0f3F800000;
	sub.f32 	%f749, %f748, %f29;
	add.s64 	%rd110, %rd97, 64;
	// begin inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r111,%r112,%r113,%r114}, [%rd109];
	// end inline asm
	mov.b32 	%f750, %r111;
	mov.b32 	%f751, %r112;
	mov.b32 	%f752, %r113;
	mov.b32 	%f753, %r114;
	mul.f32 	%f754, %f29, %f750;
	mul.f32 	%f755, %f29, %f751;
	mul.f32 	%f756, %f29, %f752;
	mul.f32 	%f757, %f29, %f753;
	fma.rn.f32 	%f1832, %f749, %f1832, %f754;
	fma.rn.f32 	%f1833, %f749, %f1833, %f755;
	fma.rn.f32 	%f1834, %f749, %f1834, %f756;
	fma.rn.f32 	%f1835, %f749, %f1835, %f757;
	add.s64 	%rd113, %rd97, 80;
	// begin inline asm
	cvta.to.global.u64 %rd112, %rd113;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r115,%r116,%r117,%r118}, [%rd112];
	// end inline asm
	mov.b32 	%f758, %r115;
	mov.b32 	%f759, %r116;
	mov.b32 	%f760, %r117;
	mov.b32 	%f761, %r118;
	mul.f32 	%f762, %f29, %f758;
	mul.f32 	%f763, %f29, %f759;
	mul.f32 	%f764, %f29, %f760;
	mul.f32 	%f765, %f29, %f761;
	fma.rn.f32 	%f1836, %f749, %f1836, %f762;
	fma.rn.f32 	%f1837, %f749, %f1837, %f763;
	fma.rn.f32 	%f1838, %f749, %f1838, %f764;
	fma.rn.f32 	%f1839, %f749, %f1839, %f765;
	add.s64 	%rd116, %rd97, 96;
	// begin inline asm
	cvta.to.global.u64 %rd115, %rd116;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r119,%r120,%r121,%r122}, [%rd115];
	// end inline asm
	mov.b32 	%f766, %r119;
	mov.b32 	%f767, %r120;
	mov.b32 	%f768, %r121;
	mov.b32 	%f769, %r122;
	mul.f32 	%f770, %f29, %f766;
	mul.f32 	%f771, %f29, %f767;
	mul.f32 	%f772, %f29, %f768;
	mul.f32 	%f773, %f29, %f769;
	fma.rn.f32 	%f1840, %f749, %f1840, %f770;
	fma.rn.f32 	%f774, %f749, %f1841, %f771;
	fma.rn.f32 	%f775, %f749, %f1842, %f772;
	fma.rn.f32 	%f776, %f749, %f1843, %f773;
	add.s64 	%rd119, %rd97, 112;
	// begin inline asm
	cvta.to.global.u64 %rd118, %rd119;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r123,%r124,%r125,%r126}, [%rd118];
	// end inline asm
	mov.b32 	%f777, %r123;
	mov.b32 	%f778, %r124;
	mov.b32 	%f779, %r125;
	mov.b32 	%f780, %r126;
	mul.f32 	%f781, %f29, %f777;
	mul.f32 	%f782, %f29, %f778;
	mul.f32 	%f783, %f29, %f779;
	mul.f32 	%f784, %f29, %f780;
	fma.rn.f32 	%f785, %f749, %f1844, %f781;
	fma.rn.f32 	%f1845, %f749, %f1845, %f782;
	fma.rn.f32 	%f1846, %f749, %f1846, %f783;
	fma.rn.f32 	%f1847, %f749, %f1847, %f784;
	mul.f32 	%f786, %f775, %f775;
	fma.rn.f32 	%f787, %f774, %f774, %f786;
	fma.rn.f32 	%f788, %f776, %f776, %f787;
	fma.rn.f32 	%f789, %f785, %f785, %f788;
	sqrt.rn.f32 	%f790, %f789;
	rcp.rn.f32 	%f791, %f790;
	mul.f32 	%f1841, %f774, %f791;
	mul.f32 	%f1842, %f775, %f791;
	mul.f32 	%f1843, %f776, %f791;
	mul.f32 	%f1844, %f791, %f785;

$L__BB3_14:
	mul.f32 	%f792, %f1842, %f1842;
	fma.rn.f32 	%f793, %f1841, %f1841, %f792;
	fma.rn.f32 	%f794, %f1843, %f1843, %f793;
	fma.rn.f32 	%f795, %f1844, %f1844, %f794;
	rcp.rn.f32 	%f796, %f795;
	mul.f32 	%f797, %f1841, %f796;
	mul.f32 	%f798, %f1842, %f796;
	mul.f32 	%f799, %f1843, %f796;
	mul.f32 	%f800, %f1844, %f796;
	mul.f32 	%f801, %f1841, %f797;
	mul.f32 	%f802, %f1842, %f798;
	mul.f32 	%f803, %f1843, %f799;
	mul.f32 	%f804, %f1841, %f798;
	mul.f32 	%f805, %f1843, %f800;
	mul.f32 	%f806, %f1841, %f799;
	mul.f32 	%f807, %f1842, %f800;
	mul.f32 	%f808, %f1842, %f799;
	mul.f32 	%f809, %f1841, %f800;
	sub.f32 	%f810, %f801, %f802;
	sub.f32 	%f811, %f810, %f803;
	fma.rn.f32 	%f812, %f1844, %f800, %f811;
	sub.f32 	%f813, %f804, %f805;
	add.f32 	%f814, %f813, %f813;
	add.f32 	%f815, %f806, %f807;
	add.f32 	%f816, %f815, %f815;
	add.f32 	%f817, %f804, %f805;
	add.f32 	%f818, %f817, %f817;
	sub.f32 	%f819, %f802, %f801;
	sub.f32 	%f820, %f819, %f803;
	fma.rn.f32 	%f821, %f1844, %f800, %f820;
	sub.f32 	%f822, %f808, %f809;
	add.f32 	%f823, %f822, %f822;
	sub.f32 	%f824, %f806, %f807;
	add.f32 	%f825, %f824, %f824;
	add.f32 	%f826, %f808, %f809;
	add.f32 	%f827, %f826, %f826;
	neg.f32 	%f828, %f801;
	sub.f32 	%f829, %f828, %f802;
	add.f32 	%f830, %f803, %f829;
	fma.rn.f32 	%f831, %f1844, %f800, %f830;
	mul.f32 	%f832, %f1835, %f812;
	fma.rn.f32 	%f833, %f1838, %f814, %f832;
	fma.rn.f32 	%f834, %f1840, %f816, %f833;
	sub.f32 	%f1848, %f1845, %f834;
	mul.f32 	%f835, %f1838, %f821;
	fma.rn.f32 	%f836, %f1835, %f818, %f835;
	fma.rn.f32 	%f837, %f1840, %f823, %f836;
	sub.f32 	%f1852, %f1846, %f837;
	mul.f32 	%f838, %f1838, %f827;
	fma.rn.f32 	%f839, %f1835, %f825, %f838;
	fma.rn.f32 	%f840, %f1840, %f831, %f839;
	sub.f32 	%f1856, %f1847, %f840;
	mul.f32 	%f841, %f1834, %f812;
	fma.rn.f32 	%f842, %f1837, %f814, %f841;
	fma.rn.f32 	%f1849, %f1839, %f816, %f842;
	mul.f32 	%f843, %f1837, %f821;
	fma.rn.f32 	%f844, %f1834, %f818, %f843;
	fma.rn.f32 	%f1853, %f1839, %f823, %f844;
	mul.f32 	%f845, %f1837, %f827;
	fma.rn.f32 	%f846, %f1834, %f825, %f845;
	fma.rn.f32 	%f1857, %f1839, %f831, %f846;
	mul.f32 	%f847, %f1833, %f812;
	fma.rn.f32 	%f1850, %f1836, %f814, %f847;
	mul.f32 	%f848, %f1836, %f821;
	fma.rn.f32 	%f1854, %f1833, %f818, %f848;
	mul.f32 	%f849, %f1836, %f827;
	fma.rn.f32 	%f1858, %f1833, %f825, %f849;
	mul.f32 	%f1851, %f1832, %f812;
	mul.f32 	%f1855, %f1832, %f818;
	mul.f32 	%f1859, %f1832, %f825;

$L__BB3_17:
	mul.f32 	%f887, %f1853, %f1858;
	mul.f32 	%f888, %f1854, %f1857;
	sub.f32 	%f889, %f888, %f887;
	mul.f32 	%f890, %f1851, %f889;
	mul.f32 	%f891, %f1853, %f1859;
	mul.f32 	%f892, %f1855, %f1857;
	sub.f32 	%f893, %f892, %f891;
	mul.f32 	%f894, %f1850, %f893;
	sub.f32 	%f895, %f890, %f894;
	mul.f32 	%f896, %f1854, %f1859;
	mul.f32 	%f897, %f1855, %f1858;
	sub.f32 	%f898, %f897, %f896;
	fma.rn.f32 	%f899, %f1849, %f898, %f895;
	rcp.rn.f32 	%f900, %f899;
	mul.f32 	%f1863, %f889, %f900;
	mul.f32 	%f901, %f1850, %f1857;
	mul.f32 	%f902, %f1849, %f1858;
	sub.f32 	%f903, %f902, %f901;
	mul.f32 	%f1862, %f903, %f900;
	mul.f32 	%f904, %f1849, %f1854;
	mul.f32 	%f905, %f1850, %f1853;
	sub.f32 	%f906, %f905, %f904;
	mul.f32 	%f1861, %f906, %f900;
	sub.f32 	%f907, %f891, %f892;
	mul.f32 	%f1867, %f907, %f900;
	mul.f32 	%f908, %f1849, %f1859;
	mul.f32 	%f909, %f1851, %f1857;
	sub.f32 	%f910, %f909, %f908;
	mul.f32 	%f1866, %f910, %f900;
	mul.f32 	%f911, %f1851, %f1853;
	mul.f32 	%f912, %f1849, %f1855;
	sub.f32 	%f913, %f912, %f911;
	mul.f32 	%f1865, %f913, %f900;
	mul.f32 	%f1871, %f898, %f900;
	mul.f32 	%f914, %f1851, %f1858;
	mul.f32 	%f915, %f1850, %f1859;
	sub.f32 	%f916, %f915, %f914;
	mul.f32 	%f1870, %f916, %f900;
	mul.f32 	%f917, %f1850, %f1855;
	mul.f32 	%f918, %f1851, %f1854;
	sub.f32 	%f919, %f918, %f917;
	mul.f32 	%f1869, %f919, %f900;
	mul.f32 	%f920, %f1848, %f1863;
	neg.f32 	%f921, %f920;
	mul.f32 	%f922, %f1852, %f1862;
	sub.f32 	%f923, %f921, %f922;
	mul.f32 	%f924, %f1856, %f1861;
	sub.f32 	%f1860, %f923, %f924;
	mul.f32 	%f925, %f1848, %f1867;
	neg.f32 	%f926, %f925;
	mul.f32 	%f927, %f1852, %f1866;
	sub.f32 	%f928, %f926, %f927;
	mul.f32 	%f929, %f1856, %f1865;
	sub.f32 	%f1864, %f928, %f929;
	mul.f32 	%f930, %f1848, %f1871;
	neg.f32 	%f931, %f930;
	mul.f32 	%f932, %f1852, %f1870;
	sub.f32 	%f933, %f931, %f932;
	mul.f32 	%f934, %f1856, %f1869;
	sub.f32 	%f1868, %f933, %f934;
	bra.uni 	$L__BB3_18;

$L__BB3_9:
	// begin inline asm
	call (%rd654), _optix_get_instance_inverse_transform_from_handle, (%rd49);
	// end inline asm

$L__BB3_10:
	// begin inline asm
	cvta.to.global.u64 %rd55, %rd654;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r40,%r41,%r42,%r43}, [%rd55];
	// end inline asm
	mov.b32 	%f1863, %r40;
	mov.b32 	%f1862, %r41;
	mov.b32 	%f1861, %r42;
	mov.b32 	%f1860, %r43;
	add.s64 	%rd59, %rd654, 16;
	// begin inline asm
	cvta.to.global.u64 %rd58, %rd59;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r44,%r45,%r46,%r47}, [%rd58];
	// end inline asm
	mov.b32 	%f1867, %r44;
	mov.b32 	%f1866, %r45;
	mov.b32 	%f1865, %r46;
	mov.b32 	%f1864, %r47;
	add.s64 	%rd62, %rd654, 32;
	// begin inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r48,%r49,%r50,%r51}, [%rd61];
	// end inline asm
	mov.b32 	%f1871, %r48;
	mov.b32 	%f1870, %r49;
	mov.b32 	%f1869, %r50;
	mov.b32 	%f1868, %r51;

$L__BB3_18:
	setp.eq.s32 	%p10, %r655, 0;
	@%p10 bra 	$L__BB3_20;

	mul.f32 	%f935, %f1828, %f1863;
	fma.rn.f32 	%f936, %f1824, %f1862, %f935;
	fma.rn.f32 	%f151, %f1820, %f1861, %f936;
	mul.f32 	%f937, %f1829, %f1863;
	fma.rn.f32 	%f938, %f1825, %f1862, %f937;
	fma.rn.f32 	%f152, %f1821, %f1861, %f938;
	mul.f32 	%f939, %f1830, %f1863;
	fma.rn.f32 	%f940, %f1826, %f1862, %f939;
	fma.rn.f32 	%f153, %f1822, %f1861, %f940;
	mul.f32 	%f941, %f1831, %f1863;
	fma.rn.f32 	%f942, %f1827, %f1862, %f941;
	fma.rn.f32 	%f943, %f1823, %f1861, %f942;
	add.f32 	%f1860, %f1860, %f943;
	mul.f32 	%f944, %f1828, %f1867;
	fma.rn.f32 	%f945, %f1824, %f1866, %f944;
	fma.rn.f32 	%f155, %f1820, %f1865, %f945;
	mul.f32 	%f946, %f1829, %f1867;
	fma.rn.f32 	%f947, %f1825, %f1866, %f946;
	fma.rn.f32 	%f156, %f1821, %f1865, %f947;
	mul.f32 	%f948, %f1830, %f1867;
	fma.rn.f32 	%f949, %f1826, %f1866, %f948;
	fma.rn.f32 	%f157, %f1822, %f1865, %f949;
	mul.f32 	%f950, %f1831, %f1867;
	fma.rn.f32 	%f951, %f1827, %f1866, %f950;
	fma.rn.f32 	%f952, %f1823, %f1865, %f951;
	add.f32 	%f1864, %f1864, %f952;
	mul.f32 	%f953, %f1828, %f1871;
	fma.rn.f32 	%f954, %f1824, %f1870, %f953;
	fma.rn.f32 	%f159, %f1820, %f1869, %f954;
	mul.f32 	%f955, %f1829, %f1871;
	fma.rn.f32 	%f956, %f1825, %f1870, %f955;
	fma.rn.f32 	%f160, %f1821, %f1869, %f956;
	mul.f32 	%f957, %f1830, %f1871;
	fma.rn.f32 	%f958, %f1826, %f1870, %f957;
	fma.rn.f32 	%f161, %f1822, %f1869, %f958;
	mul.f32 	%f959, %f1831, %f1871;
	fma.rn.f32 	%f960, %f1827, %f1870, %f959;
	fma.rn.f32 	%f961, %f1823, %f1869, %f960;
	add.f32 	%f1868, %f1868, %f961;
	mov.f32 	%f1861, %f153;
	mov.f32 	%f1862, %f152;
	mov.f32 	%f1863, %f151;
	mov.f32 	%f1865, %f157;
	mov.f32 	%f1866, %f156;
	mov.f32 	%f1867, %f155;
	mov.f32 	%f1869, %f161;
	mov.f32 	%f1870, %f160;
	mov.f32 	%f1871, %f159;

$L__BB3_20:
	add.s32 	%r655, %r655, 1;
	setp.lt.u32 	%p11, %r655, %r35;
	mov.f32 	%f1820, %f1871;
	mov.f32 	%f1821, %f1870;
	mov.f32 	%f1822, %f1869;
	mov.f32 	%f1823, %f1868;
	mov.f32 	%f1824, %f1867;
	mov.f32 	%f1825, %f1866;
	mov.f32 	%f1826, %f1865;
	mov.f32 	%f1827, %f1864;
	mov.f32 	%f1828, %f1863;
	mov.f32 	%f1829, %f1862;
	mov.f32 	%f1830, %f1861;
	mov.f32 	%f1831, %f1860;
	@%p11 bra 	$L__BB3_5;

$L__BB3_21:
	mul.f32 	%f962, %f1896, %f1863;
	fma.rn.f32 	%f963, %f1897, %f1862, %f962;
	fma.rn.f32 	%f964, %f1898, %f1861, %f963;
	mul.f32 	%f965, %f1896, %f1867;
	fma.rn.f32 	%f966, %f1897, %f1866, %f965;
	fma.rn.f32 	%f967, %f1898, %f1865, %f966;
	mul.f32 	%f968, %f1896, %f1871;
	fma.rn.f32 	%f969, %f1897, %f1870, %f968;
	fma.rn.f32 	%f970, %f1898, %f1869, %f969;
	add.f32 	%f1898, %f1868, %f970;
	add.f32 	%f1897, %f1864, %f967;
	add.f32 	%f1896, %f1860, %f964;

$L__BB3_23:
	// begin inline asm
	call (%f1954), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1955), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f973), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r186), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p12, %r186, 0;
	@%p12 bra 	$L__BB3_43;

	// begin inline asm
	call (%r187), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f974), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p13, %r187, 0;
	@%p13 bra 	$L__BB3_42;

	mov.u32 	%r656, 0;

$L__BB3_26:
	.pragma "nounroll";
	// begin inline asm
	call (%rd168), _optix_get_transform_list_handle, (%r656);
	// end inline asm
	// begin inline asm
	call (%r190), _optix_get_transform_type_from_handle, (%rd168);
	// end inline asm
	or.b32  	%r191, %r190, 1;
	setp.eq.s32 	%p14, %r191, 3;
	@%p14 bra 	$L__BB3_32;
	bra.uni 	$L__BB3_27;

$L__BB3_32:
	setp.eq.s32 	%p17, %r190, 2;
	@%p17 bra 	$L__BB3_36;
	bra.uni 	$L__BB3_33;

$L__BB3_36:
	// begin inline asm
	call (%rd240), _optix_get_matrix_motion_transform_from_handle, (%rd168);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd242, %rd240;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r279,%r280,%r281,%r282}, [%rd242];
	// end inline asm
	add.s64 	%rd246, %rd240, 16;
	// begin inline asm
	cvta.to.global.u64 %rd245, %rd246;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r283,%r284,%r285,%r286}, [%rd245];
	// end inline asm
	add.s64 	%rd249, %rd240, 32;
	// begin inline asm
	cvta.to.global.u64 %rd248, %rd249;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r287,%r288,%r289,%r290}, [%rd248];
	// end inline asm
	add.s64 	%rd252, %rd240, 48;
	// begin inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r291,%r292,%r293,%r294}, [%rd251];
	// end inline asm
	add.s64 	%rd255, %rd240, 64;
	// begin inline asm
	cvta.to.global.u64 %rd254, %rd255;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r295,%r296,%r297,%r298}, [%rd254];
	// end inline asm
	add.s64 	%rd258, %rd240, 80;
	// begin inline asm
	cvta.to.global.u64 %rd257, %rd258;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r299,%r300,%r301,%r302}, [%rd257];
	// end inline asm
	add.s64 	%rd261, %rd240, 96;
	// begin inline asm
	cvta.to.global.u64 %rd260, %rd261;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd260];
	// end inline asm
	add.s64 	%rd264, %rd240, 112;
	// begin inline asm
	cvta.to.global.u64 %rd263, %rd264;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd263];
	// end inline asm
	mov.b32 	%f1078, %r282;
	mov.b32 	%f1079, %r283;
	and.b32  	%r323, %r281, 65535;
	add.s32 	%r324, %r323, -1;
	cvt.rn.f32.s32 	%f1080, %r324;
	sub.f32 	%f1081, %f974, %f1078;
	mul.f32 	%f1082, %f1081, %f1080;
	sub.f32 	%f1083, %f1079, %f1078;
	div.rn.f32 	%f1084, %f1082, %f1083;
	min.f32 	%f1085, %f1080, %f1084;
	mov.f32 	%f1086, 0f00000000;
	max.f32 	%f1087, %f1086, %f1085;
	cvt.rmi.f32.f32 	%f1088, %f1087;
	sub.f32 	%f258, %f1087, %f1088;
	cvt.rzi.s32.f32 	%r325, %f1088;
	cvt.s64.s32 	%rd17, %r325;
	mul.wide.s32 	%rd275, %r325, 48;
	add.s64 	%rd267, %rd249, %rd275;
	// begin inline asm
	cvta.to.global.u64 %rd266, %rd267;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd266];
	// end inline asm
	mov.b32 	%f1924, %r311;
	mov.b32 	%f1925, %r312;
	mov.b32 	%f1926, %r313;
	add.s64 	%rd270, %rd267, 16;
	// begin inline asm
	cvta.to.global.u64 %rd269, %rd270;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r315,%r316,%r317,%r318}, [%rd269];
	// end inline asm
	mov.b32 	%f1921, %r315;
	mov.b32 	%f1922, %r316;
	mov.b32 	%f1923, %r317;
	add.s64 	%rd273, %rd267, 32;
	// begin inline asm
	cvta.to.global.u64 %rd272, %rd273;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r319,%r320,%r321,%r322}, [%rd272];
	// end inline asm
	mov.b32 	%f1918, %r319;
	mov.b32 	%f1919, %r320;
	mov.b32 	%f1920, %r321;
	setp.leu.f32 	%p19, %f258, 0f00000000;
	@%p19 bra 	$L__BB3_38;

	mov.f32 	%f1089, 0f3F800000;
	sub.f32 	%f1090, %f1089, %f258;
	mul.lo.s64 	%rd285, %rd17, 48;
	add.s64 	%rd286, %rd240, %rd285;
	add.s64 	%rd277, %rd286, 80;
	// begin inline asm
	cvta.to.global.u64 %rd276, %rd277;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r326,%r327,%r328,%r329}, [%rd276];
	// end inline asm
	mov.b32 	%f1091, %r326;
	mov.b32 	%f1092, %r327;
	mov.b32 	%f1093, %r328;
	mul.f32 	%f1094, %f258, %f1091;
	mul.f32 	%f1095, %f258, %f1092;
	mul.f32 	%f1096, %f258, %f1093;
	fma.rn.f32 	%f1924, %f1090, %f1924, %f1094;
	fma.rn.f32 	%f1925, %f1090, %f1925, %f1095;
	fma.rn.f32 	%f1926, %f1090, %f1926, %f1096;
	add.s64 	%rd280, %rd286, 96;
	// begin inline asm
	cvta.to.global.u64 %rd279, %rd280;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r330,%r331,%r332,%r333}, [%rd279];
	// end inline asm
	mov.b32 	%f1097, %r330;
	mov.b32 	%f1098, %r331;
	mov.b32 	%f1099, %r332;
	mul.f32 	%f1100, %f258, %f1097;
	mul.f32 	%f1101, %f258, %f1098;
	mul.f32 	%f1102, %f258, %f1099;
	fma.rn.f32 	%f1921, %f1090, %f1921, %f1100;
	fma.rn.f32 	%f1922, %f1090, %f1922, %f1101;
	fma.rn.f32 	%f1923, %f1090, %f1923, %f1102;
	add.s64 	%rd283, %rd286, 112;
	// begin inline asm
	cvta.to.global.u64 %rd282, %rd283;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r334,%r335,%r336,%r337}, [%rd282];
	// end inline asm
	mov.b32 	%f1103, %r334;
	mov.b32 	%f1104, %r335;
	mov.b32 	%f1105, %r336;
	mul.f32 	%f1106, %f258, %f1103;
	mul.f32 	%f1107, %f258, %f1104;
	mul.f32 	%f1108, %f258, %f1105;
	fma.rn.f32 	%f1918, %f1090, %f1918, %f1106;
	fma.rn.f32 	%f1919, %f1090, %f1919, %f1107;
	fma.rn.f32 	%f1920, %f1090, %f1920, %f1108;
	bra.uni 	$L__BB3_38;

$L__BB3_27:
	mov.f32 	%f1927, 0f00000000;
	mov.f32 	%f1929, 0f3F800000;
	setp.eq.s32 	%p15, %r190, 4;
	@%p15 bra 	$L__BB3_30;

	setp.ne.s32 	%p16, %r190, 1;
	mov.f32 	%f1928, %f1927;
	mov.f32 	%f1930, %f1927;
	mov.f32 	%f1931, %f1929;
	mov.f32 	%f1932, %f1927;
	mov.f32 	%f1933, %f1929;
	mov.f32 	%f1934, %f1927;
	mov.f32 	%f1935, %f1927;
	@%p16 bra 	$L__BB3_39;

	// begin inline asm
	call (%rd170), _optix_get_static_transform_from_handle, (%rd168);
	// end inline asm
	add.s64 	%rd655, %rd170, 64;
	bra.uni 	$L__BB3_31;

$L__BB3_33:
	// begin inline asm
	call (%rd183), _optix_get_srt_motion_transform_from_handle, (%rd168);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd185, %rd183;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r204,%r205,%r206,%r207}, [%rd185];
	// end inline asm
	add.s64 	%rd189, %rd183, 16;
	// begin inline asm
	cvta.to.global.u64 %rd188, %rd189;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r208,%r209,%r210,%r211}, [%rd188];
	// end inline asm
	add.s64 	%rd192, %rd183, 32;
	// begin inline asm
	cvta.to.global.u64 %rd191, %rd192;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r212,%r213,%r214,%r215}, [%rd191];
	// end inline asm
	add.s64 	%rd195, %rd183, 48;
	// begin inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r216,%r217,%r218,%r219}, [%rd194];
	// end inline asm
	add.s64 	%rd198, %rd183, 64;
	// begin inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r220,%r221,%r222,%r223}, [%rd197];
	// end inline asm
	add.s64 	%rd201, %rd183, 80;
	// begin inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r224,%r225,%r226,%r227}, [%rd200];
	// end inline asm
	add.s64 	%rd204, %rd183, 96;
	// begin inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r228,%r229,%r230,%r231}, [%rd203];
	// end inline asm
	add.s64 	%rd207, %rd183, 112;
	// begin inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r232,%r233,%r234,%r235}, [%rd206];
	// end inline asm
	add.s64 	%rd210, %rd183, 128;
	// begin inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r236,%r237,%r238,%r239}, [%rd209];
	// end inline asm
	add.s64 	%rd213, %rd183, 144;
	// begin inline asm
	cvta.to.global.u64 %rd212, %rd213;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd212];
	// end inline asm
	mov.b32 	%f986, %r207;
	mov.b32 	%f987, %r208;
	and.b32  	%r260, %r206, 65535;
	add.s32 	%r261, %r260, -1;
	cvt.rn.f32.s32 	%f988, %r261;
	sub.f32 	%f989, %f974, %f986;
	mul.f32 	%f990, %f989, %f988;
	sub.f32 	%f991, %f987, %f986;
	div.rn.f32 	%f992, %f990, %f991;
	min.f32 	%f993, %f988, %f992;
	mov.f32 	%f994, 0f00000000;
	max.f32 	%f995, %f994, %f993;
	cvt.rmi.f32.f32 	%f996, %f995;
	sub.f32 	%f218, %f995, %f996;
	cvt.rzi.s32.f32 	%r262, %f996;
	mul.wide.s32 	%rd227, %r262, 64;
	add.s64 	%rd216, %rd192, %rd227;
	// begin inline asm
	cvta.to.global.u64 %rd215, %rd216;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd215];
	// end inline asm
	mov.b32 	%f1908, %r244;
	mov.b32 	%f1909, %r245;
	mov.b32 	%f1910, %r246;
	add.s64 	%rd219, %rd216, 16;
	// begin inline asm
	cvta.to.global.u64 %rd218, %rd219;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd218];
	// end inline asm
	mov.b32 	%f1911, %r248;
	mov.b32 	%f1912, %r249;
	mov.b32 	%f1913, %r251;
	add.s64 	%rd222, %rd216, 32;
	// begin inline asm
	cvta.to.global.u64 %rd221, %rd222;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd221];
	// end inline asm
	mov.b32 	%f1914, %r253;
	mov.b32 	%f1915, %r254;
	mov.b32 	%f1916, %r255;
	add.s64 	%rd225, %rd216, 48;
	// begin inline asm
	cvta.to.global.u64 %rd224, %rd225;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd224];
	// end inline asm
	mov.b32 	%f1917, %r256;
	setp.leu.f32 	%p18, %f218, 0f00000000;
	@%p18 bra 	$L__BB3_35;

	mov.f32 	%f997, 0f3F800000;
	sub.f32 	%f998, %f997, %f218;
	add.s64 	%rd229, %rd216, 64;
	// begin inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r263,%r264,%r265,%r266}, [%rd228];
	// end inline asm
	mov.b32 	%f999, %r263;
	mov.b32 	%f1000, %r264;
	mov.b32 	%f1001, %r265;
	mul.f32 	%f1002, %f218, %f999;
	mul.f32 	%f1003, %f218, %f1000;
	mul.f32 	%f1004, %f218, %f1001;
	fma.rn.f32 	%f1908, %f998, %f1908, %f1002;
	fma.rn.f32 	%f1909, %f998, %f1909, %f1003;
	fma.rn.f32 	%f1910, %f998, %f1910, %f1004;
	add.s64 	%rd232, %rd216, 80;
	// begin inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r267,%r268,%r269,%r270}, [%rd231];
	// end inline asm
	mov.b32 	%f1005, %r267;
	mov.b32 	%f1006, %r268;
	mov.b32 	%f1007, %r270;
	mul.f32 	%f1008, %f218, %f1005;
	mul.f32 	%f1009, %f218, %f1006;
	mul.f32 	%f1010, %f218, %f1007;
	fma.rn.f32 	%f1911, %f998, %f1911, %f1008;
	fma.rn.f32 	%f1912, %f998, %f1912, %f1009;
	fma.rn.f32 	%f1913, %f998, %f1913, %f1010;
	add.s64 	%rd235, %rd216, 96;
	// begin inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r271,%r272,%r273,%r274}, [%rd234];
	// end inline asm
	mov.b32 	%f1011, %r272;
	mov.b32 	%f1012, %r273;
	mov.b32 	%f1013, %r274;
	mul.f32 	%f1014, %f218, %f1011;
	mul.f32 	%f1015, %f218, %f1012;
	mul.f32 	%f1016, %f218, %f1013;
	fma.rn.f32 	%f1017, %f998, %f1914, %f1014;
	fma.rn.f32 	%f1018, %f998, %f1915, %f1015;
	fma.rn.f32 	%f1019, %f998, %f1916, %f1016;
	add.s64 	%rd238, %rd216, 112;
	// begin inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r275,%r276,%r277,%r278}, [%rd237];
	// end inline asm
	mov.b32 	%f1020, %r275;
	mul.f32 	%f1021, %f218, %f1020;
	fma.rn.f32 	%f1022, %f998, %f1917, %f1021;
	mul.f32 	%f1023, %f1018, %f1018;
	fma.rn.f32 	%f1024, %f1017, %f1017, %f1023;
	fma.rn.f32 	%f1025, %f1019, %f1019, %f1024;
	fma.rn.f32 	%f1026, %f1022, %f1022, %f1025;
	sqrt.rn.f32 	%f1027, %f1026;
	rcp.rn.f32 	%f1028, %f1027;
	mul.f32 	%f1914, %f1017, %f1028;
	mul.f32 	%f1915, %f1018, %f1028;
	mul.f32 	%f1916, %f1019, %f1028;
	mul.f32 	%f1917, %f1028, %f1022;

$L__BB3_35:
	mul.f32 	%f1029, %f1915, %f1915;
	fma.rn.f32 	%f1030, %f1914, %f1914, %f1029;
	fma.rn.f32 	%f1031, %f1916, %f1916, %f1030;
	fma.rn.f32 	%f1032, %f1917, %f1917, %f1031;
	rcp.rn.f32 	%f1033, %f1032;
	mul.f32 	%f1034, %f1914, %f1033;
	mul.f32 	%f1035, %f1915, %f1033;
	mul.f32 	%f1036, %f1916, %f1033;
	mul.f32 	%f1037, %f1917, %f1033;
	mul.f32 	%f1038, %f1914, %f1034;
	mul.f32 	%f1039, %f1915, %f1035;
	mul.f32 	%f1040, %f1916, %f1036;
	mul.f32 	%f1041, %f1914, %f1035;
	mul.f32 	%f1042, %f1916, %f1037;
	mul.f32 	%f1043, %f1914, %f1036;
	mul.f32 	%f1044, %f1915, %f1037;
	mul.f32 	%f1045, %f1915, %f1036;
	mul.f32 	%f1046, %f1914, %f1037;
	sub.f32 	%f1047, %f1038, %f1039;
	sub.f32 	%f1048, %f1047, %f1040;
	fma.rn.f32 	%f1049, %f1917, %f1037, %f1048;
	sub.f32 	%f1050, %f1041, %f1042;
	add.f32 	%f1051, %f1050, %f1050;
	add.f32 	%f1052, %f1043, %f1044;
	add.f32 	%f1053, %f1052, %f1052;
	add.f32 	%f1054, %f1041, %f1042;
	add.f32 	%f1055, %f1054, %f1054;
	sub.f32 	%f1056, %f1039, %f1038;
	sub.f32 	%f1057, %f1056, %f1040;
	fma.rn.f32 	%f1058, %f1917, %f1037, %f1057;
	sub.f32 	%f1059, %f1045, %f1046;
	add.f32 	%f1060, %f1059, %f1059;
	sub.f32 	%f1061, %f1043, %f1044;
	add.f32 	%f1062, %f1061, %f1061;
	add.f32 	%f1063, %f1045, %f1046;
	add.f32 	%f1064, %f1063, %f1063;
	neg.f32 	%f1065, %f1038;
	sub.f32 	%f1066, %f1065, %f1039;
	add.f32 	%f1067, %f1040, %f1066;
	fma.rn.f32 	%f1068, %f1917, %f1037, %f1067;
	mul.f32 	%f1069, %f1910, %f1049;
	fma.rn.f32 	%f1070, %f1912, %f1051, %f1069;
	fma.rn.f32 	%f1926, %f1913, %f1053, %f1070;
	mul.f32 	%f1071, %f1912, %f1058;
	fma.rn.f32 	%f1072, %f1910, %f1055, %f1071;
	fma.rn.f32 	%f1923, %f1913, %f1060, %f1072;
	mul.f32 	%f1073, %f1912, %f1064;
	fma.rn.f32 	%f1074, %f1910, %f1062, %f1073;
	fma.rn.f32 	%f1920, %f1913, %f1068, %f1074;
	mul.f32 	%f1075, %f1909, %f1049;
	fma.rn.f32 	%f1925, %f1911, %f1051, %f1075;
	mul.f32 	%f1076, %f1911, %f1058;
	fma.rn.f32 	%f1922, %f1909, %f1055, %f1076;
	mul.f32 	%f1077, %f1911, %f1064;
	fma.rn.f32 	%f1919, %f1909, %f1062, %f1077;
	mul.f32 	%f1924, %f1908, %f1049;
	mul.f32 	%f1921, %f1908, %f1055;
	mul.f32 	%f1918, %f1908, %f1062;

$L__BB3_38:
	mul.f32 	%f1109, %f1919, %f1923;
	mul.f32 	%f1110, %f1920, %f1922;
	sub.f32 	%f1111, %f1110, %f1109;
	mul.f32 	%f1112, %f1924, %f1111;
	mul.f32 	%f1113, %f1918, %f1923;
	mul.f32 	%f1114, %f1920, %f1921;
	sub.f32 	%f1115, %f1114, %f1113;
	mul.f32 	%f1116, %f1115, %f1925;
	sub.f32 	%f1117, %f1112, %f1116;
	mul.f32 	%f1118, %f1918, %f1922;
	mul.f32 	%f1119, %f1919, %f1921;
	sub.f32 	%f1120, %f1119, %f1118;
	fma.rn.f32 	%f1121, %f1120, %f1926, %f1117;
	rcp.rn.f32 	%f1122, %f1121;
	mul.f32 	%f1933, %f1111, %f1122;
	mul.f32 	%f1123, %f1920, %f1925;
	mul.f32 	%f1124, %f1919, %f1926;
	sub.f32 	%f1125, %f1124, %f1123;
	mul.f32 	%f1934, %f1125, %f1122;
	mul.f32 	%f1126, %f1922, %f1926;
	mul.f32 	%f1127, %f1923, %f1925;
	sub.f32 	%f1128, %f1127, %f1126;
	mul.f32 	%f1935, %f1128, %f1122;
	sub.f32 	%f1129, %f1113, %f1114;
	mul.f32 	%f1930, %f1129, %f1122;
	mul.f32 	%f1130, %f1918, %f1926;
	mul.f32 	%f1131, %f1920, %f1924;
	sub.f32 	%f1132, %f1131, %f1130;
	mul.f32 	%f1931, %f1132, %f1122;
	mul.f32 	%f1133, %f1923, %f1924;
	mul.f32 	%f1134, %f1921, %f1926;
	sub.f32 	%f1135, %f1134, %f1133;
	mul.f32 	%f1932, %f1135, %f1122;
	mul.f32 	%f1927, %f1120, %f1122;
	mul.f32 	%f1136, %f1919, %f1924;
	mul.f32 	%f1137, %f1918, %f1925;
	sub.f32 	%f1138, %f1137, %f1136;
	mul.f32 	%f1928, %f1138, %f1122;
	mul.f32 	%f1139, %f1921, %f1925;
	mul.f32 	%f1140, %f1922, %f1924;
	sub.f32 	%f1141, %f1140, %f1139;
	mul.f32 	%f1929, %f1141, %f1122;
	bra.uni 	$L__BB3_39;

$L__BB3_30:
	// begin inline asm
	call (%rd655), _optix_get_instance_inverse_transform_from_handle, (%rd168);
	// end inline asm

$L__BB3_31:
	// begin inline asm
	cvta.to.global.u64 %rd174, %rd655;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r192,%r193,%r194,%r195}, [%rd174];
	// end inline asm
	mov.b32 	%f1933, %r192;
	mov.b32 	%f1934, %r193;
	mov.b32 	%f1935, %r194;
	add.s64 	%rd178, %rd655, 16;
	// begin inline asm
	cvta.to.global.u64 %rd177, %rd178;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r196,%r197,%r198,%r199}, [%rd177];
	// end inline asm
	mov.b32 	%f1930, %r196;
	mov.b32 	%f1931, %r197;
	mov.b32 	%f1932, %r198;
	add.s64 	%rd181, %rd655, 32;
	// begin inline asm
	cvta.to.global.u64 %rd180, %rd181;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r200,%r201,%r202,%r203}, [%rd180];
	// end inline asm
	mov.b32 	%f1927, %r200;
	mov.b32 	%f1928, %r201;
	mov.b32 	%f1929, %r202;

$L__BB3_39:
	setp.eq.s32 	%p20, %r656, 0;
	@%p20 bra 	$L__BB3_41;

	mul.f32 	%f1142, %f1904, %f1934;
	fma.rn.f32 	%f1143, %f1901, %f1933, %f1142;
	fma.rn.f32 	%f304, %f1907, %f1935, %f1143;
	mul.f32 	%f1144, %f1903, %f1934;
	fma.rn.f32 	%f1145, %f1900, %f1933, %f1144;
	fma.rn.f32 	%f305, %f1906, %f1935, %f1145;
	mul.f32 	%f1146, %f1902, %f1934;
	fma.rn.f32 	%f1147, %f1899, %f1933, %f1146;
	fma.rn.f32 	%f1935, %f1905, %f1935, %f1147;
	mul.f32 	%f1148, %f1904, %f1931;
	fma.rn.f32 	%f1149, %f1901, %f1930, %f1148;
	fma.rn.f32 	%f307, %f1907, %f1932, %f1149;
	mul.f32 	%f1150, %f1903, %f1931;
	fma.rn.f32 	%f1151, %f1900, %f1930, %f1150;
	fma.rn.f32 	%f308, %f1906, %f1932, %f1151;
	mul.f32 	%f1152, %f1902, %f1931;
	fma.rn.f32 	%f1153, %f1899, %f1930, %f1152;
	fma.rn.f32 	%f1932, %f1905, %f1932, %f1153;
	mul.f32 	%f1154, %f1904, %f1928;
	fma.rn.f32 	%f1155, %f1901, %f1927, %f1154;
	fma.rn.f32 	%f310, %f1907, %f1929, %f1155;
	mul.f32 	%f1156, %f1903, %f1928;
	fma.rn.f32 	%f1157, %f1900, %f1927, %f1156;
	fma.rn.f32 	%f311, %f1906, %f1929, %f1157;
	mul.f32 	%f1158, %f1902, %f1928;
	fma.rn.f32 	%f1159, %f1899, %f1927, %f1158;
	fma.rn.f32 	%f1929, %f1905, %f1929, %f1159;
	mov.f32 	%f1927, %f310;
	mov.f32 	%f1928, %f311;
	mov.f32 	%f1930, %f307;
	mov.f32 	%f1931, %f308;
	mov.f32 	%f1933, %f304;
	mov.f32 	%f1934, %f305;

$L__BB3_41:
	add.s32 	%r656, %r656, 1;
	setp.lt.u32 	%p21, %r656, %r187;
	mov.f32 	%f1899, %f1935;
	mov.f32 	%f1900, %f1934;
	mov.f32 	%f1901, %f1933;
	mov.f32 	%f1902, %f1932;
	mov.f32 	%f1903, %f1931;
	mov.f32 	%f1904, %f1930;
	mov.f32 	%f1905, %f1929;
	mov.f32 	%f1906, %f1928;
	mov.f32 	%f1907, %f1927;
	@%p21 bra 	$L__BB3_26;

$L__BB3_42:
	mul.f32 	%f1160, %f1955, %f1934;
	fma.rn.f32 	%f1161, %f1954, %f1933, %f1160;
	mul.f32 	%f1162, %f1955, %f1931;
	fma.rn.f32 	%f1163, %f1954, %f1930, %f1162;
	mul.f32 	%f1164, %f1955, %f1928;
	fma.rn.f32 	%f1165, %f1954, %f1927, %f1164;
	fma.rn.f32 	%f1956, %f973, %f1929, %f1165;
	fma.rn.f32 	%f1955, %f973, %f1932, %f1163;
	fma.rn.f32 	%f1954, %f973, %f1935, %f1161;
	bra.uni 	$L__BB3_44;

$L__BB3_43:
	mov.f32 	%f1956, %f973;

$L__BB3_44:
	add.s64 	%rd18, %rd3, 208;
	ld.v4.f32 	{%f1169, %f1170, %f1171, %f1172}, [%rd3+208];
	ld.f32 	%f1176, [%rd3+160];
	fma.rn.f32 	%f1177, %f1896, %f1176, %f1169;
	ld.f32 	%f1178, [%rd3+164];
	fma.rn.f32 	%f1179, %f1896, %f1178, %f1170;
	ld.f32 	%f1180, [%rd3+168];
	fma.rn.f32 	%f1181, %f1896, %f1180, %f1171;
	ld.f32 	%f1182, [%rd3+176];
	fma.rn.f32 	%f1183, %f1897, %f1182, %f1177;
	ld.f32 	%f1184, [%rd3+180];
	fma.rn.f32 	%f1185, %f1897, %f1184, %f1179;
	ld.f32 	%f1186, [%rd3+184];
	fma.rn.f32 	%f1187, %f1897, %f1186, %f1181;
	ld.f32 	%f1188, [%rd3+192];
	fma.rn.f32 	%f1189, %f1898, %f1188, %f1183;
	ld.f32 	%f1190, [%rd3+196];
	fma.rn.f32 	%f1191, %f1898, %f1190, %f1185;
	ld.f32 	%f1192, [%rd3+200];
	fma.rn.f32 	%f1193, %f1898, %f1192, %f1187;
	ld.v4.f32 	{%f1194, %f1195, %f1196, %f1197}, [%rd3+160];
	mul.f32 	%f1201, %f1954, %f1194;
	mul.f32 	%f1202, %f1954, %f1195;
	mul.f32 	%f1203, %f1954, %f1196;
	fma.rn.f32 	%f1204, %f1955, %f1182, %f1201;
	fma.rn.f32 	%f1205, %f1955, %f1184, %f1202;
	fma.rn.f32 	%f1206, %f1955, %f1186, %f1203;
	fma.rn.f32 	%f1207, %f1956, %f1188, %f1204;
	fma.rn.f32 	%f1208, %f1956, %f1190, %f1205;
	fma.rn.f32 	%f1209, %f1956, %f1192, %f1206;
	rcp.rn.f32 	%f1210, %f1209;
	mul.f32 	%f1211, %f1193, %f1210;
	neg.f32 	%f346, %f1211;
	fma.rn.f32 	%f347, %f346, %f1207, %f1189;
	fma.rn.f32 	%f348, %f346, %f1208, %f1191;
	ld.const.u64 	%rd19, [params+80];
	setp.eq.s64 	%p22, %rd19, 0;
	@%p22 bra 	$L__BB3_49;

	ld.u64 	%rd287, [%rd48];
	ld.const.u64 	%rd288, [params+328];
	cvta.to.global.u64 	%rd289, %rd288;
	cvt.u64.u32 	%rd20, %r1;
	mul.wide.u32 	%rd290, %r1, 8;
	add.s64 	%rd291, %rd289, %rd290;
	st.global.u64 	[%rd291], %rd287;
	ld.const.u64 	%rd292, [params+336];
	cvta.to.global.u64 	%rd293, %rd292;
	mul.wide.u32 	%rd294, %r1, 4;
	add.s64 	%rd295, %rd293, %rd294;
	mov.u32 	%r338, 0;
	st.global.u32 	[%rd295], %r338;
	ld.const.u64 	%rd296, [params+344];
	cvta.to.global.u64 	%rd297, %rd296;
	add.s64 	%rd21, %rd297, %rd294;
	ld.global.u32 	%r10, [%rd21];
	setp.eq.s32 	%p23, %r10, 0;
	@%p23 bra 	$L__BB3_48;

	// begin inline asm
	call (%r339), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p24, %r339, %r10;
	@%p24 bra 	$L__BB3_48;

	st.global.u32 	[%rd21], %r339;

$L__BB3_48:
	cvta.to.global.u64 	%rd298, %rd19;
	shl.b64 	%rd299, %rd20, 2;
	add.s64 	%rd300, %rd298, %rd299;
	st.global.f32 	[%rd300], %f347;
	ld.const.u64 	%rd301, [params+88];
	cvta.to.global.u64 	%rd302, %rd301;
	add.s64 	%rd303, %rd302, %rd299;
	st.global.f32 	[%rd303], %f348;
	ld.const.u64 	%rd304, [params+72];
	cvta.to.global.u64 	%rd305, %rd304;
	add.s64 	%rd306, %rd305, %rd299;
	st.global.f32 	[%rd306], %f346;
	bra.uni 	$L__BB3_117;

$L__BB3_49:
	fma.rn.f32 	%f2115, %f346, %f1954, %f1896;
	fma.rn.f32 	%f2116, %f346, %f1955, %f1897;
	fma.rn.f32 	%f2117, %f346, %f1956, %f1898;
	ld.v4.f32 	{%f1213, %f1214, %f1215, %f1216}, [%rd18+-112];
	mul.f32 	%f1220, %f1213, 0f00000000;
	mov.f32 	%f2100, 0f00000000;
	mul.f32 	%f1222, %f1214, 0f00000000;
	mul.f32 	%f1223, %f1215, 0f00000000;
	ld.v4.f32 	{%f1224, %f1225, %f1226, %f1227}, [%rd18+-96];
	fma.rn.f32 	%f1231, %f2100, %f1224, %f1220;
	fma.rn.f32 	%f1232, %f2100, %f1225, %f1222;
	fma.rn.f32 	%f1233, %f2100, %f1226, %f1223;
	ld.f32 	%f1234, [%rd18+-80];
	mov.f32 	%f2064, 0f3F800000;
	fma.rn.f32 	%f1236, %f2064, %f1234, %f1231;
	ld.f32 	%f1237, [%rd18+-76];
	fma.rn.f32 	%f1238, %f2064, %f1237, %f1232;
	ld.f32 	%f1239, [%rd18+-72];
	fma.rn.f32 	%f1240, %f2064, %f1239, %f1233;
	mul.f32 	%f1241, %f1236, %f1236;
	fma.rn.f32 	%f1242, %f1238, %f1238, %f1241;
	fma.rn.f32 	%f1243, %f1240, %f1240, %f1242;
	sqrt.rn.f32 	%f1244, %f1243;
	div.rn.f32 	%f2088, %f1236, %f1244;
	div.rn.f32 	%f2089, %f1238, %f1244;
	div.rn.f32 	%f2090, %f1240, %f1244;
	ld.const.u64 	%rd22, [params+96];
	setp.eq.s64 	%p25, %rd22, 0;
	@%p25 bra 	$L__BB3_57;

	mul.f32 	%f1245, %f347, %f347;
	fma.rn.f32 	%f1246, %f348, %f348, %f1245;
	sqrt.rn.f32 	%f1959, %f1246;
	abs.f32 	%f356, %f347;
	setp.eq.f32 	%p26, %f356, 0f00000000;
	abs.f32 	%f357, %f348;
	setp.eq.f32 	%p27, %f357, 0f00000000;
	and.pred  	%p28, %p26, %p27;
	mov.b32 	%r12, %f347;
	mov.b32 	%r340, %f348;
	and.b32  	%r13, %r340, -2147483648;
	@%p28 bra 	$L__BB3_54;
	bra.uni 	$L__BB3_51;

$L__BB3_54:
	shr.s32 	%r345, %r12, 31;
	and.b32  	%r346, %r345, 1078530011;
	or.b32  	%r347, %r346, %r13;
	mov.b32 	%f1957, %r347;
	bra.uni 	$L__BB3_55;

$L__BB3_51:
	setp.eq.f32 	%p29, %f356, 0f7F800000;
	setp.eq.f32 	%p30, %f357, 0f7F800000;
	and.pred  	%p31, %p29, %p30;
	@%p31 bra 	$L__BB3_53;
	bra.uni 	$L__BB3_52;

$L__BB3_53:
	setp.lt.s32 	%p35, %r12, 0;
	selp.b32 	%r343, 1075235812, 1061752795, %p35;
	or.b32  	%r344, %r343, %r13;
	mov.b32 	%f1957, %r344;
	bra.uni 	$L__BB3_55;

$L__BB3_52:
	setp.lt.s32 	%p32, %r12, 0;
	min.f32 	%f1247, %f357, %f356;
	max.f32 	%f1248, %f357, %f356;
	div.rn.f32 	%f1249, %f1247, %f1248;
	mul.rn.f32 	%f1250, %f1249, %f1249;
	mov.f32 	%f1251, 0fC0B59883;
	mov.f32 	%f1252, 0fBF52C7EA;
	fma.rn.f32 	%f1253, %f1250, %f1252, %f1251;
	mov.f32 	%f1254, 0fC0D21907;
	fma.rn.f32 	%f1255, %f1253, %f1250, %f1254;
	mul.f32 	%f1256, %f1250, %f1255;
	mul.f32 	%f1257, %f1249, %f1256;
	add.f32 	%f1258, %f1250, 0f41355DC0;
	mov.f32 	%f1259, 0f41E6BD60;
	fma.rn.f32 	%f1260, %f1258, %f1250, %f1259;
	mov.f32 	%f1261, 0f419D92C8;
	fma.rn.f32 	%f1262, %f1260, %f1250, %f1261;
	rcp.rn.f32 	%f1263, %f1262;
	fma.rn.f32 	%f1264, %f1257, %f1263, %f1249;
	mov.f32 	%f1265, 0f3FC90FDB;
	sub.f32 	%f1266, %f1265, %f1264;
	setp.gt.f32 	%p33, %f357, %f356;
	selp.f32 	%f1267, %f1266, %f1264, %p33;
	mov.f32 	%f1268, 0f40490FDB;
	sub.f32 	%f1269, %f1268, %f1267;
	selp.f32 	%f1270, %f1269, %f1267, %p32;
	mov.b32 	%r341, %f1270;
	or.b32  	%r342, %r13, %r341;
	mov.b32 	%f1271, %r342;
	add.f32 	%f1272, %f356, %f357;
	setp.le.f32 	%p34, %f1272, 0f7F800000;
	selp.f32 	%f1957, %f1271, %f1272, %p34;

$L__BB3_55:
	mul.f32 	%f1274, %f1957, 0f3E22F983;
	setp.lt.f32 	%p36, %f1274, 0f00000000;
	add.f32 	%f1275, %f1274, 0f3F800000;
	selp.f32 	%f1958, %f1275, %f1274, %p36;
	ld.const.u64 	%rd307, [params+184];
	setp.eq.s64 	%p37, %rd307, 0;
	@%p37 bra 	$L__BB3_57;

	rcp.rn.f32 	%f1276, %f1959;
	setp.neu.f32 	%p38, %f1959, 0f00000000;
	mul.f32 	%f1278, %f347, %f1276;
	selp.f32 	%f1279, %f1278, 0f3F800000, %p38;
	mul.f32 	%f1280, %f348, %f1276;
	selp.f32 	%f1281, %f1280, 0f00000000, %p38;
	ld.v4.f32 	{%f1282, %f1283, %f1284, %f1285}, [%rd18+-176];
	mul.f32 	%f1289, %f1279, %f1282;
	mul.f32 	%f1290, %f1279, %f1283;
	mul.f32 	%f1291, %f1279, %f1284;
	ld.v4.f32 	{%f1292, %f1293, %f1294, %f1295}, [%rd18+-160];
	fma.rn.f32 	%f1299, %f1281, %f1292, %f1289;
	fma.rn.f32 	%f1300, %f1281, %f1293, %f1290;
	fma.rn.f32 	%f1301, %f1281, %f1294, %f1291;
	ld.f32 	%f1302, [%rd18+-144];
	fma.rn.f32 	%f2106, %f2100, %f1302, %f1299;
	ld.f32 	%f1303, [%rd18+-140];
	fma.rn.f32 	%f2107, %f2100, %f1303, %f1300;
	ld.f32 	%f1304, [%rd18+-136];
	fma.rn.f32 	%f2108, %f2100, %f1304, %f1301;
	neg.f32 	%f1305, %f1281;
	mul.f32 	%f1306, %f1282, %f1305;
	mul.f32 	%f1307, %f1283, %f1305;
	mul.f32 	%f1308, %f1284, %f1305;
	fma.rn.f32 	%f1309, %f1279, %f1292, %f1306;
	fma.rn.f32 	%f1310, %f1279, %f1293, %f1307;
	fma.rn.f32 	%f1311, %f1279, %f1294, %f1308;
	fma.rn.f32 	%f2103, %f2100, %f1302, %f1309;
	fma.rn.f32 	%f2104, %f2100, %f1303, %f1310;
	fma.rn.f32 	%f2105, %f2100, %f1304, %f1311;

$L__BB3_57:
	ld.u64 	%rd23, [%rd48];
	ld.const.u64 	%rd308, [params+344];
	cvta.to.global.u64 	%rd309, %rd308;
	cvt.u64.u32 	%rd24, %r1;
	mul.wide.u32 	%rd310, %r1, 4;
	add.s64 	%rd25, %rd309, %rd310;
	ld.global.u32 	%r14, [%rd25];
	setp.eq.s32 	%p39, %r14, 0;
	mov.f32 	%f2101, 0f00000000;
	mov.f32 	%f2102, 0f00000000;
	mov.f32 	%f2112, %f2088;
	mov.f32 	%f2113, %f2089;
	mov.f32 	%f2114, %f2090;
	@%p39 bra 	$L__BB3_105;

	// begin inline asm
	call (%r348), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p40, %r348, %r14;
	mov.f32 	%f2112, %f2088;
	mov.f32 	%f2113, %f2089;
	mov.f32 	%f2114, %f2090;
	@%p40 bra 	$L__BB3_105;

	// begin inline asm
	call (%r349), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p41, %r349, 0;
	mov.f32 	%f2065, 0f00000000;
	mov.f32 	%f2002, %f2064;
	mov.f32 	%f2003, %f2065;
	mov.f32 	%f2004, %f2065;
	mov.f32 	%f2005, %f2065;
	mov.f32 	%f1998, %f2065;
	mov.f32 	%f1999, %f2064;
	mov.f32 	%f2000, %f2065;
	mov.f32 	%f2001, %f2065;
	mov.f32 	%f1994, %f2065;
	mov.f32 	%f1995, %f2065;
	mov.f32 	%f1996, %f2064;
	mov.f32 	%f1997, %f2065;
	@%p41 bra 	$L__BB3_77;

	// begin inline asm
	call (%r350), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1330), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p42, %r350, 1;
	@%p42 bra 	$L__BB3_77;

	add.s32 	%r657, %r350, 1;
	mov.u32 	%r658, 1;

$L__BB3_62:
	.pragma "nounroll";
	add.s32 	%r352, %r657, -2;
	// begin inline asm
	call (%rd311), _optix_get_transform_list_handle, (%r352);
	// end inline asm
	// begin inline asm
	call (%r353), _optix_get_transform_type_from_handle, (%rd311);
	// end inline asm
	or.b32  	%r354, %r353, 1;
	setp.eq.s32 	%p43, %r354, 3;
	@%p43 bra 	$L__BB3_68;
	bra.uni 	$L__BB3_63;

$L__BB3_68:
	setp.eq.s32 	%p46, %r353, 2;
	@%p46 bra 	$L__BB3_72;
	bra.uni 	$L__BB3_69;

$L__BB3_72:
	// begin inline asm
	call (%rd383), _optix_get_matrix_motion_transform_from_handle, (%rd311);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd385, %rd383;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r442,%r443,%r444,%r445}, [%rd385];
	// end inline asm
	add.s64 	%rd389, %rd383, 16;
	// begin inline asm
	cvta.to.global.u64 %rd388, %rd389;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd388];
	// end inline asm
	add.s64 	%rd392, %rd383, 32;
	// begin inline asm
	cvta.to.global.u64 %rd391, %rd392;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd391];
	// end inline asm
	add.s64 	%rd395, %rd383, 48;
	// begin inline asm
	cvta.to.global.u64 %rd394, %rd395;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd394];
	// end inline asm
	add.s64 	%rd398, %rd383, 64;
	// begin inline asm
	cvta.to.global.u64 %rd397, %rd398;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r458,%r459,%r460,%r461}, [%rd397];
	// end inline asm
	add.s64 	%rd401, %rd383, 80;
	// begin inline asm
	cvta.to.global.u64 %rd400, %rd401;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r462,%r463,%r464,%r465}, [%rd400];
	// end inline asm
	add.s64 	%rd404, %rd383, 96;
	// begin inline asm
	cvta.to.global.u64 %rd403, %rd404;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r466,%r467,%r468,%r469}, [%rd403];
	// end inline asm
	add.s64 	%rd407, %rd383, 112;
	// begin inline asm
	cvta.to.global.u64 %rd406, %rd407;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r470,%r471,%r472,%r473}, [%rd406];
	// end inline asm
	mov.b32 	%f1458, %r445;
	mov.b32 	%f1459, %r446;
	and.b32  	%r486, %r444, 65535;
	add.s32 	%r487, %r486, -1;
	cvt.rn.f32.s32 	%f1460, %r487;
	sub.f32 	%f1461, %f1330, %f1458;
	mul.f32 	%f1462, %f1461, %f1460;
	sub.f32 	%f1463, %f1459, %f1458;
	div.rn.f32 	%f1464, %f1462, %f1463;
	min.f32 	%f1465, %f1460, %f1464;
	mov.f32 	%f1466, 0f00000000;
	max.f32 	%f1467, %f1466, %f1465;
	cvt.rmi.f32.f32 	%f1468, %f1467;
	sub.f32 	%f463, %f1467, %f1468;
	cvt.rzi.s32.f32 	%r488, %f1468;
	cvt.s64.s32 	%rd32, %r488;
	mul.wide.s32 	%rd418, %r488, 48;
	add.s64 	%rd410, %rd392, %rd418;
	// begin inline asm
	cvta.to.global.u64 %rd409, %rd410;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r474,%r475,%r476,%r477}, [%rd409];
	// end inline asm
	mov.b32 	%f2002, %r474;
	mov.b32 	%f2003, %r475;
	mov.b32 	%f2004, %r476;
	mov.b32 	%f2005, %r477;
	add.s64 	%rd413, %rd410, 16;
	// begin inline asm
	cvta.to.global.u64 %rd412, %rd413;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r478,%r479,%r480,%r481}, [%rd412];
	// end inline asm
	mov.b32 	%f1998, %r478;
	mov.b32 	%f1999, %r479;
	mov.b32 	%f2000, %r480;
	mov.b32 	%f2001, %r481;
	add.s64 	%rd416, %rd410, 32;
	// begin inline asm
	cvta.to.global.u64 %rd415, %rd416;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r482,%r483,%r484,%r485}, [%rd415];
	// end inline asm
	mov.b32 	%f1994, %r482;
	mov.b32 	%f1995, %r483;
	mov.b32 	%f1996, %r484;
	mov.b32 	%f1997, %r485;
	setp.leu.f32 	%p48, %f463, 0f00000000;
	@%p48 bra 	$L__BB3_74;

	mov.f32 	%f1469, 0f3F800000;
	sub.f32 	%f1470, %f1469, %f463;
	mul.lo.s64 	%rd428, %rd32, 48;
	add.s64 	%rd429, %rd383, %rd428;
	add.s64 	%rd420, %rd429, 80;
	// begin inline asm
	cvta.to.global.u64 %rd419, %rd420;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r489,%r490,%r491,%r492}, [%rd419];
	// end inline asm
	mov.b32 	%f1471, %r489;
	mov.b32 	%f1472, %r490;
	mov.b32 	%f1473, %r491;
	mov.b32 	%f1474, %r492;
	mul.f32 	%f1475, %f463, %f1471;
	mul.f32 	%f1476, %f463, %f1472;
	mul.f32 	%f1477, %f463, %f1473;
	mul.f32 	%f1478, %f463, %f1474;
	fma.rn.f32 	%f2002, %f1470, %f2002, %f1475;
	fma.rn.f32 	%f2003, %f1470, %f2003, %f1476;
	fma.rn.f32 	%f2004, %f1470, %f2004, %f1477;
	fma.rn.f32 	%f2005, %f1470, %f2005, %f1478;
	add.s64 	%rd423, %rd429, 96;
	// begin inline asm
	cvta.to.global.u64 %rd422, %rd423;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r493,%r494,%r495,%r496}, [%rd422];
	// end inline asm
	mov.b32 	%f1479, %r493;
	mov.b32 	%f1480, %r494;
	mov.b32 	%f1481, %r495;
	mov.b32 	%f1482, %r496;
	mul.f32 	%f1483, %f463, %f1479;
	mul.f32 	%f1484, %f463, %f1480;
	mul.f32 	%f1485, %f463, %f1481;
	mul.f32 	%f1486, %f463, %f1482;
	fma.rn.f32 	%f1998, %f1470, %f1998, %f1483;
	fma.rn.f32 	%f1999, %f1470, %f1999, %f1484;
	fma.rn.f32 	%f2000, %f1470, %f2000, %f1485;
	fma.rn.f32 	%f2001, %f1470, %f2001, %f1486;
	add.s64 	%rd426, %rd429, 112;
	// begin inline asm
	cvta.to.global.u64 %rd425, %rd426;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd425];
	// end inline asm
	mov.b32 	%f1487, %r497;
	mov.b32 	%f1488, %r498;
	mov.b32 	%f1489, %r499;
	mov.b32 	%f1490, %r500;
	mul.f32 	%f1491, %f463, %f1487;
	mul.f32 	%f1492, %f463, %f1488;
	mul.f32 	%f1493, %f463, %f1489;
	mul.f32 	%f1494, %f463, %f1490;
	fma.rn.f32 	%f1994, %f1470, %f1994, %f1491;
	fma.rn.f32 	%f1995, %f1470, %f1995, %f1492;
	fma.rn.f32 	%f1996, %f1470, %f1996, %f1493;
	fma.rn.f32 	%f1997, %f1470, %f1997, %f1494;
	bra.uni 	$L__BB3_74;

$L__BB3_63:
	mov.f32 	%f1994, 0f00000000;
	mov.f32 	%f1996, 0f3F800000;
	setp.eq.s32 	%p44, %r353, 4;
	@%p44 bra 	$L__BB3_66;

	setp.ne.s32 	%p45, %r353, 1;
	mov.f32 	%f1995, %f1994;
	mov.f32 	%f1997, %f1994;
	mov.f32 	%f1998, %f1994;
	mov.f32 	%f1999, %f1996;
	mov.f32 	%f2000, %f1994;
	mov.f32 	%f2001, %f1994;
	mov.f32 	%f2002, %f1996;
	mov.f32 	%f2003, %f1994;
	mov.f32 	%f2004, %f1994;
	mov.f32 	%f2005, %f1994;
	@%p45 bra 	$L__BB3_74;

	// begin inline asm
	call (%rd313), _optix_get_static_transform_from_handle, (%rd311);
	// end inline asm
	add.s64 	%rd656, %rd313, 16;
	bra.uni 	$L__BB3_67;

$L__BB3_69:
	// begin inline asm
	call (%rd326), _optix_get_srt_motion_transform_from_handle, (%rd311);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd328, %rd326;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd328];
	// end inline asm
	add.s64 	%rd332, %rd326, 16;
	// begin inline asm
	cvta.to.global.u64 %rd331, %rd332;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd331];
	// end inline asm
	add.s64 	%rd335, %rd326, 32;
	// begin inline asm
	cvta.to.global.u64 %rd334, %rd335;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd334];
	// end inline asm
	add.s64 	%rd338, %rd326, 48;
	// begin inline asm
	cvta.to.global.u64 %rd337, %rd338;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd337];
	// end inline asm
	add.s64 	%rd341, %rd326, 64;
	// begin inline asm
	cvta.to.global.u64 %rd340, %rd341;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd340];
	// end inline asm
	add.s64 	%rd344, %rd326, 80;
	// begin inline asm
	cvta.to.global.u64 %rd343, %rd344;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd343];
	// end inline asm
	add.s64 	%rd347, %rd326, 96;
	// begin inline asm
	cvta.to.global.u64 %rd346, %rd347;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd346];
	// end inline asm
	add.s64 	%rd350, %rd326, 112;
	// begin inline asm
	cvta.to.global.u64 %rd349, %rd350;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd349];
	// end inline asm
	add.s64 	%rd353, %rd326, 128;
	// begin inline asm
	cvta.to.global.u64 %rd352, %rd353;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd352];
	// end inline asm
	add.s64 	%rd356, %rd326, 144;
	// begin inline asm
	cvta.to.global.u64 %rd355, %rd356;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r403,%r404,%r405,%r406}, [%rd355];
	// end inline asm
	mov.b32 	%f1345, %r370;
	mov.b32 	%f1346, %r371;
	and.b32  	%r423, %r369, 65535;
	add.s32 	%r424, %r423, -1;
	cvt.rn.f32.s32 	%f1347, %r424;
	sub.f32 	%f1348, %f1330, %f1345;
	mul.f32 	%f1349, %f1348, %f1347;
	sub.f32 	%f1350, %f1346, %f1345;
	div.rn.f32 	%f1351, %f1349, %f1350;
	min.f32 	%f1352, %f1347, %f1351;
	mov.f32 	%f1353, 0f00000000;
	max.f32 	%f1354, %f1353, %f1352;
	cvt.rmi.f32.f32 	%f1355, %f1354;
	sub.f32 	%f402, %f1354, %f1355;
	cvt.rzi.s32.f32 	%r425, %f1355;
	mul.wide.s32 	%rd370, %r425, 64;
	add.s64 	%rd359, %rd335, %rd370;
	// begin inline asm
	cvta.to.global.u64 %rd358, %rd359;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r407,%r408,%r409,%r410}, [%rd358];
	// end inline asm
	mov.b32 	%f1978, %r407;
	mov.b32 	%f1979, %r408;
	mov.b32 	%f1980, %r409;
	mov.b32 	%f1981, %r410;
	add.s64 	%rd362, %rd359, 16;
	// begin inline asm
	cvta.to.global.u64 %rd361, %rd362;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r411,%r412,%r413,%r414}, [%rd361];
	// end inline asm
	mov.b32 	%f1982, %r411;
	mov.b32 	%f1983, %r412;
	mov.b32 	%f1984, %r413;
	mov.b32 	%f1985, %r414;
	add.s64 	%rd365, %rd359, 32;
	// begin inline asm
	cvta.to.global.u64 %rd364, %rd365;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r415,%r416,%r417,%r418}, [%rd364];
	// end inline asm
	mov.b32 	%f1986, %r415;
	mov.b32 	%f1987, %r416;
	mov.b32 	%f1988, %r417;
	mov.b32 	%f1989, %r418;
	add.s64 	%rd368, %rd359, 48;
	// begin inline asm
	cvta.to.global.u64 %rd367, %rd368;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r419,%r420,%r421,%r422}, [%rd367];
	// end inline asm
	mov.b32 	%f1990, %r419;
	mov.b32 	%f1991, %r420;
	mov.b32 	%f1992, %r421;
	mov.b32 	%f1993, %r422;
	setp.leu.f32 	%p47, %f402, 0f00000000;
	@%p47 bra 	$L__BB3_71;

	mov.f32 	%f1356, 0f3F800000;
	sub.f32 	%f1357, %f1356, %f402;
	add.s64 	%rd372, %rd359, 64;
	// begin inline asm
	cvta.to.global.u64 %rd371, %rd372;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r426,%r427,%r428,%r429}, [%rd371];
	// end inline asm
	mov.b32 	%f1358, %r426;
	mov.b32 	%f1359, %r427;
	mov.b32 	%f1360, %r428;
	mov.b32 	%f1361, %r429;
	mul.f32 	%f1362, %f402, %f1358;
	mul.f32 	%f1363, %f402, %f1359;
	mul.f32 	%f1364, %f402, %f1360;
	mul.f32 	%f1365, %f402, %f1361;
	fma.rn.f32 	%f1978, %f1357, %f1978, %f1362;
	fma.rn.f32 	%f1979, %f1357, %f1979, %f1363;
	fma.rn.f32 	%f1980, %f1357, %f1980, %f1364;
	fma.rn.f32 	%f1981, %f1357, %f1981, %f1365;
	add.s64 	%rd375, %rd359, 80;
	// begin inline asm
	cvta.to.global.u64 %rd374, %rd375;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r430,%r431,%r432,%r433}, [%rd374];
	// end inline asm
	mov.b32 	%f1366, %r430;
	mov.b32 	%f1367, %r431;
	mov.b32 	%f1368, %r432;
	mov.b32 	%f1369, %r433;
	mul.f32 	%f1370, %f402, %f1366;
	mul.f32 	%f1371, %f402, %f1367;
	mul.f32 	%f1372, %f402, %f1368;
	mul.f32 	%f1373, %f402, %f1369;
	fma.rn.f32 	%f1982, %f1357, %f1982, %f1370;
	fma.rn.f32 	%f1983, %f1357, %f1983, %f1371;
	fma.rn.f32 	%f1984, %f1357, %f1984, %f1372;
	fma.rn.f32 	%f1985, %f1357, %f1985, %f1373;
	add.s64 	%rd378, %rd359, 96;
	// begin inline asm
	cvta.to.global.u64 %rd377, %rd378;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r434,%r435,%r436,%r437}, [%rd377];
	// end inline asm
	mov.b32 	%f1374, %r434;
	mov.b32 	%f1375, %r435;
	mov.b32 	%f1376, %r436;
	mov.b32 	%f1377, %r437;
	mul.f32 	%f1378, %f402, %f1374;
	mul.f32 	%f1379, %f402, %f1375;
	mul.f32 	%f1380, %f402, %f1376;
	mul.f32 	%f1381, %f402, %f1377;
	fma.rn.f32 	%f1986, %f1357, %f1986, %f1378;
	fma.rn.f32 	%f1382, %f1357, %f1987, %f1379;
	fma.rn.f32 	%f1383, %f1357, %f1988, %f1380;
	fma.rn.f32 	%f1384, %f1357, %f1989, %f1381;
	add.s64 	%rd381, %rd359, 112;
	// begin inline asm
	cvta.to.global.u64 %rd380, %rd381;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r438,%r439,%r440,%r441}, [%rd380];
	// end inline asm
	mov.b32 	%f1385, %r438;
	mov.b32 	%f1386, %r439;
	mov.b32 	%f1387, %r440;
	mov.b32 	%f1388, %r441;
	mul.f32 	%f1389, %f402, %f1385;
	mul.f32 	%f1390, %f402, %f1386;
	mul.f32 	%f1391, %f402, %f1387;
	mul.f32 	%f1392, %f402, %f1388;
	fma.rn.f32 	%f1393, %f1357, %f1990, %f1389;
	fma.rn.f32 	%f1991, %f1357, %f1991, %f1390;
	fma.rn.f32 	%f1992, %f1357, %f1992, %f1391;
	fma.rn.f32 	%f1993, %f1357, %f1993, %f1392;
	mul.f32 	%f1394, %f1383, %f1383;
	fma.rn.f32 	%f1395, %f1382, %f1382, %f1394;
	fma.rn.f32 	%f1396, %f1384, %f1384, %f1395;
	fma.rn.f32 	%f1397, %f1393, %f1393, %f1396;
	sqrt.rn.f32 	%f1398, %f1397;
	rcp.rn.f32 	%f1399, %f1398;
	mul.f32 	%f1987, %f1382, %f1399;
	mul.f32 	%f1988, %f1383, %f1399;
	mul.f32 	%f1989, %f1384, %f1399;
	mul.f32 	%f1990, %f1399, %f1393;

$L__BB3_71:
	mul.f32 	%f1400, %f1988, %f1988;
	fma.rn.f32 	%f1401, %f1987, %f1987, %f1400;
	fma.rn.f32 	%f1402, %f1989, %f1989, %f1401;
	fma.rn.f32 	%f1403, %f1990, %f1990, %f1402;
	rcp.rn.f32 	%f1404, %f1403;
	mul.f32 	%f1405, %f1987, %f1404;
	mul.f32 	%f1406, %f1988, %f1404;
	mul.f32 	%f1407, %f1989, %f1404;
	mul.f32 	%f1408, %f1990, %f1404;
	mul.f32 	%f1409, %f1987, %f1405;
	mul.f32 	%f1410, %f1988, %f1406;
	mul.f32 	%f1411, %f1989, %f1407;
	mul.f32 	%f1412, %f1987, %f1406;
	mul.f32 	%f1413, %f1989, %f1408;
	mul.f32 	%f1414, %f1987, %f1407;
	mul.f32 	%f1415, %f1988, %f1408;
	mul.f32 	%f1416, %f1988, %f1407;
	mul.f32 	%f1417, %f1987, %f1408;
	sub.f32 	%f1418, %f1409, %f1410;
	sub.f32 	%f1419, %f1418, %f1411;
	fma.rn.f32 	%f1420, %f1990, %f1408, %f1419;
	sub.f32 	%f1421, %f1412, %f1413;
	add.f32 	%f1422, %f1421, %f1421;
	add.f32 	%f1423, %f1414, %f1415;
	add.f32 	%f1424, %f1423, %f1423;
	add.f32 	%f1425, %f1412, %f1413;
	add.f32 	%f1426, %f1425, %f1425;
	sub.f32 	%f1427, %f1410, %f1409;
	sub.f32 	%f1428, %f1427, %f1411;
	fma.rn.f32 	%f1429, %f1990, %f1408, %f1428;
	sub.f32 	%f1430, %f1416, %f1417;
	add.f32 	%f1431, %f1430, %f1430;
	sub.f32 	%f1432, %f1414, %f1415;
	add.f32 	%f1433, %f1432, %f1432;
	add.f32 	%f1434, %f1416, %f1417;
	add.f32 	%f1435, %f1434, %f1434;
	neg.f32 	%f1436, %f1409;
	sub.f32 	%f1437, %f1436, %f1410;
	add.f32 	%f1438, %f1411, %f1437;
	fma.rn.f32 	%f1439, %f1990, %f1408, %f1438;
	mul.f32 	%f1440, %f1981, %f1420;
	fma.rn.f32 	%f1441, %f1984, %f1422, %f1440;
	fma.rn.f32 	%f1442, %f1986, %f1424, %f1441;
	sub.f32 	%f2005, %f1991, %f1442;
	mul.f32 	%f1443, %f1984, %f1429;
	fma.rn.f32 	%f1444, %f1981, %f1426, %f1443;
	fma.rn.f32 	%f1445, %f1986, %f1431, %f1444;
	sub.f32 	%f2001, %f1992, %f1445;
	mul.f32 	%f1446, %f1984, %f1435;
	fma.rn.f32 	%f1447, %f1981, %f1433, %f1446;
	fma.rn.f32 	%f1448, %f1986, %f1439, %f1447;
	sub.f32 	%f1997, %f1993, %f1448;
	mul.f32 	%f1449, %f1980, %f1420;
	fma.rn.f32 	%f1450, %f1983, %f1422, %f1449;
	fma.rn.f32 	%f2004, %f1985, %f1424, %f1450;
	mul.f32 	%f1451, %f1983, %f1429;
	fma.rn.f32 	%f1452, %f1980, %f1426, %f1451;
	fma.rn.f32 	%f2000, %f1985, %f1431, %f1452;
	mul.f32 	%f1453, %f1983, %f1435;
	fma.rn.f32 	%f1454, %f1980, %f1433, %f1453;
	fma.rn.f32 	%f1996, %f1985, %f1439, %f1454;
	mul.f32 	%f1455, %f1979, %f1420;
	fma.rn.f32 	%f2003, %f1982, %f1422, %f1455;
	mul.f32 	%f1456, %f1982, %f1429;
	fma.rn.f32 	%f1999, %f1979, %f1426, %f1456;
	mul.f32 	%f1457, %f1982, %f1435;
	fma.rn.f32 	%f1995, %f1979, %f1433, %f1457;
	mul.f32 	%f2002, %f1978, %f1420;
	mul.f32 	%f1998, %f1978, %f1426;
	mul.f32 	%f1994, %f1978, %f1433;
	bra.uni 	$L__BB3_74;

$L__BB3_66:
	// begin inline asm
	call (%rd656), _optix_get_instance_transform_from_handle, (%rd311);
	// end inline asm

$L__BB3_67:
	// begin inline asm
	cvta.to.global.u64 %rd317, %rd656;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r355,%r356,%r357,%r358}, [%rd317];
	// end inline asm
	mov.b32 	%f2002, %r355;
	mov.b32 	%f2003, %r356;
	mov.b32 	%f2004, %r357;
	mov.b32 	%f2005, %r358;
	add.s64 	%rd321, %rd656, 16;
	// begin inline asm
	cvta.to.global.u64 %rd320, %rd321;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r359,%r360,%r361,%r362}, [%rd320];
	// end inline asm
	mov.b32 	%f1998, %r359;
	mov.b32 	%f1999, %r360;
	mov.b32 	%f2000, %r361;
	mov.b32 	%f2001, %r362;
	add.s64 	%rd324, %rd656, 32;
	// begin inline asm
	cvta.to.global.u64 %rd323, %rd324;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r363,%r364,%r365,%r366}, [%rd323];
	// end inline asm
	mov.b32 	%f1994, %r363;
	mov.b32 	%f1995, %r364;
	mov.b32 	%f1996, %r365;
	mov.b32 	%f1997, %r366;

$L__BB3_74:
	setp.eq.s32 	%p49, %r658, 1;
	@%p49 bra 	$L__BB3_76;

	mul.f32 	%f1495, %f1973, %f2003;
	fma.rn.f32 	%f1496, %f1969, %f2002, %f1495;
	fma.rn.f32 	%f500, %f1977, %f2004, %f1496;
	mul.f32 	%f1497, %f1972, %f2003;
	fma.rn.f32 	%f1498, %f1968, %f2002, %f1497;
	fma.rn.f32 	%f501, %f1976, %f2004, %f1498;
	mul.f32 	%f1499, %f1971, %f2003;
	fma.rn.f32 	%f1500, %f1967, %f2002, %f1499;
	fma.rn.f32 	%f502, %f1975, %f2004, %f1500;
	mul.f32 	%f1501, %f1970, %f2003;
	fma.rn.f32 	%f1502, %f1966, %f2002, %f1501;
	fma.rn.f32 	%f1503, %f1974, %f2004, %f1502;
	add.f32 	%f2005, %f2005, %f1503;
	mul.f32 	%f1504, %f1973, %f1999;
	fma.rn.f32 	%f1505, %f1969, %f1998, %f1504;
	fma.rn.f32 	%f504, %f1977, %f2000, %f1505;
	mul.f32 	%f1506, %f1972, %f1999;
	fma.rn.f32 	%f1507, %f1968, %f1998, %f1506;
	fma.rn.f32 	%f505, %f1976, %f2000, %f1507;
	mul.f32 	%f1508, %f1971, %f1999;
	fma.rn.f32 	%f1509, %f1967, %f1998, %f1508;
	fma.rn.f32 	%f506, %f1975, %f2000, %f1509;
	mul.f32 	%f1510, %f1970, %f1999;
	fma.rn.f32 	%f1511, %f1966, %f1998, %f1510;
	fma.rn.f32 	%f1512, %f1974, %f2000, %f1511;
	add.f32 	%f2001, %f2001, %f1512;
	mul.f32 	%f1513, %f1973, %f1995;
	fma.rn.f32 	%f1514, %f1969, %f1994, %f1513;
	fma.rn.f32 	%f508, %f1977, %f1996, %f1514;
	mul.f32 	%f1515, %f1972, %f1995;
	fma.rn.f32 	%f1516, %f1968, %f1994, %f1515;
	fma.rn.f32 	%f509, %f1976, %f1996, %f1516;
	mul.f32 	%f1517, %f1971, %f1995;
	fma.rn.f32 	%f1518, %f1967, %f1994, %f1517;
	fma.rn.f32 	%f510, %f1975, %f1996, %f1518;
	mul.f32 	%f1519, %f1970, %f1995;
	fma.rn.f32 	%f1520, %f1966, %f1994, %f1519;
	fma.rn.f32 	%f1521, %f1974, %f1996, %f1520;
	add.f32 	%f1997, %f1997, %f1521;
	mov.f32 	%f1994, %f508;
	mov.f32 	%f1995, %f509;
	mov.f32 	%f1996, %f510;
	mov.f32 	%f1998, %f504;
	mov.f32 	%f1999, %f505;
	mov.f32 	%f2000, %f506;
	mov.f32 	%f2002, %f500;
	mov.f32 	%f2003, %f501;
	mov.f32 	%f2004, %f502;

$L__BB3_76:
	add.s32 	%r658, %r658, -1;
	add.s32 	%r657, %r657, -1;
	setp.gt.s32 	%p50, %r657, 1;
	mov.f32 	%f1966, %f2005;
	mov.f32 	%f1967, %f2004;
	mov.f32 	%f1968, %f2003;
	mov.f32 	%f1969, %f2002;
	mov.f32 	%f1970, %f2001;
	mov.f32 	%f1971, %f2000;
	mov.f32 	%f1972, %f1999;
	mov.f32 	%f1973, %f1998;
	mov.f32 	%f1974, %f1997;
	mov.f32 	%f1975, %f1996;
	mov.f32 	%f1976, %f1995;
	mov.f32 	%f1977, %f1994;
	@%p50 bra 	$L__BB3_62;

$L__BB3_77:
	// begin inline asm
	call (%r501), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p51, %r501, 0;
	mov.f32 	%f2066, %f2065;
	mov.f32 	%f2061, %f2065;
	mov.f32 	%f2062, %f2064;
	mov.f32 	%f2063, %f2065;
	mov.f32 	%f2058, %f2065;
	mov.f32 	%f2059, %f2065;
	mov.f32 	%f2060, %f2064;
	@%p51 bra 	$L__BB3_96;

	// begin inline asm
	call (%r502), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1531), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p52, %r502, 0;
	@%p52 bra 	$L__BB3_96;

	mov.u32 	%r659, 0;

$L__BB3_80:
	.pragma "nounroll";
	// begin inline asm
	call (%rd430), _optix_get_transform_list_handle, (%r659);
	// end inline asm
	// begin inline asm
	call (%r505), _optix_get_transform_type_from_handle, (%rd430);
	// end inline asm
	or.b32  	%r506, %r505, 1;
	setp.eq.s32 	%p53, %r506, 3;
	@%p53 bra 	$L__BB3_86;
	bra.uni 	$L__BB3_81;

$L__BB3_86:
	setp.eq.s32 	%p56, %r505, 2;
	@%p56 bra 	$L__BB3_90;
	bra.uni 	$L__BB3_87;

$L__BB3_90:
	// begin inline asm
	call (%rd502), _optix_get_matrix_motion_transform_from_handle, (%rd430);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd504, %rd502;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r594,%r595,%r596,%r597}, [%rd504];
	// end inline asm
	add.s64 	%rd508, %rd502, 16;
	// begin inline asm
	cvta.to.global.u64 %rd507, %rd508;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r598,%r599,%r600,%r601}, [%rd507];
	// end inline asm
	add.s64 	%rd511, %rd502, 32;
	// begin inline asm
	cvta.to.global.u64 %rd510, %rd511;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r602,%r603,%r604,%r605}, [%rd510];
	// end inline asm
	add.s64 	%rd514, %rd502, 48;
	// begin inline asm
	cvta.to.global.u64 %rd513, %rd514;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r606,%r607,%r608,%r609}, [%rd513];
	// end inline asm
	add.s64 	%rd517, %rd502, 64;
	// begin inline asm
	cvta.to.global.u64 %rd516, %rd517;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r610,%r611,%r612,%r613}, [%rd516];
	// end inline asm
	add.s64 	%rd520, %rd502, 80;
	// begin inline asm
	cvta.to.global.u64 %rd519, %rd520;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r614,%r615,%r616,%r617}, [%rd519];
	// end inline asm
	add.s64 	%rd523, %rd502, 96;
	// begin inline asm
	cvta.to.global.u64 %rd522, %rd523;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r618,%r619,%r620,%r621}, [%rd522];
	// end inline asm
	add.s64 	%rd526, %rd502, 112;
	// begin inline asm
	cvta.to.global.u64 %rd525, %rd526;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r622,%r623,%r624,%r625}, [%rd525];
	// end inline asm
	mov.b32 	%f1635, %r597;
	mov.b32 	%f1636, %r598;
	and.b32  	%r638, %r596, 65535;
	add.s32 	%r639, %r638, -1;
	cvt.rn.f32.s32 	%f1637, %r639;
	sub.f32 	%f1638, %f1531, %f1635;
	mul.f32 	%f1639, %f1638, %f1637;
	sub.f32 	%f1640, %f1636, %f1635;
	div.rn.f32 	%f1641, %f1639, %f1640;
	min.f32 	%f1642, %f1637, %f1641;
	mov.f32 	%f1643, 0f00000000;
	max.f32 	%f1644, %f1643, %f1642;
	cvt.rmi.f32.f32 	%f1645, %f1644;
	sub.f32 	%f595, %f1644, %f1645;
	cvt.rzi.s32.f32 	%r640, %f1645;
	cvt.s64.s32 	%rd39, %r640;
	mul.wide.s32 	%rd537, %r640, 48;
	add.s64 	%rd529, %rd511, %rd537;
	// begin inline asm
	cvta.to.global.u64 %rd528, %rd529;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r626,%r627,%r628,%r629}, [%rd528];
	// end inline asm
	mov.b32 	%f2055, %r626;
	mov.b32 	%f2056, %r627;
	mov.b32 	%f2057, %r628;
	add.s64 	%rd532, %rd529, 16;
	// begin inline asm
	cvta.to.global.u64 %rd531, %rd532;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r630,%r631,%r632,%r633}, [%rd531];
	// end inline asm
	mov.b32 	%f2052, %r630;
	mov.b32 	%f2053, %r631;
	mov.b32 	%f2054, %r632;
	add.s64 	%rd535, %rd529, 32;
	// begin inline asm
	cvta.to.global.u64 %rd534, %rd535;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r634,%r635,%r636,%r637}, [%rd534];
	// end inline asm
	mov.b32 	%f2049, %r634;
	mov.b32 	%f2050, %r635;
	mov.b32 	%f2051, %r636;
	setp.leu.f32 	%p58, %f595, 0f00000000;
	@%p58 bra 	$L__BB3_92;

	mov.f32 	%f1646, 0f3F800000;
	sub.f32 	%f1647, %f1646, %f595;
	mul.lo.s64 	%rd547, %rd39, 48;
	add.s64 	%rd548, %rd502, %rd547;
	add.s64 	%rd539, %rd548, 80;
	// begin inline asm
	cvta.to.global.u64 %rd538, %rd539;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r641,%r642,%r643,%r644}, [%rd538];
	// end inline asm
	mov.b32 	%f1648, %r641;
	mov.b32 	%f1649, %r642;
	mov.b32 	%f1650, %r643;
	mul.f32 	%f1651, %f595, %f1648;
	mul.f32 	%f1652, %f595, %f1649;
	mul.f32 	%f1653, %f595, %f1650;
	fma.rn.f32 	%f2055, %f1647, %f2055, %f1651;
	fma.rn.f32 	%f2056, %f1647, %f2056, %f1652;
	fma.rn.f32 	%f2057, %f1647, %f2057, %f1653;
	add.s64 	%rd542, %rd548, 96;
	// begin inline asm
	cvta.to.global.u64 %rd541, %rd542;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r645,%r646,%r647,%r648}, [%rd541];
	// end inline asm
	mov.b32 	%f1654, %r645;
	mov.b32 	%f1655, %r646;
	mov.b32 	%f1656, %r647;
	mul.f32 	%f1657, %f595, %f1654;
	mul.f32 	%f1658, %f595, %f1655;
	mul.f32 	%f1659, %f595, %f1656;
	fma.rn.f32 	%f2052, %f1647, %f2052, %f1657;
	fma.rn.f32 	%f2053, %f1647, %f2053, %f1658;
	fma.rn.f32 	%f2054, %f1647, %f2054, %f1659;
	add.s64 	%rd545, %rd548, 112;
	// begin inline asm
	cvta.to.global.u64 %rd544, %rd545;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r649,%r650,%r651,%r652}, [%rd544];
	// end inline asm
	mov.b32 	%f1660, %r649;
	mov.b32 	%f1661, %r650;
	mov.b32 	%f1662, %r651;
	mul.f32 	%f1663, %f595, %f1660;
	mul.f32 	%f1664, %f595, %f1661;
	mul.f32 	%f1665, %f595, %f1662;
	fma.rn.f32 	%f2049, %f1647, %f2049, %f1663;
	fma.rn.f32 	%f2050, %f1647, %f2050, %f1664;
	fma.rn.f32 	%f2051, %f1647, %f2051, %f1665;
	bra.uni 	$L__BB3_92;

$L__BB3_81:
	mov.f32 	%f2058, 0f00000000;
	mov.f32 	%f2060, 0f3F800000;
	setp.eq.s32 	%p54, %r505, 4;
	@%p54 bra 	$L__BB3_84;

	setp.ne.s32 	%p55, %r505, 1;
	mov.f32 	%f2059, %f2058;
	mov.f32 	%f2061, %f2058;
	mov.f32 	%f2062, %f2060;
	mov.f32 	%f2063, %f2058;
	mov.f32 	%f2064, %f2060;
	mov.f32 	%f2065, %f2058;
	mov.f32 	%f2066, %f2058;
	@%p55 bra 	$L__BB3_93;

	// begin inline asm
	call (%rd432), _optix_get_static_transform_from_handle, (%rd430);
	// end inline asm
	add.s64 	%rd657, %rd432, 64;
	bra.uni 	$L__BB3_85;

$L__BB3_87:
	// begin inline asm
	call (%rd445), _optix_get_srt_motion_transform_from_handle, (%rd430);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd447, %rd445;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r519,%r520,%r521,%r522}, [%rd447];
	// end inline asm
	add.s64 	%rd451, %rd445, 16;
	// begin inline asm
	cvta.to.global.u64 %rd450, %rd451;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r523,%r524,%r525,%r526}, [%rd450];
	// end inline asm
	add.s64 	%rd454, %rd445, 32;
	// begin inline asm
	cvta.to.global.u64 %rd453, %rd454;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r527,%r528,%r529,%r530}, [%rd453];
	// end inline asm
	add.s64 	%rd457, %rd445, 48;
	// begin inline asm
	cvta.to.global.u64 %rd456, %rd457;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r531,%r532,%r533,%r534}, [%rd456];
	// end inline asm
	add.s64 	%rd460, %rd445, 64;
	// begin inline asm
	cvta.to.global.u64 %rd459, %rd460;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r535,%r536,%r537,%r538}, [%rd459];
	// end inline asm
	add.s64 	%rd463, %rd445, 80;
	// begin inline asm
	cvta.to.global.u64 %rd462, %rd463;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r539,%r540,%r541,%r542}, [%rd462];
	// end inline asm
	add.s64 	%rd466, %rd445, 96;
	// begin inline asm
	cvta.to.global.u64 %rd465, %rd466;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r543,%r544,%r545,%r546}, [%rd465];
	// end inline asm
	add.s64 	%rd469, %rd445, 112;
	// begin inline asm
	cvta.to.global.u64 %rd468, %rd469;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r547,%r548,%r549,%r550}, [%rd468];
	// end inline asm
	add.s64 	%rd472, %rd445, 128;
	// begin inline asm
	cvta.to.global.u64 %rd471, %rd472;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r551,%r552,%r553,%r554}, [%rd471];
	// end inline asm
	add.s64 	%rd475, %rd445, 144;
	// begin inline asm
	cvta.to.global.u64 %rd474, %rd475;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r555,%r556,%r557,%r558}, [%rd474];
	// end inline asm
	mov.b32 	%f1543, %r522;
	mov.b32 	%f1544, %r523;
	and.b32  	%r575, %r521, 65535;
	add.s32 	%r576, %r575, -1;
	cvt.rn.f32.s32 	%f1545, %r576;
	sub.f32 	%f1546, %f1531, %f1543;
	mul.f32 	%f1547, %f1546, %f1545;
	sub.f32 	%f1548, %f1544, %f1543;
	div.rn.f32 	%f1549, %f1547, %f1548;
	min.f32 	%f1550, %f1545, %f1549;
	mov.f32 	%f1551, 0f00000000;
	max.f32 	%f1552, %f1551, %f1550;
	cvt.rmi.f32.f32 	%f1553, %f1552;
	sub.f32 	%f555, %f1552, %f1553;
	cvt.rzi.s32.f32 	%r577, %f1553;
	mul.wide.s32 	%rd489, %r577, 64;
	add.s64 	%rd478, %rd454, %rd489;
	// begin inline asm
	cvta.to.global.u64 %rd477, %rd478;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r559,%r560,%r561,%r562}, [%rd477];
	// end inline asm
	mov.b32 	%f2039, %r559;
	mov.b32 	%f2040, %r560;
	mov.b32 	%f2041, %r561;
	add.s64 	%rd481, %rd478, 16;
	// begin inline asm
	cvta.to.global.u64 %rd480, %rd481;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r563,%r564,%r565,%r566}, [%rd480];
	// end inline asm
	mov.b32 	%f2042, %r563;
	mov.b32 	%f2043, %r564;
	mov.b32 	%f2044, %r566;
	add.s64 	%rd484, %rd478, 32;
	// begin inline asm
	cvta.to.global.u64 %rd483, %rd484;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r567,%r568,%r569,%r570}, [%rd483];
	// end inline asm
	mov.b32 	%f2045, %r568;
	mov.b32 	%f2046, %r569;
	mov.b32 	%f2047, %r570;
	add.s64 	%rd487, %rd478, 48;
	// begin inline asm
	cvta.to.global.u64 %rd486, %rd487;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r571,%r572,%r573,%r574}, [%rd486];
	// end inline asm
	mov.b32 	%f2048, %r571;
	setp.leu.f32 	%p57, %f555, 0f00000000;
	@%p57 bra 	$L__BB3_89;

	mov.f32 	%f1554, 0f3F800000;
	sub.f32 	%f1555, %f1554, %f555;
	add.s64 	%rd491, %rd478, 64;
	// begin inline asm
	cvta.to.global.u64 %rd490, %rd491;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r578,%r579,%r580,%r581}, [%rd490];
	// end inline asm
	mov.b32 	%f1556, %r578;
	mov.b32 	%f1557, %r579;
	mov.b32 	%f1558, %r580;
	mul.f32 	%f1559, %f555, %f1556;
	mul.f32 	%f1560, %f555, %f1557;
	mul.f32 	%f1561, %f555, %f1558;
	fma.rn.f32 	%f2039, %f1555, %f2039, %f1559;
	fma.rn.f32 	%f2040, %f1555, %f2040, %f1560;
	fma.rn.f32 	%f2041, %f1555, %f2041, %f1561;
	add.s64 	%rd494, %rd478, 80;
	// begin inline asm
	cvta.to.global.u64 %rd493, %rd494;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r582,%r583,%r584,%r585}, [%rd493];
	// end inline asm
	mov.b32 	%f1562, %r582;
	mov.b32 	%f1563, %r583;
	mov.b32 	%f1564, %r585;
	mul.f32 	%f1565, %f555, %f1562;
	mul.f32 	%f1566, %f555, %f1563;
	mul.f32 	%f1567, %f555, %f1564;
	fma.rn.f32 	%f2042, %f1555, %f2042, %f1565;
	fma.rn.f32 	%f2043, %f1555, %f2043, %f1566;
	fma.rn.f32 	%f2044, %f1555, %f2044, %f1567;
	add.s64 	%rd497, %rd478, 96;
	// begin inline asm
	cvta.to.global.u64 %rd496, %rd497;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r586,%r587,%r588,%r589}, [%rd496];
	// end inline asm
	mov.b32 	%f1568, %r587;
	mov.b32 	%f1569, %r588;
	mov.b32 	%f1570, %r589;
	mul.f32 	%f1571, %f555, %f1568;
	mul.f32 	%f1572, %f555, %f1569;
	mul.f32 	%f1573, %f555, %f1570;
	fma.rn.f32 	%f1574, %f1555, %f2045, %f1571;
	fma.rn.f32 	%f1575, %f1555, %f2046, %f1572;
	fma.rn.f32 	%f1576, %f1555, %f2047, %f1573;
	add.s64 	%rd500, %rd478, 112;
	// begin inline asm
	cvta.to.global.u64 %rd499, %rd500;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r590,%r591,%r592,%r593}, [%rd499];
	// end inline asm
	mov.b32 	%f1577, %r590;
	mul.f32 	%f1578, %f555, %f1577;
	fma.rn.f32 	%f1579, %f1555, %f2048, %f1578;
	mul.f32 	%f1580, %f1575, %f1575;
	fma.rn.f32 	%f1581, %f1574, %f1574, %f1580;
	fma.rn.f32 	%f1582, %f1576, %f1576, %f1581;
	fma.rn.f32 	%f1583, %f1579, %f1579, %f1582;
	sqrt.rn.f32 	%f1584, %f1583;
	rcp.rn.f32 	%f1585, %f1584;
	mul.f32 	%f2045, %f1574, %f1585;
	mul.f32 	%f2046, %f1575, %f1585;
	mul.f32 	%f2047, %f1576, %f1585;
	mul.f32 	%f2048, %f1585, %f1579;

$L__BB3_89:
	mul.f32 	%f1586, %f2046, %f2046;
	fma.rn.f32 	%f1587, %f2045, %f2045, %f1586;
	fma.rn.f32 	%f1588, %f2047, %f2047, %f1587;
	fma.rn.f32 	%f1589, %f2048, %f2048, %f1588;
	rcp.rn.f32 	%f1590, %f1589;
	mul.f32 	%f1591, %f2045, %f1590;
	mul.f32 	%f1592, %f2046, %f1590;
	mul.f32 	%f1593, %f2047, %f1590;
	mul.f32 	%f1594, %f2048, %f1590;
	mul.f32 	%f1595, %f2045, %f1591;
	mul.f32 	%f1596, %f2046, %f1592;
	mul.f32 	%f1597, %f2047, %f1593;
	mul.f32 	%f1598, %f2045, %f1592;
	mul.f32 	%f1599, %f2047, %f1594;
	mul.f32 	%f1600, %f2045, %f1593;
	mul.f32 	%f1601, %f2046, %f1594;
	mul.f32 	%f1602, %f2046, %f1593;
	mul.f32 	%f1603, %f2045, %f1594;
	sub.f32 	%f1604, %f1595, %f1596;
	sub.f32 	%f1605, %f1604, %f1597;
	fma.rn.f32 	%f1606, %f2048, %f1594, %f1605;
	sub.f32 	%f1607, %f1598, %f1599;
	add.f32 	%f1608, %f1607, %f1607;
	add.f32 	%f1609, %f1600, %f1601;
	add.f32 	%f1610, %f1609, %f1609;
	add.f32 	%f1611, %f1598, %f1599;
	add.f32 	%f1612, %f1611, %f1611;
	sub.f32 	%f1613, %f1596, %f1595;
	sub.f32 	%f1614, %f1613, %f1597;
	fma.rn.f32 	%f1615, %f2048, %f1594, %f1614;
	sub.f32 	%f1616, %f1602, %f1603;
	add.f32 	%f1617, %f1616, %f1616;
	sub.f32 	%f1618, %f1600, %f1601;
	add.f32 	%f1619, %f1618, %f1618;
	add.f32 	%f1620, %f1602, %f1603;
	add.f32 	%f1621, %f1620, %f1620;
	neg.f32 	%f1622, %f1595;
	sub.f32 	%f1623, %f1622, %f1596;
	add.f32 	%f1624, %f1597, %f1623;
	fma.rn.f32 	%f1625, %f2048, %f1594, %f1624;
	mul.f32 	%f1626, %f2041, %f1606;
	fma.rn.f32 	%f1627, %f2043, %f1608, %f1626;
	fma.rn.f32 	%f2057, %f2044, %f1610, %f1627;
	mul.f32 	%f1628, %f2043, %f1615;
	fma.rn.f32 	%f1629, %f2041, %f1612, %f1628;
	fma.rn.f32 	%f2054, %f2044, %f1617, %f1629;
	mul.f32 	%f1630, %f2043, %f1621;
	fma.rn.f32 	%f1631, %f2041, %f1619, %f1630;
	fma.rn.f32 	%f2051, %f2044, %f1625, %f1631;
	mul.f32 	%f1632, %f2040, %f1606;
	fma.rn.f32 	%f2056, %f2042, %f1608, %f1632;
	mul.f32 	%f1633, %f2042, %f1615;
	fma.rn.f32 	%f2053, %f2040, %f1612, %f1633;
	mul.f32 	%f1634, %f2042, %f1621;
	fma.rn.f32 	%f2050, %f2040, %f1619, %f1634;
	mul.f32 	%f2055, %f2039, %f1606;
	mul.f32 	%f2052, %f2039, %f1612;
	mul.f32 	%f2049, %f2039, %f1619;

$L__BB3_92:
	mul.f32 	%f1666, %f2050, %f2054;
	mul.f32 	%f1667, %f2051, %f2053;
	sub.f32 	%f1668, %f1667, %f1666;
	mul.f32 	%f1669, %f2055, %f1668;
	mul.f32 	%f1670, %f2049, %f2054;
	mul.f32 	%f1671, %f2051, %f2052;
	sub.f32 	%f1672, %f1671, %f1670;
	mul.f32 	%f1673, %f1672, %f2056;
	sub.f32 	%f1674, %f1669, %f1673;
	mul.f32 	%f1675, %f2049, %f2053;
	mul.f32 	%f1676, %f2050, %f2052;
	sub.f32 	%f1677, %f1676, %f1675;
	fma.rn.f32 	%f1678, %f1677, %f2057, %f1674;
	rcp.rn.f32 	%f1679, %f1678;
	mul.f32 	%f2064, %f1668, %f1679;
	mul.f32 	%f1680, %f2051, %f2056;
	mul.f32 	%f1681, %f2050, %f2057;
	sub.f32 	%f1682, %f1681, %f1680;
	mul.f32 	%f2065, %f1682, %f1679;
	mul.f32 	%f1683, %f2053, %f2057;
	mul.f32 	%f1684, %f2054, %f2056;
	sub.f32 	%f1685, %f1684, %f1683;
	mul.f32 	%f2066, %f1685, %f1679;
	sub.f32 	%f1686, %f1670, %f1671;
	mul.f32 	%f2061, %f1686, %f1679;
	mul.f32 	%f1687, %f2049, %f2057;
	mul.f32 	%f1688, %f2051, %f2055;
	sub.f32 	%f1689, %f1688, %f1687;
	mul.f32 	%f2062, %f1689, %f1679;
	mul.f32 	%f1690, %f2054, %f2055;
	mul.f32 	%f1691, %f2052, %f2057;
	sub.f32 	%f1692, %f1691, %f1690;
	mul.f32 	%f2063, %f1692, %f1679;
	mul.f32 	%f2058, %f1677, %f1679;
	mul.f32 	%f1693, %f2050, %f2055;
	mul.f32 	%f1694, %f2049, %f2056;
	sub.f32 	%f1695, %f1694, %f1693;
	mul.f32 	%f2059, %f1695, %f1679;
	mul.f32 	%f1696, %f2052, %f2056;
	mul.f32 	%f1697, %f2053, %f2055;
	sub.f32 	%f1698, %f1697, %f1696;
	mul.f32 	%f2060, %f1698, %f1679;
	bra.uni 	$L__BB3_93;

$L__BB3_84:
	// begin inline asm
	call (%rd657), _optix_get_instance_inverse_transform_from_handle, (%rd430);
	// end inline asm

$L__BB3_85:
	// begin inline asm
	cvta.to.global.u64 %rd436, %rd657;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r507,%r508,%r509,%r510}, [%rd436];
	// end inline asm
	mov.b32 	%f2064, %r507;
	mov.b32 	%f2065, %r508;
	mov.b32 	%f2066, %r509;
	add.s64 	%rd440, %rd657, 16;
	// begin inline asm
	cvta.to.global.u64 %rd439, %rd440;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r511,%r512,%r513,%r514}, [%rd439];
	// end inline asm
	mov.b32 	%f2061, %r511;
	mov.b32 	%f2062, %r512;
	mov.b32 	%f2063, %r513;
	add.s64 	%rd443, %rd657, 32;
	// begin inline asm
	cvta.to.global.u64 %rd442, %rd443;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r515,%r516,%r517,%r518}, [%rd442];
	// end inline asm
	mov.b32 	%f2058, %r515;
	mov.b32 	%f2059, %r516;
	mov.b32 	%f2060, %r517;

$L__BB3_93:
	setp.eq.s32 	%p59, %r659, 0;
	@%p59 bra 	$L__BB3_95;

	mul.f32 	%f1699, %f2035, %f2065;
	fma.rn.f32 	%f1700, %f2032, %f2064, %f1699;
	fma.rn.f32 	%f641, %f2038, %f2066, %f1700;
	mul.f32 	%f1701, %f2034, %f2065;
	fma.rn.f32 	%f1702, %f2031, %f2064, %f1701;
	fma.rn.f32 	%f642, %f2037, %f2066, %f1702;
	mul.f32 	%f1703, %f2033, %f2065;
	fma.rn.f32 	%f1704, %f2030, %f2064, %f1703;
	fma.rn.f32 	%f2066, %f2036, %f2066, %f1704;
	mul.f32 	%f1705, %f2035, %f2062;
	fma.rn.f32 	%f1706, %f2032, %f2061, %f1705;
	fma.rn.f32 	%f644, %f2038, %f2063, %f1706;
	mul.f32 	%f1707, %f2034, %f2062;
	fma.rn.f32 	%f1708, %f2031, %f2061, %f1707;
	fma.rn.f32 	%f645, %f2037, %f2063, %f1708;
	mul.f32 	%f1709, %f2033, %f2062;
	fma.rn.f32 	%f1710, %f2030, %f2061, %f1709;
	fma.rn.f32 	%f2063, %f2036, %f2063, %f1710;
	mul.f32 	%f1711, %f2035, %f2059;
	fma.rn.f32 	%f1712, %f2032, %f2058, %f1711;
	fma.rn.f32 	%f647, %f2038, %f2060, %f1712;
	mul.f32 	%f1713, %f2034, %f2059;
	fma.rn.f32 	%f1714, %f2031, %f2058, %f1713;
	fma.rn.f32 	%f648, %f2037, %f2060, %f1714;
	mul.f32 	%f1715, %f2033, %f2059;
	fma.rn.f32 	%f1716, %f2030, %f2058, %f1715;
	fma.rn.f32 	%f2060, %f2036, %f2060, %f1716;
	mov.f32 	%f2058, %f647;
	mov.f32 	%f2059, %f648;
	mov.f32 	%f2061, %f644;
	mov.f32 	%f2062, %f645;
	mov.f32 	%f2064, %f641;
	mov.f32 	%f2065, %f642;

$L__BB3_95:
	add.s32 	%r659, %r659, 1;
	setp.lt.u32 	%p60, %r659, %r502;
	mov.f32 	%f2030, %f2066;
	mov.f32 	%f2031, %f2065;
	mov.f32 	%f2032, %f2064;
	mov.f32 	%f2033, %f2063;
	mov.f32 	%f2034, %f2062;
	mov.f32 	%f2035, %f2061;
	mov.f32 	%f2036, %f2060;
	mov.f32 	%f2037, %f2059;
	mov.f32 	%f2038, %f2058;
	@%p60 bra 	$L__BB3_80;

$L__BB3_96:
	fma.rn.f32 	%f1717, %f2115, %f2002, %f2005;
	fma.rn.f32 	%f1718, %f2116, %f2003, %f1717;
	fma.rn.f32 	%f1719, %f2115, %f1998, %f2001;
	fma.rn.f32 	%f1720, %f2116, %f1999, %f1719;
	fma.rn.f32 	%f1721, %f2115, %f1994, %f1997;
	fma.rn.f32 	%f1722, %f2116, %f1995, %f1721;
	fma.rn.f32 	%f2115, %f2117, %f2004, %f1718;
	fma.rn.f32 	%f2116, %f2117, %f2000, %f1720;
	fma.rn.f32 	%f2117, %f2117, %f1996, %f1722;
	ld.const.u64 	%rd549, [params+112];
	setp.eq.s64 	%p61, %rd549, 0;
	mov.f32 	%f2085, %f2088;
	mov.f32 	%f2086, %f2089;
	mov.f32 	%f2087, %f2090;
	@%p61 bra 	$L__BB3_98;

	mul.f32 	%f1723, %f2088, %f2064;
	fma.rn.f32 	%f1724, %f2089, %f2061, %f1723;
	mul.f32 	%f1725, %f2088, %f2065;
	fma.rn.f32 	%f1726, %f2089, %f2062, %f1725;
	mul.f32 	%f1727, %f2088, %f2066;
	fma.rn.f32 	%f1728, %f2089, %f2063, %f1727;
	fma.rn.f32 	%f1729, %f2090, %f2058, %f1724;
	fma.rn.f32 	%f1730, %f2090, %f2059, %f1726;
	fma.rn.f32 	%f1731, %f2090, %f2060, %f1728;
	mul.f32 	%f1732, %f1729, %f1729;
	fma.rn.f32 	%f1733, %f1730, %f1730, %f1732;
	fma.rn.f32 	%f1734, %f1731, %f1731, %f1733;
	sqrt.rn.f32 	%f1735, %f1734;
	div.rn.f32 	%f2085, %f1729, %f1735;
	div.rn.f32 	%f2086, %f1730, %f1735;
	div.rn.f32 	%f2087, %f1731, %f1735;

$L__BB3_98:
	ld.const.u64 	%rd550, [params+136];
	setp.eq.s64 	%p62, %rd550, 0;
	@%p62 bra 	$L__BB3_100;

	mul.f32 	%f1736, %f2088, %f2064;
	fma.rn.f32 	%f1737, %f2089, %f2061, %f1736;
	mul.f32 	%f1738, %f2088, %f2065;
	fma.rn.f32 	%f1739, %f2089, %f2062, %f1738;
	mul.f32 	%f1740, %f2088, %f2066;
	fma.rn.f32 	%f1741, %f2089, %f2063, %f1740;
	fma.rn.f32 	%f1742, %f2090, %f2058, %f1737;
	fma.rn.f32 	%f1743, %f2090, %f2059, %f1739;
	fma.rn.f32 	%f1744, %f2090, %f2060, %f1741;
	mul.f32 	%f1745, %f1742, %f1742;
	fma.rn.f32 	%f1746, %f1743, %f1743, %f1745;
	fma.rn.f32 	%f1747, %f1744, %f1744, %f1746;
	sqrt.rn.f32 	%f1748, %f1747;
	div.rn.f32 	%f2088, %f1742, %f1748;
	div.rn.f32 	%f2089, %f1743, %f1748;
	div.rn.f32 	%f2090, %f1744, %f1748;

$L__BB3_100:
	mov.f32 	%f2114, %f2090;
	mov.f32 	%f2113, %f2089;
	mov.f32 	%f2112, %f2088;
	ld.const.u64 	%rd551, [params+184];
	setp.eq.s64 	%p63, %rd551, 0;
	@%p63 bra 	$L__BB3_102;

	mul.f32 	%f1749, %f2106, %f2002;
	fma.rn.f32 	%f1750, %f2107, %f2003, %f1749;
	mul.f32 	%f1751, %f2106, %f1998;
	fma.rn.f32 	%f1752, %f2107, %f1999, %f1751;
	mul.f32 	%f1753, %f2106, %f1994;
	fma.rn.f32 	%f1754, %f2107, %f1995, %f1753;
	fma.rn.f32 	%f2106, %f2108, %f2004, %f1750;
	fma.rn.f32 	%f2107, %f2108, %f2000, %f1752;
	fma.rn.f32 	%f2108, %f2108, %f1996, %f1754;
	mul.f32 	%f1755, %f2103, %f2002;
	fma.rn.f32 	%f1756, %f2104, %f2003, %f1755;
	mul.f32 	%f1757, %f2103, %f1998;
	fma.rn.f32 	%f1758, %f2104, %f1999, %f1757;
	mul.f32 	%f1759, %f2103, %f1994;
	fma.rn.f32 	%f1760, %f2104, %f1995, %f1759;
	fma.rn.f32 	%f2103, %f2105, %f2004, %f1756;
	fma.rn.f32 	%f2104, %f2105, %f2000, %f1758;
	fma.rn.f32 	%f2105, %f2105, %f1996, %f1760;

$L__BB3_102:
	ld.const.u64 	%rd552, [params+232];
	ld.const.u64 	%rd553, [params+280];
	or.b64  	%rd554, %rd552, %rd553;
	setp.eq.s64 	%p64, %rd554, 0;
	mov.f32 	%f2100, 0f00000000;
	mov.f32 	%f2101, %f2100;
	mov.f32 	%f2102, %f2100;
	@%p64 bra 	$L__BB3_104;

	mul.f32 	%f1764, %f2112, %f2002;
	fma.rn.f32 	%f1765, %f2113, %f1998, %f1764;
	mul.f32 	%f1766, %f2112, %f2003;
	fma.rn.f32 	%f1767, %f2113, %f1999, %f1766;
	mul.f32 	%f1768, %f2112, %f2004;
	fma.rn.f32 	%f1769, %f2113, %f2000, %f1768;
	fma.rn.f32 	%f1770, %f2114, %f1994, %f1765;
	fma.rn.f32 	%f1771, %f2114, %f1995, %f1767;
	fma.rn.f32 	%f1772, %f2114, %f1996, %f1769;
	mul.f32 	%f1773, %f1770, %f1770;
	fma.rn.f32 	%f1774, %f1771, %f1771, %f1773;
	fma.rn.f32 	%f1775, %f1772, %f1772, %f1774;
	sqrt.rn.f32 	%f1776, %f1775;
	div.rn.f32 	%f1777, %f1770, %f1776;
	div.rn.f32 	%f1778, %f1771, %f1776;
	div.rn.f32 	%f1779, %f1772, %f1776;
	mul.f32 	%f1780, %f1777, %f2064;
	mul.f32 	%f1781, %f1777, %f2065;
	mul.f32 	%f1782, %f1777, %f2066;
	fma.rn.f32 	%f1783, %f1778, %f2061, %f1780;
	fma.rn.f32 	%f1784, %f1778, %f2062, %f1781;
	fma.rn.f32 	%f1785, %f1778, %f2063, %f1782;
	fma.rn.f32 	%f1786, %f1779, %f2058, %f1783;
	fma.rn.f32 	%f1787, %f1779, %f2059, %f1784;
	fma.rn.f32 	%f1788, %f1779, %f2060, %f1785;
	mul.f32 	%f1789, %f1786, %f1786;
	fma.rn.f32 	%f1790, %f1787, %f1787, %f1789;
	fma.rn.f32 	%f1791, %f1788, %f1788, %f1790;
	sqrt.rn.f32 	%f1792, %f1791;
	rcp.rn.f32 	%f1793, %f1792;
	mul.f32 	%f1794, %f1793, %f1786;
	mul.f32 	%f1795, %f1793, %f1787;
	mul.f32 	%f1796, %f1793, %f1788;
	mul.f32 	%f1797, %f2064, 0f00000000;
	mov.f32 	%f1798, 0f00000000;
	fma.rn.f32 	%f1799, %f1798, %f2061, %f1797;
	mul.f32 	%f1800, %f2065, 0f00000000;
	fma.rn.f32 	%f1801, %f1798, %f2062, %f1800;
	mul.f32 	%f1802, %f2066, 0f00000000;
	fma.rn.f32 	%f1803, %f1798, %f2063, %f1802;
	fma.rn.f32 	%f1804, %f1798, %f2058, %f1799;
	fma.rn.f32 	%f1805, %f1798, %f2059, %f1801;
	fma.rn.f32 	%f1806, %f1798, %f2060, %f1803;
	mul.f32 	%f1807, %f1804, %f1793;
	mul.f32 	%f1808, %f1805, %f1793;
	mul.f32 	%f1809, %f1806, %f1793;
	mul.f32 	%f1810, %f1794, %f1807;
	fma.rn.f32 	%f1811, %f1795, %f1808, %f1810;
	fma.rn.f32 	%f1812, %f1796, %f1809, %f1811;
	mul.f32 	%f1813, %f1794, %f1812;
	mul.f32 	%f1814, %f1795, %f1812;
	mul.f32 	%f1815, %f1796, %f1812;
	sub.f32 	%f2100, %f1807, %f1813;
	sub.f32 	%f2101, %f1808, %f1814;
	sub.f32 	%f2102, %f1809, %f1815;

$L__BB3_104:
	st.global.u32 	[%rd25], %r348;
	mov.f32 	%f2088, %f2085;
	mov.f32 	%f2089, %f2086;
	mov.f32 	%f2090, %f2087;

$L__BB3_105:
	ld.const.u64 	%rd555, [params+328];
	cvta.to.global.u64 	%rd556, %rd555;
	shl.b64 	%rd557, %rd24, 3;
	add.s64 	%rd558, %rd556, %rd557;
	st.global.u64 	[%rd558], %rd23;
	ld.const.u64 	%rd559, [params+336];
	cvta.to.global.u64 	%rd560, %rd559;
	shl.b64 	%rd561, %rd24, 2;
	add.s64 	%rd562, %rd560, %rd561;
	mov.u32 	%r653, 0;
	st.global.u32 	[%rd562], %r653;
	ld.const.u64 	%rd563, [params+160];
	cvta.to.global.u64 	%rd564, %rd563;
	add.s64 	%rd565, %rd564, %rd561;
	st.global.f32 	[%rd565], %f2115;
	ld.const.u64 	%rd566, [params+168];
	cvta.to.global.u64 	%rd567, %rd566;
	add.s64 	%rd568, %rd567, %rd561;
	st.global.f32 	[%rd568], %f2116;
	ld.const.u64 	%rd569, [params+176];
	cvta.to.global.u64 	%rd570, %rd569;
	add.s64 	%rd571, %rd570, %rd561;
	st.global.f32 	[%rd571], %f2117;
	ld.const.u64 	%rd572, [params+72];
	cvta.to.global.u64 	%rd573, %rd572;
	add.s64 	%rd574, %rd573, %rd561;
	st.global.f32 	[%rd574], %f346;
	@%p25 bra 	$L__BB3_107;

	cvta.to.global.u64 	%rd575, %rd22;
	add.s64 	%rd577, %rd575, %rd561;
	st.global.f32 	[%rd577], %f1959;
	ld.const.u64 	%rd578, [params+104];
	cvta.to.global.u64 	%rd579, %rd578;
	add.s64 	%rd580, %rd579, %rd561;
	st.global.f32 	[%rd580], %f1958;

$L__BB3_107:
	ld.const.u64 	%rd40, [params+112];
	setp.eq.s64 	%p66, %rd40, 0;
	@%p66 bra 	$L__BB3_109;

	cvta.to.global.u64 	%rd581, %rd40;
	add.s64 	%rd583, %rd581, %rd561;
	st.global.f32 	[%rd583], %f2088;
	ld.const.u64 	%rd584, [params+120];
	cvta.to.global.u64 	%rd585, %rd584;
	add.s64 	%rd586, %rd585, %rd561;
	st.global.f32 	[%rd586], %f2089;
	ld.const.u64 	%rd587, [params+128];
	cvta.to.global.u64 	%rd588, %rd587;
	add.s64 	%rd589, %rd588, %rd561;
	st.global.f32 	[%rd589], %f2090;

$L__BB3_109:
	ld.const.u64 	%rd41, [params+136];
	setp.eq.s64 	%p67, %rd41, 0;
	@%p67 bra 	$L__BB3_111;

	cvta.to.global.u64 	%rd590, %rd41;
	add.s64 	%rd592, %rd590, %rd561;
	st.global.f32 	[%rd592], %f2112;
	ld.const.u64 	%rd593, [params+144];
	cvta.to.global.u64 	%rd594, %rd593;
	add.s64 	%rd595, %rd594, %rd561;
	st.global.f32 	[%rd595], %f2113;
	ld.const.u64 	%rd596, [params+152];
	cvta.to.global.u64 	%rd597, %rd596;
	add.s64 	%rd598, %rd597, %rd561;
	st.global.f32 	[%rd598], %f2114;

$L__BB3_111:
	ld.const.u64 	%rd42, [params+184];
	setp.eq.s64 	%p68, %rd42, 0;
	@%p68 bra 	$L__BB3_113;

	cvta.to.global.u64 	%rd599, %rd42;
	add.s64 	%rd601, %rd599, %rd561;
	st.global.f32 	[%rd601], %f2106;
	ld.const.u64 	%rd602, [params+192];
	cvta.to.global.u64 	%rd603, %rd602;
	add.s64 	%rd604, %rd603, %rd561;
	st.global.f32 	[%rd604], %f2107;
	ld.const.u64 	%rd605, [params+200];
	cvta.to.global.u64 	%rd606, %rd605;
	add.s64 	%rd607, %rd606, %rd561;
	st.global.f32 	[%rd607], %f2108;
	ld.const.u64 	%rd608, [params+208];
	cvta.to.global.u64 	%rd609, %rd608;
	add.s64 	%rd610, %rd609, %rd561;
	st.global.f32 	[%rd610], %f2103;
	ld.const.u64 	%rd611, [params+216];
	cvta.to.global.u64 	%rd612, %rd611;
	add.s64 	%rd613, %rd612, %rd561;
	st.global.f32 	[%rd613], %f2104;
	ld.const.u64 	%rd614, [params+224];
	cvta.to.global.u64 	%rd615, %rd614;
	add.s64 	%rd616, %rd615, %rd561;
	st.global.f32 	[%rd616], %f2105;

$L__BB3_113:
	ld.const.u64 	%rd43, [params+232];
	setp.eq.s64 	%p69, %rd43, 0;
	@%p69 bra 	$L__BB3_115;

	cvta.to.global.u64 	%rd617, %rd43;
	add.s64 	%rd619, %rd617, %rd561;
	st.global.f32 	[%rd619], %f2100;
	ld.const.u64 	%rd620, [params+240];
	cvta.to.global.u64 	%rd621, %rd620;
	add.s64 	%rd622, %rd621, %rd561;
	st.global.f32 	[%rd622], %f2101;
	ld.const.u64 	%rd623, [params+248];
	cvta.to.global.u64 	%rd624, %rd623;
	add.s64 	%rd625, %rd624, %rd561;
	st.global.f32 	[%rd625], %f2102;
	ld.const.u64 	%rd626, [params+256];
	cvta.to.global.u64 	%rd627, %rd626;
	add.s64 	%rd628, %rd627, %rd561;
	st.global.f32 	[%rd628], %f2100;
	ld.const.u64 	%rd629, [params+264];
	cvta.to.global.u64 	%rd630, %rd629;
	add.s64 	%rd631, %rd630, %rd561;
	st.global.f32 	[%rd631], %f2101;
	ld.const.u64 	%rd632, [params+272];
	cvta.to.global.u64 	%rd633, %rd632;
	add.s64 	%rd634, %rd633, %rd561;
	st.global.f32 	[%rd634], %f2102;

$L__BB3_115:
	ld.const.u64 	%rd44, [params+280];
	setp.eq.s64 	%p70, %rd44, 0;
	@%p70 bra 	$L__BB3_117;

	cvta.to.global.u64 	%rd635, %rd44;
	add.s64 	%rd637, %rd635, %rd561;
	st.global.f32 	[%rd637], %f2100;
	ld.const.u64 	%rd638, [params+288];
	cvta.to.global.u64 	%rd639, %rd638;
	add.s64 	%rd640, %rd639, %rd561;
	st.global.f32 	[%rd640], %f2101;
	ld.const.u64 	%rd641, [params+296];
	cvta.to.global.u64 	%rd642, %rd641;
	add.s64 	%rd643, %rd642, %rd561;
	st.global.f32 	[%rd643], %f2102;
	ld.const.u64 	%rd644, [params+304];
	cvta.to.global.u64 	%rd645, %rd644;
	add.s64 	%rd646, %rd645, %rd561;
	st.global.f32 	[%rd646], %f2100;
	ld.const.u64 	%rd647, [params+312];
	cvta.to.global.u64 	%rd648, %rd647;
	add.s64 	%rd649, %rd648, %rd561;
	st.global.f32 	[%rd649], %f2101;
	ld.const.u64 	%rd650, [params+320];
	cvta.to.global.u64 	%rd651, %rd650;
	add.s64 	%rd652, %rd651, %rd561;
	st.global.f32 	[%rd652], %f2102;

$L__BB3_117:
	ret;

}
	// .globl	__closesthit__mesh
.visible .entry __closesthit__mesh()
{
	.reg .pred 	%p<45>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<1286>;
	.reg .b32 	%r<338>;
	.reg .b64 	%rd<443>;


	// begin inline asm
	call (%r15), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r16), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r18), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r19), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r20), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r21, %r20, %r16, %r19;
	mad.lo.s32 	%r1, %r21, %r15, %r18;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64 	%p1, %rd1, 0;
	@%p1 bra 	$L__BB4_2;

	cvta.to.global.u64 	%rd39, %rd1;
	cvt.u64.u32 	%rd40, %r1;
	add.s64 	%rd41, %rd39, %rd40;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd41], %rs1;
	bra.uni 	$L__BB4_76;

$L__BB4_2:
	// begin inline asm
	call (%rd42), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd3, [%rd42+8];
	// begin inline asm
	call (%r22), _optix_read_primitive_idx, ();
	// end inline asm
	// begin inline asm
	call (%f437), _optix_get_ray_tmax, ();
	// end inline asm
	// begin inline asm
	call (%f1120, %f1121), _optix_get_triangle_barycentrics, ();
	// end inline asm
	ld.const.u64 	%rd4, [params+80];
	setp.eq.s64 	%p2, %rd4, 0;
	mov.f32 	%f1111, 0f00000000;
	mov.f32 	%f1112, 0f00000000;
	mov.f32 	%f1113, 0f00000000;
	mov.f32 	%f1114, 0f00000000;
	mov.f32 	%f1115, 0f00000000;
	mov.f32 	%f1116, 0f00000000;
	@%p2 bra 	$L__BB4_7;

	ld.u64 	%rd43, [%rd42];
	ld.const.u64 	%rd44, [params+328];
	cvta.to.global.u64 	%rd45, %rd44;
	cvt.u64.u32 	%rd5, %r1;
	mul.wide.u32 	%rd46, %r1, 8;
	add.s64 	%rd47, %rd45, %rd46;
	st.global.u64 	[%rd47], %rd43;
	ld.const.u64 	%rd48, [params+336];
	cvta.to.global.u64 	%rd49, %rd48;
	mul.wide.u32 	%rd50, %r1, 4;
	add.s64 	%rd51, %rd49, %rd50;
	st.global.u32 	[%rd51], %r22;
	ld.const.u64 	%rd52, [params+344];
	cvta.to.global.u64 	%rd53, %rd52;
	add.s64 	%rd6, %rd53, %rd50;
	ld.global.u32 	%r3, [%rd6];
	setp.eq.s32 	%p3, %r3, 0;
	@%p3 bra 	$L__BB4_6;

	// begin inline asm
	call (%r23), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p4, %r23, %r3;
	@%p4 bra 	$L__BB4_6;

	st.global.u32 	[%rd6], %r23;

$L__BB4_6:
	cvta.to.global.u64 	%rd54, %rd4;
	shl.b64 	%rd55, %rd5, 2;
	add.s64 	%rd56, %rd54, %rd55;
	st.global.f32 	[%rd56], %f1120;
	ld.const.u64 	%rd57, [params+88];
	cvta.to.global.u64 	%rd58, %rd57;
	add.s64 	%rd59, %rd58, %rd55;
	st.global.f32 	[%rd59], %f1121;
	ld.const.u64 	%rd60, [params+72];
	cvta.to.global.u64 	%rd61, %rd60;
	add.s64 	%rd62, %rd61, %rd55;
	st.global.f32 	[%rd62], %f437;
	bra.uni 	$L__BB4_76;

$L__BB4_7:
	mov.f32 	%f446, 0f3F800000;
	sub.f32 	%f447, %f446, %f1120;
	sub.f32 	%f4, %f447, %f1121;
	ld.u64 	%rd63, [%rd3];
	mul.wide.u32 	%rd64, %r22, 12;
	add.s64 	%rd65, %rd63, %rd64;
	ld.u32 	%r24, [%rd65];
	mul.wide.u32 	%rd9, %r24, 3;
	ld.u64 	%rd66, [%rd3+8];
	shl.b64 	%rd67, %rd9, 2;
	add.s64 	%rd68, %rd66, %rd67;
	ld.u32 	%r25, [%rd65+4];
	mul.wide.u32 	%rd11, %r25, 3;
	shl.b64 	%rd69, %rd11, 2;
	add.s64 	%rd70, %rd66, %rd69;
	ld.u32 	%r26, [%rd65+8];
	mul.wide.u32 	%rd13, %r26, 3;
	shl.b64 	%rd71, %rd13, 2;
	add.s64 	%rd72, %rd66, %rd71;
	ld.f32 	%f448, [%rd68];
	ld.f32 	%f449, [%rd68+4];
	ld.f32 	%f450, [%rd68+8];
	ld.f32 	%f451, [%rd70];
	mul.f32 	%f452, %f451, %f1120;
	ld.f32 	%f453, [%rd70+4];
	mul.f32 	%f454, %f453, %f1120;
	ld.f32 	%f455, [%rd70+8];
	mul.f32 	%f456, %f455, %f1120;
	fma.rn.f32 	%f457, %f448, %f4, %f452;
	fma.rn.f32 	%f458, %f449, %f4, %f454;
	fma.rn.f32 	%f459, %f450, %f4, %f456;
	ld.f32 	%f460, [%rd72];
	ld.f32 	%f461, [%rd72+4];
	ld.f32 	%f462, [%rd72+8];
	fma.rn.f32 	%f1283, %f460, %f1121, %f457;
	fma.rn.f32 	%f1284, %f461, %f1121, %f458;
	fma.rn.f32 	%f1285, %f462, %f1121, %f459;
	sub.f32 	%f8, %f451, %f448;
	sub.f32 	%f9, %f453, %f449;
	sub.f32 	%f10, %f455, %f450;
	sub.f32 	%f11, %f460, %f448;
	sub.f32 	%f12, %f461, %f449;
	sub.f32 	%f13, %f462, %f450;
	mul.f32 	%f463, %f9, %f13;
	mul.f32 	%f464, %f10, %f12;
	sub.f32 	%f465, %f463, %f464;
	mul.f32 	%f466, %f10, %f11;
	mul.f32 	%f467, %f8, %f13;
	sub.f32 	%f468, %f466, %f467;
	mul.f32 	%f469, %f8, %f12;
	mul.f32 	%f470, %f9, %f11;
	sub.f32 	%f471, %f469, %f470;
	mul.f32 	%f472, %f465, %f465;
	fma.rn.f32 	%f473, %f468, %f468, %f472;
	fma.rn.f32 	%f474, %f471, %f471, %f473;
	sqrt.rn.f32 	%f475, %f474;
	div.rn.f32 	%f1247, %f465, %f475;
	div.rn.f32 	%f1248, %f468, %f475;
	div.rn.f32 	%f1249, %f471, %f475;
	ld.const.u64 	%rd14, [params+136];
	setp.eq.s64 	%p5, %rd14, 0;
	mov.f32 	%f1117, %f1247;
	mov.f32 	%f1118, %f1248;
	mov.f32 	%f1119, %f1249;
	@%p5 bra 	$L__BB4_11;

	mov.f32 	%f1116, 0f00000000;
	mov.f32 	%f1115, 0f00000000;
	mov.f32 	%f1114, 0f00000000;
	mov.f32 	%f1113, 0f00000000;
	mov.f32 	%f1112, 0f00000000;
	mov.f32 	%f1111, 0f00000000;
	ld.u64 	%rd15, [%rd3+16];
	setp.eq.s64 	%p6, %rd15, 0;
	mov.f32 	%f1117, %f1247;
	mov.f32 	%f1118, %f1248;
	mov.f32 	%f1119, %f1249;
	@%p6 bra 	$L__BB4_11;

	mul.wide.u32 	%rd437, %r24, 3;
	shl.b64 	%rd436, %rd437, 2;
	mov.f32 	%f1116, 0f00000000;
	mov.f32 	%f1115, 0f00000000;
	mov.f32 	%f1114, 0f00000000;
	mov.f32 	%f1113, 0f00000000;
	mov.f32 	%f1112, 0f00000000;
	mov.f32 	%f1111, 0f00000000;
	add.s64 	%rd74, %rd15, %rd436;
	add.s64 	%rd76, %rd15, %rd69;
	add.s64 	%rd78, %rd15, %rd71;
	ld.f32 	%f21, [%rd74];
	ld.f32 	%f22, [%rd74+4];
	ld.f32 	%f23, [%rd74+8];
	ld.f32 	%f24, [%rd76];
	mul.f32 	%f488, %f24, %f1120;
	ld.f32 	%f25, [%rd76+4];
	mul.f32 	%f489, %f25, %f1120;
	ld.f32 	%f26, [%rd76+8];
	mul.f32 	%f490, %f26, %f1120;
	fma.rn.f32 	%f491, %f21, %f4, %f488;
	fma.rn.f32 	%f492, %f22, %f4, %f489;
	fma.rn.f32 	%f493, %f23, %f4, %f490;
	ld.f32 	%f27, [%rd78];
	ld.f32 	%f28, [%rd78+4];
	ld.f32 	%f29, [%rd78+8];
	fma.rn.f32 	%f494, %f27, %f1121, %f491;
	fma.rn.f32 	%f495, %f28, %f1121, %f492;
	fma.rn.f32 	%f496, %f29, %f1121, %f493;
	mul.f32 	%f497, %f494, %f494;
	fma.rn.f32 	%f498, %f495, %f495, %f497;
	fma.rn.f32 	%f499, %f496, %f496, %f498;
	sqrt.rn.f32 	%f500, %f499;
	div.rn.f32 	%f1119, %f496, %f500;
	div.rn.f32 	%f1118, %f495, %f500;
	div.rn.f32 	%f1117, %f494, %f500;
	ld.const.u64 	%rd79, [params+280];
	setp.eq.s64 	%p7, %rd79, 0;
	@%p7 bra 	$L__BB4_11;

	mul.f32 	%f501, %f1120, %f27;
	fma.rn.f32 	%f502, %f4, %f24, %f501;
	mul.f32 	%f503, %f1120, %f28;
	fma.rn.f32 	%f504, %f4, %f25, %f503;
	mul.f32 	%f505, %f1120, %f29;
	fma.rn.f32 	%f506, %f4, %f26, %f505;
	fma.rn.f32 	%f507, %f1121, %f21, %f502;
	fma.rn.f32 	%f508, %f1121, %f22, %f504;
	fma.rn.f32 	%f509, %f1121, %f23, %f506;
	mul.f32 	%f510, %f507, %f507;
	fma.rn.f32 	%f511, %f508, %f508, %f510;
	fma.rn.f32 	%f512, %f509, %f509, %f511;
	sqrt.rn.f32 	%f513, %f512;
	rcp.rn.f32 	%f514, %f513;
	mul.f32 	%f515, %f514, %f507;
	mul.f32 	%f516, %f514, %f508;
	mul.f32 	%f517, %f514, %f509;
	sub.f32 	%f518, %f24, %f21;
	mul.f32 	%f519, %f518, %f514;
	sub.f32 	%f520, %f25, %f22;
	mul.f32 	%f521, %f520, %f514;
	sub.f32 	%f522, %f26, %f23;
	mul.f32 	%f523, %f522, %f514;
	sub.f32 	%f524, %f27, %f21;
	mul.f32 	%f525, %f524, %f514;
	sub.f32 	%f526, %f28, %f22;
	mul.f32 	%f527, %f526, %f514;
	sub.f32 	%f528, %f29, %f23;
	mul.f32 	%f529, %f528, %f514;
	mul.f32 	%f530, %f515, %f519;
	fma.rn.f32 	%f531, %f516, %f521, %f530;
	fma.rn.f32 	%f532, %f517, %f523, %f531;
	neg.f32 	%f533, %f515;
	neg.f32 	%f534, %f516;
	neg.f32 	%f535, %f517;
	fma.rn.f32 	%f1114, %f532, %f533, %f519;
	fma.rn.f32 	%f1115, %f532, %f534, %f521;
	fma.rn.f32 	%f1116, %f532, %f535, %f523;
	mul.f32 	%f536, %f515, %f1114;
	fma.rn.f32 	%f537, %f516, %f1115, %f536;
	fma.rn.f32 	%f538, %f517, %f1116, %f537;
	fma.rn.f32 	%f1111, %f538, %f533, %f525;
	fma.rn.f32 	%f1112, %f538, %f534, %f527;
	fma.rn.f32 	%f1113, %f538, %f535, %f529;

$L__BB4_11:
	mov.b32 	%r27, %f1249;
	and.b32  	%r28, %r27, -2147483648;
	or.b32  	%r29, %r28, 1065353216;
	mov.b32 	%f539, %r29;
	add.f32 	%f540, %f1249, %f539;
	mov.f32 	%f541, 0fBF800000;
	div.rn.f32 	%f542, %f541, %f540;
	mul.f32 	%f543, %f1247, %f1248;
	mul.f32 	%f1127, %f543, %f542;
	mul.f32 	%f544, %f1247, %f1247;
	mul.f32 	%f545, %f544, %f542;
	fma.rn.f32 	%f1124, %f545, %f539, 0f3F800000;
	mul.f32 	%f1123, %f1127, %f539;
	mul.f32 	%f546, %f1247, %f539;
	neg.f32 	%f1122, %f546;
	mul.f32 	%f547, %f1248, %f1248;
	fma.rn.f32 	%f1126, %f547, %f542, %f539;
	neg.f32 	%f1125, %f1248;
	ld.const.u64 	%rd16, [params+96];
	setp.eq.s64 	%p8, %rd16, 0;
	@%p8 bra 	$L__BB4_16;

	ld.u64 	%rd17, [%rd3+24];
	setp.eq.s64 	%p9, %rd17, 0;
	@%p9 bra 	$L__BB4_16;

	mov.f32 	%f1109, 0f3F800000;
	sub.f32 	%f1108, %f1109, %f1120;
	sub.f32 	%f1107, %f1108, %f1121;
	cvt.u64.u32 	%rd440, %r26;
	cvt.u64.u32 	%rd439, %r25;
	cvt.u64.u32 	%rd438, %r24;
	shl.b64 	%rd80, %rd438, 3;
	add.s64 	%rd81, %rd17, %rd80;
	shl.b64 	%rd82, %rd439, 3;
	add.s64 	%rd83, %rd17, %rd82;
	shl.b64 	%rd84, %rd440, 3;
	add.s64 	%rd85, %rd17, %rd84;
	ld.f32 	%f56, [%rd81];
	ld.f32 	%f57, [%rd81+4];
	ld.f32 	%f58, [%rd83];
	mul.f32 	%f548, %f58, %f1120;
	ld.f32 	%f59, [%rd83+4];
	mul.f32 	%f549, %f59, %f1120;
	fma.rn.f32 	%f550, %f56, %f1107, %f548;
	fma.rn.f32 	%f551, %f57, %f1107, %f549;
	ld.f32 	%f60, [%rd85];
	ld.f32 	%f61, [%rd85+4];
	fma.rn.f32 	%f1120, %f60, %f1121, %f550;
	fma.rn.f32 	%f1121, %f61, %f1121, %f551;
	ld.const.u64 	%rd86, [params+184];
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB4_16;

	neg.f32 	%f1125, %f1248;
	sub.f32 	%f64, %f58, %f56;
	sub.f32 	%f65, %f61, %f57;
	mul.f32 	%f552, %f64, %f65;
	sub.f32 	%f66, %f60, %f56;
	sub.f32 	%f67, %f59, %f57;
	mul.f32 	%f553, %f67, %f66;
	sub.f32 	%f68, %f552, %f553;
	setp.eq.f32 	%p11, %f68, 0f00000000;
	@%p11 bra 	$L__BB4_16;

	rcp.rn.f32 	%f554, %f68;
	mul.f32 	%f555, %f67, %f11;
	mul.f32 	%f556, %f65, %f8;
	sub.f32 	%f557, %f556, %f555;
	mul.f32 	%f558, %f67, %f12;
	mul.f32 	%f559, %f65, %f9;
	sub.f32 	%f560, %f559, %f558;
	mul.f32 	%f561, %f67, %f13;
	mul.f32 	%f562, %f65, %f10;
	sub.f32 	%f563, %f562, %f561;
	mul.f32 	%f1124, %f557, %f554;
	mul.f32 	%f1123, %f560, %f554;
	mul.f32 	%f1122, %f563, %f554;
	mul.f32 	%f564, %f8, %f66;
	mul.f32 	%f565, %f9, %f66;
	mul.f32 	%f566, %f10, %f66;
	mul.f32 	%f567, %f64, %f11;
	sub.f32 	%f568, %f567, %f564;
	mul.f32 	%f569, %f64, %f12;
	sub.f32 	%f570, %f569, %f565;
	mul.f32 	%f571, %f64, %f13;
	sub.f32 	%f572, %f571, %f566;
	mul.f32 	%f1127, %f568, %f554;
	mul.f32 	%f1126, %f570, %f554;
	mul.f32 	%f1125, %f572, %f554;

$L__BB4_16:
	ld.u64 	%rd18, [%rd42];
	ld.const.u64 	%rd87, [params+344];
	cvta.to.global.u64 	%rd88, %rd87;
	mul.wide.u32 	%rd89, %r1, 4;
	add.s64 	%rd20, %rd88, %rd89;
	ld.global.u32 	%r5, [%rd20];
	setp.eq.s32 	%p12, %r5, 0;
	@%p12 bra 	$L__BB4_64;

	// begin inline asm
	call (%r30), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p13, %r30, %r5;
	@%p13 bra 	$L__BB4_64;

	mov.f32 	%f1164, 0f3F800000;
	// begin inline asm
	call (%r31), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p14, %r31, 0;
	mov.f32 	%f1165, 0f00000000;
	mov.f32 	%f1166, %f1165;
	mov.f32 	%f1167, %f1165;
	mov.f32 	%f1160, %f1165;
	mov.f32 	%f1161, %f1164;
	mov.f32 	%f1162, %f1165;
	mov.f32 	%f1163, %f1165;
	mov.f32 	%f1156, %f1165;
	mov.f32 	%f1157, %f1165;
	mov.f32 	%f1158, %f1164;
	mov.f32 	%f1159, %f1165;
	@%p14 bra 	$L__BB4_36;

	// begin inline asm
	call (%r32), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f585), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p15, %r32, 1;
	@%p15 bra 	$L__BB4_36;

	mov.u32 	%r336, %r32;

$L__BB4_21:
	.pragma "nounroll";
	add.s32 	%r33, %r336, -1;
	// begin inline asm
	call (%rd90), _optix_get_transform_list_handle, (%r33);
	// end inline asm
	// begin inline asm
	call (%r34), _optix_get_transform_type_from_handle, (%rd90);
	// end inline asm
	or.b32  	%r35, %r34, 1;
	setp.eq.s32 	%p16, %r35, 3;
	@%p16 bra 	$L__BB4_27;
	bra.uni 	$L__BB4_22;

$L__BB4_27:
	setp.eq.s32 	%p19, %r34, 2;
	@%p19 bra 	$L__BB4_31;
	bra.uni 	$L__BB4_28;

$L__BB4_31:
	// begin inline asm
	call (%rd162), _optix_get_matrix_motion_transform_from_handle, (%rd90);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd164, %rd162;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r123,%r124,%r125,%r126}, [%rd164];
	// end inline asm
	add.s64 	%rd168, %rd162, 16;
	// begin inline asm
	cvta.to.global.u64 %rd167, %rd168;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r127,%r128,%r129,%r130}, [%rd167];
	// end inline asm
	add.s64 	%rd171, %rd162, 32;
	// begin inline asm
	cvta.to.global.u64 %rd170, %rd171;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r131,%r132,%r133,%r134}, [%rd170];
	// end inline asm
	add.s64 	%rd174, %rd162, 48;
	// begin inline asm
	cvta.to.global.u64 %rd173, %rd174;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r135,%r136,%r137,%r138}, [%rd173];
	// end inline asm
	add.s64 	%rd177, %rd162, 64;
	// begin inline asm
	cvta.to.global.u64 %rd176, %rd177;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r139,%r140,%r141,%r142}, [%rd176];
	// end inline asm
	add.s64 	%rd180, %rd162, 80;
	// begin inline asm
	cvta.to.global.u64 %rd179, %rd180;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r143,%r144,%r145,%r146}, [%rd179];
	// end inline asm
	add.s64 	%rd183, %rd162, 96;
	// begin inline asm
	cvta.to.global.u64 %rd182, %rd183;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd182];
	// end inline asm
	add.s64 	%rd186, %rd162, 112;
	// begin inline asm
	cvta.to.global.u64 %rd185, %rd186;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd185];
	// end inline asm
	mov.b32 	%f713, %r126;
	mov.b32 	%f714, %r127;
	and.b32  	%r167, %r125, 65535;
	add.s32 	%r168, %r167, -1;
	cvt.rn.f32.s32 	%f715, %r168;
	sub.f32 	%f716, %f585, %f713;
	mul.f32 	%f717, %f716, %f715;
	sub.f32 	%f718, %f714, %f713;
	div.rn.f32 	%f719, %f717, %f718;
	min.f32 	%f720, %f715, %f719;
	mov.f32 	%f721, 0f00000000;
	max.f32 	%f722, %f721, %f720;
	cvt.rmi.f32.f32 	%f723, %f722;
	sub.f32 	%f172, %f722, %f723;
	cvt.rzi.s32.f32 	%r169, %f723;
	mul.wide.s32 	%rd197, %r169, 48;
	add.s64 	%rd189, %rd171, %rd197;
	// begin inline asm
	cvta.to.global.u64 %rd188, %rd189;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd188];
	// end inline asm
	mov.b32 	%f1164, %r155;
	mov.b32 	%f1165, %r156;
	mov.b32 	%f1166, %r157;
	mov.b32 	%f1167, %r158;
	add.s64 	%rd192, %rd189, 16;
	// begin inline asm
	cvta.to.global.u64 %rd191, %rd192;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r159,%r160,%r161,%r162}, [%rd191];
	// end inline asm
	mov.b32 	%f1160, %r159;
	mov.b32 	%f1161, %r160;
	mov.b32 	%f1162, %r161;
	mov.b32 	%f1163, %r162;
	add.s64 	%rd195, %rd189, 32;
	// begin inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd194];
	// end inline asm
	mov.b32 	%f1156, %r163;
	mov.b32 	%f1157, %r164;
	mov.b32 	%f1158, %r165;
	mov.b32 	%f1159, %r166;
	setp.leu.f32 	%p21, %f172, 0f00000000;
	@%p21 bra 	$L__BB4_33;

	cvt.rmi.f32.f32 	%f1093, %f722;
	cvt.rzi.s32.f32 	%r335, %f1093;
	cvt.s64.s32 	%rd435, %r335;
	mov.f32 	%f724, 0f3F800000;
	sub.f32 	%f725, %f724, %f172;
	mul.lo.s64 	%rd207, %rd435, 48;
	add.s64 	%rd208, %rd162, %rd207;
	add.s64 	%rd199, %rd208, 80;
	// begin inline asm
	cvta.to.global.u64 %rd198, %rd199;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r170,%r171,%r172,%r173}, [%rd198];
	// end inline asm
	mov.b32 	%f726, %r170;
	mov.b32 	%f727, %r171;
	mov.b32 	%f728, %r172;
	mov.b32 	%f729, %r173;
	mul.f32 	%f730, %f172, %f726;
	mul.f32 	%f731, %f172, %f727;
	mul.f32 	%f732, %f172, %f728;
	mul.f32 	%f733, %f172, %f729;
	fma.rn.f32 	%f1164, %f725, %f1164, %f730;
	fma.rn.f32 	%f1165, %f725, %f1165, %f731;
	fma.rn.f32 	%f1166, %f725, %f1166, %f732;
	fma.rn.f32 	%f1167, %f725, %f1167, %f733;
	add.s64 	%rd202, %rd208, 96;
	// begin inline asm
	cvta.to.global.u64 %rd201, %rd202;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r174,%r175,%r176,%r177}, [%rd201];
	// end inline asm
	mov.b32 	%f734, %r174;
	mov.b32 	%f735, %r175;
	mov.b32 	%f736, %r176;
	mov.b32 	%f737, %r177;
	mul.f32 	%f738, %f172, %f734;
	mul.f32 	%f739, %f172, %f735;
	mul.f32 	%f740, %f172, %f736;
	mul.f32 	%f741, %f172, %f737;
	fma.rn.f32 	%f1160, %f725, %f1160, %f738;
	fma.rn.f32 	%f1161, %f725, %f1161, %f739;
	fma.rn.f32 	%f1162, %f725, %f1162, %f740;
	fma.rn.f32 	%f1163, %f725, %f1163, %f741;
	add.s64 	%rd205, %rd208, 112;
	// begin inline asm
	cvta.to.global.u64 %rd204, %rd205;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r178,%r179,%r180,%r181}, [%rd204];
	// end inline asm
	mov.b32 	%f742, %r178;
	mov.b32 	%f743, %r179;
	mov.b32 	%f744, %r180;
	mov.b32 	%f745, %r181;
	mul.f32 	%f746, %f172, %f742;
	mul.f32 	%f747, %f172, %f743;
	mul.f32 	%f748, %f172, %f744;
	mul.f32 	%f749, %f172, %f745;
	fma.rn.f32 	%f1156, %f725, %f1156, %f746;
	fma.rn.f32 	%f1157, %f725, %f1157, %f747;
	fma.rn.f32 	%f1158, %f725, %f1158, %f748;
	fma.rn.f32 	%f1159, %f725, %f1159, %f749;
	bra.uni 	$L__BB4_33;

$L__BB4_22:
	mov.f32 	%f1156, 0f00000000;
	mov.f32 	%f1158, 0f3F800000;
	setp.eq.s32 	%p17, %r34, 4;
	@%p17 bra 	$L__BB4_25;

	setp.ne.s32 	%p18, %r34, 1;
	mov.f32 	%f1157, %f1156;
	mov.f32 	%f1159, %f1156;
	mov.f32 	%f1160, %f1156;
	mov.f32 	%f1161, %f1158;
	mov.f32 	%f1162, %f1156;
	mov.f32 	%f1163, %f1156;
	mov.f32 	%f1164, %f1158;
	mov.f32 	%f1165, %f1156;
	mov.f32 	%f1166, %f1156;
	mov.f32 	%f1167, %f1156;
	@%p18 bra 	$L__BB4_33;

	// begin inline asm
	call (%rd92), _optix_get_static_transform_from_handle, (%rd90);
	// end inline asm
	add.s64 	%rd441, %rd92, 16;
	bra.uni 	$L__BB4_26;

$L__BB4_28:
	// begin inline asm
	call (%rd105), _optix_get_srt_motion_transform_from_handle, (%rd90);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd107, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r48,%r49,%r50,%r51}, [%rd107];
	// end inline asm
	add.s64 	%rd111, %rd105, 16;
	// begin inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r52,%r53,%r54,%r55}, [%rd110];
	// end inline asm
	add.s64 	%rd114, %rd105, 32;
	// begin inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r56,%r57,%r58,%r59}, [%rd113];
	// end inline asm
	add.s64 	%rd117, %rd105, 48;
	// begin inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r60,%r61,%r62,%r63}, [%rd116];
	// end inline asm
	add.s64 	%rd120, %rd105, 64;
	// begin inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r64,%r65,%r66,%r67}, [%rd119];
	// end inline asm
	add.s64 	%rd123, %rd105, 80;
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r68,%r69,%r70,%r71}, [%rd122];
	// end inline asm
	add.s64 	%rd126, %rd105, 96;
	// begin inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r72,%r73,%r74,%r75}, [%rd125];
	// end inline asm
	add.s64 	%rd129, %rd105, 112;
	// begin inline asm
	cvta.to.global.u64 %rd128, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r76,%r77,%r78,%r79}, [%rd128];
	// end inline asm
	add.s64 	%rd132, %rd105, 128;
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r80,%r81,%r82,%r83}, [%rd131];
	// end inline asm
	add.s64 	%rd135, %rd105, 144;
	// begin inline asm
	cvta.to.global.u64 %rd134, %rd135;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd134];
	// end inline asm
	mov.b32 	%f600, %r51;
	mov.b32 	%f601, %r52;
	and.b32  	%r104, %r50, 65535;
	add.s32 	%r105, %r104, -1;
	cvt.rn.f32.s32 	%f602, %r105;
	sub.f32 	%f603, %f585, %f600;
	mul.f32 	%f604, %f603, %f602;
	sub.f32 	%f605, %f601, %f600;
	div.rn.f32 	%f606, %f604, %f605;
	min.f32 	%f607, %f602, %f606;
	mov.f32 	%f608, 0f00000000;
	max.f32 	%f609, %f608, %f607;
	cvt.rmi.f32.f32 	%f610, %f609;
	sub.f32 	%f111, %f609, %f610;
	cvt.rzi.s32.f32 	%r106, %f610;
	mul.wide.s32 	%rd149, %r106, 64;
	add.s64 	%rd138, %rd114, %rd149;
	// begin inline asm
	cvta.to.global.u64 %rd137, %rd138;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd137];
	// end inline asm
	mov.b32 	%f1140, %r88;
	mov.b32 	%f1141, %r89;
	mov.b32 	%f1142, %r90;
	mov.b32 	%f1143, %r91;
	add.s64 	%rd141, %rd138, 16;
	// begin inline asm
	cvta.to.global.u64 %rd140, %rd141;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd140];
	// end inline asm
	mov.b32 	%f1144, %r92;
	mov.b32 	%f1145, %r93;
	mov.b32 	%f1146, %r94;
	mov.b32 	%f1147, %r95;
	add.s64 	%rd144, %rd138, 32;
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd144;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd143];
	// end inline asm
	mov.b32 	%f1148, %r96;
	mov.b32 	%f1149, %r97;
	mov.b32 	%f1150, %r98;
	mov.b32 	%f1151, %r99;
	add.s64 	%rd147, %rd138, 48;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd146];
	// end inline asm
	mov.b32 	%f1152, %r100;
	mov.b32 	%f1153, %r101;
	mov.b32 	%f1154, %r102;
	mov.b32 	%f1155, %r103;
	setp.leu.f32 	%p20, %f111, 0f00000000;
	@%p20 bra 	$L__BB4_30;

	mov.f32 	%f611, 0f3F800000;
	sub.f32 	%f612, %f611, %f111;
	add.s64 	%rd151, %rd138, 64;
	// begin inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r107,%r108,%r109,%r110}, [%rd150];
	// end inline asm
	mov.b32 	%f613, %r107;
	mov.b32 	%f614, %r108;
	mov.b32 	%f615, %r109;
	mov.b32 	%f616, %r110;
	mul.f32 	%f617, %f111, %f613;
	mul.f32 	%f618, %f111, %f614;
	mul.f32 	%f619, %f111, %f615;
	mul.f32 	%f620, %f111, %f616;
	fma.rn.f32 	%f1140, %f612, %f1140, %f617;
	fma.rn.f32 	%f1141, %f612, %f1141, %f618;
	fma.rn.f32 	%f1142, %f612, %f1142, %f619;
	fma.rn.f32 	%f1143, %f612, %f1143, %f620;
	add.s64 	%rd154, %rd138, 80;
	// begin inline asm
	cvta.to.global.u64 %rd153, %rd154;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r111,%r112,%r113,%r114}, [%rd153];
	// end inline asm
	mov.b32 	%f621, %r111;
	mov.b32 	%f622, %r112;
	mov.b32 	%f623, %r113;
	mov.b32 	%f624, %r114;
	mul.f32 	%f625, %f111, %f621;
	mul.f32 	%f626, %f111, %f622;
	mul.f32 	%f627, %f111, %f623;
	mul.f32 	%f628, %f111, %f624;
	fma.rn.f32 	%f1144, %f612, %f1144, %f625;
	fma.rn.f32 	%f1145, %f612, %f1145, %f626;
	fma.rn.f32 	%f1146, %f612, %f1146, %f627;
	fma.rn.f32 	%f1147, %f612, %f1147, %f628;
	add.s64 	%rd157, %rd138, 96;
	// begin inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r115,%r116,%r117,%r118}, [%rd156];
	// end inline asm
	mov.b32 	%f629, %r115;
	mov.b32 	%f630, %r116;
	mov.b32 	%f631, %r117;
	mov.b32 	%f632, %r118;
	mul.f32 	%f633, %f111, %f629;
	mul.f32 	%f634, %f111, %f630;
	mul.f32 	%f635, %f111, %f631;
	mul.f32 	%f636, %f111, %f632;
	fma.rn.f32 	%f1148, %f612, %f1148, %f633;
	fma.rn.f32 	%f637, %f612, %f1149, %f634;
	fma.rn.f32 	%f638, %f612, %f1150, %f635;
	fma.rn.f32 	%f639, %f612, %f1151, %f636;
	add.s64 	%rd160, %rd138, 112;
	// begin inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r119,%r120,%r121,%r122}, [%rd159];
	// end inline asm
	mov.b32 	%f640, %r119;
	mov.b32 	%f641, %r120;
	mov.b32 	%f642, %r121;
	mov.b32 	%f643, %r122;
	mul.f32 	%f644, %f111, %f640;
	mul.f32 	%f645, %f111, %f641;
	mul.f32 	%f646, %f111, %f642;
	mul.f32 	%f647, %f111, %f643;
	fma.rn.f32 	%f648, %f612, %f1152, %f644;
	fma.rn.f32 	%f1153, %f612, %f1153, %f645;
	fma.rn.f32 	%f1154, %f612, %f1154, %f646;
	fma.rn.f32 	%f1155, %f612, %f1155, %f647;
	mul.f32 	%f649, %f638, %f638;
	fma.rn.f32 	%f650, %f637, %f637, %f649;
	fma.rn.f32 	%f651, %f639, %f639, %f650;
	fma.rn.f32 	%f652, %f648, %f648, %f651;
	sqrt.rn.f32 	%f653, %f652;
	rcp.rn.f32 	%f654, %f653;
	mul.f32 	%f1149, %f637, %f654;
	mul.f32 	%f1150, %f638, %f654;
	mul.f32 	%f1151, %f639, %f654;
	mul.f32 	%f1152, %f654, %f648;

$L__BB4_30:
	mul.f32 	%f655, %f1150, %f1150;
	fma.rn.f32 	%f656, %f1149, %f1149, %f655;
	fma.rn.f32 	%f657, %f1151, %f1151, %f656;
	fma.rn.f32 	%f658, %f1152, %f1152, %f657;
	rcp.rn.f32 	%f659, %f658;
	mul.f32 	%f660, %f1149, %f659;
	mul.f32 	%f661, %f1150, %f659;
	mul.f32 	%f662, %f1151, %f659;
	mul.f32 	%f663, %f1152, %f659;
	mul.f32 	%f664, %f1149, %f660;
	mul.f32 	%f665, %f1150, %f661;
	mul.f32 	%f666, %f1151, %f662;
	mul.f32 	%f667, %f1149, %f661;
	mul.f32 	%f668, %f1151, %f663;
	mul.f32 	%f669, %f1149, %f662;
	mul.f32 	%f670, %f1150, %f663;
	mul.f32 	%f671, %f1150, %f662;
	mul.f32 	%f672, %f1149, %f663;
	sub.f32 	%f673, %f664, %f665;
	sub.f32 	%f674, %f673, %f666;
	fma.rn.f32 	%f675, %f1152, %f663, %f674;
	sub.f32 	%f676, %f667, %f668;
	add.f32 	%f677, %f676, %f676;
	add.f32 	%f678, %f669, %f670;
	add.f32 	%f679, %f678, %f678;
	add.f32 	%f680, %f667, %f668;
	add.f32 	%f681, %f680, %f680;
	sub.f32 	%f682, %f665, %f664;
	sub.f32 	%f683, %f682, %f666;
	fma.rn.f32 	%f684, %f1152, %f663, %f683;
	sub.f32 	%f685, %f671, %f672;
	add.f32 	%f686, %f685, %f685;
	sub.f32 	%f687, %f669, %f670;
	add.f32 	%f688, %f687, %f687;
	add.f32 	%f689, %f671, %f672;
	add.f32 	%f690, %f689, %f689;
	neg.f32 	%f691, %f664;
	sub.f32 	%f692, %f691, %f665;
	add.f32 	%f693, %f666, %f692;
	fma.rn.f32 	%f694, %f1152, %f663, %f693;
	mul.f32 	%f695, %f1143, %f675;
	fma.rn.f32 	%f696, %f1146, %f677, %f695;
	fma.rn.f32 	%f697, %f1148, %f679, %f696;
	sub.f32 	%f1167, %f1153, %f697;
	mul.f32 	%f698, %f1146, %f684;
	fma.rn.f32 	%f699, %f1143, %f681, %f698;
	fma.rn.f32 	%f700, %f1148, %f686, %f699;
	sub.f32 	%f1163, %f1154, %f700;
	mul.f32 	%f701, %f1146, %f690;
	fma.rn.f32 	%f702, %f1143, %f688, %f701;
	fma.rn.f32 	%f703, %f1148, %f694, %f702;
	sub.f32 	%f1159, %f1155, %f703;
	mul.f32 	%f704, %f1142, %f675;
	fma.rn.f32 	%f705, %f1145, %f677, %f704;
	fma.rn.f32 	%f1166, %f1147, %f679, %f705;
	mul.f32 	%f706, %f1145, %f684;
	fma.rn.f32 	%f707, %f1142, %f681, %f706;
	fma.rn.f32 	%f1162, %f1147, %f686, %f707;
	mul.f32 	%f708, %f1145, %f690;
	fma.rn.f32 	%f709, %f1142, %f688, %f708;
	fma.rn.f32 	%f1158, %f1147, %f694, %f709;
	mul.f32 	%f710, %f1141, %f675;
	fma.rn.f32 	%f1165, %f1144, %f677, %f710;
	mul.f32 	%f711, %f1144, %f684;
	fma.rn.f32 	%f1161, %f1141, %f681, %f711;
	mul.f32 	%f712, %f1144, %f690;
	fma.rn.f32 	%f1157, %f1141, %f688, %f712;
	mul.f32 	%f1164, %f1140, %f675;
	mul.f32 	%f1160, %f1140, %f681;
	mul.f32 	%f1156, %f1140, %f688;
	bra.uni 	$L__BB4_33;

$L__BB4_25:
	// begin inline asm
	call (%rd441), _optix_get_instance_transform_from_handle, (%rd90);
	// end inline asm

$L__BB4_26:
	// begin inline asm
	cvta.to.global.u64 %rd96, %rd441;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r36,%r37,%r38,%r39}, [%rd96];
	// end inline asm
	mov.b32 	%f1164, %r36;
	mov.b32 	%f1165, %r37;
	mov.b32 	%f1166, %r38;
	mov.b32 	%f1167, %r39;
	add.s64 	%rd100, %rd441, 16;
	// begin inline asm
	cvta.to.global.u64 %rd99, %rd100;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r40,%r41,%r42,%r43}, [%rd99];
	// end inline asm
	mov.b32 	%f1160, %r40;
	mov.b32 	%f1161, %r41;
	mov.b32 	%f1162, %r42;
	mov.b32 	%f1163, %r43;
	add.s64 	%rd103, %rd441, 32;
	// begin inline asm
	cvta.to.global.u64 %rd102, %rd103;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r44,%r45,%r46,%r47}, [%rd102];
	// end inline asm
	mov.b32 	%f1156, %r44;
	mov.b32 	%f1157, %r45;
	mov.b32 	%f1158, %r46;
	mov.b32 	%f1159, %r47;

$L__BB4_33:
	setp.eq.s32 	%p22, %r336, %r32;
	@%p22 bra 	$L__BB4_35;

	mul.f32 	%f750, %f1132, %f1165;
	fma.rn.f32 	%f751, %f1136, %f1164, %f750;
	fma.rn.f32 	%f209, %f1128, %f1166, %f751;
	mul.f32 	%f752, %f1133, %f1165;
	fma.rn.f32 	%f753, %f1137, %f1164, %f752;
	fma.rn.f32 	%f210, %f1129, %f1166, %f753;
	mul.f32 	%f754, %f1134, %f1165;
	fma.rn.f32 	%f755, %f1138, %f1164, %f754;
	fma.rn.f32 	%f211, %f1130, %f1166, %f755;
	mul.f32 	%f756, %f1135, %f1165;
	fma.rn.f32 	%f757, %f1139, %f1164, %f756;
	fma.rn.f32 	%f758, %f1131, %f1166, %f757;
	add.f32 	%f1167, %f1167, %f758;
	mul.f32 	%f759, %f1132, %f1161;
	fma.rn.f32 	%f760, %f1136, %f1160, %f759;
	fma.rn.f32 	%f213, %f1128, %f1162, %f760;
	mul.f32 	%f761, %f1133, %f1161;
	fma.rn.f32 	%f762, %f1137, %f1160, %f761;
	fma.rn.f32 	%f214, %f1129, %f1162, %f762;
	mul.f32 	%f763, %f1134, %f1161;
	fma.rn.f32 	%f764, %f1138, %f1160, %f763;
	fma.rn.f32 	%f215, %f1130, %f1162, %f764;
	mul.f32 	%f765, %f1135, %f1161;
	fma.rn.f32 	%f766, %f1139, %f1160, %f765;
	fma.rn.f32 	%f767, %f1131, %f1162, %f766;
	add.f32 	%f1163, %f1163, %f767;
	mul.f32 	%f768, %f1132, %f1157;
	fma.rn.f32 	%f769, %f1136, %f1156, %f768;
	fma.rn.f32 	%f217, %f1128, %f1158, %f769;
	mul.f32 	%f770, %f1133, %f1157;
	fma.rn.f32 	%f771, %f1137, %f1156, %f770;
	fma.rn.f32 	%f218, %f1129, %f1158, %f771;
	mul.f32 	%f772, %f1134, %f1157;
	fma.rn.f32 	%f773, %f1138, %f1156, %f772;
	fma.rn.f32 	%f219, %f1130, %f1158, %f773;
	mul.f32 	%f774, %f1135, %f1157;
	fma.rn.f32 	%f775, %f1139, %f1156, %f774;
	fma.rn.f32 	%f776, %f1131, %f1158, %f775;
	add.f32 	%f1159, %f1159, %f776;
	mov.f32 	%f1166, %f211;
	mov.f32 	%f1165, %f210;
	mov.f32 	%f1164, %f209;
	mov.f32 	%f1162, %f215;
	mov.f32 	%f1161, %f214;
	mov.f32 	%f1160, %f213;
	mov.f32 	%f1158, %f219;
	mov.f32 	%f1157, %f218;
	mov.f32 	%f1156, %f217;

$L__BB4_35:
	add.s32 	%r334, %r336, -1;
	setp.gt.s32 	%p23, %r336, 1;
	mov.u32 	%r336, %r334;
	mov.f32 	%f1128, %f1156;
	mov.f32 	%f1129, %f1157;
	mov.f32 	%f1130, %f1158;
	mov.f32 	%f1131, %f1159;
	mov.f32 	%f1132, %f1160;
	mov.f32 	%f1133, %f1161;
	mov.f32 	%f1134, %f1162;
	mov.f32 	%f1135, %f1163;
	mov.f32 	%f1136, %f1164;
	mov.f32 	%f1137, %f1165;
	mov.f32 	%f1138, %f1166;
	mov.f32 	%f1139, %f1167;
	@%p23 bra 	$L__BB4_21;

$L__BB4_36:
	mov.f32 	%f1227, 0f00000000;
	mov.f32 	%f1226, 0f3F800000;
	// begin inline asm
	call (%r182), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p24, %r182, 0;
	mov.f32 	%f1228, %f1227;
	mov.f32 	%f1223, %f1227;
	mov.f32 	%f1224, %f1226;
	mov.f32 	%f1225, %f1227;
	mov.f32 	%f1220, %f1227;
	mov.f32 	%f1221, %f1227;
	mov.f32 	%f1222, %f1226;
	@%p24 bra 	$L__BB4_55;

	// begin inline asm
	call (%r183), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f786), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p25, %r183, 0;
	@%p25 bra 	$L__BB4_55;

	mov.u32 	%r337, 0;

$L__BB4_39:
	.pragma "nounroll";
	// begin inline asm
	call (%rd209), _optix_get_transform_list_handle, (%r337);
	// end inline asm
	// begin inline asm
	call (%r186), _optix_get_transform_type_from_handle, (%rd209);
	// end inline asm
	or.b32  	%r187, %r186, 1;
	setp.eq.s32 	%p26, %r187, 3;
	@%p26 bra 	$L__BB4_45;
	bra.uni 	$L__BB4_40;

$L__BB4_45:
	setp.eq.s32 	%p29, %r186, 2;
	@%p29 bra 	$L__BB4_49;
	bra.uni 	$L__BB4_46;

$L__BB4_49:
	// begin inline asm
	call (%rd281), _optix_get_matrix_motion_transform_from_handle, (%rd209);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd283, %rd281;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r275,%r276,%r277,%r278}, [%rd283];
	// end inline asm
	add.s64 	%rd287, %rd281, 16;
	// begin inline asm
	cvta.to.global.u64 %rd286, %rd287;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r279,%r280,%r281,%r282}, [%rd286];
	// end inline asm
	add.s64 	%rd290, %rd281, 32;
	// begin inline asm
	cvta.to.global.u64 %rd289, %rd290;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r283,%r284,%r285,%r286}, [%rd289];
	// end inline asm
	add.s64 	%rd293, %rd281, 48;
	// begin inline asm
	cvta.to.global.u64 %rd292, %rd293;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r287,%r288,%r289,%r290}, [%rd292];
	// end inline asm
	add.s64 	%rd296, %rd281, 64;
	// begin inline asm
	cvta.to.global.u64 %rd295, %rd296;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r291,%r292,%r293,%r294}, [%rd295];
	// end inline asm
	add.s64 	%rd299, %rd281, 80;
	// begin inline asm
	cvta.to.global.u64 %rd298, %rd299;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r295,%r296,%r297,%r298}, [%rd298];
	// end inline asm
	add.s64 	%rd302, %rd281, 96;
	// begin inline asm
	cvta.to.global.u64 %rd301, %rd302;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r299,%r300,%r301,%r302}, [%rd301];
	// end inline asm
	add.s64 	%rd305, %rd281, 112;
	// begin inline asm
	cvta.to.global.u64 %rd304, %rd305;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd304];
	// end inline asm
	mov.b32 	%f890, %r278;
	mov.b32 	%f891, %r279;
	and.b32  	%r319, %r277, 65535;
	add.s32 	%r320, %r319, -1;
	cvt.rn.f32.s32 	%f892, %r320;
	sub.f32 	%f893, %f786, %f890;
	mul.f32 	%f894, %f893, %f892;
	sub.f32 	%f895, %f891, %f890;
	div.rn.f32 	%f896, %f894, %f895;
	min.f32 	%f897, %f892, %f896;
	mov.f32 	%f898, 0f00000000;
	max.f32 	%f899, %f898, %f897;
	cvt.rmi.f32.f32 	%f900, %f899;
	sub.f32 	%f304, %f899, %f900;
	cvt.rzi.s32.f32 	%r321, %f900;
	cvt.s64.s32 	%rd34, %r321;
	mul.wide.s32 	%rd316, %r321, 48;
	add.s64 	%rd308, %rd290, %rd316;
	// begin inline asm
	cvta.to.global.u64 %rd307, %rd308;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd307];
	// end inline asm
	mov.b32 	%f1217, %r307;
	mov.b32 	%f1218, %r308;
	mov.b32 	%f1219, %r309;
	add.s64 	%rd311, %rd308, 16;
	// begin inline asm
	cvta.to.global.u64 %rd310, %rd311;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd310];
	// end inline asm
	mov.b32 	%f1214, %r311;
	mov.b32 	%f1215, %r312;
	mov.b32 	%f1216, %r313;
	add.s64 	%rd314, %rd308, 32;
	// begin inline asm
	cvta.to.global.u64 %rd313, %rd314;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r315,%r316,%r317,%r318}, [%rd313];
	// end inline asm
	mov.b32 	%f1211, %r315;
	mov.b32 	%f1212, %r316;
	mov.b32 	%f1213, %r317;
	setp.leu.f32 	%p31, %f304, 0f00000000;
	@%p31 bra 	$L__BB4_51;

	mov.f32 	%f901, 0f3F800000;
	sub.f32 	%f902, %f901, %f304;
	mul.lo.s64 	%rd326, %rd34, 48;
	add.s64 	%rd327, %rd281, %rd326;
	add.s64 	%rd318, %rd327, 80;
	// begin inline asm
	cvta.to.global.u64 %rd317, %rd318;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r322,%r323,%r324,%r325}, [%rd317];
	// end inline asm
	mov.b32 	%f903, %r322;
	mov.b32 	%f904, %r323;
	mov.b32 	%f905, %r324;
	mul.f32 	%f906, %f304, %f903;
	mul.f32 	%f907, %f304, %f904;
	mul.f32 	%f908, %f304, %f905;
	fma.rn.f32 	%f1217, %f902, %f1217, %f906;
	fma.rn.f32 	%f1218, %f902, %f1218, %f907;
	fma.rn.f32 	%f1219, %f902, %f1219, %f908;
	add.s64 	%rd321, %rd327, 96;
	// begin inline asm
	cvta.to.global.u64 %rd320, %rd321;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r326,%r327,%r328,%r329}, [%rd320];
	// end inline asm
	mov.b32 	%f909, %r326;
	mov.b32 	%f910, %r327;
	mov.b32 	%f911, %r328;
	mul.f32 	%f912, %f304, %f909;
	mul.f32 	%f913, %f304, %f910;
	mul.f32 	%f914, %f304, %f911;
	fma.rn.f32 	%f1214, %f902, %f1214, %f912;
	fma.rn.f32 	%f1215, %f902, %f1215, %f913;
	fma.rn.f32 	%f1216, %f902, %f1216, %f914;
	add.s64 	%rd324, %rd327, 112;
	// begin inline asm
	cvta.to.global.u64 %rd323, %rd324;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r330,%r331,%r332,%r333}, [%rd323];
	// end inline asm
	mov.b32 	%f915, %r330;
	mov.b32 	%f916, %r331;
	mov.b32 	%f917, %r332;
	mul.f32 	%f918, %f304, %f915;
	mul.f32 	%f919, %f304, %f916;
	mul.f32 	%f920, %f304, %f917;
	fma.rn.f32 	%f1211, %f902, %f1211, %f918;
	fma.rn.f32 	%f1212, %f902, %f1212, %f919;
	fma.rn.f32 	%f1213, %f902, %f1213, %f920;
	bra.uni 	$L__BB4_51;

$L__BB4_40:
	mov.f32 	%f1220, 0f00000000;
	mov.f32 	%f1222, 0f3F800000;
	setp.eq.s32 	%p27, %r186, 4;
	@%p27 bra 	$L__BB4_43;

	setp.ne.s32 	%p28, %r186, 1;
	mov.f32 	%f1221, %f1220;
	mov.f32 	%f1223, %f1220;
	mov.f32 	%f1224, %f1222;
	mov.f32 	%f1225, %f1220;
	mov.f32 	%f1226, %f1222;
	mov.f32 	%f1227, %f1220;
	mov.f32 	%f1228, %f1220;
	@%p28 bra 	$L__BB4_52;

	// begin inline asm
	call (%rd211), _optix_get_static_transform_from_handle, (%rd209);
	// end inline asm
	add.s64 	%rd442, %rd211, 64;
	bra.uni 	$L__BB4_44;

$L__BB4_46:
	// begin inline asm
	call (%rd224), _optix_get_srt_motion_transform_from_handle, (%rd209);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd226, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r200,%r201,%r202,%r203}, [%rd226];
	// end inline asm
	add.s64 	%rd230, %rd224, 16;
	// begin inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r204,%r205,%r206,%r207}, [%rd229];
	// end inline asm
	add.s64 	%rd233, %rd224, 32;
	// begin inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r208,%r209,%r210,%r211}, [%rd232];
	// end inline asm
	add.s64 	%rd236, %rd224, 48;
	// begin inline asm
	cvta.to.global.u64 %rd235, %rd236;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r212,%r213,%r214,%r215}, [%rd235];
	// end inline asm
	add.s64 	%rd239, %rd224, 64;
	// begin inline asm
	cvta.to.global.u64 %rd238, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r216,%r217,%r218,%r219}, [%rd238];
	// end inline asm
	add.s64 	%rd242, %rd224, 80;
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd242;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r220,%r221,%r222,%r223}, [%rd241];
	// end inline asm
	add.s64 	%rd245, %rd224, 96;
	// begin inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r224,%r225,%r226,%r227}, [%rd244];
	// end inline asm
	add.s64 	%rd248, %rd224, 112;
	// begin inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r228,%r229,%r230,%r231}, [%rd247];
	// end inline asm
	add.s64 	%rd251, %rd224, 128;
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r232,%r233,%r234,%r235}, [%rd250];
	// end inline asm
	add.s64 	%rd254, %rd224, 144;
	// begin inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r236,%r237,%r238,%r239}, [%rd253];
	// end inline asm
	mov.b32 	%f798, %r203;
	mov.b32 	%f799, %r204;
	and.b32  	%r256, %r202, 65535;
	add.s32 	%r257, %r256, -1;
	cvt.rn.f32.s32 	%f800, %r257;
	sub.f32 	%f801, %f786, %f798;
	mul.f32 	%f802, %f801, %f800;
	sub.f32 	%f803, %f799, %f798;
	div.rn.f32 	%f804, %f802, %f803;
	min.f32 	%f805, %f800, %f804;
	mov.f32 	%f806, 0f00000000;
	max.f32 	%f807, %f806, %f805;
	cvt.rmi.f32.f32 	%f808, %f807;
	sub.f32 	%f264, %f807, %f808;
	cvt.rzi.s32.f32 	%r258, %f808;
	mul.wide.s32 	%rd268, %r258, 64;
	add.s64 	%rd257, %rd233, %rd268;
	// begin inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd256];
	// end inline asm
	mov.b32 	%f1201, %r240;
	mov.b32 	%f1202, %r241;
	mov.b32 	%f1203, %r242;
	add.s64 	%rd260, %rd257, 16;
	// begin inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd259];
	// end inline asm
	mov.b32 	%f1204, %r244;
	mov.b32 	%f1205, %r245;
	mov.b32 	%f1206, %r247;
	add.s64 	%rd263, %rd257, 32;
	// begin inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd262];
	// end inline asm
	mov.b32 	%f1207, %r249;
	mov.b32 	%f1208, %r250;
	mov.b32 	%f1209, %r251;
	add.s64 	%rd266, %rd257, 48;
	// begin inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd265];
	// end inline asm
	mov.b32 	%f1210, %r252;
	setp.leu.f32 	%p30, %f264, 0f00000000;
	@%p30 bra 	$L__BB4_48;

	mov.f32 	%f809, 0f3F800000;
	sub.f32 	%f810, %f809, %f264;
	add.s64 	%rd270, %rd257, 64;
	// begin inline asm
	cvta.to.global.u64 %rd269, %rd270;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r259,%r260,%r261,%r262}, [%rd269];
	// end inline asm
	mov.b32 	%f811, %r259;
	mov.b32 	%f812, %r260;
	mov.b32 	%f813, %r261;
	mul.f32 	%f814, %f264, %f811;
	mul.f32 	%f815, %f264, %f812;
	mul.f32 	%f816, %f264, %f813;
	fma.rn.f32 	%f1201, %f810, %f1201, %f814;
	fma.rn.f32 	%f1202, %f810, %f1202, %f815;
	fma.rn.f32 	%f1203, %f810, %f1203, %f816;
	add.s64 	%rd273, %rd257, 80;
	// begin inline asm
	cvta.to.global.u64 %rd272, %rd273;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r263,%r264,%r265,%r266}, [%rd272];
	// end inline asm
	mov.b32 	%f817, %r263;
	mov.b32 	%f818, %r264;
	mov.b32 	%f819, %r266;
	mul.f32 	%f820, %f264, %f817;
	mul.f32 	%f821, %f264, %f818;
	mul.f32 	%f822, %f264, %f819;
	fma.rn.f32 	%f1204, %f810, %f1204, %f820;
	fma.rn.f32 	%f1205, %f810, %f1205, %f821;
	fma.rn.f32 	%f1206, %f810, %f1206, %f822;
	add.s64 	%rd276, %rd257, 96;
	// begin inline asm
	cvta.to.global.u64 %rd275, %rd276;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r267,%r268,%r269,%r270}, [%rd275];
	// end inline asm
	mov.b32 	%f823, %r268;
	mov.b32 	%f824, %r269;
	mov.b32 	%f825, %r270;
	mul.f32 	%f826, %f264, %f823;
	mul.f32 	%f827, %f264, %f824;
	mul.f32 	%f828, %f264, %f825;
	fma.rn.f32 	%f829, %f810, %f1207, %f826;
	fma.rn.f32 	%f830, %f810, %f1208, %f827;
	fma.rn.f32 	%f831, %f810, %f1209, %f828;
	add.s64 	%rd279, %rd257, 112;
	// begin inline asm
	cvta.to.global.u64 %rd278, %rd279;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r271,%r272,%r273,%r274}, [%rd278];
	// end inline asm
	mov.b32 	%f832, %r271;
	mul.f32 	%f833, %f264, %f832;
	fma.rn.f32 	%f834, %f810, %f1210, %f833;
	mul.f32 	%f835, %f830, %f830;
	fma.rn.f32 	%f836, %f829, %f829, %f835;
	fma.rn.f32 	%f837, %f831, %f831, %f836;
	fma.rn.f32 	%f838, %f834, %f834, %f837;
	sqrt.rn.f32 	%f839, %f838;
	rcp.rn.f32 	%f840, %f839;
	mul.f32 	%f1207, %f829, %f840;
	mul.f32 	%f1208, %f830, %f840;
	mul.f32 	%f1209, %f831, %f840;
	mul.f32 	%f1210, %f840, %f834;

$L__BB4_48:
	mul.f32 	%f841, %f1208, %f1208;
	fma.rn.f32 	%f842, %f1207, %f1207, %f841;
	fma.rn.f32 	%f843, %f1209, %f1209, %f842;
	fma.rn.f32 	%f844, %f1210, %f1210, %f843;
	rcp.rn.f32 	%f845, %f844;
	mul.f32 	%f846, %f1207, %f845;
	mul.f32 	%f847, %f1208, %f845;
	mul.f32 	%f848, %f1209, %f845;
	mul.f32 	%f849, %f1210, %f845;
	mul.f32 	%f850, %f1207, %f846;
	mul.f32 	%f851, %f1208, %f847;
	mul.f32 	%f852, %f1209, %f848;
	mul.f32 	%f853, %f1207, %f847;
	mul.f32 	%f854, %f1209, %f849;
	mul.f32 	%f855, %f1207, %f848;
	mul.f32 	%f856, %f1208, %f849;
	mul.f32 	%f857, %f1208, %f848;
	mul.f32 	%f858, %f1207, %f849;
	sub.f32 	%f859, %f850, %f851;
	sub.f32 	%f860, %f859, %f852;
	fma.rn.f32 	%f861, %f1210, %f849, %f860;
	sub.f32 	%f862, %f853, %f854;
	add.f32 	%f863, %f862, %f862;
	add.f32 	%f864, %f855, %f856;
	add.f32 	%f865, %f864, %f864;
	add.f32 	%f866, %f853, %f854;
	add.f32 	%f867, %f866, %f866;
	sub.f32 	%f868, %f851, %f850;
	sub.f32 	%f869, %f868, %f852;
	fma.rn.f32 	%f870, %f1210, %f849, %f869;
	sub.f32 	%f871, %f857, %f858;
	add.f32 	%f872, %f871, %f871;
	sub.f32 	%f873, %f855, %f856;
	add.f32 	%f874, %f873, %f873;
	add.f32 	%f875, %f857, %f858;
	add.f32 	%f876, %f875, %f875;
	neg.f32 	%f877, %f850;
	sub.f32 	%f878, %f877, %f851;
	add.f32 	%f879, %f852, %f878;
	fma.rn.f32 	%f880, %f1210, %f849, %f879;
	mul.f32 	%f881, %f1203, %f861;
	fma.rn.f32 	%f882, %f1205, %f863, %f881;
	fma.rn.f32 	%f1219, %f1206, %f865, %f882;
	mul.f32 	%f883, %f1205, %f870;
	fma.rn.f32 	%f884, %f1203, %f867, %f883;
	fma.rn.f32 	%f1216, %f1206, %f872, %f884;
	mul.f32 	%f885, %f1205, %f876;
	fma.rn.f32 	%f886, %f1203, %f874, %f885;
	fma.rn.f32 	%f1213, %f1206, %f880, %f886;
	mul.f32 	%f887, %f1202, %f861;
	fma.rn.f32 	%f1218, %f1204, %f863, %f887;
	mul.f32 	%f888, %f1204, %f870;
	fma.rn.f32 	%f1215, %f1202, %f867, %f888;
	mul.f32 	%f889, %f1204, %f876;
	fma.rn.f32 	%f1212, %f1202, %f874, %f889;
	mul.f32 	%f1217, %f1201, %f861;
	mul.f32 	%f1214, %f1201, %f867;
	mul.f32 	%f1211, %f1201, %f874;

$L__BB4_51:
	mul.f32 	%f921, %f1212, %f1216;
	mul.f32 	%f922, %f1213, %f1215;
	sub.f32 	%f923, %f922, %f921;
	mul.f32 	%f924, %f1217, %f923;
	mul.f32 	%f925, %f1211, %f1216;
	mul.f32 	%f926, %f1213, %f1214;
	sub.f32 	%f927, %f926, %f925;
	mul.f32 	%f928, %f927, %f1218;
	sub.f32 	%f929, %f924, %f928;
	mul.f32 	%f930, %f1211, %f1215;
	mul.f32 	%f931, %f1212, %f1214;
	sub.f32 	%f932, %f931, %f930;
	fma.rn.f32 	%f933, %f932, %f1219, %f929;
	rcp.rn.f32 	%f934, %f933;
	mul.f32 	%f1226, %f923, %f934;
	mul.f32 	%f935, %f1213, %f1218;
	mul.f32 	%f936, %f1212, %f1219;
	sub.f32 	%f937, %f936, %f935;
	mul.f32 	%f1227, %f937, %f934;
	mul.f32 	%f938, %f1215, %f1219;
	mul.f32 	%f939, %f1216, %f1218;
	sub.f32 	%f940, %f939, %f938;
	mul.f32 	%f1228, %f940, %f934;
	sub.f32 	%f941, %f925, %f926;
	mul.f32 	%f1223, %f941, %f934;
	mul.f32 	%f942, %f1211, %f1219;
	mul.f32 	%f943, %f1213, %f1217;
	sub.f32 	%f944, %f943, %f942;
	mul.f32 	%f1224, %f944, %f934;
	mul.f32 	%f945, %f1216, %f1217;
	mul.f32 	%f946, %f1214, %f1219;
	sub.f32 	%f947, %f946, %f945;
	mul.f32 	%f1225, %f947, %f934;
	mul.f32 	%f1220, %f932, %f934;
	mul.f32 	%f948, %f1212, %f1217;
	mul.f32 	%f949, %f1211, %f1218;
	sub.f32 	%f950, %f949, %f948;
	mul.f32 	%f1221, %f950, %f934;
	mul.f32 	%f951, %f1214, %f1218;
	mul.f32 	%f952, %f1215, %f1217;
	sub.f32 	%f953, %f952, %f951;
	mul.f32 	%f1222, %f953, %f934;
	bra.uni 	$L__BB4_52;

$L__BB4_43:
	// begin inline asm
	call (%rd442), _optix_get_instance_inverse_transform_from_handle, (%rd209);
	// end inline asm

$L__BB4_44:
	// begin inline asm
	cvta.to.global.u64 %rd215, %rd442;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r188,%r189,%r190,%r191}, [%rd215];
	// end inline asm
	mov.b32 	%f1226, %r188;
	mov.b32 	%f1227, %r189;
	mov.b32 	%f1228, %r190;
	add.s64 	%rd219, %rd442, 16;
	// begin inline asm
	cvta.to.global.u64 %rd218, %rd219;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r192,%r193,%r194,%r195}, [%rd218];
	// end inline asm
	mov.b32 	%f1223, %r192;
	mov.b32 	%f1224, %r193;
	mov.b32 	%f1225, %r194;
	add.s64 	%rd222, %rd442, 32;
	// begin inline asm
	cvta.to.global.u64 %rd221, %rd222;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r196,%r197,%r198,%r199}, [%rd221];
	// end inline asm
	mov.b32 	%f1220, %r196;
	mov.b32 	%f1221, %r197;
	mov.b32 	%f1222, %r198;

$L__BB4_52:
	setp.eq.s32 	%p32, %r337, 0;
	@%p32 bra 	$L__BB4_54;

	mul.f32 	%f954, %f1197, %f1227;
	fma.rn.f32 	%f955, %f1194, %f1226, %f954;
	fma.rn.f32 	%f350, %f1200, %f1228, %f955;
	mul.f32 	%f956, %f1196, %f1227;
	fma.rn.f32 	%f957, %f1193, %f1226, %f956;
	fma.rn.f32 	%f351, %f1199, %f1228, %f957;
	mul.f32 	%f958, %f1195, %f1227;
	fma.rn.f32 	%f959, %f1192, %f1226, %f958;
	fma.rn.f32 	%f1228, %f1198, %f1228, %f959;
	mul.f32 	%f960, %f1197, %f1224;
	fma.rn.f32 	%f961, %f1194, %f1223, %f960;
	fma.rn.f32 	%f353, %f1200, %f1225, %f961;
	mul.f32 	%f962, %f1196, %f1224;
	fma.rn.f32 	%f963, %f1193, %f1223, %f962;
	fma.rn.f32 	%f354, %f1199, %f1225, %f963;
	mul.f32 	%f964, %f1195, %f1224;
	fma.rn.f32 	%f965, %f1192, %f1223, %f964;
	fma.rn.f32 	%f1225, %f1198, %f1225, %f965;
	mul.f32 	%f966, %f1197, %f1221;
	fma.rn.f32 	%f967, %f1194, %f1220, %f966;
	fma.rn.f32 	%f356, %f1200, %f1222, %f967;
	mul.f32 	%f968, %f1196, %f1221;
	fma.rn.f32 	%f969, %f1193, %f1220, %f968;
	fma.rn.f32 	%f357, %f1199, %f1222, %f969;
	mul.f32 	%f970, %f1195, %f1221;
	fma.rn.f32 	%f971, %f1192, %f1220, %f970;
	fma.rn.f32 	%f1222, %f1198, %f1222, %f971;
	mov.f32 	%f1220, %f356;
	mov.f32 	%f1221, %f357;
	mov.f32 	%f1223, %f353;
	mov.f32 	%f1224, %f354;
	mov.f32 	%f1226, %f350;
	mov.f32 	%f1227, %f351;

$L__BB4_54:
	add.s32 	%r337, %r337, 1;
	setp.lt.u32 	%p33, %r337, %r183;
	mov.f32 	%f1192, %f1228;
	mov.f32 	%f1193, %f1227;
	mov.f32 	%f1194, %f1226;
	mov.f32 	%f1195, %f1225;
	mov.f32 	%f1196, %f1224;
	mov.f32 	%f1197, %f1223;
	mov.f32 	%f1198, %f1222;
	mov.f32 	%f1199, %f1221;
	mov.f32 	%f1200, %f1220;
	@%p33 bra 	$L__BB4_39;

$L__BB4_55:
	fma.rn.f32 	%f972, %f1283, %f1164, %f1167;
	fma.rn.f32 	%f973, %f1284, %f1165, %f972;
	fma.rn.f32 	%f974, %f1283, %f1160, %f1163;
	fma.rn.f32 	%f975, %f1284, %f1161, %f974;
	fma.rn.f32 	%f976, %f1283, %f1156, %f1159;
	fma.rn.f32 	%f977, %f1284, %f1157, %f976;
	fma.rn.f32 	%f1283, %f1285, %f1166, %f973;
	fma.rn.f32 	%f1284, %f1285, %f1162, %f975;
	fma.rn.f32 	%f1285, %f1285, %f1158, %f977;
	ld.const.u64 	%rd328, [params+112];
	setp.eq.s64 	%p34, %rd328, 0;
	@%p34 bra 	$L__BB4_57;

	mul.f32 	%f978, %f1247, %f1226;
	fma.rn.f32 	%f979, %f1248, %f1223, %f978;
	mul.f32 	%f980, %f1247, %f1227;
	fma.rn.f32 	%f981, %f1248, %f1224, %f980;
	mul.f32 	%f982, %f1247, %f1228;
	fma.rn.f32 	%f983, %f1248, %f1225, %f982;
	fma.rn.f32 	%f984, %f1249, %f1220, %f979;
	fma.rn.f32 	%f985, %f1249, %f1221, %f981;
	fma.rn.f32 	%f986, %f1249, %f1222, %f983;
	mul.f32 	%f987, %f984, %f984;
	fma.rn.f32 	%f988, %f985, %f985, %f987;
	fma.rn.f32 	%f989, %f986, %f986, %f988;
	sqrt.rn.f32 	%f990, %f989;
	div.rn.f32 	%f1247, %f984, %f990;
	div.rn.f32 	%f1248, %f985, %f990;
	div.rn.f32 	%f1249, %f986, %f990;

$L__BB4_57:
	@%p5 bra 	$L__BB4_59;

	mul.f32 	%f991, %f1117, %f1226;
	fma.rn.f32 	%f992, %f1118, %f1223, %f991;
	mul.f32 	%f993, %f1117, %f1227;
	fma.rn.f32 	%f994, %f1118, %f1224, %f993;
	mul.f32 	%f995, %f1117, %f1228;
	fma.rn.f32 	%f996, %f1118, %f1225, %f995;
	fma.rn.f32 	%f997, %f1119, %f1220, %f992;
	fma.rn.f32 	%f998, %f1119, %f1221, %f994;
	fma.rn.f32 	%f999, %f1119, %f1222, %f996;
	mul.f32 	%f1000, %f997, %f997;
	fma.rn.f32 	%f1001, %f998, %f998, %f1000;
	fma.rn.f32 	%f1002, %f999, %f999, %f1001;
	sqrt.rn.f32 	%f1003, %f1002;
	div.rn.f32 	%f1117, %f997, %f1003;
	div.rn.f32 	%f1118, %f998, %f1003;
	div.rn.f32 	%f1119, %f999, %f1003;

$L__BB4_59:
	ld.const.u64 	%rd329, [params+184];
	setp.eq.s64 	%p36, %rd329, 0;
	@%p36 bra 	$L__BB4_61;

	mul.f32 	%f1004, %f1124, %f1164;
	fma.rn.f32 	%f1005, %f1123, %f1165, %f1004;
	mul.f32 	%f1006, %f1124, %f1160;
	fma.rn.f32 	%f1007, %f1123, %f1161, %f1006;
	mul.f32 	%f1008, %f1124, %f1156;
	fma.rn.f32 	%f1009, %f1123, %f1157, %f1008;
	fma.rn.f32 	%f1124, %f1122, %f1166, %f1005;
	fma.rn.f32 	%f1123, %f1122, %f1162, %f1007;
	fma.rn.f32 	%f1122, %f1122, %f1158, %f1009;
	mul.f32 	%f1010, %f1127, %f1164;
	fma.rn.f32 	%f1011, %f1126, %f1165, %f1010;
	mul.f32 	%f1012, %f1127, %f1160;
	fma.rn.f32 	%f1013, %f1126, %f1161, %f1012;
	mul.f32 	%f1014, %f1127, %f1156;
	fma.rn.f32 	%f1015, %f1126, %f1157, %f1014;
	fma.rn.f32 	%f1127, %f1125, %f1166, %f1011;
	fma.rn.f32 	%f1126, %f1125, %f1162, %f1013;
	fma.rn.f32 	%f1125, %f1125, %f1158, %f1015;

$L__BB4_61:
	ld.const.u64 	%rd330, [params+232];
	ld.const.u64 	%rd331, [params+280];
	or.b64  	%rd332, %rd330, %rd331;
	setp.eq.s64 	%p37, %rd332, 0;
	@%p37 bra 	$L__BB4_63;

	mul.f32 	%f1016, %f1117, %f1164;
	fma.rn.f32 	%f1017, %f1118, %f1160, %f1016;
	mul.f32 	%f1018, %f1117, %f1165;
	fma.rn.f32 	%f1019, %f1118, %f1161, %f1018;
	mul.f32 	%f1020, %f1117, %f1166;
	fma.rn.f32 	%f1021, %f1118, %f1162, %f1020;
	fma.rn.f32 	%f1022, %f1119, %f1156, %f1017;
	fma.rn.f32 	%f1023, %f1119, %f1157, %f1019;
	fma.rn.f32 	%f1024, %f1119, %f1158, %f1021;
	mul.f32 	%f1025, %f1022, %f1022;
	fma.rn.f32 	%f1026, %f1023, %f1023, %f1025;
	fma.rn.f32 	%f1027, %f1024, %f1024, %f1026;
	sqrt.rn.f32 	%f1028, %f1027;
	div.rn.f32 	%f1029, %f1022, %f1028;
	div.rn.f32 	%f1030, %f1023, %f1028;
	div.rn.f32 	%f1031, %f1024, %f1028;
	mul.f32 	%f1032, %f1029, %f1226;
	mul.f32 	%f1033, %f1029, %f1227;
	mul.f32 	%f1034, %f1029, %f1228;
	fma.rn.f32 	%f1035, %f1030, %f1223, %f1032;
	fma.rn.f32 	%f1036, %f1030, %f1224, %f1033;
	fma.rn.f32 	%f1037, %f1030, %f1225, %f1034;
	fma.rn.f32 	%f1038, %f1031, %f1220, %f1035;
	fma.rn.f32 	%f1039, %f1031, %f1221, %f1036;
	fma.rn.f32 	%f1040, %f1031, %f1222, %f1037;
	mul.f32 	%f1041, %f1038, %f1038;
	fma.rn.f32 	%f1042, %f1039, %f1039, %f1041;
	fma.rn.f32 	%f1043, %f1040, %f1040, %f1042;
	sqrt.rn.f32 	%f1044, %f1043;
	rcp.rn.f32 	%f1045, %f1044;
	mul.f32 	%f1046, %f1045, %f1038;
	mul.f32 	%f1047, %f1045, %f1039;
	mul.f32 	%f1048, %f1045, %f1040;
	mul.f32 	%f1049, %f1114, %f1226;
	fma.rn.f32 	%f1050, %f1115, %f1223, %f1049;
	mul.f32 	%f1051, %f1114, %f1227;
	fma.rn.f32 	%f1052, %f1115, %f1224, %f1051;
	mul.f32 	%f1053, %f1114, %f1228;
	fma.rn.f32 	%f1054, %f1115, %f1225, %f1053;
	fma.rn.f32 	%f1055, %f1116, %f1220, %f1050;
	fma.rn.f32 	%f1056, %f1116, %f1221, %f1052;
	fma.rn.f32 	%f1057, %f1116, %f1222, %f1054;
	mul.f32 	%f1058, %f1055, %f1045;
	mul.f32 	%f1059, %f1056, %f1045;
	mul.f32 	%f1060, %f1057, %f1045;
	mul.f32 	%f1061, %f1111, %f1226;
	fma.rn.f32 	%f1062, %f1112, %f1223, %f1061;
	mul.f32 	%f1063, %f1111, %f1227;
	fma.rn.f32 	%f1064, %f1112, %f1224, %f1063;
	mul.f32 	%f1065, %f1111, %f1228;
	fma.rn.f32 	%f1066, %f1112, %f1225, %f1065;
	fma.rn.f32 	%f1067, %f1113, %f1220, %f1062;
	fma.rn.f32 	%f1068, %f1113, %f1221, %f1064;
	fma.rn.f32 	%f1069, %f1113, %f1222, %f1066;
	mul.f32 	%f1070, %f1067, %f1045;
	mul.f32 	%f1071, %f1068, %f1045;
	mul.f32 	%f1072, %f1069, %f1045;
	mul.f32 	%f1073, %f1046, %f1058;
	fma.rn.f32 	%f1074, %f1047, %f1059, %f1073;
	fma.rn.f32 	%f1075, %f1048, %f1060, %f1074;
	mul.f32 	%f1076, %f1046, %f1075;
	mul.f32 	%f1077, %f1047, %f1075;
	mul.f32 	%f1078, %f1048, %f1075;
	sub.f32 	%f1114, %f1058, %f1076;
	sub.f32 	%f1115, %f1059, %f1077;
	sub.f32 	%f1116, %f1060, %f1078;
	mul.f32 	%f1079, %f1046, %f1070;
	fma.rn.f32 	%f1080, %f1047, %f1071, %f1079;
	fma.rn.f32 	%f1081, %f1048, %f1072, %f1080;
	mul.f32 	%f1082, %f1046, %f1081;
	mul.f32 	%f1083, %f1047, %f1081;
	mul.f32 	%f1084, %f1048, %f1081;
	sub.f32 	%f1111, %f1070, %f1082;
	sub.f32 	%f1112, %f1071, %f1083;
	sub.f32 	%f1113, %f1072, %f1084;

$L__BB4_63:
	st.global.u32 	[%rd20], %r30;

$L__BB4_64:
	ld.const.u64 	%rd434, [params+96];
	setp.eq.s64 	%p44, %rd434, 0;
	cvt.u64.u32 	%rd431, %r1;
	ld.const.u64 	%rd333, [params+328];
	cvta.to.global.u64 	%rd334, %rd333;
	shl.b64 	%rd335, %rd431, 3;
	add.s64 	%rd336, %rd334, %rd335;
	st.global.u64 	[%rd336], %rd18;
	ld.const.u64 	%rd337, [params+336];
	cvta.to.global.u64 	%rd338, %rd337;
	shl.b64 	%rd339, %rd431, 2;
	add.s64 	%rd340, %rd338, %rd339;
	st.global.u32 	[%rd340], %r22;
	ld.const.u64 	%rd341, [params+160];
	cvta.to.global.u64 	%rd342, %rd341;
	add.s64 	%rd343, %rd342, %rd339;
	st.global.f32 	[%rd343], %f1283;
	ld.const.u64 	%rd344, [params+168];
	cvta.to.global.u64 	%rd345, %rd344;
	add.s64 	%rd346, %rd345, %rd339;
	st.global.f32 	[%rd346], %f1284;
	ld.const.u64 	%rd347, [params+176];
	cvta.to.global.u64 	%rd348, %rd347;
	add.s64 	%rd349, %rd348, %rd339;
	st.global.f32 	[%rd349], %f1285;
	ld.const.u64 	%rd350, [params+72];
	cvta.to.global.u64 	%rd351, %rd350;
	add.s64 	%rd352, %rd351, %rd339;
	st.global.f32 	[%rd352], %f437;
	@%p44 bra 	$L__BB4_66;

	ld.const.u64 	%rd432, [params+96];
	cvta.to.global.u64 	%rd353, %rd432;
	add.s64 	%rd355, %rd353, %rd339;
	st.global.f32 	[%rd355], %f1120;
	ld.const.u64 	%rd356, [params+104];
	cvta.to.global.u64 	%rd357, %rd356;
	add.s64 	%rd358, %rd357, %rd339;
	st.global.f32 	[%rd358], %f1121;

$L__BB4_66:
	ld.const.u64 	%rd35, [params+112];
	setp.eq.s64 	%p39, %rd35, 0;
	@%p39 bra 	$L__BB4_68;

	cvta.to.global.u64 	%rd359, %rd35;
	add.s64 	%rd361, %rd359, %rd339;
	st.global.f32 	[%rd361], %f1247;
	ld.const.u64 	%rd362, [params+120];
	cvta.to.global.u64 	%rd363, %rd362;
	add.s64 	%rd364, %rd363, %rd339;
	st.global.f32 	[%rd364], %f1248;
	ld.const.u64 	%rd365, [params+128];
	cvta.to.global.u64 	%rd366, %rd365;
	add.s64 	%rd367, %rd366, %rd339;
	st.global.f32 	[%rd367], %f1249;

$L__BB4_68:
	@%p5 bra 	$L__BB4_70;

	ld.const.u64 	%rd433, [params+136];
	cvta.to.global.u64 	%rd368, %rd433;
	add.s64 	%rd370, %rd368, %rd339;
	st.global.f32 	[%rd370], %f1117;
	ld.const.u64 	%rd371, [params+144];
	cvta.to.global.u64 	%rd372, %rd371;
	add.s64 	%rd373, %rd372, %rd339;
	st.global.f32 	[%rd373], %f1118;
	ld.const.u64 	%rd374, [params+152];
	cvta.to.global.u64 	%rd375, %rd374;
	add.s64 	%rd376, %rd375, %rd339;
	st.global.f32 	[%rd376], %f1119;

$L__BB4_70:
	ld.const.u64 	%rd36, [params+184];
	setp.eq.s64 	%p41, %rd36, 0;
	@%p41 bra 	$L__BB4_72;

	cvta.to.global.u64 	%rd377, %rd36;
	add.s64 	%rd379, %rd377, %rd339;
	st.global.f32 	[%rd379], %f1124;
	ld.const.u64 	%rd380, [params+192];
	cvta.to.global.u64 	%rd381, %rd380;
	add.s64 	%rd382, %rd381, %rd339;
	st.global.f32 	[%rd382], %f1123;
	ld.const.u64 	%rd383, [params+200];
	cvta.to.global.u64 	%rd384, %rd383;
	add.s64 	%rd385, %rd384, %rd339;
	st.global.f32 	[%rd385], %f1122;
	ld.const.u64 	%rd386, [params+208];
	cvta.to.global.u64 	%rd387, %rd386;
	add.s64 	%rd388, %rd387, %rd339;
	st.global.f32 	[%rd388], %f1127;
	ld.const.u64 	%rd389, [params+216];
	cvta.to.global.u64 	%rd390, %rd389;
	add.s64 	%rd391, %rd390, %rd339;
	st.global.f32 	[%rd391], %f1126;
	ld.const.u64 	%rd392, [params+224];
	cvta.to.global.u64 	%rd393, %rd392;
	add.s64 	%rd394, %rd393, %rd339;
	st.global.f32 	[%rd394], %f1125;

$L__BB4_72:
	ld.const.u64 	%rd37, [params+232];
	setp.eq.s64 	%p42, %rd37, 0;
	@%p42 bra 	$L__BB4_74;

	cvta.to.global.u64 	%rd395, %rd37;
	add.s64 	%rd397, %rd395, %rd339;
	st.global.f32 	[%rd397], %f1114;
	ld.const.u64 	%rd398, [params+240];
	cvta.to.global.u64 	%rd399, %rd398;
	add.s64 	%rd400, %rd399, %rd339;
	st.global.f32 	[%rd400], %f1115;
	ld.const.u64 	%rd401, [params+248];
	cvta.to.global.u64 	%rd402, %rd401;
	add.s64 	%rd403, %rd402, %rd339;
	st.global.f32 	[%rd403], %f1116;
	ld.const.u64 	%rd404, [params+256];
	cvta.to.global.u64 	%rd405, %rd404;
	add.s64 	%rd406, %rd405, %rd339;
	st.global.f32 	[%rd406], %f1111;
	ld.const.u64 	%rd407, [params+264];
	cvta.to.global.u64 	%rd408, %rd407;
	add.s64 	%rd409, %rd408, %rd339;
	st.global.f32 	[%rd409], %f1112;
	ld.const.u64 	%rd410, [params+272];
	cvta.to.global.u64 	%rd411, %rd410;
	add.s64 	%rd412, %rd411, %rd339;
	st.global.f32 	[%rd412], %f1113;

$L__BB4_74:
	ld.const.u64 	%rd38, [params+280];
	setp.eq.s64 	%p43, %rd38, 0;
	@%p43 bra 	$L__BB4_76;

	cvta.to.global.u64 	%rd413, %rd38;
	add.s64 	%rd415, %rd413, %rd339;
	st.global.f32 	[%rd415], %f1114;
	ld.const.u64 	%rd416, [params+288];
	cvta.to.global.u64 	%rd417, %rd416;
	add.s64 	%rd418, %rd417, %rd339;
	st.global.f32 	[%rd418], %f1115;
	ld.const.u64 	%rd419, [params+296];
	cvta.to.global.u64 	%rd420, %rd419;
	add.s64 	%rd421, %rd420, %rd339;
	st.global.f32 	[%rd421], %f1116;
	ld.const.u64 	%rd422, [params+304];
	cvta.to.global.u64 	%rd423, %rd422;
	add.s64 	%rd424, %rd423, %rd339;
	st.global.f32 	[%rd424], %f1111;
	ld.const.u64 	%rd425, [params+312];
	cvta.to.global.u64 	%rd426, %rd425;
	add.s64 	%rd427, %rd426, %rd339;
	st.global.f32 	[%rd427], %f1112;
	ld.const.u64 	%rd428, [params+320];
	cvta.to.global.u64 	%rd429, %rd428;
	add.s64 	%rd430, %rd429, %rd339;
	st.global.f32 	[%rd430], %f1113;

$L__BB4_76:
	ret;

}
	// .globl	__intersection__rectangle
.visible .entry __intersection__rectangle()
{
	.reg .pred 	%p<23>;
	.reg .f32 	%f<977>;
	.reg .b32 	%r<318>;
	.reg .b64 	%rd<258>;


	// begin inline asm
	call (%rd16), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd1, [%rd16+8];
	// begin inline asm
	call (%f916), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f917), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f918), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r9), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p1, %r9, 0;
	@%p1 bra 	$L__BB5_21;

	// begin inline asm
	call (%r10), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f345), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p2, %r10, 0;
	@%p2 bra 	$L__BB5_19;

	mov.u32 	%r316, 0;

$L__BB5_3:
	.pragma "nounroll";
	// begin inline asm
	call (%rd17), _optix_get_transform_list_handle, (%r316);
	// end inline asm
	// begin inline asm
	call (%r13), _optix_get_transform_type_from_handle, (%rd17);
	// end inline asm
	or.b32  	%r14, %r13, 1;
	setp.eq.s32 	%p3, %r14, 3;
	@%p3 bra 	$L__BB5_9;
	bra.uni 	$L__BB5_4;

$L__BB5_9:
	setp.eq.s32 	%p6, %r13, 2;
	@%p6 bra 	$L__BB5_13;
	bra.uni 	$L__BB5_10;

$L__BB5_13:
	// begin inline asm
	call (%rd89), _optix_get_matrix_motion_transform_from_handle, (%rd17);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd91, %rd89;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd91];
	// end inline asm
	add.s64 	%rd95, %rd89, 16;
	// begin inline asm
	cvta.to.global.u64 %rd94, %rd95;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd94];
	// end inline asm
	add.s64 	%rd98, %rd89, 32;
	// begin inline asm
	cvta.to.global.u64 %rd97, %rd98;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd97];
	// end inline asm
	add.s64 	%rd101, %rd89, 48;
	// begin inline asm
	cvta.to.global.u64 %rd100, %rd101;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd100];
	// end inline asm
	add.s64 	%rd104, %rd89, 64;
	// begin inline asm
	cvta.to.global.u64 %rd103, %rd104;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd103];
	// end inline asm
	add.s64 	%rd107, %rd89, 80;
	// begin inline asm
	cvta.to.global.u64 %rd106, %rd107;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd106];
	// end inline asm
	add.s64 	%rd110, %rd89, 96;
	// begin inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd109];
	// end inline asm
	add.s64 	%rd113, %rd89, 112;
	// begin inline asm
	cvta.to.global.u64 %rd112, %rd113;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd112];
	// end inline asm
	mov.b32 	%f473, %r105;
	mov.b32 	%f474, %r106;
	and.b32  	%r146, %r104, 65535;
	add.s32 	%r147, %r146, -1;
	cvt.rn.f32.s32 	%f475, %r147;
	sub.f32 	%f476, %f345, %f473;
	mul.f32 	%f477, %f476, %f475;
	sub.f32 	%f478, %f474, %f473;
	div.rn.f32 	%f479, %f477, %f478;
	min.f32 	%f480, %f475, %f479;
	mov.f32 	%f481, 0f00000000;
	max.f32 	%f482, %f481, %f480;
	cvt.rmi.f32.f32 	%f483, %f482;
	sub.f32 	%f90, %f482, %f483;
	cvt.rzi.s32.f32 	%r148, %f483;
	mul.wide.s32 	%rd124, %r148, 48;
	add.s64 	%rd116, %rd98, %rd124;
	// begin inline asm
	cvta.to.global.u64 %rd115, %rd116;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd115];
	// end inline asm
	mov.b32 	%f871, %r134;
	mov.b32 	%f870, %r135;
	mov.b32 	%f869, %r136;
	mov.b32 	%f868, %r137;
	add.s64 	%rd119, %rd116, 16;
	// begin inline asm
	cvta.to.global.u64 %rd118, %rd119;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd118];
	// end inline asm
	mov.b32 	%f875, %r138;
	mov.b32 	%f874, %r139;
	mov.b32 	%f873, %r140;
	mov.b32 	%f872, %r141;
	add.s64 	%rd122, %rd116, 32;
	// begin inline asm
	cvta.to.global.u64 %rd121, %rd122;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd121];
	// end inline asm
	mov.b32 	%f879, %r142;
	mov.b32 	%f878, %r143;
	mov.b32 	%f877, %r144;
	mov.b32 	%f876, %r145;
	setp.leu.f32 	%p8, %f90, 0f00000000;
	@%p8 bra 	$L__BB5_15;

	cvt.rmi.f32.f32 	%f839, %f482;
	cvt.rzi.s32.f32 	%r315, %f839;
	cvt.s64.s32 	%rd255, %r315;
	mov.f32 	%f484, 0f3F800000;
	sub.f32 	%f485, %f484, %f90;
	mul.lo.s64 	%rd134, %rd255, 48;
	add.s64 	%rd135, %rd89, %rd134;
	add.s64 	%rd126, %rd135, 80;
	// begin inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd125];
	// end inline asm
	mov.b32 	%f486, %r149;
	mov.b32 	%f487, %r150;
	mov.b32 	%f488, %r151;
	mov.b32 	%f489, %r152;
	mul.f32 	%f490, %f90, %f486;
	mul.f32 	%f491, %f90, %f487;
	mul.f32 	%f492, %f90, %f488;
	mul.f32 	%f493, %f90, %f489;
	fma.rn.f32 	%f871, %f485, %f871, %f490;
	fma.rn.f32 	%f870, %f485, %f870, %f491;
	fma.rn.f32 	%f869, %f485, %f869, %f492;
	fma.rn.f32 	%f868, %f485, %f868, %f493;
	add.s64 	%rd129, %rd135, 96;
	// begin inline asm
	cvta.to.global.u64 %rd128, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd128];
	// end inline asm
	mov.b32 	%f494, %r153;
	mov.b32 	%f495, %r154;
	mov.b32 	%f496, %r155;
	mov.b32 	%f497, %r156;
	mul.f32 	%f498, %f90, %f494;
	mul.f32 	%f499, %f90, %f495;
	mul.f32 	%f500, %f90, %f496;
	mul.f32 	%f501, %f90, %f497;
	fma.rn.f32 	%f875, %f485, %f875, %f498;
	fma.rn.f32 	%f874, %f485, %f874, %f499;
	fma.rn.f32 	%f873, %f485, %f873, %f500;
	fma.rn.f32 	%f872, %f485, %f872, %f501;
	add.s64 	%rd132, %rd135, 112;
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd131];
	// end inline asm
	mov.b32 	%f502, %r157;
	mov.b32 	%f503, %r158;
	mov.b32 	%f504, %r159;
	mov.b32 	%f505, %r160;
	mul.f32 	%f506, %f90, %f502;
	mul.f32 	%f507, %f90, %f503;
	mul.f32 	%f508, %f90, %f504;
	mul.f32 	%f509, %f90, %f505;
	fma.rn.f32 	%f879, %f485, %f879, %f506;
	fma.rn.f32 	%f878, %f485, %f878, %f507;
	fma.rn.f32 	%f877, %f485, %f877, %f508;
	fma.rn.f32 	%f876, %f485, %f876, %f509;
	bra.uni 	$L__BB5_15;

$L__BB5_4:
	mov.f32 	%f880, 0f00000000;
	mov.f32 	%f883, 0f3F800000;
	setp.eq.s32 	%p4, %r13, 4;
	@%p4 bra 	$L__BB5_7;

	setp.ne.s32 	%p5, %r13, 1;
	mov.f32 	%f881, %f880;
	mov.f32 	%f882, %f880;
	mov.f32 	%f884, %f880;
	mov.f32 	%f885, %f880;
	mov.f32 	%f886, %f883;
	mov.f32 	%f887, %f880;
	mov.f32 	%f888, %f880;
	mov.f32 	%f889, %f883;
	mov.f32 	%f890, %f880;
	mov.f32 	%f891, %f880;
	@%p5 bra 	$L__BB5_16;

	// begin inline asm
	call (%rd19), _optix_get_static_transform_from_handle, (%rd17);
	// end inline asm
	add.s64 	%rd256, %rd19, 64;
	bra.uni 	$L__BB5_8;

$L__BB5_10:
	// begin inline asm
	call (%rd32), _optix_get_srt_motion_transform_from_handle, (%rd17);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd34, %rd32;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r27,%r28,%r29,%r30}, [%rd34];
	// end inline asm
	add.s64 	%rd38, %rd32, 16;
	// begin inline asm
	cvta.to.global.u64 %rd37, %rd38;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r31,%r32,%r33,%r34}, [%rd37];
	// end inline asm
	add.s64 	%rd41, %rd32, 32;
	// begin inline asm
	cvta.to.global.u64 %rd40, %rd41;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd40];
	// end inline asm
	add.s64 	%rd44, %rd32, 48;
	// begin inline asm
	cvta.to.global.u64 %rd43, %rd44;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd43];
	// end inline asm
	add.s64 	%rd47, %rd32, 64;
	// begin inline asm
	cvta.to.global.u64 %rd46, %rd47;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd46];
	// end inline asm
	add.s64 	%rd50, %rd32, 80;
	// begin inline asm
	cvta.to.global.u64 %rd49, %rd50;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd49];
	// end inline asm
	add.s64 	%rd53, %rd32, 96;
	// begin inline asm
	cvta.to.global.u64 %rd52, %rd53;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd52];
	// end inline asm
	add.s64 	%rd56, %rd32, 112;
	// begin inline asm
	cvta.to.global.u64 %rd55, %rd56;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd55];
	// end inline asm
	add.s64 	%rd59, %rd32, 128;
	// begin inline asm
	cvta.to.global.u64 %rd58, %rd59;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd58];
	// end inline asm
	add.s64 	%rd62, %rd32, 144;
	// begin inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd61];
	// end inline asm
	mov.b32 	%f360, %r30;
	mov.b32 	%f361, %r31;
	and.b32  	%r83, %r29, 65535;
	add.s32 	%r84, %r83, -1;
	cvt.rn.f32.s32 	%f362, %r84;
	sub.f32 	%f363, %f345, %f360;
	mul.f32 	%f364, %f363, %f362;
	sub.f32 	%f365, %f361, %f360;
	div.rn.f32 	%f366, %f364, %f365;
	min.f32 	%f367, %f362, %f366;
	mov.f32 	%f368, 0f00000000;
	max.f32 	%f369, %f368, %f367;
	cvt.rmi.f32.f32 	%f370, %f369;
	sub.f32 	%f29, %f369, %f370;
	cvt.rzi.s32.f32 	%r85, %f370;
	mul.wide.s32 	%rd76, %r85, 64;
	add.s64 	%rd65, %rd41, %rd76;
	// begin inline asm
	cvta.to.global.u64 %rd64, %rd65;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd64];
	// end inline asm
	mov.b32 	%f852, %r67;
	mov.b32 	%f853, %r68;
	mov.b32 	%f854, %r69;
	mov.b32 	%f855, %r70;
	add.s64 	%rd68, %rd65, 16;
	// begin inline asm
	cvta.to.global.u64 %rd67, %rd68;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd67];
	// end inline asm
	mov.b32 	%f856, %r71;
	mov.b32 	%f857, %r72;
	mov.b32 	%f858, %r73;
	mov.b32 	%f859, %r74;
	add.s64 	%rd71, %rd65, 32;
	// begin inline asm
	cvta.to.global.u64 %rd70, %rd71;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd70];
	// end inline asm
	mov.b32 	%f860, %r75;
	mov.b32 	%f861, %r76;
	mov.b32 	%f862, %r77;
	mov.b32 	%f863, %r78;
	add.s64 	%rd74, %rd65, 48;
	// begin inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd73];
	// end inline asm
	mov.b32 	%f864, %r79;
	mov.b32 	%f865, %r80;
	mov.b32 	%f866, %r81;
	mov.b32 	%f867, %r82;
	setp.leu.f32 	%p7, %f29, 0f00000000;
	@%p7 bra 	$L__BB5_12;

	mov.f32 	%f371, 0f3F800000;
	sub.f32 	%f372, %f371, %f29;
	add.s64 	%rd78, %rd65, 64;
	// begin inline asm
	cvta.to.global.u64 %rd77, %rd78;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r86,%r87,%r88,%r89}, [%rd77];
	// end inline asm
	mov.b32 	%f373, %r86;
	mov.b32 	%f374, %r87;
	mov.b32 	%f375, %r88;
	mov.b32 	%f376, %r89;
	mul.f32 	%f377, %f29, %f373;
	mul.f32 	%f378, %f29, %f374;
	mul.f32 	%f379, %f29, %f375;
	mul.f32 	%f380, %f29, %f376;
	fma.rn.f32 	%f852, %f372, %f852, %f377;
	fma.rn.f32 	%f853, %f372, %f853, %f378;
	fma.rn.f32 	%f854, %f372, %f854, %f379;
	fma.rn.f32 	%f855, %f372, %f855, %f380;
	add.s64 	%rd81, %rd65, 80;
	// begin inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd80];
	// end inline asm
	mov.b32 	%f381, %r90;
	mov.b32 	%f382, %r91;
	mov.b32 	%f383, %r92;
	mov.b32 	%f384, %r93;
	mul.f32 	%f385, %f29, %f381;
	mul.f32 	%f386, %f29, %f382;
	mul.f32 	%f387, %f29, %f383;
	mul.f32 	%f388, %f29, %f384;
	fma.rn.f32 	%f856, %f372, %f856, %f385;
	fma.rn.f32 	%f857, %f372, %f857, %f386;
	fma.rn.f32 	%f858, %f372, %f858, %f387;
	fma.rn.f32 	%f859, %f372, %f859, %f388;
	add.s64 	%rd84, %rd65, 96;
	// begin inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd83];
	// end inline asm
	mov.b32 	%f389, %r94;
	mov.b32 	%f390, %r95;
	mov.b32 	%f391, %r96;
	mov.b32 	%f392, %r97;
	mul.f32 	%f393, %f29, %f389;
	mul.f32 	%f394, %f29, %f390;
	mul.f32 	%f395, %f29, %f391;
	mul.f32 	%f396, %f29, %f392;
	fma.rn.f32 	%f860, %f372, %f860, %f393;
	fma.rn.f32 	%f397, %f372, %f861, %f394;
	fma.rn.f32 	%f398, %f372, %f862, %f395;
	fma.rn.f32 	%f399, %f372, %f863, %f396;
	add.s64 	%rd87, %rd65, 112;
	// begin inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd86];
	// end inline asm
	mov.b32 	%f400, %r98;
	mov.b32 	%f401, %r99;
	mov.b32 	%f402, %r100;
	mov.b32 	%f403, %r101;
	mul.f32 	%f404, %f29, %f400;
	mul.f32 	%f405, %f29, %f401;
	mul.f32 	%f406, %f29, %f402;
	mul.f32 	%f407, %f29, %f403;
	fma.rn.f32 	%f408, %f372, %f864, %f404;
	fma.rn.f32 	%f865, %f372, %f865, %f405;
	fma.rn.f32 	%f866, %f372, %f866, %f406;
	fma.rn.f32 	%f867, %f372, %f867, %f407;
	mul.f32 	%f409, %f398, %f398;
	fma.rn.f32 	%f410, %f397, %f397, %f409;
	fma.rn.f32 	%f411, %f399, %f399, %f410;
	fma.rn.f32 	%f412, %f408, %f408, %f411;
	sqrt.rn.f32 	%f413, %f412;
	rcp.rn.f32 	%f414, %f413;
	mul.f32 	%f861, %f397, %f414;
	mul.f32 	%f862, %f398, %f414;
	mul.f32 	%f863, %f399, %f414;
	mul.f32 	%f864, %f414, %f408;

$L__BB5_12:
	mul.f32 	%f415, %f862, %f862;
	fma.rn.f32 	%f416, %f861, %f861, %f415;
	fma.rn.f32 	%f417, %f863, %f863, %f416;
	fma.rn.f32 	%f418, %f864, %f864, %f417;
	rcp.rn.f32 	%f419, %f418;
	mul.f32 	%f420, %f861, %f419;
	mul.f32 	%f421, %f862, %f419;
	mul.f32 	%f422, %f863, %f419;
	mul.f32 	%f423, %f864, %f419;
	mul.f32 	%f424, %f861, %f420;
	mul.f32 	%f425, %f862, %f421;
	mul.f32 	%f426, %f863, %f422;
	mul.f32 	%f427, %f861, %f421;
	mul.f32 	%f428, %f863, %f423;
	mul.f32 	%f429, %f861, %f422;
	mul.f32 	%f430, %f862, %f423;
	mul.f32 	%f431, %f862, %f422;
	mul.f32 	%f432, %f861, %f423;
	sub.f32 	%f433, %f424, %f425;
	sub.f32 	%f434, %f433, %f426;
	fma.rn.f32 	%f435, %f864, %f423, %f434;
	sub.f32 	%f436, %f427, %f428;
	add.f32 	%f437, %f436, %f436;
	add.f32 	%f438, %f429, %f430;
	add.f32 	%f439, %f438, %f438;
	add.f32 	%f440, %f427, %f428;
	add.f32 	%f441, %f440, %f440;
	sub.f32 	%f442, %f425, %f424;
	sub.f32 	%f443, %f442, %f426;
	fma.rn.f32 	%f444, %f864, %f423, %f443;
	sub.f32 	%f445, %f431, %f432;
	add.f32 	%f446, %f445, %f445;
	sub.f32 	%f447, %f429, %f430;
	add.f32 	%f448, %f447, %f447;
	add.f32 	%f449, %f431, %f432;
	add.f32 	%f450, %f449, %f449;
	neg.f32 	%f451, %f424;
	sub.f32 	%f452, %f451, %f425;
	add.f32 	%f453, %f426, %f452;
	fma.rn.f32 	%f454, %f864, %f423, %f453;
	mul.f32 	%f455, %f855, %f435;
	fma.rn.f32 	%f456, %f858, %f437, %f455;
	fma.rn.f32 	%f457, %f860, %f439, %f456;
	sub.f32 	%f868, %f865, %f457;
	mul.f32 	%f458, %f858, %f444;
	fma.rn.f32 	%f459, %f855, %f441, %f458;
	fma.rn.f32 	%f460, %f860, %f446, %f459;
	sub.f32 	%f872, %f866, %f460;
	mul.f32 	%f461, %f858, %f450;
	fma.rn.f32 	%f462, %f855, %f448, %f461;
	fma.rn.f32 	%f463, %f860, %f454, %f462;
	sub.f32 	%f876, %f867, %f463;
	mul.f32 	%f464, %f854, %f435;
	fma.rn.f32 	%f465, %f857, %f437, %f464;
	fma.rn.f32 	%f869, %f859, %f439, %f465;
	mul.f32 	%f466, %f857, %f444;
	fma.rn.f32 	%f467, %f854, %f441, %f466;
	fma.rn.f32 	%f873, %f859, %f446, %f467;
	mul.f32 	%f468, %f857, %f450;
	fma.rn.f32 	%f469, %f854, %f448, %f468;
	fma.rn.f32 	%f877, %f859, %f454, %f469;
	mul.f32 	%f470, %f853, %f435;
	fma.rn.f32 	%f870, %f856, %f437, %f470;
	mul.f32 	%f471, %f856, %f444;
	fma.rn.f32 	%f874, %f853, %f441, %f471;
	mul.f32 	%f472, %f856, %f450;
	fma.rn.f32 	%f878, %f853, %f448, %f472;
	mul.f32 	%f871, %f852, %f435;
	mul.f32 	%f875, %f852, %f441;
	mul.f32 	%f879, %f852, %f448;

$L__BB5_15:
	mul.f32 	%f510, %f873, %f878;
	mul.f32 	%f511, %f874, %f877;
	sub.f32 	%f512, %f511, %f510;
	mul.f32 	%f513, %f871, %f512;
	mul.f32 	%f514, %f873, %f879;
	mul.f32 	%f515, %f875, %f877;
	sub.f32 	%f516, %f515, %f514;
	mul.f32 	%f517, %f870, %f516;
	sub.f32 	%f518, %f513, %f517;
	mul.f32 	%f519, %f874, %f879;
	mul.f32 	%f520, %f875, %f878;
	sub.f32 	%f521, %f520, %f519;
	fma.rn.f32 	%f522, %f869, %f521, %f518;
	rcp.rn.f32 	%f523, %f522;
	mul.f32 	%f883, %f512, %f523;
	mul.f32 	%f524, %f870, %f877;
	mul.f32 	%f525, %f869, %f878;
	sub.f32 	%f526, %f525, %f524;
	mul.f32 	%f882, %f526, %f523;
	mul.f32 	%f527, %f869, %f874;
	mul.f32 	%f528, %f870, %f873;
	sub.f32 	%f529, %f528, %f527;
	mul.f32 	%f881, %f529, %f523;
	sub.f32 	%f530, %f514, %f515;
	mul.f32 	%f887, %f530, %f523;
	mul.f32 	%f531, %f869, %f879;
	mul.f32 	%f532, %f871, %f877;
	sub.f32 	%f533, %f532, %f531;
	mul.f32 	%f886, %f533, %f523;
	mul.f32 	%f534, %f871, %f873;
	mul.f32 	%f535, %f869, %f875;
	sub.f32 	%f536, %f535, %f534;
	mul.f32 	%f885, %f536, %f523;
	mul.f32 	%f891, %f521, %f523;
	mul.f32 	%f537, %f871, %f878;
	mul.f32 	%f538, %f870, %f879;
	sub.f32 	%f539, %f538, %f537;
	mul.f32 	%f890, %f539, %f523;
	mul.f32 	%f540, %f870, %f875;
	mul.f32 	%f541, %f871, %f874;
	sub.f32 	%f542, %f541, %f540;
	mul.f32 	%f889, %f542, %f523;
	mul.f32 	%f543, %f868, %f883;
	neg.f32 	%f544, %f543;
	mul.f32 	%f545, %f872, %f882;
	sub.f32 	%f546, %f544, %f545;
	mul.f32 	%f547, %f876, %f881;
	sub.f32 	%f880, %f546, %f547;
	mul.f32 	%f548, %f868, %f887;
	neg.f32 	%f549, %f548;
	mul.f32 	%f550, %f872, %f886;
	sub.f32 	%f551, %f549, %f550;
	mul.f32 	%f552, %f876, %f885;
	sub.f32 	%f884, %f551, %f552;
	mul.f32 	%f553, %f868, %f891;
	neg.f32 	%f554, %f553;
	mul.f32 	%f555, %f872, %f890;
	sub.f32 	%f556, %f554, %f555;
	mul.f32 	%f557, %f876, %f889;
	sub.f32 	%f888, %f556, %f557;
	bra.uni 	$L__BB5_16;

$L__BB5_7:
	// begin inline asm
	call (%rd256), _optix_get_instance_inverse_transform_from_handle, (%rd17);
	// end inline asm

$L__BB5_8:
	// begin inline asm
	cvta.to.global.u64 %rd23, %rd256;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r15,%r16,%r17,%r18}, [%rd23];
	// end inline asm
	mov.b32 	%f883, %r15;
	mov.b32 	%f882, %r16;
	mov.b32 	%f881, %r17;
	mov.b32 	%f880, %r18;
	add.s64 	%rd27, %rd256, 16;
	// begin inline asm
	cvta.to.global.u64 %rd26, %rd27;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r19,%r20,%r21,%r22}, [%rd26];
	// end inline asm
	mov.b32 	%f887, %r19;
	mov.b32 	%f886, %r20;
	mov.b32 	%f885, %r21;
	mov.b32 	%f884, %r22;
	add.s64 	%rd30, %rd256, 32;
	// begin inline asm
	cvta.to.global.u64 %rd29, %rd30;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r23,%r24,%r25,%r26}, [%rd29];
	// end inline asm
	mov.b32 	%f891, %r23;
	mov.b32 	%f890, %r24;
	mov.b32 	%f889, %r25;
	mov.b32 	%f888, %r26;

$L__BB5_16:
	setp.eq.s32 	%p9, %r316, 0;
	@%p9 bra 	$L__BB5_18;

	mul.f32 	%f558, %f848, %f883;
	fma.rn.f32 	%f559, %f844, %f882, %f558;
	fma.rn.f32 	%f151, %f840, %f881, %f559;
	mul.f32 	%f560, %f849, %f883;
	fma.rn.f32 	%f561, %f845, %f882, %f560;
	fma.rn.f32 	%f152, %f841, %f881, %f561;
	mul.f32 	%f562, %f850, %f883;
	fma.rn.f32 	%f563, %f846, %f882, %f562;
	fma.rn.f32 	%f153, %f842, %f881, %f563;
	mul.f32 	%f564, %f851, %f883;
	fma.rn.f32 	%f565, %f847, %f882, %f564;
	fma.rn.f32 	%f566, %f843, %f881, %f565;
	add.f32 	%f880, %f880, %f566;
	mul.f32 	%f567, %f848, %f887;
	fma.rn.f32 	%f568, %f844, %f886, %f567;
	fma.rn.f32 	%f155, %f840, %f885, %f568;
	mul.f32 	%f569, %f849, %f887;
	fma.rn.f32 	%f570, %f845, %f886, %f569;
	fma.rn.f32 	%f156, %f841, %f885, %f570;
	mul.f32 	%f571, %f850, %f887;
	fma.rn.f32 	%f572, %f846, %f886, %f571;
	fma.rn.f32 	%f157, %f842, %f885, %f572;
	mul.f32 	%f573, %f851, %f887;
	fma.rn.f32 	%f574, %f847, %f886, %f573;
	fma.rn.f32 	%f575, %f843, %f885, %f574;
	add.f32 	%f884, %f884, %f575;
	mul.f32 	%f576, %f848, %f891;
	fma.rn.f32 	%f577, %f844, %f890, %f576;
	fma.rn.f32 	%f159, %f840, %f889, %f577;
	mul.f32 	%f578, %f849, %f891;
	fma.rn.f32 	%f579, %f845, %f890, %f578;
	fma.rn.f32 	%f160, %f841, %f889, %f579;
	mul.f32 	%f580, %f850, %f891;
	fma.rn.f32 	%f581, %f846, %f890, %f580;
	fma.rn.f32 	%f161, %f842, %f889, %f581;
	mul.f32 	%f582, %f851, %f891;
	fma.rn.f32 	%f583, %f847, %f890, %f582;
	fma.rn.f32 	%f584, %f843, %f889, %f583;
	add.f32 	%f888, %f888, %f584;
	mov.f32 	%f881, %f153;
	mov.f32 	%f882, %f152;
	mov.f32 	%f883, %f151;
	mov.f32 	%f885, %f157;
	mov.f32 	%f886, %f156;
	mov.f32 	%f887, %f155;
	mov.f32 	%f889, %f161;
	mov.f32 	%f890, %f160;
	mov.f32 	%f891, %f159;

$L__BB5_18:
	add.s32 	%r316, %r316, 1;
	setp.lt.u32 	%p10, %r316, %r10;
	mov.f32 	%f840, %f891;
	mov.f32 	%f841, %f890;
	mov.f32 	%f842, %f889;
	mov.f32 	%f843, %f888;
	mov.f32 	%f844, %f887;
	mov.f32 	%f845, %f886;
	mov.f32 	%f846, %f885;
	mov.f32 	%f847, %f884;
	mov.f32 	%f848, %f883;
	mov.f32 	%f849, %f882;
	mov.f32 	%f850, %f881;
	mov.f32 	%f851, %f880;
	@%p10 bra 	$L__BB5_3;

$L__BB5_19:
	mul.f32 	%f585, %f916, %f883;
	fma.rn.f32 	%f586, %f917, %f882, %f585;
	fma.rn.f32 	%f587, %f918, %f881, %f586;
	mul.f32 	%f588, %f916, %f887;
	fma.rn.f32 	%f589, %f917, %f886, %f588;
	fma.rn.f32 	%f590, %f918, %f885, %f589;
	mul.f32 	%f591, %f916, %f891;
	fma.rn.f32 	%f592, %f917, %f890, %f591;
	fma.rn.f32 	%f593, %f918, %f889, %f592;
	add.f32 	%f918, %f888, %f593;
	add.f32 	%f917, %f884, %f590;
	add.f32 	%f916, %f880, %f587;

$L__BB5_21:
	// begin inline asm
	call (%f974), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f975), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f596), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r161), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p11, %r161, 0;
	@%p11 bra 	$L__BB5_41;

	// begin inline asm
	call (%r162), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f597), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p12, %r162, 0;
	@%p12 bra 	$L__BB5_40;

	mov.u32 	%r317, 0;

$L__BB5_24:
	.pragma "nounroll";
	// begin inline asm
	call (%rd136), _optix_get_transform_list_handle, (%r317);
	// end inline asm
	// begin inline asm
	call (%r165), _optix_get_transform_type_from_handle, (%rd136);
	// end inline asm
	or.b32  	%r166, %r165, 1;
	setp.eq.s32 	%p13, %r166, 3;
	@%p13 bra 	$L__BB5_30;
	bra.uni 	$L__BB5_25;

$L__BB5_30:
	setp.eq.s32 	%p16, %r165, 2;
	@%p16 bra 	$L__BB5_34;
	bra.uni 	$L__BB5_31;

$L__BB5_34:
	// begin inline asm
	call (%rd208), _optix_get_matrix_motion_transform_from_handle, (%rd136);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd210, %rd208;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd210];
	// end inline asm
	add.s64 	%rd214, %rd208, 16;
	// begin inline asm
	cvta.to.global.u64 %rd213, %rd214;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd213];
	// end inline asm
	add.s64 	%rd217, %rd208, 32;
	// begin inline asm
	cvta.to.global.u64 %rd216, %rd217;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd216];
	// end inline asm
	add.s64 	%rd220, %rd208, 48;
	// begin inline asm
	cvta.to.global.u64 %rd219, %rd220;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd219];
	// end inline asm
	add.s64 	%rd223, %rd208, 64;
	// begin inline asm
	cvta.to.global.u64 %rd222, %rd223;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd222];
	// end inline asm
	add.s64 	%rd226, %rd208, 80;
	// begin inline asm
	cvta.to.global.u64 %rd225, %rd226;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd225];
	// end inline asm
	add.s64 	%rd229, %rd208, 96;
	// begin inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd228];
	// end inline asm
	add.s64 	%rd232, %rd208, 112;
	// begin inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd231];
	// end inline asm
	mov.b32 	%f701, %r257;
	mov.b32 	%f702, %r258;
	and.b32  	%r298, %r256, 65535;
	add.s32 	%r299, %r298, -1;
	cvt.rn.f32.s32 	%f703, %r299;
	sub.f32 	%f704, %f597, %f701;
	mul.f32 	%f705, %f704, %f703;
	sub.f32 	%f706, %f702, %f701;
	div.rn.f32 	%f707, %f705, %f706;
	min.f32 	%f708, %f703, %f707;
	mov.f32 	%f709, 0f00000000;
	max.f32 	%f710, %f709, %f708;
	cvt.rmi.f32.f32 	%f711, %f710;
	sub.f32 	%f258, %f710, %f711;
	cvt.rzi.s32.f32 	%r300, %f711;
	cvt.s64.s32 	%rd15, %r300;
	mul.wide.s32 	%rd243, %r300, 48;
	add.s64 	%rd235, %rd217, %rd243;
	// begin inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd234];
	// end inline asm
	mov.b32 	%f944, %r286;
	mov.b32 	%f945, %r287;
	mov.b32 	%f946, %r288;
	add.s64 	%rd238, %rd235, 16;
	// begin inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd237];
	// end inline asm
	mov.b32 	%f941, %r290;
	mov.b32 	%f942, %r291;
	mov.b32 	%f943, %r292;
	add.s64 	%rd241, %rd235, 32;
	// begin inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r294,%r295,%r296,%r297}, [%rd240];
	// end inline asm
	mov.b32 	%f938, %r294;
	mov.b32 	%f939, %r295;
	mov.b32 	%f940, %r296;
	setp.leu.f32 	%p18, %f258, 0f00000000;
	@%p18 bra 	$L__BB5_36;

	mov.f32 	%f712, 0f3F800000;
	sub.f32 	%f713, %f712, %f258;
	mul.lo.s64 	%rd253, %rd15, 48;
	add.s64 	%rd254, %rd208, %rd253;
	add.s64 	%rd245, %rd254, 80;
	// begin inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd244];
	// end inline asm
	mov.b32 	%f714, %r301;
	mov.b32 	%f715, %r302;
	mov.b32 	%f716, %r303;
	mul.f32 	%f717, %f258, %f714;
	mul.f32 	%f718, %f258, %f715;
	mul.f32 	%f719, %f258, %f716;
	fma.rn.f32 	%f944, %f713, %f944, %f717;
	fma.rn.f32 	%f945, %f713, %f945, %f718;
	fma.rn.f32 	%f946, %f713, %f946, %f719;
	add.s64 	%rd248, %rd254, 96;
	// begin inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd247];
	// end inline asm
	mov.b32 	%f720, %r305;
	mov.b32 	%f721, %r306;
	mov.b32 	%f722, %r307;
	mul.f32 	%f723, %f258, %f720;
	mul.f32 	%f724, %f258, %f721;
	mul.f32 	%f725, %f258, %f722;
	fma.rn.f32 	%f941, %f713, %f941, %f723;
	fma.rn.f32 	%f942, %f713, %f942, %f724;
	fma.rn.f32 	%f943, %f713, %f943, %f725;
	add.s64 	%rd251, %rd254, 112;
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r309,%r310,%r311,%r312}, [%rd250];
	// end inline asm
	mov.b32 	%f726, %r309;
	mov.b32 	%f727, %r310;
	mov.b32 	%f728, %r311;
	mul.f32 	%f729, %f258, %f726;
	mul.f32 	%f730, %f258, %f727;
	mul.f32 	%f731, %f258, %f728;
	fma.rn.f32 	%f938, %f713, %f938, %f729;
	fma.rn.f32 	%f939, %f713, %f939, %f730;
	fma.rn.f32 	%f940, %f713, %f940, %f731;
	bra.uni 	$L__BB5_36;

$L__BB5_25:
	mov.f32 	%f947, 0f00000000;
	mov.f32 	%f949, 0f3F800000;
	setp.eq.s32 	%p14, %r165, 4;
	@%p14 bra 	$L__BB5_28;

	setp.ne.s32 	%p15, %r165, 1;
	mov.f32 	%f948, %f947;
	mov.f32 	%f950, %f947;
	mov.f32 	%f951, %f949;
	mov.f32 	%f952, %f947;
	mov.f32 	%f953, %f949;
	mov.f32 	%f954, %f947;
	mov.f32 	%f955, %f947;
	@%p15 bra 	$L__BB5_37;

	// begin inline asm
	call (%rd138), _optix_get_static_transform_from_handle, (%rd136);
	// end inline asm
	add.s64 	%rd257, %rd138, 64;
	bra.uni 	$L__BB5_29;

$L__BB5_31:
	// begin inline asm
	call (%rd151), _optix_get_srt_motion_transform_from_handle, (%rd136);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd153, %rd151;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd153];
	// end inline asm
	add.s64 	%rd157, %rd151, 16;
	// begin inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd156];
	// end inline asm
	add.s64 	%rd160, %rd151, 32;
	// begin inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd159];
	// end inline asm
	add.s64 	%rd163, %rd151, 48;
	// begin inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd162];
	// end inline asm
	add.s64 	%rd166, %rd151, 64;
	// begin inline asm
	cvta.to.global.u64 %rd165, %rd166;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd165];
	// end inline asm
	add.s64 	%rd169, %rd151, 80;
	// begin inline asm
	cvta.to.global.u64 %rd168, %rd169;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd168];
	// end inline asm
	add.s64 	%rd172, %rd151, 96;
	// begin inline asm
	cvta.to.global.u64 %rd171, %rd172;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd171];
	// end inline asm
	add.s64 	%rd175, %rd151, 112;
	// begin inline asm
	cvta.to.global.u64 %rd174, %rd175;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd174];
	// end inline asm
	add.s64 	%rd178, %rd151, 128;
	// begin inline asm
	cvta.to.global.u64 %rd177, %rd178;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd177];
	// end inline asm
	add.s64 	%rd181, %rd151, 144;
	// begin inline asm
	cvta.to.global.u64 %rd180, %rd181;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd180];
	// end inline asm
	mov.b32 	%f609, %r182;
	mov.b32 	%f610, %r183;
	and.b32  	%r235, %r181, 65535;
	add.s32 	%r236, %r235, -1;
	cvt.rn.f32.s32 	%f611, %r236;
	sub.f32 	%f612, %f597, %f609;
	mul.f32 	%f613, %f612, %f611;
	sub.f32 	%f614, %f610, %f609;
	div.rn.f32 	%f615, %f613, %f614;
	min.f32 	%f616, %f611, %f615;
	mov.f32 	%f617, 0f00000000;
	max.f32 	%f618, %f617, %f616;
	cvt.rmi.f32.f32 	%f619, %f618;
	sub.f32 	%f218, %f618, %f619;
	cvt.rzi.s32.f32 	%r237, %f619;
	mul.wide.s32 	%rd195, %r237, 64;
	add.s64 	%rd184, %rd160, %rd195;
	// begin inline asm
	cvta.to.global.u64 %rd183, %rd184;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd183];
	// end inline asm
	mov.b32 	%f928, %r219;
	mov.b32 	%f929, %r220;
	mov.b32 	%f930, %r221;
	add.s64 	%rd187, %rd184, 16;
	// begin inline asm
	cvta.to.global.u64 %rd186, %rd187;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd186];
	// end inline asm
	mov.b32 	%f931, %r223;
	mov.b32 	%f932, %r224;
	mov.b32 	%f933, %r226;
	add.s64 	%rd190, %rd184, 32;
	// begin inline asm
	cvta.to.global.u64 %rd189, %rd190;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd189];
	// end inline asm
	mov.b32 	%f934, %r228;
	mov.b32 	%f935, %r229;
	mov.b32 	%f936, %r230;
	add.s64 	%rd193, %rd184, 48;
	// begin inline asm
	cvta.to.global.u64 %rd192, %rd193;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r231,%r232,%r233,%r234}, [%rd192];
	// end inline asm
	mov.b32 	%f937, %r231;
	setp.leu.f32 	%p17, %f218, 0f00000000;
	@%p17 bra 	$L__BB5_33;

	mov.f32 	%f620, 0f3F800000;
	sub.f32 	%f621, %f620, %f218;
	add.s64 	%rd197, %rd184, 64;
	// begin inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd196];
	// end inline asm
	mov.b32 	%f622, %r238;
	mov.b32 	%f623, %r239;
	mov.b32 	%f624, %r240;
	mul.f32 	%f625, %f218, %f622;
	mul.f32 	%f626, %f218, %f623;
	mul.f32 	%f627, %f218, %f624;
	fma.rn.f32 	%f928, %f621, %f928, %f625;
	fma.rn.f32 	%f929, %f621, %f929, %f626;
	fma.rn.f32 	%f930, %f621, %f930, %f627;
	add.s64 	%rd200, %rd184, 80;
	// begin inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd199];
	// end inline asm
	mov.b32 	%f628, %r242;
	mov.b32 	%f629, %r243;
	mov.b32 	%f630, %r245;
	mul.f32 	%f631, %f218, %f628;
	mul.f32 	%f632, %f218, %f629;
	mul.f32 	%f633, %f218, %f630;
	fma.rn.f32 	%f931, %f621, %f931, %f631;
	fma.rn.f32 	%f932, %f621, %f932, %f632;
	fma.rn.f32 	%f933, %f621, %f933, %f633;
	add.s64 	%rd203, %rd184, 96;
	// begin inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd202];
	// end inline asm
	mov.b32 	%f634, %r247;
	mov.b32 	%f635, %r248;
	mov.b32 	%f636, %r249;
	mul.f32 	%f637, %f218, %f634;
	mul.f32 	%f638, %f218, %f635;
	mul.f32 	%f639, %f218, %f636;
	fma.rn.f32 	%f640, %f621, %f934, %f637;
	fma.rn.f32 	%f641, %f621, %f935, %f638;
	fma.rn.f32 	%f642, %f621, %f936, %f639;
	add.s64 	%rd206, %rd184, 112;
	// begin inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd205];
	// end inline asm
	mov.b32 	%f643, %r250;
	mul.f32 	%f644, %f218, %f643;
	fma.rn.f32 	%f645, %f621, %f937, %f644;
	mul.f32 	%f646, %f641, %f641;
	fma.rn.f32 	%f647, %f640, %f640, %f646;
	fma.rn.f32 	%f648, %f642, %f642, %f647;
	fma.rn.f32 	%f649, %f645, %f645, %f648;
	sqrt.rn.f32 	%f650, %f649;
	rcp.rn.f32 	%f651, %f650;
	mul.f32 	%f934, %f640, %f651;
	mul.f32 	%f935, %f641, %f651;
	mul.f32 	%f936, %f642, %f651;
	mul.f32 	%f937, %f651, %f645;

$L__BB5_33:
	mul.f32 	%f652, %f935, %f935;
	fma.rn.f32 	%f653, %f934, %f934, %f652;
	fma.rn.f32 	%f654, %f936, %f936, %f653;
	fma.rn.f32 	%f655, %f937, %f937, %f654;
	rcp.rn.f32 	%f656, %f655;
	mul.f32 	%f657, %f934, %f656;
	mul.f32 	%f658, %f935, %f656;
	mul.f32 	%f659, %f936, %f656;
	mul.f32 	%f660, %f937, %f656;
	mul.f32 	%f661, %f934, %f657;
	mul.f32 	%f662, %f935, %f658;
	mul.f32 	%f663, %f936, %f659;
	mul.f32 	%f664, %f934, %f658;
	mul.f32 	%f665, %f936, %f660;
	mul.f32 	%f666, %f934, %f659;
	mul.f32 	%f667, %f935, %f660;
	mul.f32 	%f668, %f935, %f659;
	mul.f32 	%f669, %f934, %f660;
	sub.f32 	%f670, %f661, %f662;
	sub.f32 	%f671, %f670, %f663;
	fma.rn.f32 	%f672, %f937, %f660, %f671;
	sub.f32 	%f673, %f664, %f665;
	add.f32 	%f674, %f673, %f673;
	add.f32 	%f675, %f666, %f667;
	add.f32 	%f676, %f675, %f675;
	add.f32 	%f677, %f664, %f665;
	add.f32 	%f678, %f677, %f677;
	sub.f32 	%f679, %f662, %f661;
	sub.f32 	%f680, %f679, %f663;
	fma.rn.f32 	%f681, %f937, %f660, %f680;
	sub.f32 	%f682, %f668, %f669;
	add.f32 	%f683, %f682, %f682;
	sub.f32 	%f684, %f666, %f667;
	add.f32 	%f685, %f684, %f684;
	add.f32 	%f686, %f668, %f669;
	add.f32 	%f687, %f686, %f686;
	neg.f32 	%f688, %f661;
	sub.f32 	%f689, %f688, %f662;
	add.f32 	%f690, %f663, %f689;
	fma.rn.f32 	%f691, %f937, %f660, %f690;
	mul.f32 	%f692, %f930, %f672;
	fma.rn.f32 	%f693, %f932, %f674, %f692;
	fma.rn.f32 	%f946, %f933, %f676, %f693;
	mul.f32 	%f694, %f932, %f681;
	fma.rn.f32 	%f695, %f930, %f678, %f694;
	fma.rn.f32 	%f943, %f933, %f683, %f695;
	mul.f32 	%f696, %f932, %f687;
	fma.rn.f32 	%f697, %f930, %f685, %f696;
	fma.rn.f32 	%f940, %f933, %f691, %f697;
	mul.f32 	%f698, %f929, %f672;
	fma.rn.f32 	%f945, %f931, %f674, %f698;
	mul.f32 	%f699, %f931, %f681;
	fma.rn.f32 	%f942, %f929, %f678, %f699;
	mul.f32 	%f700, %f931, %f687;
	fma.rn.f32 	%f939, %f929, %f685, %f700;
	mul.f32 	%f944, %f928, %f672;
	mul.f32 	%f941, %f928, %f678;
	mul.f32 	%f938, %f928, %f685;

$L__BB5_36:
	mul.f32 	%f732, %f939, %f943;
	mul.f32 	%f733, %f940, %f942;
	sub.f32 	%f734, %f733, %f732;
	mul.f32 	%f735, %f944, %f734;
	mul.f32 	%f736, %f938, %f943;
	mul.f32 	%f737, %f940, %f941;
	sub.f32 	%f738, %f737, %f736;
	mul.f32 	%f739, %f738, %f945;
	sub.f32 	%f740, %f735, %f739;
	mul.f32 	%f741, %f938, %f942;
	mul.f32 	%f742, %f939, %f941;
	sub.f32 	%f743, %f742, %f741;
	fma.rn.f32 	%f744, %f743, %f946, %f740;
	rcp.rn.f32 	%f745, %f744;
	mul.f32 	%f953, %f734, %f745;
	mul.f32 	%f746, %f940, %f945;
	mul.f32 	%f747, %f939, %f946;
	sub.f32 	%f748, %f747, %f746;
	mul.f32 	%f954, %f748, %f745;
	mul.f32 	%f749, %f942, %f946;
	mul.f32 	%f750, %f943, %f945;
	sub.f32 	%f751, %f750, %f749;
	mul.f32 	%f955, %f751, %f745;
	sub.f32 	%f752, %f736, %f737;
	mul.f32 	%f950, %f752, %f745;
	mul.f32 	%f753, %f938, %f946;
	mul.f32 	%f754, %f940, %f944;
	sub.f32 	%f755, %f754, %f753;
	mul.f32 	%f951, %f755, %f745;
	mul.f32 	%f756, %f943, %f944;
	mul.f32 	%f757, %f941, %f946;
	sub.f32 	%f758, %f757, %f756;
	mul.f32 	%f952, %f758, %f745;
	mul.f32 	%f947, %f743, %f745;
	mul.f32 	%f759, %f939, %f944;
	mul.f32 	%f760, %f938, %f945;
	sub.f32 	%f761, %f760, %f759;
	mul.f32 	%f948, %f761, %f745;
	mul.f32 	%f762, %f941, %f945;
	mul.f32 	%f763, %f942, %f944;
	sub.f32 	%f764, %f763, %f762;
	mul.f32 	%f949, %f764, %f745;
	bra.uni 	$L__BB5_37;

$L__BB5_28:
	// begin inline asm
	call (%rd257), _optix_get_instance_inverse_transform_from_handle, (%rd136);
	// end inline asm

$L__BB5_29:
	// begin inline asm
	cvta.to.global.u64 %rd142, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd142];
	// end inline asm
	mov.b32 	%f953, %r167;
	mov.b32 	%f954, %r168;
	mov.b32 	%f955, %r169;
	add.s64 	%rd146, %rd257, 16;
	// begin inline asm
	cvta.to.global.u64 %rd145, %rd146;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd145];
	// end inline asm
	mov.b32 	%f950, %r171;
	mov.b32 	%f951, %r172;
	mov.b32 	%f952, %r173;
	add.s64 	%rd149, %rd257, 32;
	// begin inline asm
	cvta.to.global.u64 %rd148, %rd149;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd148];
	// end inline asm
	mov.b32 	%f947, %r175;
	mov.b32 	%f948, %r176;
	mov.b32 	%f949, %r177;

$L__BB5_37:
	setp.eq.s32 	%p19, %r317, 0;
	@%p19 bra 	$L__BB5_39;

	mul.f32 	%f765, %f924, %f954;
	fma.rn.f32 	%f766, %f921, %f953, %f765;
	fma.rn.f32 	%f304, %f927, %f955, %f766;
	mul.f32 	%f767, %f923, %f954;
	fma.rn.f32 	%f768, %f920, %f953, %f767;
	fma.rn.f32 	%f305, %f926, %f955, %f768;
	mul.f32 	%f769, %f922, %f954;
	fma.rn.f32 	%f770, %f919, %f953, %f769;
	fma.rn.f32 	%f955, %f925, %f955, %f770;
	mul.f32 	%f771, %f924, %f951;
	fma.rn.f32 	%f772, %f921, %f950, %f771;
	fma.rn.f32 	%f307, %f927, %f952, %f772;
	mul.f32 	%f773, %f923, %f951;
	fma.rn.f32 	%f774, %f920, %f950, %f773;
	fma.rn.f32 	%f308, %f926, %f952, %f774;
	mul.f32 	%f775, %f922, %f951;
	fma.rn.f32 	%f776, %f919, %f950, %f775;
	fma.rn.f32 	%f952, %f925, %f952, %f776;
	mul.f32 	%f777, %f924, %f948;
	fma.rn.f32 	%f778, %f921, %f947, %f777;
	fma.rn.f32 	%f310, %f927, %f949, %f778;
	mul.f32 	%f779, %f923, %f948;
	fma.rn.f32 	%f780, %f920, %f947, %f779;
	fma.rn.f32 	%f311, %f926, %f949, %f780;
	mul.f32 	%f781, %f922, %f948;
	fma.rn.f32 	%f782, %f919, %f947, %f781;
	fma.rn.f32 	%f949, %f925, %f949, %f782;
	mov.f32 	%f947, %f310;
	mov.f32 	%f948, %f311;
	mov.f32 	%f950, %f307;
	mov.f32 	%f951, %f308;
	mov.f32 	%f953, %f304;
	mov.f32 	%f954, %f305;

$L__BB5_39:
	add.s32 	%r317, %r317, 1;
	setp.lt.u32 	%p20, %r317, %r162;
	mov.f32 	%f919, %f955;
	mov.f32 	%f920, %f954;
	mov.f32 	%f921, %f953;
	mov.f32 	%f922, %f952;
	mov.f32 	%f923, %f951;
	mov.f32 	%f924, %f950;
	mov.f32 	%f925, %f949;
	mov.f32 	%f926, %f948;
	mov.f32 	%f927, %f947;
	@%p20 bra 	$L__BB5_24;

$L__BB5_40:
	mul.f32 	%f783, %f975, %f954;
	fma.rn.f32 	%f784, %f974, %f953, %f783;
	mul.f32 	%f785, %f975, %f951;
	fma.rn.f32 	%f786, %f974, %f950, %f785;
	mul.f32 	%f787, %f975, %f948;
	fma.rn.f32 	%f788, %f974, %f947, %f787;
	fma.rn.f32 	%f976, %f596, %f949, %f788;
	fma.rn.f32 	%f975, %f596, %f952, %f786;
	fma.rn.f32 	%f974, %f596, %f955, %f784;
	bra.uni 	$L__BB5_42;

$L__BB5_41:
	mov.f32 	%f976, %f596;

$L__BB5_42:
	ld.v4.f32 	{%f792, %f793, %f794, %f795}, [%rd1+80];
	ld.f32 	%f799, [%rd1+32];
	fma.rn.f32 	%f800, %f916, %f799, %f792;
	ld.f32 	%f801, [%rd1+36];
	fma.rn.f32 	%f802, %f916, %f801, %f793;
	ld.f32 	%f803, [%rd1+40];
	fma.rn.f32 	%f804, %f916, %f803, %f794;
	ld.f32 	%f805, [%rd1+48];
	fma.rn.f32 	%f806, %f917, %f805, %f800;
	ld.f32 	%f807, [%rd1+52];
	fma.rn.f32 	%f808, %f917, %f807, %f802;
	ld.f32 	%f809, [%rd1+56];
	fma.rn.f32 	%f810, %f917, %f809, %f804;
	ld.f32 	%f811, [%rd1+64];
	fma.rn.f32 	%f812, %f918, %f811, %f806;
	ld.f32 	%f813, [%rd1+68];
	fma.rn.f32 	%f814, %f918, %f813, %f808;
	ld.f32 	%f815, [%rd1+72];
	fma.rn.f32 	%f816, %f918, %f815, %f810;
	ld.v4.f32 	{%f817, %f818, %f819, %f820}, [%rd1+32];
	mul.f32 	%f824, %f974, %f817;
	mul.f32 	%f825, %f974, %f818;
	mul.f32 	%f826, %f974, %f819;
	fma.rn.f32 	%f827, %f975, %f805, %f824;
	fma.rn.f32 	%f828, %f975, %f807, %f825;
	fma.rn.f32 	%f829, %f975, %f809, %f826;
	fma.rn.f32 	%f830, %f976, %f811, %f827;
	fma.rn.f32 	%f831, %f976, %f813, %f828;
	fma.rn.f32 	%f832, %f976, %f815, %f829;
	rcp.rn.f32 	%f833, %f832;
	mul.f32 	%f834, %f816, %f833;
	neg.f32 	%f340, %f834;
	fma.rn.f32 	%f835, %f340, %f830, %f812;
	fma.rn.f32 	%f341, %f340, %f831, %f814;
	abs.f32 	%f836, %f835;
	setp.gtu.f32 	%p21, %f836, 0f3F800000;
	@%p21 bra 	$L__BB5_45;

	abs.f32 	%f837, %f341;
	setp.gtu.f32 	%p22, %f837, 0f3F800000;
	@%p22 bra 	$L__BB5_45;

	mov.u32 	%r314, 254;
	// begin inline asm
	call (%r313), _optix_report_intersection_0, (%f340, %r314);
	// end inline asm

$L__BB5_45:
	ret;

}
	// .globl	__closesthit__rectangle
.visible .entry __closesthit__rectangle()
{
	.reg .pred 	%p<57>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<2007>;
	.reg .b32 	%r<650>;
	.reg .b64 	%rd<656>;


	// begin inline asm
	call (%r25), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r26), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r28), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r29), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r30), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r31, %r30, %r26, %r29;
	mad.lo.s32 	%r1, %r31, %r25, %r28;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64 	%p1, %rd1, 0;
	@%p1 bra 	$L__BB6_2;

	cvta.to.global.u64 	%rd44, %rd1;
	cvt.u64.u32 	%rd45, %r1;
	add.s64 	%rd46, %rd44, %rd45;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd46], %rs1;
	bra.uni 	$L__BB6_109;

$L__BB6_2:
	// begin inline asm
	call (%rd47), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd3, [%rd47+8];
	// begin inline asm
	call (%f1794), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1795), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1796), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r32), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p2, %r32, 0;
	@%p2 bra 	$L__BB6_23;

	// begin inline asm
	call (%r33), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f708), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p3, %r33, 0;
	@%p3 bra 	$L__BB6_21;

	mov.u32 	%r645, 0;

$L__BB6_5:
	.pragma "nounroll";
	// begin inline asm
	call (%rd48), _optix_get_transform_list_handle, (%r645);
	// end inline asm
	// begin inline asm
	call (%r36), _optix_get_transform_type_from_handle, (%rd48);
	// end inline asm
	or.b32  	%r37, %r36, 1;
	setp.eq.s32 	%p4, %r37, 3;
	@%p4 bra 	$L__BB6_11;
	bra.uni 	$L__BB6_6;

$L__BB6_11:
	setp.eq.s32 	%p7, %r36, 2;
	@%p7 bra 	$L__BB6_15;
	bra.uni 	$L__BB6_12;

$L__BB6_15:
	// begin inline asm
	call (%rd120), _optix_get_matrix_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r125,%r126,%r127,%r128}, [%rd122];
	// end inline asm
	add.s64 	%rd126, %rd120, 16;
	// begin inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r129,%r130,%r131,%r132}, [%rd125];
	// end inline asm
	add.s64 	%rd129, %rd120, 32;
	// begin inline asm
	cvta.to.global.u64 %rd128, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r133,%r134,%r135,%r136}, [%rd128];
	// end inline asm
	add.s64 	%rd132, %rd120, 48;
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r137,%r138,%r139,%r140}, [%rd131];
	// end inline asm
	add.s64 	%rd135, %rd120, 64;
	// begin inline asm
	cvta.to.global.u64 %rd134, %rd135;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r141,%r142,%r143,%r144}, [%rd134];
	// end inline asm
	add.s64 	%rd138, %rd120, 80;
	// begin inline asm
	cvta.to.global.u64 %rd137, %rd138;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r145,%r146,%r147,%r148}, [%rd137];
	// end inline asm
	add.s64 	%rd141, %rd120, 96;
	// begin inline asm
	cvta.to.global.u64 %rd140, %rd141;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd140];
	// end inline asm
	add.s64 	%rd144, %rd120, 112;
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd144;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd143];
	// end inline asm
	mov.b32 	%f836, %r128;
	mov.b32 	%f837, %r129;
	and.b32  	%r169, %r127, 65535;
	add.s32 	%r170, %r169, -1;
	cvt.rn.f32.s32 	%f838, %r170;
	sub.f32 	%f839, %f708, %f836;
	mul.f32 	%f840, %f839, %f838;
	sub.f32 	%f841, %f837, %f836;
	div.rn.f32 	%f842, %f840, %f841;
	min.f32 	%f843, %f838, %f842;
	mov.f32 	%f844, 0f00000000;
	max.f32 	%f845, %f844, %f843;
	cvt.rmi.f32.f32 	%f846, %f845;
	sub.f32 	%f90, %f845, %f846;
	cvt.rzi.s32.f32 	%r171, %f846;
	mul.wide.s32 	%rd155, %r171, 48;
	add.s64 	%rd147, %rd129, %rd155;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd146];
	// end inline asm
	mov.b32 	%f1749, %r157;
	mov.b32 	%f1748, %r158;
	mov.b32 	%f1747, %r159;
	mov.b32 	%f1746, %r160;
	add.s64 	%rd150, %rd147, 16;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r161,%r162,%r163,%r164}, [%rd149];
	// end inline asm
	mov.b32 	%f1753, %r161;
	mov.b32 	%f1752, %r162;
	mov.b32 	%f1751, %r163;
	mov.b32 	%f1750, %r164;
	add.s64 	%rd153, %rd147, 32;
	// begin inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r165,%r166,%r167,%r168}, [%rd152];
	// end inline asm
	mov.b32 	%f1757, %r165;
	mov.b32 	%f1756, %r166;
	mov.b32 	%f1755, %r167;
	mov.b32 	%f1754, %r168;
	setp.leu.f32 	%p9, %f90, 0f00000000;
	@%p9 bra 	$L__BB6_17;

	cvt.rmi.f32.f32 	%f1717, %f845;
	cvt.rzi.s32.f32 	%r644, %f1717;
	cvt.s64.s32 	%rd651, %r644;
	mov.f32 	%f847, 0f3F800000;
	sub.f32 	%f848, %f847, %f90;
	mul.lo.s64 	%rd165, %rd651, 48;
	add.s64 	%rd166, %rd120, %rd165;
	add.s64 	%rd157, %rd166, 80;
	// begin inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r172,%r173,%r174,%r175}, [%rd156];
	// end inline asm
	mov.b32 	%f849, %r172;
	mov.b32 	%f850, %r173;
	mov.b32 	%f851, %r174;
	mov.b32 	%f852, %r175;
	mul.f32 	%f853, %f90, %f849;
	mul.f32 	%f854, %f90, %f850;
	mul.f32 	%f855, %f90, %f851;
	mul.f32 	%f856, %f90, %f852;
	fma.rn.f32 	%f1749, %f848, %f1749, %f853;
	fma.rn.f32 	%f1748, %f848, %f1748, %f854;
	fma.rn.f32 	%f1747, %f848, %f1747, %f855;
	fma.rn.f32 	%f1746, %f848, %f1746, %f856;
	add.s64 	%rd160, %rd166, 96;
	// begin inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r176,%r177,%r178,%r179}, [%rd159];
	// end inline asm
	mov.b32 	%f857, %r176;
	mov.b32 	%f858, %r177;
	mov.b32 	%f859, %r178;
	mov.b32 	%f860, %r179;
	mul.f32 	%f861, %f90, %f857;
	mul.f32 	%f862, %f90, %f858;
	mul.f32 	%f863, %f90, %f859;
	mul.f32 	%f864, %f90, %f860;
	fma.rn.f32 	%f1753, %f848, %f1753, %f861;
	fma.rn.f32 	%f1752, %f848, %f1752, %f862;
	fma.rn.f32 	%f1751, %f848, %f1751, %f863;
	fma.rn.f32 	%f1750, %f848, %f1750, %f864;
	add.s64 	%rd163, %rd166, 112;
	// begin inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r180,%r181,%r182,%r183}, [%rd162];
	// end inline asm
	mov.b32 	%f865, %r180;
	mov.b32 	%f866, %r181;
	mov.b32 	%f867, %r182;
	mov.b32 	%f868, %r183;
	mul.f32 	%f869, %f90, %f865;
	mul.f32 	%f870, %f90, %f866;
	mul.f32 	%f871, %f90, %f867;
	mul.f32 	%f872, %f90, %f868;
	fma.rn.f32 	%f1757, %f848, %f1757, %f869;
	fma.rn.f32 	%f1756, %f848, %f1756, %f870;
	fma.rn.f32 	%f1755, %f848, %f1755, %f871;
	fma.rn.f32 	%f1754, %f848, %f1754, %f872;
	bra.uni 	$L__BB6_17;

$L__BB6_6:
	mov.f32 	%f1758, 0f00000000;
	mov.f32 	%f1761, 0f3F800000;
	setp.eq.s32 	%p5, %r36, 4;
	@%p5 bra 	$L__BB6_9;

	setp.ne.s32 	%p6, %r36, 1;
	mov.f32 	%f1759, %f1758;
	mov.f32 	%f1760, %f1758;
	mov.f32 	%f1762, %f1758;
	mov.f32 	%f1763, %f1758;
	mov.f32 	%f1764, %f1761;
	mov.f32 	%f1765, %f1758;
	mov.f32 	%f1766, %f1758;
	mov.f32 	%f1767, %f1761;
	mov.f32 	%f1768, %f1758;
	mov.f32 	%f1769, %f1758;
	@%p6 bra 	$L__BB6_18;

	// begin inline asm
	call (%rd50), _optix_get_static_transform_from_handle, (%rd48);
	// end inline asm
	add.s64 	%rd652, %rd50, 64;
	bra.uni 	$L__BB6_10;

$L__BB6_12:
	// begin inline asm
	call (%rd63), _optix_get_srt_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r50,%r51,%r52,%r53}, [%rd65];
	// end inline asm
	add.s64 	%rd69, %rd63, 16;
	// begin inline asm
	cvta.to.global.u64 %rd68, %rd69;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r54,%r55,%r56,%r57}, [%rd68];
	// end inline asm
	add.s64 	%rd72, %rd63, 32;
	// begin inline asm
	cvta.to.global.u64 %rd71, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r58,%r59,%r60,%r61}, [%rd71];
	// end inline asm
	add.s64 	%rd75, %rd63, 48;
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd75;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r62,%r63,%r64,%r65}, [%rd74];
	// end inline asm
	add.s64 	%rd78, %rd63, 64;
	// begin inline asm
	cvta.to.global.u64 %rd77, %rd78;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r66,%r67,%r68,%r69}, [%rd77];
	// end inline asm
	add.s64 	%rd81, %rd63, 80;
	// begin inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r70,%r71,%r72,%r73}, [%rd80];
	// end inline asm
	add.s64 	%rd84, %rd63, 96;
	// begin inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r74,%r75,%r76,%r77}, [%rd83];
	// end inline asm
	add.s64 	%rd87, %rd63, 112;
	// begin inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r78,%r79,%r80,%r81}, [%rd86];
	// end inline asm
	add.s64 	%rd90, %rd63, 128;
	// begin inline asm
	cvta.to.global.u64 %rd89, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r82,%r83,%r84,%r85}, [%rd89];
	// end inline asm
	add.s64 	%rd93, %rd63, 144;
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd93;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r86,%r87,%r88,%r89}, [%rd92];
	// end inline asm
	mov.b32 	%f723, %r53;
	mov.b32 	%f724, %r54;
	and.b32  	%r106, %r52, 65535;
	add.s32 	%r107, %r106, -1;
	cvt.rn.f32.s32 	%f725, %r107;
	sub.f32 	%f726, %f708, %f723;
	mul.f32 	%f727, %f726, %f725;
	sub.f32 	%f728, %f724, %f723;
	div.rn.f32 	%f729, %f727, %f728;
	min.f32 	%f730, %f725, %f729;
	mov.f32 	%f731, 0f00000000;
	max.f32 	%f732, %f731, %f730;
	cvt.rmi.f32.f32 	%f733, %f732;
	sub.f32 	%f29, %f732, %f733;
	cvt.rzi.s32.f32 	%r108, %f733;
	mul.wide.s32 	%rd107, %r108, 64;
	add.s64 	%rd96, %rd72, %rd107;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd95];
	// end inline asm
	mov.b32 	%f1730, %r90;
	mov.b32 	%f1731, %r91;
	mov.b32 	%f1732, %r92;
	mov.b32 	%f1733, %r93;
	add.s64 	%rd99, %rd96, 16;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd98];
	// end inline asm
	mov.b32 	%f1734, %r94;
	mov.b32 	%f1735, %r95;
	mov.b32 	%f1736, %r96;
	mov.b32 	%f1737, %r97;
	add.s64 	%rd102, %rd96, 32;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd101];
	// end inline asm
	mov.b32 	%f1738, %r98;
	mov.b32 	%f1739, %r99;
	mov.b32 	%f1740, %r100;
	mov.b32 	%f1741, %r101;
	add.s64 	%rd105, %rd96, 48;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd104];
	// end inline asm
	mov.b32 	%f1742, %r102;
	mov.b32 	%f1743, %r103;
	mov.b32 	%f1744, %r104;
	mov.b32 	%f1745, %r105;
	setp.leu.f32 	%p8, %f29, 0f00000000;
	@%p8 bra 	$L__BB6_14;

	mov.f32 	%f734, 0f3F800000;
	sub.f32 	%f735, %f734, %f29;
	add.s64 	%rd109, %rd96, 64;
	// begin inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r109,%r110,%r111,%r112}, [%rd108];
	// end inline asm
	mov.b32 	%f736, %r109;
	mov.b32 	%f737, %r110;
	mov.b32 	%f738, %r111;
	mov.b32 	%f739, %r112;
	mul.f32 	%f740, %f29, %f736;
	mul.f32 	%f741, %f29, %f737;
	mul.f32 	%f742, %f29, %f738;
	mul.f32 	%f743, %f29, %f739;
	fma.rn.f32 	%f1730, %f735, %f1730, %f740;
	fma.rn.f32 	%f1731, %f735, %f1731, %f741;
	fma.rn.f32 	%f1732, %f735, %f1732, %f742;
	fma.rn.f32 	%f1733, %f735, %f1733, %f743;
	add.s64 	%rd112, %rd96, 80;
	// begin inline asm
	cvta.to.global.u64 %rd111, %rd112;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r113,%r114,%r115,%r116}, [%rd111];
	// end inline asm
	mov.b32 	%f744, %r113;
	mov.b32 	%f745, %r114;
	mov.b32 	%f746, %r115;
	mov.b32 	%f747, %r116;
	mul.f32 	%f748, %f29, %f744;
	mul.f32 	%f749, %f29, %f745;
	mul.f32 	%f750, %f29, %f746;
	mul.f32 	%f751, %f29, %f747;
	fma.rn.f32 	%f1734, %f735, %f1734, %f748;
	fma.rn.f32 	%f1735, %f735, %f1735, %f749;
	fma.rn.f32 	%f1736, %f735, %f1736, %f750;
	fma.rn.f32 	%f1737, %f735, %f1737, %f751;
	add.s64 	%rd115, %rd96, 96;
	// begin inline asm
	cvta.to.global.u64 %rd114, %rd115;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r117,%r118,%r119,%r120}, [%rd114];
	// end inline asm
	mov.b32 	%f752, %r117;
	mov.b32 	%f753, %r118;
	mov.b32 	%f754, %r119;
	mov.b32 	%f755, %r120;
	mul.f32 	%f756, %f29, %f752;
	mul.f32 	%f757, %f29, %f753;
	mul.f32 	%f758, %f29, %f754;
	mul.f32 	%f759, %f29, %f755;
	fma.rn.f32 	%f1738, %f735, %f1738, %f756;
	fma.rn.f32 	%f760, %f735, %f1739, %f757;
	fma.rn.f32 	%f761, %f735, %f1740, %f758;
	fma.rn.f32 	%f762, %f735, %f1741, %f759;
	add.s64 	%rd118, %rd96, 112;
	// begin inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r121,%r122,%r123,%r124}, [%rd117];
	// end inline asm
	mov.b32 	%f763, %r121;
	mov.b32 	%f764, %r122;
	mov.b32 	%f765, %r123;
	mov.b32 	%f766, %r124;
	mul.f32 	%f767, %f29, %f763;
	mul.f32 	%f768, %f29, %f764;
	mul.f32 	%f769, %f29, %f765;
	mul.f32 	%f770, %f29, %f766;
	fma.rn.f32 	%f771, %f735, %f1742, %f767;
	fma.rn.f32 	%f1743, %f735, %f1743, %f768;
	fma.rn.f32 	%f1744, %f735, %f1744, %f769;
	fma.rn.f32 	%f1745, %f735, %f1745, %f770;
	mul.f32 	%f772, %f761, %f761;
	fma.rn.f32 	%f773, %f760, %f760, %f772;
	fma.rn.f32 	%f774, %f762, %f762, %f773;
	fma.rn.f32 	%f775, %f771, %f771, %f774;
	sqrt.rn.f32 	%f776, %f775;
	rcp.rn.f32 	%f777, %f776;
	mul.f32 	%f1739, %f760, %f777;
	mul.f32 	%f1740, %f761, %f777;
	mul.f32 	%f1741, %f762, %f777;
	mul.f32 	%f1742, %f777, %f771;

$L__BB6_14:
	mul.f32 	%f778, %f1740, %f1740;
	fma.rn.f32 	%f779, %f1739, %f1739, %f778;
	fma.rn.f32 	%f780, %f1741, %f1741, %f779;
	fma.rn.f32 	%f781, %f1742, %f1742, %f780;
	rcp.rn.f32 	%f782, %f781;
	mul.f32 	%f783, %f1739, %f782;
	mul.f32 	%f784, %f1740, %f782;
	mul.f32 	%f785, %f1741, %f782;
	mul.f32 	%f786, %f1742, %f782;
	mul.f32 	%f787, %f1739, %f783;
	mul.f32 	%f788, %f1740, %f784;
	mul.f32 	%f789, %f1741, %f785;
	mul.f32 	%f790, %f1739, %f784;
	mul.f32 	%f791, %f1741, %f786;
	mul.f32 	%f792, %f1739, %f785;
	mul.f32 	%f793, %f1740, %f786;
	mul.f32 	%f794, %f1740, %f785;
	mul.f32 	%f795, %f1739, %f786;
	sub.f32 	%f796, %f787, %f788;
	sub.f32 	%f797, %f796, %f789;
	fma.rn.f32 	%f798, %f1742, %f786, %f797;
	sub.f32 	%f799, %f790, %f791;
	add.f32 	%f800, %f799, %f799;
	add.f32 	%f801, %f792, %f793;
	add.f32 	%f802, %f801, %f801;
	add.f32 	%f803, %f790, %f791;
	add.f32 	%f804, %f803, %f803;
	sub.f32 	%f805, %f788, %f787;
	sub.f32 	%f806, %f805, %f789;
	fma.rn.f32 	%f807, %f1742, %f786, %f806;
	sub.f32 	%f808, %f794, %f795;
	add.f32 	%f809, %f808, %f808;
	sub.f32 	%f810, %f792, %f793;
	add.f32 	%f811, %f810, %f810;
	add.f32 	%f812, %f794, %f795;
	add.f32 	%f813, %f812, %f812;
	neg.f32 	%f814, %f787;
	sub.f32 	%f815, %f814, %f788;
	add.f32 	%f816, %f789, %f815;
	fma.rn.f32 	%f817, %f1742, %f786, %f816;
	mul.f32 	%f818, %f1733, %f798;
	fma.rn.f32 	%f819, %f1736, %f800, %f818;
	fma.rn.f32 	%f820, %f1738, %f802, %f819;
	sub.f32 	%f1746, %f1743, %f820;
	mul.f32 	%f821, %f1736, %f807;
	fma.rn.f32 	%f822, %f1733, %f804, %f821;
	fma.rn.f32 	%f823, %f1738, %f809, %f822;
	sub.f32 	%f1750, %f1744, %f823;
	mul.f32 	%f824, %f1736, %f813;
	fma.rn.f32 	%f825, %f1733, %f811, %f824;
	fma.rn.f32 	%f826, %f1738, %f817, %f825;
	sub.f32 	%f1754, %f1745, %f826;
	mul.f32 	%f827, %f1732, %f798;
	fma.rn.f32 	%f828, %f1735, %f800, %f827;
	fma.rn.f32 	%f1747, %f1737, %f802, %f828;
	mul.f32 	%f829, %f1735, %f807;
	fma.rn.f32 	%f830, %f1732, %f804, %f829;
	fma.rn.f32 	%f1751, %f1737, %f809, %f830;
	mul.f32 	%f831, %f1735, %f813;
	fma.rn.f32 	%f832, %f1732, %f811, %f831;
	fma.rn.f32 	%f1755, %f1737, %f817, %f832;
	mul.f32 	%f833, %f1731, %f798;
	fma.rn.f32 	%f1748, %f1734, %f800, %f833;
	mul.f32 	%f834, %f1734, %f807;
	fma.rn.f32 	%f1752, %f1731, %f804, %f834;
	mul.f32 	%f835, %f1734, %f813;
	fma.rn.f32 	%f1756, %f1731, %f811, %f835;
	mul.f32 	%f1749, %f1730, %f798;
	mul.f32 	%f1753, %f1730, %f804;
	mul.f32 	%f1757, %f1730, %f811;

$L__BB6_17:
	mul.f32 	%f873, %f1751, %f1756;
	mul.f32 	%f874, %f1752, %f1755;
	sub.f32 	%f875, %f874, %f873;
	mul.f32 	%f876, %f1749, %f875;
	mul.f32 	%f877, %f1751, %f1757;
	mul.f32 	%f878, %f1753, %f1755;
	sub.f32 	%f879, %f878, %f877;
	mul.f32 	%f880, %f1748, %f879;
	sub.f32 	%f881, %f876, %f880;
	mul.f32 	%f882, %f1752, %f1757;
	mul.f32 	%f883, %f1753, %f1756;
	sub.f32 	%f884, %f883, %f882;
	fma.rn.f32 	%f885, %f1747, %f884, %f881;
	rcp.rn.f32 	%f886, %f885;
	mul.f32 	%f1761, %f875, %f886;
	mul.f32 	%f887, %f1748, %f1755;
	mul.f32 	%f888, %f1747, %f1756;
	sub.f32 	%f889, %f888, %f887;
	mul.f32 	%f1760, %f889, %f886;
	mul.f32 	%f890, %f1747, %f1752;
	mul.f32 	%f891, %f1748, %f1751;
	sub.f32 	%f892, %f891, %f890;
	mul.f32 	%f1759, %f892, %f886;
	sub.f32 	%f893, %f877, %f878;
	mul.f32 	%f1765, %f893, %f886;
	mul.f32 	%f894, %f1747, %f1757;
	mul.f32 	%f895, %f1749, %f1755;
	sub.f32 	%f896, %f895, %f894;
	mul.f32 	%f1764, %f896, %f886;
	mul.f32 	%f897, %f1749, %f1751;
	mul.f32 	%f898, %f1747, %f1753;
	sub.f32 	%f899, %f898, %f897;
	mul.f32 	%f1763, %f899, %f886;
	mul.f32 	%f1769, %f884, %f886;
	mul.f32 	%f900, %f1749, %f1756;
	mul.f32 	%f901, %f1748, %f1757;
	sub.f32 	%f902, %f901, %f900;
	mul.f32 	%f1768, %f902, %f886;
	mul.f32 	%f903, %f1748, %f1753;
	mul.f32 	%f904, %f1749, %f1752;
	sub.f32 	%f905, %f904, %f903;
	mul.f32 	%f1767, %f905, %f886;
	mul.f32 	%f906, %f1746, %f1761;
	neg.f32 	%f907, %f906;
	mul.f32 	%f908, %f1750, %f1760;
	sub.f32 	%f909, %f907, %f908;
	mul.f32 	%f910, %f1754, %f1759;
	sub.f32 	%f1758, %f909, %f910;
	mul.f32 	%f911, %f1746, %f1765;
	neg.f32 	%f912, %f911;
	mul.f32 	%f913, %f1750, %f1764;
	sub.f32 	%f914, %f912, %f913;
	mul.f32 	%f915, %f1754, %f1763;
	sub.f32 	%f1762, %f914, %f915;
	mul.f32 	%f916, %f1746, %f1769;
	neg.f32 	%f917, %f916;
	mul.f32 	%f918, %f1750, %f1768;
	sub.f32 	%f919, %f917, %f918;
	mul.f32 	%f920, %f1754, %f1767;
	sub.f32 	%f1766, %f919, %f920;
	bra.uni 	$L__BB6_18;

$L__BB6_9:
	// begin inline asm
	call (%rd652), _optix_get_instance_inverse_transform_from_handle, (%rd48);
	// end inline asm

$L__BB6_10:
	// begin inline asm
	cvta.to.global.u64 %rd54, %rd652;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r38,%r39,%r40,%r41}, [%rd54];
	// end inline asm
	mov.b32 	%f1761, %r38;
	mov.b32 	%f1760, %r39;
	mov.b32 	%f1759, %r40;
	mov.b32 	%f1758, %r41;
	add.s64 	%rd58, %rd652, 16;
	// begin inline asm
	cvta.to.global.u64 %rd57, %rd58;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r42,%r43,%r44,%r45}, [%rd57];
	// end inline asm
	mov.b32 	%f1765, %r42;
	mov.b32 	%f1764, %r43;
	mov.b32 	%f1763, %r44;
	mov.b32 	%f1762, %r45;
	add.s64 	%rd61, %rd652, 32;
	// begin inline asm
	cvta.to.global.u64 %rd60, %rd61;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r46,%r47,%r48,%r49}, [%rd60];
	// end inline asm
	mov.b32 	%f1769, %r46;
	mov.b32 	%f1768, %r47;
	mov.b32 	%f1767, %r48;
	mov.b32 	%f1766, %r49;

$L__BB6_18:
	setp.eq.s32 	%p10, %r645, 0;
	@%p10 bra 	$L__BB6_20;

	mul.f32 	%f921, %f1726, %f1761;
	fma.rn.f32 	%f922, %f1722, %f1760, %f921;
	fma.rn.f32 	%f151, %f1718, %f1759, %f922;
	mul.f32 	%f923, %f1727, %f1761;
	fma.rn.f32 	%f924, %f1723, %f1760, %f923;
	fma.rn.f32 	%f152, %f1719, %f1759, %f924;
	mul.f32 	%f925, %f1728, %f1761;
	fma.rn.f32 	%f926, %f1724, %f1760, %f925;
	fma.rn.f32 	%f153, %f1720, %f1759, %f926;
	mul.f32 	%f927, %f1729, %f1761;
	fma.rn.f32 	%f928, %f1725, %f1760, %f927;
	fma.rn.f32 	%f929, %f1721, %f1759, %f928;
	add.f32 	%f1758, %f1758, %f929;
	mul.f32 	%f930, %f1726, %f1765;
	fma.rn.f32 	%f931, %f1722, %f1764, %f930;
	fma.rn.f32 	%f155, %f1718, %f1763, %f931;
	mul.f32 	%f932, %f1727, %f1765;
	fma.rn.f32 	%f933, %f1723, %f1764, %f932;
	fma.rn.f32 	%f156, %f1719, %f1763, %f933;
	mul.f32 	%f934, %f1728, %f1765;
	fma.rn.f32 	%f935, %f1724, %f1764, %f934;
	fma.rn.f32 	%f157, %f1720, %f1763, %f935;
	mul.f32 	%f936, %f1729, %f1765;
	fma.rn.f32 	%f937, %f1725, %f1764, %f936;
	fma.rn.f32 	%f938, %f1721, %f1763, %f937;
	add.f32 	%f1762, %f1762, %f938;
	mul.f32 	%f939, %f1726, %f1769;
	fma.rn.f32 	%f940, %f1722, %f1768, %f939;
	fma.rn.f32 	%f159, %f1718, %f1767, %f940;
	mul.f32 	%f941, %f1727, %f1769;
	fma.rn.f32 	%f942, %f1723, %f1768, %f941;
	fma.rn.f32 	%f160, %f1719, %f1767, %f942;
	mul.f32 	%f943, %f1728, %f1769;
	fma.rn.f32 	%f944, %f1724, %f1768, %f943;
	fma.rn.f32 	%f161, %f1720, %f1767, %f944;
	mul.f32 	%f945, %f1729, %f1769;
	fma.rn.f32 	%f946, %f1725, %f1768, %f945;
	fma.rn.f32 	%f947, %f1721, %f1767, %f946;
	add.f32 	%f1766, %f1766, %f947;
	mov.f32 	%f1759, %f153;
	mov.f32 	%f1760, %f152;
	mov.f32 	%f1761, %f151;
	mov.f32 	%f1763, %f157;
	mov.f32 	%f1764, %f156;
	mov.f32 	%f1765, %f155;
	mov.f32 	%f1767, %f161;
	mov.f32 	%f1768, %f160;
	mov.f32 	%f1769, %f159;

$L__BB6_20:
	add.s32 	%r645, %r645, 1;
	setp.lt.u32 	%p11, %r645, %r33;
	mov.f32 	%f1718, %f1769;
	mov.f32 	%f1719, %f1768;
	mov.f32 	%f1720, %f1767;
	mov.f32 	%f1721, %f1766;
	mov.f32 	%f1722, %f1765;
	mov.f32 	%f1723, %f1764;
	mov.f32 	%f1724, %f1763;
	mov.f32 	%f1725, %f1762;
	mov.f32 	%f1726, %f1761;
	mov.f32 	%f1727, %f1760;
	mov.f32 	%f1728, %f1759;
	mov.f32 	%f1729, %f1758;
	@%p11 bra 	$L__BB6_5;

$L__BB6_21:
	mul.f32 	%f948, %f1794, %f1761;
	fma.rn.f32 	%f949, %f1795, %f1760, %f948;
	fma.rn.f32 	%f950, %f1796, %f1759, %f949;
	mul.f32 	%f951, %f1794, %f1765;
	fma.rn.f32 	%f952, %f1795, %f1764, %f951;
	fma.rn.f32 	%f953, %f1796, %f1763, %f952;
	mul.f32 	%f954, %f1794, %f1769;
	fma.rn.f32 	%f955, %f1795, %f1768, %f954;
	fma.rn.f32 	%f956, %f1796, %f1767, %f955;
	add.f32 	%f1796, %f1766, %f956;
	add.f32 	%f1795, %f1762, %f953;
	add.f32 	%f1794, %f1758, %f950;

$L__BB6_23:
	// begin inline asm
	call (%f1852), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1853), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f959), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r184), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p12, %r184, 0;
	@%p12 bra 	$L__BB6_43;

	// begin inline asm
	call (%r185), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f960), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p13, %r185, 0;
	@%p13 bra 	$L__BB6_42;

	mov.u32 	%r646, 0;

$L__BB6_26:
	.pragma "nounroll";
	// begin inline asm
	call (%rd167), _optix_get_transform_list_handle, (%r646);
	// end inline asm
	// begin inline asm
	call (%r188), _optix_get_transform_type_from_handle, (%rd167);
	// end inline asm
	or.b32  	%r189, %r188, 1;
	setp.eq.s32 	%p14, %r189, 3;
	@%p14 bra 	$L__BB6_32;
	bra.uni 	$L__BB6_27;

$L__BB6_32:
	setp.eq.s32 	%p17, %r188, 2;
	@%p17 bra 	$L__BB6_36;
	bra.uni 	$L__BB6_33;

$L__BB6_36:
	// begin inline asm
	call (%rd239), _optix_get_matrix_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r277,%r278,%r279,%r280}, [%rd241];
	// end inline asm
	add.s64 	%rd245, %rd239, 16;
	// begin inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r281,%r282,%r283,%r284}, [%rd244];
	// end inline asm
	add.s64 	%rd248, %rd239, 32;
	// begin inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r285,%r286,%r287,%r288}, [%rd247];
	// end inline asm
	add.s64 	%rd251, %rd239, 48;
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r289,%r290,%r291,%r292}, [%rd250];
	// end inline asm
	add.s64 	%rd254, %rd239, 64;
	// begin inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r293,%r294,%r295,%r296}, [%rd253];
	// end inline asm
	add.s64 	%rd257, %rd239, 80;
	// begin inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r297,%r298,%r299,%r300}, [%rd256];
	// end inline asm
	add.s64 	%rd260, %rd239, 96;
	// begin inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd259];
	// end inline asm
	add.s64 	%rd263, %rd239, 112;
	// begin inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd262];
	// end inline asm
	mov.b32 	%f1064, %r280;
	mov.b32 	%f1065, %r281;
	and.b32  	%r321, %r279, 65535;
	add.s32 	%r322, %r321, -1;
	cvt.rn.f32.s32 	%f1066, %r322;
	sub.f32 	%f1067, %f960, %f1064;
	mul.f32 	%f1068, %f1067, %f1066;
	sub.f32 	%f1069, %f1065, %f1064;
	div.rn.f32 	%f1070, %f1068, %f1069;
	min.f32 	%f1071, %f1066, %f1070;
	mov.f32 	%f1072, 0f00000000;
	max.f32 	%f1073, %f1072, %f1071;
	cvt.rmi.f32.f32 	%f1074, %f1073;
	sub.f32 	%f258, %f1073, %f1074;
	cvt.rzi.s32.f32 	%r323, %f1074;
	cvt.s64.s32 	%rd17, %r323;
	mul.wide.s32 	%rd274, %r323, 48;
	add.s64 	%rd266, %rd248, %rd274;
	// begin inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r309,%r310,%r311,%r312}, [%rd265];
	// end inline asm
	mov.b32 	%f1822, %r309;
	mov.b32 	%f1823, %r310;
	mov.b32 	%f1824, %r311;
	add.s64 	%rd269, %rd266, 16;
	// begin inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r313,%r314,%r315,%r316}, [%rd268];
	// end inline asm
	mov.b32 	%f1819, %r313;
	mov.b32 	%f1820, %r314;
	mov.b32 	%f1821, %r315;
	add.s64 	%rd272, %rd266, 32;
	// begin inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r317,%r318,%r319,%r320}, [%rd271];
	// end inline asm
	mov.b32 	%f1816, %r317;
	mov.b32 	%f1817, %r318;
	mov.b32 	%f1818, %r319;
	setp.leu.f32 	%p19, %f258, 0f00000000;
	@%p19 bra 	$L__BB6_38;

	mov.f32 	%f1075, 0f3F800000;
	sub.f32 	%f1076, %f1075, %f258;
	mul.lo.s64 	%rd284, %rd17, 48;
	add.s64 	%rd285, %rd239, %rd284;
	add.s64 	%rd276, %rd285, 80;
	// begin inline asm
	cvta.to.global.u64 %rd275, %rd276;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r324,%r325,%r326,%r327}, [%rd275];
	// end inline asm
	mov.b32 	%f1077, %r324;
	mov.b32 	%f1078, %r325;
	mov.b32 	%f1079, %r326;
	mul.f32 	%f1080, %f258, %f1077;
	mul.f32 	%f1081, %f258, %f1078;
	mul.f32 	%f1082, %f258, %f1079;
	fma.rn.f32 	%f1822, %f1076, %f1822, %f1080;
	fma.rn.f32 	%f1823, %f1076, %f1823, %f1081;
	fma.rn.f32 	%f1824, %f1076, %f1824, %f1082;
	add.s64 	%rd279, %rd285, 96;
	// begin inline asm
	cvta.to.global.u64 %rd278, %rd279;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r328,%r329,%r330,%r331}, [%rd278];
	// end inline asm
	mov.b32 	%f1083, %r328;
	mov.b32 	%f1084, %r329;
	mov.b32 	%f1085, %r330;
	mul.f32 	%f1086, %f258, %f1083;
	mul.f32 	%f1087, %f258, %f1084;
	mul.f32 	%f1088, %f258, %f1085;
	fma.rn.f32 	%f1819, %f1076, %f1819, %f1086;
	fma.rn.f32 	%f1820, %f1076, %f1820, %f1087;
	fma.rn.f32 	%f1821, %f1076, %f1821, %f1088;
	add.s64 	%rd282, %rd285, 112;
	// begin inline asm
	cvta.to.global.u64 %rd281, %rd282;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r332,%r333,%r334,%r335}, [%rd281];
	// end inline asm
	mov.b32 	%f1089, %r332;
	mov.b32 	%f1090, %r333;
	mov.b32 	%f1091, %r334;
	mul.f32 	%f1092, %f258, %f1089;
	mul.f32 	%f1093, %f258, %f1090;
	mul.f32 	%f1094, %f258, %f1091;
	fma.rn.f32 	%f1816, %f1076, %f1816, %f1092;
	fma.rn.f32 	%f1817, %f1076, %f1817, %f1093;
	fma.rn.f32 	%f1818, %f1076, %f1818, %f1094;
	bra.uni 	$L__BB6_38;

$L__BB6_27:
	mov.f32 	%f1825, 0f00000000;
	mov.f32 	%f1827, 0f3F800000;
	setp.eq.s32 	%p15, %r188, 4;
	@%p15 bra 	$L__BB6_30;

	setp.ne.s32 	%p16, %r188, 1;
	mov.f32 	%f1826, %f1825;
	mov.f32 	%f1828, %f1825;
	mov.f32 	%f1829, %f1827;
	mov.f32 	%f1830, %f1825;
	mov.f32 	%f1831, %f1827;
	mov.f32 	%f1832, %f1825;
	mov.f32 	%f1833, %f1825;
	@%p16 bra 	$L__BB6_39;

	// begin inline asm
	call (%rd169), _optix_get_static_transform_from_handle, (%rd167);
	// end inline asm
	add.s64 	%rd653, %rd169, 64;
	bra.uni 	$L__BB6_31;

$L__BB6_33:
	// begin inline asm
	call (%rd182), _optix_get_srt_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r202,%r203,%r204,%r205}, [%rd184];
	// end inline asm
	add.s64 	%rd188, %rd182, 16;
	// begin inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r206,%r207,%r208,%r209}, [%rd187];
	// end inline asm
	add.s64 	%rd191, %rd182, 32;
	// begin inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r210,%r211,%r212,%r213}, [%rd190];
	// end inline asm
	add.s64 	%rd194, %rd182, 48;
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r214,%r215,%r216,%r217}, [%rd193];
	// end inline asm
	add.s64 	%rd197, %rd182, 64;
	// begin inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r218,%r219,%r220,%r221}, [%rd196];
	// end inline asm
	add.s64 	%rd200, %rd182, 80;
	// begin inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r222,%r223,%r224,%r225}, [%rd199];
	// end inline asm
	add.s64 	%rd203, %rd182, 96;
	// begin inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r226,%r227,%r228,%r229}, [%rd202];
	// end inline asm
	add.s64 	%rd206, %rd182, 112;
	// begin inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r230,%r231,%r232,%r233}, [%rd205];
	// end inline asm
	add.s64 	%rd209, %rd182, 128;
	// begin inline asm
	cvta.to.global.u64 %rd208, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r234,%r235,%r236,%r237}, [%rd208];
	// end inline asm
	add.s64 	%rd212, %rd182, 144;
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd212;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd211];
	// end inline asm
	mov.b32 	%f972, %r205;
	mov.b32 	%f973, %r206;
	and.b32  	%r258, %r204, 65535;
	add.s32 	%r259, %r258, -1;
	cvt.rn.f32.s32 	%f974, %r259;
	sub.f32 	%f975, %f960, %f972;
	mul.f32 	%f976, %f975, %f974;
	sub.f32 	%f977, %f973, %f972;
	div.rn.f32 	%f978, %f976, %f977;
	min.f32 	%f979, %f974, %f978;
	mov.f32 	%f980, 0f00000000;
	max.f32 	%f981, %f980, %f979;
	cvt.rmi.f32.f32 	%f982, %f981;
	sub.f32 	%f218, %f981, %f982;
	cvt.rzi.s32.f32 	%r260, %f982;
	mul.wide.s32 	%rd226, %r260, 64;
	add.s64 	%rd215, %rd191, %rd226;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd214];
	// end inline asm
	mov.b32 	%f1806, %r242;
	mov.b32 	%f1807, %r243;
	mov.b32 	%f1808, %r244;
	add.s64 	%rd218, %rd215, 16;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd217];
	// end inline asm
	mov.b32 	%f1809, %r246;
	mov.b32 	%f1810, %r247;
	mov.b32 	%f1811, %r249;
	add.s64 	%rd221, %rd215, 32;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd220];
	// end inline asm
	mov.b32 	%f1812, %r251;
	mov.b32 	%f1813, %r252;
	mov.b32 	%f1814, %r253;
	add.s64 	%rd224, %rd215, 48;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd223];
	// end inline asm
	mov.b32 	%f1815, %r254;
	setp.leu.f32 	%p18, %f218, 0f00000000;
	@%p18 bra 	$L__BB6_35;

	mov.f32 	%f983, 0f3F800000;
	sub.f32 	%f984, %f983, %f218;
	add.s64 	%rd228, %rd215, 64;
	// begin inline asm
	cvta.to.global.u64 %rd227, %rd228;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r261,%r262,%r263,%r264}, [%rd227];
	// end inline asm
	mov.b32 	%f985, %r261;
	mov.b32 	%f986, %r262;
	mov.b32 	%f987, %r263;
	mul.f32 	%f988, %f218, %f985;
	mul.f32 	%f989, %f218, %f986;
	mul.f32 	%f990, %f218, %f987;
	fma.rn.f32 	%f1806, %f984, %f1806, %f988;
	fma.rn.f32 	%f1807, %f984, %f1807, %f989;
	fma.rn.f32 	%f1808, %f984, %f1808, %f990;
	add.s64 	%rd231, %rd215, 80;
	// begin inline asm
	cvta.to.global.u64 %rd230, %rd231;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r265,%r266,%r267,%r268}, [%rd230];
	// end inline asm
	mov.b32 	%f991, %r265;
	mov.b32 	%f992, %r266;
	mov.b32 	%f993, %r268;
	mul.f32 	%f994, %f218, %f991;
	mul.f32 	%f995, %f218, %f992;
	mul.f32 	%f996, %f218, %f993;
	fma.rn.f32 	%f1809, %f984, %f1809, %f994;
	fma.rn.f32 	%f1810, %f984, %f1810, %f995;
	fma.rn.f32 	%f1811, %f984, %f1811, %f996;
	add.s64 	%rd234, %rd215, 96;
	// begin inline asm
	cvta.to.global.u64 %rd233, %rd234;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r269,%r270,%r271,%r272}, [%rd233];
	// end inline asm
	mov.b32 	%f997, %r270;
	mov.b32 	%f998, %r271;
	mov.b32 	%f999, %r272;
	mul.f32 	%f1000, %f218, %f997;
	mul.f32 	%f1001, %f218, %f998;
	mul.f32 	%f1002, %f218, %f999;
	fma.rn.f32 	%f1003, %f984, %f1812, %f1000;
	fma.rn.f32 	%f1004, %f984, %f1813, %f1001;
	fma.rn.f32 	%f1005, %f984, %f1814, %f1002;
	add.s64 	%rd237, %rd215, 112;
	// begin inline asm
	cvta.to.global.u64 %rd236, %rd237;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r273,%r274,%r275,%r276}, [%rd236];
	// end inline asm
	mov.b32 	%f1006, %r273;
	mul.f32 	%f1007, %f218, %f1006;
	fma.rn.f32 	%f1008, %f984, %f1815, %f1007;
	mul.f32 	%f1009, %f1004, %f1004;
	fma.rn.f32 	%f1010, %f1003, %f1003, %f1009;
	fma.rn.f32 	%f1011, %f1005, %f1005, %f1010;
	fma.rn.f32 	%f1012, %f1008, %f1008, %f1011;
	sqrt.rn.f32 	%f1013, %f1012;
	rcp.rn.f32 	%f1014, %f1013;
	mul.f32 	%f1812, %f1003, %f1014;
	mul.f32 	%f1813, %f1004, %f1014;
	mul.f32 	%f1814, %f1005, %f1014;
	mul.f32 	%f1815, %f1014, %f1008;

$L__BB6_35:
	mul.f32 	%f1015, %f1813, %f1813;
	fma.rn.f32 	%f1016, %f1812, %f1812, %f1015;
	fma.rn.f32 	%f1017, %f1814, %f1814, %f1016;
	fma.rn.f32 	%f1018, %f1815, %f1815, %f1017;
	rcp.rn.f32 	%f1019, %f1018;
	mul.f32 	%f1020, %f1812, %f1019;
	mul.f32 	%f1021, %f1813, %f1019;
	mul.f32 	%f1022, %f1814, %f1019;
	mul.f32 	%f1023, %f1815, %f1019;
	mul.f32 	%f1024, %f1812, %f1020;
	mul.f32 	%f1025, %f1813, %f1021;
	mul.f32 	%f1026, %f1814, %f1022;
	mul.f32 	%f1027, %f1812, %f1021;
	mul.f32 	%f1028, %f1814, %f1023;
	mul.f32 	%f1029, %f1812, %f1022;
	mul.f32 	%f1030, %f1813, %f1023;
	mul.f32 	%f1031, %f1813, %f1022;
	mul.f32 	%f1032, %f1812, %f1023;
	sub.f32 	%f1033, %f1024, %f1025;
	sub.f32 	%f1034, %f1033, %f1026;
	fma.rn.f32 	%f1035, %f1815, %f1023, %f1034;
	sub.f32 	%f1036, %f1027, %f1028;
	add.f32 	%f1037, %f1036, %f1036;
	add.f32 	%f1038, %f1029, %f1030;
	add.f32 	%f1039, %f1038, %f1038;
	add.f32 	%f1040, %f1027, %f1028;
	add.f32 	%f1041, %f1040, %f1040;
	sub.f32 	%f1042, %f1025, %f1024;
	sub.f32 	%f1043, %f1042, %f1026;
	fma.rn.f32 	%f1044, %f1815, %f1023, %f1043;
	sub.f32 	%f1045, %f1031, %f1032;
	add.f32 	%f1046, %f1045, %f1045;
	sub.f32 	%f1047, %f1029, %f1030;
	add.f32 	%f1048, %f1047, %f1047;
	add.f32 	%f1049, %f1031, %f1032;
	add.f32 	%f1050, %f1049, %f1049;
	neg.f32 	%f1051, %f1024;
	sub.f32 	%f1052, %f1051, %f1025;
	add.f32 	%f1053, %f1026, %f1052;
	fma.rn.f32 	%f1054, %f1815, %f1023, %f1053;
	mul.f32 	%f1055, %f1808, %f1035;
	fma.rn.f32 	%f1056, %f1810, %f1037, %f1055;
	fma.rn.f32 	%f1824, %f1811, %f1039, %f1056;
	mul.f32 	%f1057, %f1810, %f1044;
	fma.rn.f32 	%f1058, %f1808, %f1041, %f1057;
	fma.rn.f32 	%f1821, %f1811, %f1046, %f1058;
	mul.f32 	%f1059, %f1810, %f1050;
	fma.rn.f32 	%f1060, %f1808, %f1048, %f1059;
	fma.rn.f32 	%f1818, %f1811, %f1054, %f1060;
	mul.f32 	%f1061, %f1807, %f1035;
	fma.rn.f32 	%f1823, %f1809, %f1037, %f1061;
	mul.f32 	%f1062, %f1809, %f1044;
	fma.rn.f32 	%f1820, %f1807, %f1041, %f1062;
	mul.f32 	%f1063, %f1809, %f1050;
	fma.rn.f32 	%f1817, %f1807, %f1048, %f1063;
	mul.f32 	%f1822, %f1806, %f1035;
	mul.f32 	%f1819, %f1806, %f1041;
	mul.f32 	%f1816, %f1806, %f1048;

$L__BB6_38:
	mul.f32 	%f1095, %f1817, %f1821;
	mul.f32 	%f1096, %f1818, %f1820;
	sub.f32 	%f1097, %f1096, %f1095;
	mul.f32 	%f1098, %f1822, %f1097;
	mul.f32 	%f1099, %f1816, %f1821;
	mul.f32 	%f1100, %f1818, %f1819;
	sub.f32 	%f1101, %f1100, %f1099;
	mul.f32 	%f1102, %f1101, %f1823;
	sub.f32 	%f1103, %f1098, %f1102;
	mul.f32 	%f1104, %f1816, %f1820;
	mul.f32 	%f1105, %f1817, %f1819;
	sub.f32 	%f1106, %f1105, %f1104;
	fma.rn.f32 	%f1107, %f1106, %f1824, %f1103;
	rcp.rn.f32 	%f1108, %f1107;
	mul.f32 	%f1831, %f1097, %f1108;
	mul.f32 	%f1109, %f1818, %f1823;
	mul.f32 	%f1110, %f1817, %f1824;
	sub.f32 	%f1111, %f1110, %f1109;
	mul.f32 	%f1832, %f1111, %f1108;
	mul.f32 	%f1112, %f1820, %f1824;
	mul.f32 	%f1113, %f1821, %f1823;
	sub.f32 	%f1114, %f1113, %f1112;
	mul.f32 	%f1833, %f1114, %f1108;
	sub.f32 	%f1115, %f1099, %f1100;
	mul.f32 	%f1828, %f1115, %f1108;
	mul.f32 	%f1116, %f1816, %f1824;
	mul.f32 	%f1117, %f1818, %f1822;
	sub.f32 	%f1118, %f1117, %f1116;
	mul.f32 	%f1829, %f1118, %f1108;
	mul.f32 	%f1119, %f1821, %f1822;
	mul.f32 	%f1120, %f1819, %f1824;
	sub.f32 	%f1121, %f1120, %f1119;
	mul.f32 	%f1830, %f1121, %f1108;
	mul.f32 	%f1825, %f1106, %f1108;
	mul.f32 	%f1122, %f1817, %f1822;
	mul.f32 	%f1123, %f1816, %f1823;
	sub.f32 	%f1124, %f1123, %f1122;
	mul.f32 	%f1826, %f1124, %f1108;
	mul.f32 	%f1125, %f1819, %f1823;
	mul.f32 	%f1126, %f1820, %f1822;
	sub.f32 	%f1127, %f1126, %f1125;
	mul.f32 	%f1827, %f1127, %f1108;
	bra.uni 	$L__BB6_39;

$L__BB6_30:
	// begin inline asm
	call (%rd653), _optix_get_instance_inverse_transform_from_handle, (%rd167);
	// end inline asm

$L__BB6_31:
	// begin inline asm
	cvta.to.global.u64 %rd173, %rd653;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r190,%r191,%r192,%r193}, [%rd173];
	// end inline asm
	mov.b32 	%f1831, %r190;
	mov.b32 	%f1832, %r191;
	mov.b32 	%f1833, %r192;
	add.s64 	%rd177, %rd653, 16;
	// begin inline asm
	cvta.to.global.u64 %rd176, %rd177;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r194,%r195,%r196,%r197}, [%rd176];
	// end inline asm
	mov.b32 	%f1828, %r194;
	mov.b32 	%f1829, %r195;
	mov.b32 	%f1830, %r196;
	add.s64 	%rd180, %rd653, 32;
	// begin inline asm
	cvta.to.global.u64 %rd179, %rd180;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r198,%r199,%r200,%r201}, [%rd179];
	// end inline asm
	mov.b32 	%f1825, %r198;
	mov.b32 	%f1826, %r199;
	mov.b32 	%f1827, %r200;

$L__BB6_39:
	setp.eq.s32 	%p20, %r646, 0;
	@%p20 bra 	$L__BB6_41;

	mul.f32 	%f1128, %f1802, %f1832;
	fma.rn.f32 	%f1129, %f1799, %f1831, %f1128;
	fma.rn.f32 	%f304, %f1805, %f1833, %f1129;
	mul.f32 	%f1130, %f1801, %f1832;
	fma.rn.f32 	%f1131, %f1798, %f1831, %f1130;
	fma.rn.f32 	%f305, %f1804, %f1833, %f1131;
	mul.f32 	%f1132, %f1800, %f1832;
	fma.rn.f32 	%f1133, %f1797, %f1831, %f1132;
	fma.rn.f32 	%f1833, %f1803, %f1833, %f1133;
	mul.f32 	%f1134, %f1802, %f1829;
	fma.rn.f32 	%f1135, %f1799, %f1828, %f1134;
	fma.rn.f32 	%f307, %f1805, %f1830, %f1135;
	mul.f32 	%f1136, %f1801, %f1829;
	fma.rn.f32 	%f1137, %f1798, %f1828, %f1136;
	fma.rn.f32 	%f308, %f1804, %f1830, %f1137;
	mul.f32 	%f1138, %f1800, %f1829;
	fma.rn.f32 	%f1139, %f1797, %f1828, %f1138;
	fma.rn.f32 	%f1830, %f1803, %f1830, %f1139;
	mul.f32 	%f1140, %f1802, %f1826;
	fma.rn.f32 	%f1141, %f1799, %f1825, %f1140;
	fma.rn.f32 	%f310, %f1805, %f1827, %f1141;
	mul.f32 	%f1142, %f1801, %f1826;
	fma.rn.f32 	%f1143, %f1798, %f1825, %f1142;
	fma.rn.f32 	%f311, %f1804, %f1827, %f1143;
	mul.f32 	%f1144, %f1800, %f1826;
	fma.rn.f32 	%f1145, %f1797, %f1825, %f1144;
	fma.rn.f32 	%f1827, %f1803, %f1827, %f1145;
	mov.f32 	%f1825, %f310;
	mov.f32 	%f1826, %f311;
	mov.f32 	%f1828, %f307;
	mov.f32 	%f1829, %f308;
	mov.f32 	%f1831, %f304;
	mov.f32 	%f1832, %f305;

$L__BB6_41:
	add.s32 	%r646, %r646, 1;
	setp.lt.u32 	%p21, %r646, %r185;
	mov.f32 	%f1797, %f1833;
	mov.f32 	%f1798, %f1832;
	mov.f32 	%f1799, %f1831;
	mov.f32 	%f1800, %f1830;
	mov.f32 	%f1801, %f1829;
	mov.f32 	%f1802, %f1828;
	mov.f32 	%f1803, %f1827;
	mov.f32 	%f1804, %f1826;
	mov.f32 	%f1805, %f1825;
	@%p21 bra 	$L__BB6_26;

$L__BB6_42:
	mul.f32 	%f1146, %f1853, %f1832;
	fma.rn.f32 	%f1147, %f1852, %f1831, %f1146;
	mul.f32 	%f1148, %f1853, %f1829;
	fma.rn.f32 	%f1149, %f1852, %f1828, %f1148;
	mul.f32 	%f1150, %f1853, %f1826;
	fma.rn.f32 	%f1151, %f1852, %f1825, %f1150;
	fma.rn.f32 	%f1854, %f959, %f1827, %f1151;
	fma.rn.f32 	%f1853, %f959, %f1830, %f1149;
	fma.rn.f32 	%f1852, %f959, %f1833, %f1147;
	bra.uni 	$L__BB6_44;

$L__BB6_43:
	mov.f32 	%f1854, %f959;

$L__BB6_44:
	add.s64 	%rd18, %rd3, 80;
	ld.v4.f32 	{%f1155, %f1156, %f1157, %f1158}, [%rd3+80];
	ld.f32 	%f1162, [%rd3+32];
	fma.rn.f32 	%f1163, %f1794, %f1162, %f1155;
	ld.f32 	%f1164, [%rd3+36];
	fma.rn.f32 	%f1165, %f1794, %f1164, %f1156;
	ld.f32 	%f1166, [%rd3+40];
	fma.rn.f32 	%f1167, %f1794, %f1166, %f1157;
	ld.f32 	%f1168, [%rd3+48];
	fma.rn.f32 	%f1169, %f1795, %f1168, %f1163;
	ld.f32 	%f1170, [%rd3+52];
	fma.rn.f32 	%f1171, %f1795, %f1170, %f1165;
	ld.f32 	%f1172, [%rd3+56];
	fma.rn.f32 	%f1173, %f1795, %f1172, %f1167;
	ld.f32 	%f1174, [%rd3+64];
	fma.rn.f32 	%f1175, %f1796, %f1174, %f1169;
	ld.f32 	%f1176, [%rd3+68];
	fma.rn.f32 	%f1177, %f1796, %f1176, %f1171;
	ld.f32 	%f1178, [%rd3+72];
	fma.rn.f32 	%f1179, %f1796, %f1178, %f1173;
	ld.v4.f32 	{%f1180, %f1181, %f1182, %f1183}, [%rd3+32];
	mul.f32 	%f1187, %f1852, %f1180;
	mul.f32 	%f1188, %f1852, %f1181;
	mul.f32 	%f1189, %f1852, %f1182;
	fma.rn.f32 	%f1190, %f1853, %f1168, %f1187;
	fma.rn.f32 	%f1191, %f1853, %f1170, %f1188;
	fma.rn.f32 	%f1192, %f1853, %f1172, %f1189;
	fma.rn.f32 	%f1193, %f1854, %f1174, %f1190;
	fma.rn.f32 	%f1194, %f1854, %f1176, %f1191;
	fma.rn.f32 	%f1195, %f1854, %f1178, %f1192;
	rcp.rn.f32 	%f1196, %f1195;
	mul.f32 	%f1197, %f1179, %f1196;
	neg.f32 	%f346, %f1197;
	fma.rn.f32 	%f347, %f346, %f1193, %f1175;
	fma.rn.f32 	%f348, %f346, %f1194, %f1177;
	ld.const.u64 	%rd19, [params+80];
	setp.eq.s64 	%p22, %rd19, 0;
	cvt.u64.u32 	%rd20, %r1;
	mov.f32 	%f1989, 0f00000000;
	mov.f32 	%f1990, 0f00000000;
	mov.f32 	%f1991, 0f00000000;
	@%p22 bra 	$L__BB6_49;

	ld.u64 	%rd286, [%rd47];
	ld.const.u64 	%rd287, [params+328];
	cvta.to.global.u64 	%rd288, %rd287;
	shl.b64 	%rd289, %rd20, 3;
	add.s64 	%rd290, %rd288, %rd289;
	st.global.u64 	[%rd290], %rd286;
	ld.const.u64 	%rd291, [params+336];
	cvta.to.global.u64 	%rd292, %rd291;
	shl.b64 	%rd293, %rd20, 2;
	add.s64 	%rd294, %rd292, %rd293;
	mov.u32 	%r336, 0;
	st.global.u32 	[%rd294], %r336;
	ld.const.u64 	%rd295, [params+344];
	cvta.to.global.u64 	%rd296, %rd295;
	add.s64 	%rd21, %rd296, %rd293;
	ld.global.u32 	%r10, [%rd21];
	setp.eq.s32 	%p23, %r10, 0;
	@%p23 bra 	$L__BB6_48;

	// begin inline asm
	call (%r337), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p24, %r337, %r10;
	@%p24 bra 	$L__BB6_48;

	st.global.u32 	[%rd21], %r337;

$L__BB6_48:
	cvta.to.global.u64 	%rd297, %rd19;
	add.s64 	%rd299, %rd297, %rd293;
	st.global.f32 	[%rd299], %f347;
	ld.const.u64 	%rd300, [params+88];
	cvta.to.global.u64 	%rd301, %rd300;
	add.s64 	%rd302, %rd301, %rd293;
	st.global.f32 	[%rd302], %f348;
	ld.const.u64 	%rd303, [params+72];
	cvta.to.global.u64 	%rd304, %rd303;
	add.s64 	%rd305, %rd304, %rd293;
	st.global.f32 	[%rd305], %f346;
	bra.uni 	$L__BB6_109;

$L__BB6_49:
	fma.rn.f32 	%f2004, %f346, %f1852, %f1794;
	fma.rn.f32 	%f2005, %f346, %f1853, %f1795;
	fma.rn.f32 	%f2006, %f346, %f1854, %f1796;
	fma.rn.f32 	%f352, %f347, 0f3F000000, 0f3F000000;
	fma.rn.f32 	%f353, %f348, 0f3F000000, 0f3F000000;
	ld.v4.f32 	{%f2001, %f2002, %f2003, %f1204}, [%rd18+80];
	ld.v4.f32 	{%f1995, %f1996, %f1997, %f1208}, [%rd18+96];
	ld.v4.f32 	{%f1992, %f1993, %f1994, %f1212}, [%rd18+112];
	ld.u64 	%rd22, [%rd47];
	ld.const.u64 	%rd306, [params+344];
	cvta.to.global.u64 	%rd307, %rd306;
	shl.b64 	%rd308, %rd20, 2;
	add.s64 	%rd23, %rd307, %rd308;
	ld.global.u32 	%r12, [%rd23];
	setp.eq.s32 	%p25, %r12, 0;
	mov.f32 	%f1998, %f2001;
	mov.f32 	%f1999, %f2002;
	mov.f32 	%f2000, %f2003;
	@%p25 bra 	$L__BB6_97;

	// begin inline asm
	call (%r338), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p26, %r338, %r12;
	mov.f32 	%f1998, %f2001;
	mov.f32 	%f1999, %f2002;
	mov.f32 	%f2000, %f2003;
	@%p26 bra 	$L__BB6_97;

	// begin inline asm
	call (%r339), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p27, %r339, 0;
	mov.f32 	%f1954, 0f00000000;
	mov.f32 	%f1953, 0f3F800000;
	mov.f32 	%f1891, %f1953;
	mov.f32 	%f1892, %f1954;
	mov.f32 	%f1893, %f1954;
	mov.f32 	%f1894, %f1954;
	mov.f32 	%f1887, %f1954;
	mov.f32 	%f1888, %f1953;
	mov.f32 	%f1889, %f1954;
	mov.f32 	%f1890, %f1954;
	mov.f32 	%f1883, %f1954;
	mov.f32 	%f1884, %f1954;
	mov.f32 	%f1885, %f1953;
	mov.f32 	%f1886, %f1954;
	@%p27 bra 	$L__BB6_69;

	// begin inline asm
	call (%r340), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1228), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p28, %r340, 1;
	@%p28 bra 	$L__BB6_69;

	add.s32 	%r647, %r340, 1;
	mov.u32 	%r648, 1;

$L__BB6_54:
	.pragma "nounroll";
	add.s32 	%r342, %r647, -2;
	// begin inline asm
	call (%rd309), _optix_get_transform_list_handle, (%r342);
	// end inline asm
	// begin inline asm
	call (%r343), _optix_get_transform_type_from_handle, (%rd309);
	// end inline asm
	or.b32  	%r344, %r343, 1;
	setp.eq.s32 	%p29, %r344, 3;
	@%p29 bra 	$L__BB6_60;
	bra.uni 	$L__BB6_55;

$L__BB6_60:
	setp.eq.s32 	%p32, %r343, 2;
	@%p32 bra 	$L__BB6_64;
	bra.uni 	$L__BB6_61;

$L__BB6_64:
	// begin inline asm
	call (%rd381), _optix_get_matrix_motion_transform_from_handle, (%rd309);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd383, %rd381;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r432,%r433,%r434,%r435}, [%rd383];
	// end inline asm
	add.s64 	%rd387, %rd381, 16;
	// begin inline asm
	cvta.to.global.u64 %rd386, %rd387;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r436,%r437,%r438,%r439}, [%rd386];
	// end inline asm
	add.s64 	%rd390, %rd381, 32;
	// begin inline asm
	cvta.to.global.u64 %rd389, %rd390;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r440,%r441,%r442,%r443}, [%rd389];
	// end inline asm
	add.s64 	%rd393, %rd381, 48;
	// begin inline asm
	cvta.to.global.u64 %rd392, %rd393;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r444,%r445,%r446,%r447}, [%rd392];
	// end inline asm
	add.s64 	%rd396, %rd381, 64;
	// begin inline asm
	cvta.to.global.u64 %rd395, %rd396;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r448,%r449,%r450,%r451}, [%rd395];
	// end inline asm
	add.s64 	%rd399, %rd381, 80;
	// begin inline asm
	cvta.to.global.u64 %rd398, %rd399;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r452,%r453,%r454,%r455}, [%rd398];
	// end inline asm
	add.s64 	%rd402, %rd381, 96;
	// begin inline asm
	cvta.to.global.u64 %rd401, %rd402;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r456,%r457,%r458,%r459}, [%rd401];
	// end inline asm
	add.s64 	%rd405, %rd381, 112;
	// begin inline asm
	cvta.to.global.u64 %rd404, %rd405;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r460,%r461,%r462,%r463}, [%rd404];
	// end inline asm
	mov.b32 	%f1356, %r435;
	mov.b32 	%f1357, %r436;
	and.b32  	%r476, %r434, 65535;
	add.s32 	%r477, %r476, -1;
	cvt.rn.f32.s32 	%f1358, %r477;
	sub.f32 	%f1359, %f1228, %f1356;
	mul.f32 	%f1360, %f1359, %f1358;
	sub.f32 	%f1361, %f1357, %f1356;
	div.rn.f32 	%f1362, %f1360, %f1361;
	min.f32 	%f1363, %f1358, %f1362;
	mov.f32 	%f1364, 0f00000000;
	max.f32 	%f1365, %f1364, %f1363;
	cvt.rmi.f32.f32 	%f1366, %f1365;
	sub.f32 	%f449, %f1365, %f1366;
	cvt.rzi.s32.f32 	%r478, %f1366;
	cvt.s64.s32 	%rd30, %r478;
	mul.wide.s32 	%rd416, %r478, 48;
	add.s64 	%rd408, %rd390, %rd416;
	// begin inline asm
	cvta.to.global.u64 %rd407, %rd408;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r464,%r465,%r466,%r467}, [%rd407];
	// end inline asm
	mov.b32 	%f1891, %r464;
	mov.b32 	%f1892, %r465;
	mov.b32 	%f1893, %r466;
	mov.b32 	%f1894, %r467;
	add.s64 	%rd411, %rd408, 16;
	// begin inline asm
	cvta.to.global.u64 %rd410, %rd411;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r468,%r469,%r470,%r471}, [%rd410];
	// end inline asm
	mov.b32 	%f1887, %r468;
	mov.b32 	%f1888, %r469;
	mov.b32 	%f1889, %r470;
	mov.b32 	%f1890, %r471;
	add.s64 	%rd414, %rd408, 32;
	// begin inline asm
	cvta.to.global.u64 %rd413, %rd414;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r472,%r473,%r474,%r475}, [%rd413];
	// end inline asm
	mov.b32 	%f1883, %r472;
	mov.b32 	%f1884, %r473;
	mov.b32 	%f1885, %r474;
	mov.b32 	%f1886, %r475;
	setp.leu.f32 	%p34, %f449, 0f00000000;
	@%p34 bra 	$L__BB6_66;

	mov.f32 	%f1367, 0f3F800000;
	sub.f32 	%f1368, %f1367, %f449;
	mul.lo.s64 	%rd426, %rd30, 48;
	add.s64 	%rd427, %rd381, %rd426;
	add.s64 	%rd418, %rd427, 80;
	// begin inline asm
	cvta.to.global.u64 %rd417, %rd418;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r479,%r480,%r481,%r482}, [%rd417];
	// end inline asm
	mov.b32 	%f1369, %r479;
	mov.b32 	%f1370, %r480;
	mov.b32 	%f1371, %r481;
	mov.b32 	%f1372, %r482;
	mul.f32 	%f1373, %f449, %f1369;
	mul.f32 	%f1374, %f449, %f1370;
	mul.f32 	%f1375, %f449, %f1371;
	mul.f32 	%f1376, %f449, %f1372;
	fma.rn.f32 	%f1891, %f1368, %f1891, %f1373;
	fma.rn.f32 	%f1892, %f1368, %f1892, %f1374;
	fma.rn.f32 	%f1893, %f1368, %f1893, %f1375;
	fma.rn.f32 	%f1894, %f1368, %f1894, %f1376;
	add.s64 	%rd421, %rd427, 96;
	// begin inline asm
	cvta.to.global.u64 %rd420, %rd421;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r483,%r484,%r485,%r486}, [%rd420];
	// end inline asm
	mov.b32 	%f1377, %r483;
	mov.b32 	%f1378, %r484;
	mov.b32 	%f1379, %r485;
	mov.b32 	%f1380, %r486;
	mul.f32 	%f1381, %f449, %f1377;
	mul.f32 	%f1382, %f449, %f1378;
	mul.f32 	%f1383, %f449, %f1379;
	mul.f32 	%f1384, %f449, %f1380;
	fma.rn.f32 	%f1887, %f1368, %f1887, %f1381;
	fma.rn.f32 	%f1888, %f1368, %f1888, %f1382;
	fma.rn.f32 	%f1889, %f1368, %f1889, %f1383;
	fma.rn.f32 	%f1890, %f1368, %f1890, %f1384;
	add.s64 	%rd424, %rd427, 112;
	// begin inline asm
	cvta.to.global.u64 %rd423, %rd424;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r487,%r488,%r489,%r490}, [%rd423];
	// end inline asm
	mov.b32 	%f1385, %r487;
	mov.b32 	%f1386, %r488;
	mov.b32 	%f1387, %r489;
	mov.b32 	%f1388, %r490;
	mul.f32 	%f1389, %f449, %f1385;
	mul.f32 	%f1390, %f449, %f1386;
	mul.f32 	%f1391, %f449, %f1387;
	mul.f32 	%f1392, %f449, %f1388;
	fma.rn.f32 	%f1883, %f1368, %f1883, %f1389;
	fma.rn.f32 	%f1884, %f1368, %f1884, %f1390;
	fma.rn.f32 	%f1885, %f1368, %f1885, %f1391;
	fma.rn.f32 	%f1886, %f1368, %f1886, %f1392;
	bra.uni 	$L__BB6_66;

$L__BB6_55:
	mov.f32 	%f1883, 0f00000000;
	mov.f32 	%f1885, 0f3F800000;
	setp.eq.s32 	%p30, %r343, 4;
	@%p30 bra 	$L__BB6_58;

	setp.ne.s32 	%p31, %r343, 1;
	mov.f32 	%f1884, %f1883;
	mov.f32 	%f1886, %f1883;
	mov.f32 	%f1887, %f1883;
	mov.f32 	%f1888, %f1885;
	mov.f32 	%f1889, %f1883;
	mov.f32 	%f1890, %f1883;
	mov.f32 	%f1891, %f1885;
	mov.f32 	%f1892, %f1883;
	mov.f32 	%f1893, %f1883;
	mov.f32 	%f1894, %f1883;
	@%p31 bra 	$L__BB6_66;

	// begin inline asm
	call (%rd311), _optix_get_static_transform_from_handle, (%rd309);
	// end inline asm
	add.s64 	%rd654, %rd311, 16;
	bra.uni 	$L__BB6_59;

$L__BB6_61:
	// begin inline asm
	call (%rd324), _optix_get_srt_motion_transform_from_handle, (%rd309);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd326, %rd324;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r357,%r358,%r359,%r360}, [%rd326];
	// end inline asm
	add.s64 	%rd330, %rd324, 16;
	// begin inline asm
	cvta.to.global.u64 %rd329, %rd330;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r361,%r362,%r363,%r364}, [%rd329];
	// end inline asm
	add.s64 	%rd333, %rd324, 32;
	// begin inline asm
	cvta.to.global.u64 %rd332, %rd333;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r365,%r366,%r367,%r368}, [%rd332];
	// end inline asm
	add.s64 	%rd336, %rd324, 48;
	// begin inline asm
	cvta.to.global.u64 %rd335, %rd336;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r369,%r370,%r371,%r372}, [%rd335];
	// end inline asm
	add.s64 	%rd339, %rd324, 64;
	// begin inline asm
	cvta.to.global.u64 %rd338, %rd339;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r373,%r374,%r375,%r376}, [%rd338];
	// end inline asm
	add.s64 	%rd342, %rd324, 80;
	// begin inline asm
	cvta.to.global.u64 %rd341, %rd342;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r377,%r378,%r379,%r380}, [%rd341];
	// end inline asm
	add.s64 	%rd345, %rd324, 96;
	// begin inline asm
	cvta.to.global.u64 %rd344, %rd345;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r381,%r382,%r383,%r384}, [%rd344];
	// end inline asm
	add.s64 	%rd348, %rd324, 112;
	// begin inline asm
	cvta.to.global.u64 %rd347, %rd348;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r385,%r386,%r387,%r388}, [%rd347];
	// end inline asm
	add.s64 	%rd351, %rd324, 128;
	// begin inline asm
	cvta.to.global.u64 %rd350, %rd351;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r389,%r390,%r391,%r392}, [%rd350];
	// end inline asm
	add.s64 	%rd354, %rd324, 144;
	// begin inline asm
	cvta.to.global.u64 %rd353, %rd354;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r393,%r394,%r395,%r396}, [%rd353];
	// end inline asm
	mov.b32 	%f1243, %r360;
	mov.b32 	%f1244, %r361;
	and.b32  	%r413, %r359, 65535;
	add.s32 	%r414, %r413, -1;
	cvt.rn.f32.s32 	%f1245, %r414;
	sub.f32 	%f1246, %f1228, %f1243;
	mul.f32 	%f1247, %f1246, %f1245;
	sub.f32 	%f1248, %f1244, %f1243;
	div.rn.f32 	%f1249, %f1247, %f1248;
	min.f32 	%f1250, %f1245, %f1249;
	mov.f32 	%f1251, 0f00000000;
	max.f32 	%f1252, %f1251, %f1250;
	cvt.rmi.f32.f32 	%f1253, %f1252;
	sub.f32 	%f388, %f1252, %f1253;
	cvt.rzi.s32.f32 	%r415, %f1253;
	mul.wide.s32 	%rd368, %r415, 64;
	add.s64 	%rd357, %rd333, %rd368;
	// begin inline asm
	cvta.to.global.u64 %rd356, %rd357;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r397,%r398,%r399,%r400}, [%rd356];
	// end inline asm
	mov.b32 	%f1867, %r397;
	mov.b32 	%f1868, %r398;
	mov.b32 	%f1869, %r399;
	mov.b32 	%f1870, %r400;
	add.s64 	%rd360, %rd357, 16;
	// begin inline asm
	cvta.to.global.u64 %rd359, %rd360;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r401,%r402,%r403,%r404}, [%rd359];
	// end inline asm
	mov.b32 	%f1871, %r401;
	mov.b32 	%f1872, %r402;
	mov.b32 	%f1873, %r403;
	mov.b32 	%f1874, %r404;
	add.s64 	%rd363, %rd357, 32;
	// begin inline asm
	cvta.to.global.u64 %rd362, %rd363;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r405,%r406,%r407,%r408}, [%rd362];
	// end inline asm
	mov.b32 	%f1875, %r405;
	mov.b32 	%f1876, %r406;
	mov.b32 	%f1877, %r407;
	mov.b32 	%f1878, %r408;
	add.s64 	%rd366, %rd357, 48;
	// begin inline asm
	cvta.to.global.u64 %rd365, %rd366;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r409,%r410,%r411,%r412}, [%rd365];
	// end inline asm
	mov.b32 	%f1879, %r409;
	mov.b32 	%f1880, %r410;
	mov.b32 	%f1881, %r411;
	mov.b32 	%f1882, %r412;
	setp.leu.f32 	%p33, %f388, 0f00000000;
	@%p33 bra 	$L__BB6_63;

	mov.f32 	%f1254, 0f3F800000;
	sub.f32 	%f1255, %f1254, %f388;
	add.s64 	%rd370, %rd357, 64;
	// begin inline asm
	cvta.to.global.u64 %rd369, %rd370;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r416,%r417,%r418,%r419}, [%rd369];
	// end inline asm
	mov.b32 	%f1256, %r416;
	mov.b32 	%f1257, %r417;
	mov.b32 	%f1258, %r418;
	mov.b32 	%f1259, %r419;
	mul.f32 	%f1260, %f388, %f1256;
	mul.f32 	%f1261, %f388, %f1257;
	mul.f32 	%f1262, %f388, %f1258;
	mul.f32 	%f1263, %f388, %f1259;
	fma.rn.f32 	%f1867, %f1255, %f1867, %f1260;
	fma.rn.f32 	%f1868, %f1255, %f1868, %f1261;
	fma.rn.f32 	%f1869, %f1255, %f1869, %f1262;
	fma.rn.f32 	%f1870, %f1255, %f1870, %f1263;
	add.s64 	%rd373, %rd357, 80;
	// begin inline asm
	cvta.to.global.u64 %rd372, %rd373;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r420,%r421,%r422,%r423}, [%rd372];
	// end inline asm
	mov.b32 	%f1264, %r420;
	mov.b32 	%f1265, %r421;
	mov.b32 	%f1266, %r422;
	mov.b32 	%f1267, %r423;
	mul.f32 	%f1268, %f388, %f1264;
	mul.f32 	%f1269, %f388, %f1265;
	mul.f32 	%f1270, %f388, %f1266;
	mul.f32 	%f1271, %f388, %f1267;
	fma.rn.f32 	%f1871, %f1255, %f1871, %f1268;
	fma.rn.f32 	%f1872, %f1255, %f1872, %f1269;
	fma.rn.f32 	%f1873, %f1255, %f1873, %f1270;
	fma.rn.f32 	%f1874, %f1255, %f1874, %f1271;
	add.s64 	%rd376, %rd357, 96;
	// begin inline asm
	cvta.to.global.u64 %rd375, %rd376;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r424,%r425,%r426,%r427}, [%rd375];
	// end inline asm
	mov.b32 	%f1272, %r424;
	mov.b32 	%f1273, %r425;
	mov.b32 	%f1274, %r426;
	mov.b32 	%f1275, %r427;
	mul.f32 	%f1276, %f388, %f1272;
	mul.f32 	%f1277, %f388, %f1273;
	mul.f32 	%f1278, %f388, %f1274;
	mul.f32 	%f1279, %f388, %f1275;
	fma.rn.f32 	%f1875, %f1255, %f1875, %f1276;
	fma.rn.f32 	%f1280, %f1255, %f1876, %f1277;
	fma.rn.f32 	%f1281, %f1255, %f1877, %f1278;
	fma.rn.f32 	%f1282, %f1255, %f1878, %f1279;
	add.s64 	%rd379, %rd357, 112;
	// begin inline asm
	cvta.to.global.u64 %rd378, %rd379;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r428,%r429,%r430,%r431}, [%rd378];
	// end inline asm
	mov.b32 	%f1283, %r428;
	mov.b32 	%f1284, %r429;
	mov.b32 	%f1285, %r430;
	mov.b32 	%f1286, %r431;
	mul.f32 	%f1287, %f388, %f1283;
	mul.f32 	%f1288, %f388, %f1284;
	mul.f32 	%f1289, %f388, %f1285;
	mul.f32 	%f1290, %f388, %f1286;
	fma.rn.f32 	%f1291, %f1255, %f1879, %f1287;
	fma.rn.f32 	%f1880, %f1255, %f1880, %f1288;
	fma.rn.f32 	%f1881, %f1255, %f1881, %f1289;
	fma.rn.f32 	%f1882, %f1255, %f1882, %f1290;
	mul.f32 	%f1292, %f1281, %f1281;
	fma.rn.f32 	%f1293, %f1280, %f1280, %f1292;
	fma.rn.f32 	%f1294, %f1282, %f1282, %f1293;
	fma.rn.f32 	%f1295, %f1291, %f1291, %f1294;
	sqrt.rn.f32 	%f1296, %f1295;
	rcp.rn.f32 	%f1297, %f1296;
	mul.f32 	%f1876, %f1280, %f1297;
	mul.f32 	%f1877, %f1281, %f1297;
	mul.f32 	%f1878, %f1282, %f1297;
	mul.f32 	%f1879, %f1297, %f1291;

$L__BB6_63:
	mul.f32 	%f1298, %f1877, %f1877;
	fma.rn.f32 	%f1299, %f1876, %f1876, %f1298;
	fma.rn.f32 	%f1300, %f1878, %f1878, %f1299;
	fma.rn.f32 	%f1301, %f1879, %f1879, %f1300;
	rcp.rn.f32 	%f1302, %f1301;
	mul.f32 	%f1303, %f1876, %f1302;
	mul.f32 	%f1304, %f1877, %f1302;
	mul.f32 	%f1305, %f1878, %f1302;
	mul.f32 	%f1306, %f1879, %f1302;
	mul.f32 	%f1307, %f1876, %f1303;
	mul.f32 	%f1308, %f1877, %f1304;
	mul.f32 	%f1309, %f1878, %f1305;
	mul.f32 	%f1310, %f1876, %f1304;
	mul.f32 	%f1311, %f1878, %f1306;
	mul.f32 	%f1312, %f1876, %f1305;
	mul.f32 	%f1313, %f1877, %f1306;
	mul.f32 	%f1314, %f1877, %f1305;
	mul.f32 	%f1315, %f1876, %f1306;
	sub.f32 	%f1316, %f1307, %f1308;
	sub.f32 	%f1317, %f1316, %f1309;
	fma.rn.f32 	%f1318, %f1879, %f1306, %f1317;
	sub.f32 	%f1319, %f1310, %f1311;
	add.f32 	%f1320, %f1319, %f1319;
	add.f32 	%f1321, %f1312, %f1313;
	add.f32 	%f1322, %f1321, %f1321;
	add.f32 	%f1323, %f1310, %f1311;
	add.f32 	%f1324, %f1323, %f1323;
	sub.f32 	%f1325, %f1308, %f1307;
	sub.f32 	%f1326, %f1325, %f1309;
	fma.rn.f32 	%f1327, %f1879, %f1306, %f1326;
	sub.f32 	%f1328, %f1314, %f1315;
	add.f32 	%f1329, %f1328, %f1328;
	sub.f32 	%f1330, %f1312, %f1313;
	add.f32 	%f1331, %f1330, %f1330;
	add.f32 	%f1332, %f1314, %f1315;
	add.f32 	%f1333, %f1332, %f1332;
	neg.f32 	%f1334, %f1307;
	sub.f32 	%f1335, %f1334, %f1308;
	add.f32 	%f1336, %f1309, %f1335;
	fma.rn.f32 	%f1337, %f1879, %f1306, %f1336;
	mul.f32 	%f1338, %f1870, %f1318;
	fma.rn.f32 	%f1339, %f1873, %f1320, %f1338;
	fma.rn.f32 	%f1340, %f1875, %f1322, %f1339;
	sub.f32 	%f1894, %f1880, %f1340;
	mul.f32 	%f1341, %f1873, %f1327;
	fma.rn.f32 	%f1342, %f1870, %f1324, %f1341;
	fma.rn.f32 	%f1343, %f1875, %f1329, %f1342;
	sub.f32 	%f1890, %f1881, %f1343;
	mul.f32 	%f1344, %f1873, %f1333;
	fma.rn.f32 	%f1345, %f1870, %f1331, %f1344;
	fma.rn.f32 	%f1346, %f1875, %f1337, %f1345;
	sub.f32 	%f1886, %f1882, %f1346;
	mul.f32 	%f1347, %f1869, %f1318;
	fma.rn.f32 	%f1348, %f1872, %f1320, %f1347;
	fma.rn.f32 	%f1893, %f1874, %f1322, %f1348;
	mul.f32 	%f1349, %f1872, %f1327;
	fma.rn.f32 	%f1350, %f1869, %f1324, %f1349;
	fma.rn.f32 	%f1889, %f1874, %f1329, %f1350;
	mul.f32 	%f1351, %f1872, %f1333;
	fma.rn.f32 	%f1352, %f1869, %f1331, %f1351;
	fma.rn.f32 	%f1885, %f1874, %f1337, %f1352;
	mul.f32 	%f1353, %f1868, %f1318;
	fma.rn.f32 	%f1892, %f1871, %f1320, %f1353;
	mul.f32 	%f1354, %f1871, %f1327;
	fma.rn.f32 	%f1888, %f1868, %f1324, %f1354;
	mul.f32 	%f1355, %f1871, %f1333;
	fma.rn.f32 	%f1884, %f1868, %f1331, %f1355;
	mul.f32 	%f1891, %f1867, %f1318;
	mul.f32 	%f1887, %f1867, %f1324;
	mul.f32 	%f1883, %f1867, %f1331;
	bra.uni 	$L__BB6_66;

$L__BB6_58:
	// begin inline asm
	call (%rd654), _optix_get_instance_transform_from_handle, (%rd309);
	// end inline asm

$L__BB6_59:
	// begin inline asm
	cvta.to.global.u64 %rd315, %rd654;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r345,%r346,%r347,%r348}, [%rd315];
	// end inline asm
	mov.b32 	%f1891, %r345;
	mov.b32 	%f1892, %r346;
	mov.b32 	%f1893, %r347;
	mov.b32 	%f1894, %r348;
	add.s64 	%rd319, %rd654, 16;
	// begin inline asm
	cvta.to.global.u64 %rd318, %rd319;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r349,%r350,%r351,%r352}, [%rd318];
	// end inline asm
	mov.b32 	%f1887, %r349;
	mov.b32 	%f1888, %r350;
	mov.b32 	%f1889, %r351;
	mov.b32 	%f1890, %r352;
	add.s64 	%rd322, %rd654, 32;
	// begin inline asm
	cvta.to.global.u64 %rd321, %rd322;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r353,%r354,%r355,%r356}, [%rd321];
	// end inline asm
	mov.b32 	%f1883, %r353;
	mov.b32 	%f1884, %r354;
	mov.b32 	%f1885, %r355;
	mov.b32 	%f1886, %r356;

$L__BB6_66:
	setp.eq.s32 	%p35, %r648, 1;
	@%p35 bra 	$L__BB6_68;

	mul.f32 	%f1393, %f1862, %f1892;
	fma.rn.f32 	%f1394, %f1858, %f1891, %f1393;
	fma.rn.f32 	%f486, %f1866, %f1893, %f1394;
	mul.f32 	%f1395, %f1861, %f1892;
	fma.rn.f32 	%f1396, %f1857, %f1891, %f1395;
	fma.rn.f32 	%f487, %f1865, %f1893, %f1396;
	mul.f32 	%f1397, %f1860, %f1892;
	fma.rn.f32 	%f1398, %f1856, %f1891, %f1397;
	fma.rn.f32 	%f488, %f1864, %f1893, %f1398;
	mul.f32 	%f1399, %f1859, %f1892;
	fma.rn.f32 	%f1400, %f1855, %f1891, %f1399;
	fma.rn.f32 	%f1401, %f1863, %f1893, %f1400;
	add.f32 	%f1894, %f1894, %f1401;
	mul.f32 	%f1402, %f1862, %f1888;
	fma.rn.f32 	%f1403, %f1858, %f1887, %f1402;
	fma.rn.f32 	%f490, %f1866, %f1889, %f1403;
	mul.f32 	%f1404, %f1861, %f1888;
	fma.rn.f32 	%f1405, %f1857, %f1887, %f1404;
	fma.rn.f32 	%f491, %f1865, %f1889, %f1405;
	mul.f32 	%f1406, %f1860, %f1888;
	fma.rn.f32 	%f1407, %f1856, %f1887, %f1406;
	fma.rn.f32 	%f492, %f1864, %f1889, %f1407;
	mul.f32 	%f1408, %f1859, %f1888;
	fma.rn.f32 	%f1409, %f1855, %f1887, %f1408;
	fma.rn.f32 	%f1410, %f1863, %f1889, %f1409;
	add.f32 	%f1890, %f1890, %f1410;
	mul.f32 	%f1411, %f1862, %f1884;
	fma.rn.f32 	%f1412, %f1858, %f1883, %f1411;
	fma.rn.f32 	%f494, %f1866, %f1885, %f1412;
	mul.f32 	%f1413, %f1861, %f1884;
	fma.rn.f32 	%f1414, %f1857, %f1883, %f1413;
	fma.rn.f32 	%f495, %f1865, %f1885, %f1414;
	mul.f32 	%f1415, %f1860, %f1884;
	fma.rn.f32 	%f1416, %f1856, %f1883, %f1415;
	fma.rn.f32 	%f496, %f1864, %f1885, %f1416;
	mul.f32 	%f1417, %f1859, %f1884;
	fma.rn.f32 	%f1418, %f1855, %f1883, %f1417;
	fma.rn.f32 	%f1419, %f1863, %f1885, %f1418;
	add.f32 	%f1886, %f1886, %f1419;
	mov.f32 	%f1883, %f494;
	mov.f32 	%f1884, %f495;
	mov.f32 	%f1885, %f496;
	mov.f32 	%f1887, %f490;
	mov.f32 	%f1888, %f491;
	mov.f32 	%f1889, %f492;
	mov.f32 	%f1891, %f486;
	mov.f32 	%f1892, %f487;
	mov.f32 	%f1893, %f488;

$L__BB6_68:
	add.s32 	%r648, %r648, -1;
	add.s32 	%r647, %r647, -1;
	setp.gt.s32 	%p36, %r647, 1;
	mov.f32 	%f1855, %f1894;
	mov.f32 	%f1856, %f1893;
	mov.f32 	%f1857, %f1892;
	mov.f32 	%f1858, %f1891;
	mov.f32 	%f1859, %f1890;
	mov.f32 	%f1860, %f1889;
	mov.f32 	%f1861, %f1888;
	mov.f32 	%f1862, %f1887;
	mov.f32 	%f1863, %f1886;
	mov.f32 	%f1864, %f1885;
	mov.f32 	%f1865, %f1884;
	mov.f32 	%f1866, %f1883;
	@%p36 bra 	$L__BB6_54;

$L__BB6_69:
	// begin inline asm
	call (%r491), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p37, %r491, 0;
	mov.f32 	%f1955, %f1954;
	mov.f32 	%f1950, %f1954;
	mov.f32 	%f1951, %f1953;
	mov.f32 	%f1952, %f1954;
	mov.f32 	%f1947, %f1954;
	mov.f32 	%f1948, %f1954;
	mov.f32 	%f1949, %f1953;
	@%p37 bra 	$L__BB6_88;

	// begin inline asm
	call (%r492), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1429), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p38, %r492, 0;
	@%p38 bra 	$L__BB6_88;

	mov.u32 	%r649, 0;

$L__BB6_72:
	.pragma "nounroll";
	// begin inline asm
	call (%rd428), _optix_get_transform_list_handle, (%r649);
	// end inline asm
	// begin inline asm
	call (%r495), _optix_get_transform_type_from_handle, (%rd428);
	// end inline asm
	or.b32  	%r496, %r495, 1;
	setp.eq.s32 	%p39, %r496, 3;
	@%p39 bra 	$L__BB6_78;
	bra.uni 	$L__BB6_73;

$L__BB6_78:
	setp.eq.s32 	%p42, %r495, 2;
	@%p42 bra 	$L__BB6_82;
	bra.uni 	$L__BB6_79;

$L__BB6_82:
	// begin inline asm
	call (%rd500), _optix_get_matrix_motion_transform_from_handle, (%rd428);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd502, %rd500;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd502];
	// end inline asm
	add.s64 	%rd506, %rd500, 16;
	// begin inline asm
	cvta.to.global.u64 %rd505, %rd506;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r588,%r589,%r590,%r591}, [%rd505];
	// end inline asm
	add.s64 	%rd509, %rd500, 32;
	// begin inline asm
	cvta.to.global.u64 %rd508, %rd509;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd508];
	// end inline asm
	add.s64 	%rd512, %rd500, 48;
	// begin inline asm
	cvta.to.global.u64 %rd511, %rd512;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd511];
	// end inline asm
	add.s64 	%rd515, %rd500, 64;
	// begin inline asm
	cvta.to.global.u64 %rd514, %rd515;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd514];
	// end inline asm
	add.s64 	%rd518, %rd500, 80;
	// begin inline asm
	cvta.to.global.u64 %rd517, %rd518;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd517];
	// end inline asm
	add.s64 	%rd521, %rd500, 96;
	// begin inline asm
	cvta.to.global.u64 %rd520, %rd521;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd520];
	// end inline asm
	add.s64 	%rd524, %rd500, 112;
	// begin inline asm
	cvta.to.global.u64 %rd523, %rd524;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r612,%r613,%r614,%r615}, [%rd523];
	// end inline asm
	mov.b32 	%f1533, %r587;
	mov.b32 	%f1534, %r588;
	and.b32  	%r628, %r586, 65535;
	add.s32 	%r629, %r628, -1;
	cvt.rn.f32.s32 	%f1535, %r629;
	sub.f32 	%f1536, %f1429, %f1533;
	mul.f32 	%f1537, %f1536, %f1535;
	sub.f32 	%f1538, %f1534, %f1533;
	div.rn.f32 	%f1539, %f1537, %f1538;
	min.f32 	%f1540, %f1535, %f1539;
	mov.f32 	%f1541, 0f00000000;
	max.f32 	%f1542, %f1541, %f1540;
	cvt.rmi.f32.f32 	%f1543, %f1542;
	sub.f32 	%f581, %f1542, %f1543;
	cvt.rzi.s32.f32 	%r630, %f1543;
	cvt.s64.s32 	%rd37, %r630;
	mul.wide.s32 	%rd535, %r630, 48;
	add.s64 	%rd527, %rd509, %rd535;
	// begin inline asm
	cvta.to.global.u64 %rd526, %rd527;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r616,%r617,%r618,%r619}, [%rd526];
	// end inline asm
	mov.b32 	%f1944, %r616;
	mov.b32 	%f1945, %r617;
	mov.b32 	%f1946, %r618;
	add.s64 	%rd530, %rd527, 16;
	// begin inline asm
	cvta.to.global.u64 %rd529, %rd530;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r620,%r621,%r622,%r623}, [%rd529];
	// end inline asm
	mov.b32 	%f1941, %r620;
	mov.b32 	%f1942, %r621;
	mov.b32 	%f1943, %r622;
	add.s64 	%rd533, %rd527, 32;
	// begin inline asm
	cvta.to.global.u64 %rd532, %rd533;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r624,%r625,%r626,%r627}, [%rd532];
	// end inline asm
	mov.b32 	%f1938, %r624;
	mov.b32 	%f1939, %r625;
	mov.b32 	%f1940, %r626;
	setp.leu.f32 	%p44, %f581, 0f00000000;
	@%p44 bra 	$L__BB6_84;

	mov.f32 	%f1544, 0f3F800000;
	sub.f32 	%f1545, %f1544, %f581;
	mul.lo.s64 	%rd545, %rd37, 48;
	add.s64 	%rd546, %rd500, %rd545;
	add.s64 	%rd537, %rd546, 80;
	// begin inline asm
	cvta.to.global.u64 %rd536, %rd537;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r631,%r632,%r633,%r634}, [%rd536];
	// end inline asm
	mov.b32 	%f1546, %r631;
	mov.b32 	%f1547, %r632;
	mov.b32 	%f1548, %r633;
	mul.f32 	%f1549, %f581, %f1546;
	mul.f32 	%f1550, %f581, %f1547;
	mul.f32 	%f1551, %f581, %f1548;
	fma.rn.f32 	%f1944, %f1545, %f1944, %f1549;
	fma.rn.f32 	%f1945, %f1545, %f1945, %f1550;
	fma.rn.f32 	%f1946, %f1545, %f1946, %f1551;
	add.s64 	%rd540, %rd546, 96;
	// begin inline asm
	cvta.to.global.u64 %rd539, %rd540;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r635,%r636,%r637,%r638}, [%rd539];
	// end inline asm
	mov.b32 	%f1552, %r635;
	mov.b32 	%f1553, %r636;
	mov.b32 	%f1554, %r637;
	mul.f32 	%f1555, %f581, %f1552;
	mul.f32 	%f1556, %f581, %f1553;
	mul.f32 	%f1557, %f581, %f1554;
	fma.rn.f32 	%f1941, %f1545, %f1941, %f1555;
	fma.rn.f32 	%f1942, %f1545, %f1942, %f1556;
	fma.rn.f32 	%f1943, %f1545, %f1943, %f1557;
	add.s64 	%rd543, %rd546, 112;
	// begin inline asm
	cvta.to.global.u64 %rd542, %rd543;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r639,%r640,%r641,%r642}, [%rd542];
	// end inline asm
	mov.b32 	%f1558, %r639;
	mov.b32 	%f1559, %r640;
	mov.b32 	%f1560, %r641;
	mul.f32 	%f1561, %f581, %f1558;
	mul.f32 	%f1562, %f581, %f1559;
	mul.f32 	%f1563, %f581, %f1560;
	fma.rn.f32 	%f1938, %f1545, %f1938, %f1561;
	fma.rn.f32 	%f1939, %f1545, %f1939, %f1562;
	fma.rn.f32 	%f1940, %f1545, %f1940, %f1563;
	bra.uni 	$L__BB6_84;

$L__BB6_73:
	mov.f32 	%f1947, 0f00000000;
	mov.f32 	%f1949, 0f3F800000;
	setp.eq.s32 	%p40, %r495, 4;
	@%p40 bra 	$L__BB6_76;

	setp.ne.s32 	%p41, %r495, 1;
	mov.f32 	%f1948, %f1947;
	mov.f32 	%f1950, %f1947;
	mov.f32 	%f1951, %f1949;
	mov.f32 	%f1952, %f1947;
	mov.f32 	%f1953, %f1949;
	mov.f32 	%f1954, %f1947;
	mov.f32 	%f1955, %f1947;
	@%p41 bra 	$L__BB6_85;

	// begin inline asm
	call (%rd430), _optix_get_static_transform_from_handle, (%rd428);
	// end inline asm
	add.s64 	%rd655, %rd430, 64;
	bra.uni 	$L__BB6_77;

$L__BB6_79:
	// begin inline asm
	call (%rd443), _optix_get_srt_motion_transform_from_handle, (%rd428);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd445, %rd443;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd445];
	// end inline asm
	add.s64 	%rd449, %rd443, 16;
	// begin inline asm
	cvta.to.global.u64 %rd448, %rd449;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r513,%r514,%r515,%r516}, [%rd448];
	// end inline asm
	add.s64 	%rd452, %rd443, 32;
	// begin inline asm
	cvta.to.global.u64 %rd451, %rd452;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r517,%r518,%r519,%r520}, [%rd451];
	// end inline asm
	add.s64 	%rd455, %rd443, 48;
	// begin inline asm
	cvta.to.global.u64 %rd454, %rd455;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r521,%r522,%r523,%r524}, [%rd454];
	// end inline asm
	add.s64 	%rd458, %rd443, 64;
	// begin inline asm
	cvta.to.global.u64 %rd457, %rd458;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r525,%r526,%r527,%r528}, [%rd457];
	// end inline asm
	add.s64 	%rd461, %rd443, 80;
	// begin inline asm
	cvta.to.global.u64 %rd460, %rd461;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r529,%r530,%r531,%r532}, [%rd460];
	// end inline asm
	add.s64 	%rd464, %rd443, 96;
	// begin inline asm
	cvta.to.global.u64 %rd463, %rd464;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r533,%r534,%r535,%r536}, [%rd463];
	// end inline asm
	add.s64 	%rd467, %rd443, 112;
	// begin inline asm
	cvta.to.global.u64 %rd466, %rd467;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r537,%r538,%r539,%r540}, [%rd466];
	// end inline asm
	add.s64 	%rd470, %rd443, 128;
	// begin inline asm
	cvta.to.global.u64 %rd469, %rd470;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r541,%r542,%r543,%r544}, [%rd469];
	// end inline asm
	add.s64 	%rd473, %rd443, 144;
	// begin inline asm
	cvta.to.global.u64 %rd472, %rd473;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r545,%r546,%r547,%r548}, [%rd472];
	// end inline asm
	mov.b32 	%f1441, %r512;
	mov.b32 	%f1442, %r513;
	and.b32  	%r565, %r511, 65535;
	add.s32 	%r566, %r565, -1;
	cvt.rn.f32.s32 	%f1443, %r566;
	sub.f32 	%f1444, %f1429, %f1441;
	mul.f32 	%f1445, %f1444, %f1443;
	sub.f32 	%f1446, %f1442, %f1441;
	div.rn.f32 	%f1447, %f1445, %f1446;
	min.f32 	%f1448, %f1443, %f1447;
	mov.f32 	%f1449, 0f00000000;
	max.f32 	%f1450, %f1449, %f1448;
	cvt.rmi.f32.f32 	%f1451, %f1450;
	sub.f32 	%f541, %f1450, %f1451;
	cvt.rzi.s32.f32 	%r567, %f1451;
	mul.wide.s32 	%rd487, %r567, 64;
	add.s64 	%rd476, %rd452, %rd487;
	// begin inline asm
	cvta.to.global.u64 %rd475, %rd476;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r549,%r550,%r551,%r552}, [%rd475];
	// end inline asm
	mov.b32 	%f1928, %r549;
	mov.b32 	%f1929, %r550;
	mov.b32 	%f1930, %r551;
	add.s64 	%rd479, %rd476, 16;
	// begin inline asm
	cvta.to.global.u64 %rd478, %rd479;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r553,%r554,%r555,%r556}, [%rd478];
	// end inline asm
	mov.b32 	%f1931, %r553;
	mov.b32 	%f1932, %r554;
	mov.b32 	%f1933, %r556;
	add.s64 	%rd482, %rd476, 32;
	// begin inline asm
	cvta.to.global.u64 %rd481, %rd482;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r557,%r558,%r559,%r560}, [%rd481];
	// end inline asm
	mov.b32 	%f1934, %r558;
	mov.b32 	%f1935, %r559;
	mov.b32 	%f1936, %r560;
	add.s64 	%rd485, %rd476, 48;
	// begin inline asm
	cvta.to.global.u64 %rd484, %rd485;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r561,%r562,%r563,%r564}, [%rd484];
	// end inline asm
	mov.b32 	%f1937, %r561;
	setp.leu.f32 	%p43, %f541, 0f00000000;
	@%p43 bra 	$L__BB6_81;

	mov.f32 	%f1452, 0f3F800000;
	sub.f32 	%f1453, %f1452, %f541;
	add.s64 	%rd489, %rd476, 64;
	// begin inline asm
	cvta.to.global.u64 %rd488, %rd489;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd488];
	// end inline asm
	mov.b32 	%f1454, %r568;
	mov.b32 	%f1455, %r569;
	mov.b32 	%f1456, %r570;
	mul.f32 	%f1457, %f541, %f1454;
	mul.f32 	%f1458, %f541, %f1455;
	mul.f32 	%f1459, %f541, %f1456;
	fma.rn.f32 	%f1928, %f1453, %f1928, %f1457;
	fma.rn.f32 	%f1929, %f1453, %f1929, %f1458;
	fma.rn.f32 	%f1930, %f1453, %f1930, %f1459;
	add.s64 	%rd492, %rd476, 80;
	// begin inline asm
	cvta.to.global.u64 %rd491, %rd492;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd491];
	// end inline asm
	mov.b32 	%f1460, %r572;
	mov.b32 	%f1461, %r573;
	mov.b32 	%f1462, %r575;
	mul.f32 	%f1463, %f541, %f1460;
	mul.f32 	%f1464, %f541, %f1461;
	mul.f32 	%f1465, %f541, %f1462;
	fma.rn.f32 	%f1931, %f1453, %f1931, %f1463;
	fma.rn.f32 	%f1932, %f1453, %f1932, %f1464;
	fma.rn.f32 	%f1933, %f1453, %f1933, %f1465;
	add.s64 	%rd495, %rd476, 96;
	// begin inline asm
	cvta.to.global.u64 %rd494, %rd495;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd494];
	// end inline asm
	mov.b32 	%f1466, %r577;
	mov.b32 	%f1467, %r578;
	mov.b32 	%f1468, %r579;
	mul.f32 	%f1469, %f541, %f1466;
	mul.f32 	%f1470, %f541, %f1467;
	mul.f32 	%f1471, %f541, %f1468;
	fma.rn.f32 	%f1472, %f1453, %f1934, %f1469;
	fma.rn.f32 	%f1473, %f1453, %f1935, %f1470;
	fma.rn.f32 	%f1474, %f1453, %f1936, %f1471;
	add.s64 	%rd498, %rd476, 112;
	// begin inline asm
	cvta.to.global.u64 %rd497, %rd498;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd497];
	// end inline asm
	mov.b32 	%f1475, %r580;
	mul.f32 	%f1476, %f541, %f1475;
	fma.rn.f32 	%f1477, %f1453, %f1937, %f1476;
	mul.f32 	%f1478, %f1473, %f1473;
	fma.rn.f32 	%f1479, %f1472, %f1472, %f1478;
	fma.rn.f32 	%f1480, %f1474, %f1474, %f1479;
	fma.rn.f32 	%f1481, %f1477, %f1477, %f1480;
	sqrt.rn.f32 	%f1482, %f1481;
	rcp.rn.f32 	%f1483, %f1482;
	mul.f32 	%f1934, %f1472, %f1483;
	mul.f32 	%f1935, %f1473, %f1483;
	mul.f32 	%f1936, %f1474, %f1483;
	mul.f32 	%f1937, %f1483, %f1477;

$L__BB6_81:
	mul.f32 	%f1484, %f1935, %f1935;
	fma.rn.f32 	%f1485, %f1934, %f1934, %f1484;
	fma.rn.f32 	%f1486, %f1936, %f1936, %f1485;
	fma.rn.f32 	%f1487, %f1937, %f1937, %f1486;
	rcp.rn.f32 	%f1488, %f1487;
	mul.f32 	%f1489, %f1934, %f1488;
	mul.f32 	%f1490, %f1935, %f1488;
	mul.f32 	%f1491, %f1936, %f1488;
	mul.f32 	%f1492, %f1937, %f1488;
	mul.f32 	%f1493, %f1934, %f1489;
	mul.f32 	%f1494, %f1935, %f1490;
	mul.f32 	%f1495, %f1936, %f1491;
	mul.f32 	%f1496, %f1934, %f1490;
	mul.f32 	%f1497, %f1936, %f1492;
	mul.f32 	%f1498, %f1934, %f1491;
	mul.f32 	%f1499, %f1935, %f1492;
	mul.f32 	%f1500, %f1935, %f1491;
	mul.f32 	%f1501, %f1934, %f1492;
	sub.f32 	%f1502, %f1493, %f1494;
	sub.f32 	%f1503, %f1502, %f1495;
	fma.rn.f32 	%f1504, %f1937, %f1492, %f1503;
	sub.f32 	%f1505, %f1496, %f1497;
	add.f32 	%f1506, %f1505, %f1505;
	add.f32 	%f1507, %f1498, %f1499;
	add.f32 	%f1508, %f1507, %f1507;
	add.f32 	%f1509, %f1496, %f1497;
	add.f32 	%f1510, %f1509, %f1509;
	sub.f32 	%f1511, %f1494, %f1493;
	sub.f32 	%f1512, %f1511, %f1495;
	fma.rn.f32 	%f1513, %f1937, %f1492, %f1512;
	sub.f32 	%f1514, %f1500, %f1501;
	add.f32 	%f1515, %f1514, %f1514;
	sub.f32 	%f1516, %f1498, %f1499;
	add.f32 	%f1517, %f1516, %f1516;
	add.f32 	%f1518, %f1500, %f1501;
	add.f32 	%f1519, %f1518, %f1518;
	neg.f32 	%f1520, %f1493;
	sub.f32 	%f1521, %f1520, %f1494;
	add.f32 	%f1522, %f1495, %f1521;
	fma.rn.f32 	%f1523, %f1937, %f1492, %f1522;
	mul.f32 	%f1524, %f1930, %f1504;
	fma.rn.f32 	%f1525, %f1932, %f1506, %f1524;
	fma.rn.f32 	%f1946, %f1933, %f1508, %f1525;
	mul.f32 	%f1526, %f1932, %f1513;
	fma.rn.f32 	%f1527, %f1930, %f1510, %f1526;
	fma.rn.f32 	%f1943, %f1933, %f1515, %f1527;
	mul.f32 	%f1528, %f1932, %f1519;
	fma.rn.f32 	%f1529, %f1930, %f1517, %f1528;
	fma.rn.f32 	%f1940, %f1933, %f1523, %f1529;
	mul.f32 	%f1530, %f1929, %f1504;
	fma.rn.f32 	%f1945, %f1931, %f1506, %f1530;
	mul.f32 	%f1531, %f1931, %f1513;
	fma.rn.f32 	%f1942, %f1929, %f1510, %f1531;
	mul.f32 	%f1532, %f1931, %f1519;
	fma.rn.f32 	%f1939, %f1929, %f1517, %f1532;
	mul.f32 	%f1944, %f1928, %f1504;
	mul.f32 	%f1941, %f1928, %f1510;
	mul.f32 	%f1938, %f1928, %f1517;

$L__BB6_84:
	mul.f32 	%f1564, %f1939, %f1943;
	mul.f32 	%f1565, %f1940, %f1942;
	sub.f32 	%f1566, %f1565, %f1564;
	mul.f32 	%f1567, %f1944, %f1566;
	mul.f32 	%f1568, %f1938, %f1943;
	mul.f32 	%f1569, %f1940, %f1941;
	sub.f32 	%f1570, %f1569, %f1568;
	mul.f32 	%f1571, %f1570, %f1945;
	sub.f32 	%f1572, %f1567, %f1571;
	mul.f32 	%f1573, %f1938, %f1942;
	mul.f32 	%f1574, %f1939, %f1941;
	sub.f32 	%f1575, %f1574, %f1573;
	fma.rn.f32 	%f1576, %f1575, %f1946, %f1572;
	rcp.rn.f32 	%f1577, %f1576;
	mul.f32 	%f1953, %f1566, %f1577;
	mul.f32 	%f1578, %f1940, %f1945;
	mul.f32 	%f1579, %f1939, %f1946;
	sub.f32 	%f1580, %f1579, %f1578;
	mul.f32 	%f1954, %f1580, %f1577;
	mul.f32 	%f1581, %f1942, %f1946;
	mul.f32 	%f1582, %f1943, %f1945;
	sub.f32 	%f1583, %f1582, %f1581;
	mul.f32 	%f1955, %f1583, %f1577;
	sub.f32 	%f1584, %f1568, %f1569;
	mul.f32 	%f1950, %f1584, %f1577;
	mul.f32 	%f1585, %f1938, %f1946;
	mul.f32 	%f1586, %f1940, %f1944;
	sub.f32 	%f1587, %f1586, %f1585;
	mul.f32 	%f1951, %f1587, %f1577;
	mul.f32 	%f1588, %f1943, %f1944;
	mul.f32 	%f1589, %f1941, %f1946;
	sub.f32 	%f1590, %f1589, %f1588;
	mul.f32 	%f1952, %f1590, %f1577;
	mul.f32 	%f1947, %f1575, %f1577;
	mul.f32 	%f1591, %f1939, %f1944;
	mul.f32 	%f1592, %f1938, %f1945;
	sub.f32 	%f1593, %f1592, %f1591;
	mul.f32 	%f1948, %f1593, %f1577;
	mul.f32 	%f1594, %f1941, %f1945;
	mul.f32 	%f1595, %f1942, %f1944;
	sub.f32 	%f1596, %f1595, %f1594;
	mul.f32 	%f1949, %f1596, %f1577;
	bra.uni 	$L__BB6_85;

$L__BB6_76:
	// begin inline asm
	call (%rd655), _optix_get_instance_inverse_transform_from_handle, (%rd428);
	// end inline asm

$L__BB6_77:
	// begin inline asm
	cvta.to.global.u64 %rd434, %rd655;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd434];
	// end inline asm
	mov.b32 	%f1953, %r497;
	mov.b32 	%f1954, %r498;
	mov.b32 	%f1955, %r499;
	add.s64 	%rd438, %rd655, 16;
	// begin inline asm
	cvta.to.global.u64 %rd437, %rd438;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd437];
	// end inline asm
	mov.b32 	%f1950, %r501;
	mov.b32 	%f1951, %r502;
	mov.b32 	%f1952, %r503;
	add.s64 	%rd441, %rd655, 32;
	// begin inline asm
	cvta.to.global.u64 %rd440, %rd441;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd440];
	// end inline asm
	mov.b32 	%f1947, %r505;
	mov.b32 	%f1948, %r506;
	mov.b32 	%f1949, %r507;

$L__BB6_85:
	setp.eq.s32 	%p45, %r649, 0;
	@%p45 bra 	$L__BB6_87;

	mul.f32 	%f1597, %f1924, %f1954;
	fma.rn.f32 	%f1598, %f1921, %f1953, %f1597;
	fma.rn.f32 	%f627, %f1927, %f1955, %f1598;
	mul.f32 	%f1599, %f1923, %f1954;
	fma.rn.f32 	%f1600, %f1920, %f1953, %f1599;
	fma.rn.f32 	%f628, %f1926, %f1955, %f1600;
	mul.f32 	%f1601, %f1922, %f1954;
	fma.rn.f32 	%f1602, %f1919, %f1953, %f1601;
	fma.rn.f32 	%f1955, %f1925, %f1955, %f1602;
	mul.f32 	%f1603, %f1924, %f1951;
	fma.rn.f32 	%f1604, %f1921, %f1950, %f1603;
	fma.rn.f32 	%f630, %f1927, %f1952, %f1604;
	mul.f32 	%f1605, %f1923, %f1951;
	fma.rn.f32 	%f1606, %f1920, %f1950, %f1605;
	fma.rn.f32 	%f631, %f1926, %f1952, %f1606;
	mul.f32 	%f1607, %f1922, %f1951;
	fma.rn.f32 	%f1608, %f1919, %f1950, %f1607;
	fma.rn.f32 	%f1952, %f1925, %f1952, %f1608;
	mul.f32 	%f1609, %f1924, %f1948;
	fma.rn.f32 	%f1610, %f1921, %f1947, %f1609;
	fma.rn.f32 	%f633, %f1927, %f1949, %f1610;
	mul.f32 	%f1611, %f1923, %f1948;
	fma.rn.f32 	%f1612, %f1920, %f1947, %f1611;
	fma.rn.f32 	%f634, %f1926, %f1949, %f1612;
	mul.f32 	%f1613, %f1922, %f1948;
	fma.rn.f32 	%f1614, %f1919, %f1947, %f1613;
	fma.rn.f32 	%f1949, %f1925, %f1949, %f1614;
	mov.f32 	%f1947, %f633;
	mov.f32 	%f1948, %f634;
	mov.f32 	%f1950, %f630;
	mov.f32 	%f1951, %f631;
	mov.f32 	%f1953, %f627;
	mov.f32 	%f1954, %f628;

$L__BB6_87:
	add.s32 	%r649, %r649, 1;
	setp.lt.u32 	%p46, %r649, %r492;
	mov.f32 	%f1919, %f1955;
	mov.f32 	%f1920, %f1954;
	mov.f32 	%f1921, %f1953;
	mov.f32 	%f1922, %f1952;
	mov.f32 	%f1923, %f1951;
	mov.f32 	%f1924, %f1950;
	mov.f32 	%f1925, %f1949;
	mov.f32 	%f1926, %f1948;
	mov.f32 	%f1927, %f1947;
	@%p46 bra 	$L__BB6_72;

$L__BB6_88:
	fma.rn.f32 	%f1615, %f2004, %f1891, %f1894;
	fma.rn.f32 	%f1616, %f2005, %f1892, %f1615;
	fma.rn.f32 	%f1617, %f2004, %f1887, %f1890;
	fma.rn.f32 	%f1618, %f2005, %f1888, %f1617;
	fma.rn.f32 	%f1619, %f2004, %f1883, %f1886;
	fma.rn.f32 	%f1620, %f2005, %f1884, %f1619;
	fma.rn.f32 	%f2004, %f2006, %f1893, %f1616;
	fma.rn.f32 	%f2005, %f2006, %f1889, %f1618;
	fma.rn.f32 	%f2006, %f2006, %f1885, %f1620;
	ld.const.u64 	%rd547, [params+112];
	setp.eq.s64 	%p47, %rd547, 0;
	mov.f32 	%f1998, %f2001;
	mov.f32 	%f1999, %f2002;
	mov.f32 	%f2000, %f2003;
	@%p47 bra 	$L__BB6_90;

	mul.f32 	%f1621, %f2001, %f1953;
	fma.rn.f32 	%f1622, %f2002, %f1950, %f1621;
	mul.f32 	%f1623, %f2001, %f1954;
	fma.rn.f32 	%f1624, %f2002, %f1951, %f1623;
	mul.f32 	%f1625, %f2001, %f1955;
	fma.rn.f32 	%f1626, %f2002, %f1952, %f1625;
	fma.rn.f32 	%f1627, %f2003, %f1947, %f1622;
	fma.rn.f32 	%f1628, %f2003, %f1948, %f1624;
	fma.rn.f32 	%f1629, %f2003, %f1949, %f1626;
	mul.f32 	%f1630, %f1627, %f1627;
	fma.rn.f32 	%f1631, %f1628, %f1628, %f1630;
	fma.rn.f32 	%f1632, %f1629, %f1629, %f1631;
	sqrt.rn.f32 	%f1633, %f1632;
	div.rn.f32 	%f1998, %f1627, %f1633;
	div.rn.f32 	%f1999, %f1628, %f1633;
	div.rn.f32 	%f2000, %f1629, %f1633;

$L__BB6_90:
	ld.const.u64 	%rd548, [params+136];
	setp.eq.s64 	%p48, %rd548, 0;
	@%p48 bra 	$L__BB6_92;

	mul.f32 	%f1634, %f2001, %f1953;
	fma.rn.f32 	%f1635, %f2002, %f1950, %f1634;
	mul.f32 	%f1636, %f2001, %f1954;
	fma.rn.f32 	%f1637, %f2002, %f1951, %f1636;
	mul.f32 	%f1638, %f2001, %f1955;
	fma.rn.f32 	%f1639, %f2002, %f1952, %f1638;
	fma.rn.f32 	%f1640, %f2003, %f1947, %f1635;
	fma.rn.f32 	%f1641, %f2003, %f1948, %f1637;
	fma.rn.f32 	%f1642, %f2003, %f1949, %f1639;
	mul.f32 	%f1643, %f1640, %f1640;
	fma.rn.f32 	%f1644, %f1641, %f1641, %f1643;
	fma.rn.f32 	%f1645, %f1642, %f1642, %f1644;
	sqrt.rn.f32 	%f1646, %f1645;
	div.rn.f32 	%f2001, %f1640, %f1646;
	div.rn.f32 	%f2002, %f1641, %f1646;
	div.rn.f32 	%f2003, %f1642, %f1646;

$L__BB6_92:
	ld.const.u64 	%rd549, [params+184];
	setp.eq.s64 	%p49, %rd549, 0;
	@%p49 bra 	$L__BB6_94;

	mul.f32 	%f1647, %f1995, %f1891;
	fma.rn.f32 	%f1648, %f1996, %f1892, %f1647;
	mul.f32 	%f1649, %f1995, %f1887;
	fma.rn.f32 	%f1650, %f1996, %f1888, %f1649;
	mul.f32 	%f1651, %f1995, %f1883;
	fma.rn.f32 	%f1652, %f1996, %f1884, %f1651;
	fma.rn.f32 	%f1995, %f1997, %f1893, %f1648;
	fma.rn.f32 	%f1996, %f1997, %f1889, %f1650;
	fma.rn.f32 	%f1997, %f1997, %f1885, %f1652;
	mul.f32 	%f1653, %f1992, %f1891;
	fma.rn.f32 	%f1654, %f1993, %f1892, %f1653;
	mul.f32 	%f1655, %f1992, %f1887;
	fma.rn.f32 	%f1656, %f1993, %f1888, %f1655;
	mul.f32 	%f1657, %f1992, %f1883;
	fma.rn.f32 	%f1658, %f1993, %f1884, %f1657;
	fma.rn.f32 	%f1992, %f1994, %f1893, %f1654;
	fma.rn.f32 	%f1993, %f1994, %f1889, %f1656;
	fma.rn.f32 	%f1994, %f1994, %f1885, %f1658;

$L__BB6_94:
	ld.const.u64 	%rd550, [params+232];
	ld.const.u64 	%rd551, [params+280];
	or.b64  	%rd552, %rd550, %rd551;
	setp.eq.s64 	%p50, %rd552, 0;
	mov.f32 	%f1989, 0f00000000;
	mov.f32 	%f1990, %f1989;
	mov.f32 	%f1991, %f1989;
	@%p50 bra 	$L__BB6_96;

	mul.f32 	%f1662, %f2001, %f1891;
	fma.rn.f32 	%f1663, %f2002, %f1887, %f1662;
	mul.f32 	%f1664, %f2001, %f1892;
	fma.rn.f32 	%f1665, %f2002, %f1888, %f1664;
	mul.f32 	%f1666, %f2001, %f1893;
	fma.rn.f32 	%f1667, %f2002, %f1889, %f1666;
	fma.rn.f32 	%f1668, %f2003, %f1883, %f1663;
	fma.rn.f32 	%f1669, %f2003, %f1884, %f1665;
	fma.rn.f32 	%f1670, %f2003, %f1885, %f1667;
	mul.f32 	%f1671, %f1668, %f1668;
	fma.rn.f32 	%f1672, %f1669, %f1669, %f1671;
	fma.rn.f32 	%f1673, %f1670, %f1670, %f1672;
	sqrt.rn.f32 	%f1674, %f1673;
	div.rn.f32 	%f1675, %f1668, %f1674;
	div.rn.f32 	%f1676, %f1669, %f1674;
	div.rn.f32 	%f1677, %f1670, %f1674;
	mul.f32 	%f1678, %f1675, %f1953;
	mul.f32 	%f1679, %f1675, %f1954;
	mul.f32 	%f1680, %f1675, %f1955;
	fma.rn.f32 	%f1681, %f1676, %f1950, %f1678;
	fma.rn.f32 	%f1682, %f1676, %f1951, %f1679;
	fma.rn.f32 	%f1683, %f1676, %f1952, %f1680;
	fma.rn.f32 	%f1684, %f1677, %f1947, %f1681;
	fma.rn.f32 	%f1685, %f1677, %f1948, %f1682;
	fma.rn.f32 	%f1686, %f1677, %f1949, %f1683;
	mul.f32 	%f1687, %f1684, %f1684;
	fma.rn.f32 	%f1688, %f1685, %f1685, %f1687;
	fma.rn.f32 	%f1689, %f1686, %f1686, %f1688;
	sqrt.rn.f32 	%f1690, %f1689;
	rcp.rn.f32 	%f1691, %f1690;
	mul.f32 	%f1692, %f1691, %f1684;
	mul.f32 	%f1693, %f1691, %f1685;
	mul.f32 	%f1694, %f1691, %f1686;
	mul.f32 	%f1695, %f1953, 0f00000000;
	mov.f32 	%f1696, 0f00000000;
	fma.rn.f32 	%f1697, %f1696, %f1950, %f1695;
	mul.f32 	%f1698, %f1954, 0f00000000;
	fma.rn.f32 	%f1699, %f1696, %f1951, %f1698;
	mul.f32 	%f1700, %f1955, 0f00000000;
	fma.rn.f32 	%f1701, %f1696, %f1952, %f1700;
	fma.rn.f32 	%f1702, %f1696, %f1947, %f1697;
	fma.rn.f32 	%f1703, %f1696, %f1948, %f1699;
	fma.rn.f32 	%f1704, %f1696, %f1949, %f1701;
	mul.f32 	%f1705, %f1702, %f1691;
	mul.f32 	%f1706, %f1703, %f1691;
	mul.f32 	%f1707, %f1704, %f1691;
	mul.f32 	%f1708, %f1692, %f1705;
	fma.rn.f32 	%f1709, %f1693, %f1706, %f1708;
	fma.rn.f32 	%f1710, %f1694, %f1707, %f1709;
	mul.f32 	%f1711, %f1692, %f1710;
	mul.f32 	%f1712, %f1693, %f1710;
	mul.f32 	%f1713, %f1694, %f1710;
	sub.f32 	%f1989, %f1705, %f1711;
	sub.f32 	%f1990, %f1706, %f1712;
	sub.f32 	%f1991, %f1707, %f1713;

$L__BB6_96:
	st.global.u32 	[%rd23], %r338;

$L__BB6_97:
	ld.const.u64 	%rd553, [params+328];
	cvta.to.global.u64 	%rd554, %rd553;
	shl.b64 	%rd555, %rd20, 3;
	add.s64 	%rd556, %rd554, %rd555;
	st.global.u64 	[%rd556], %rd22;
	ld.const.u64 	%rd557, [params+336];
	cvta.to.global.u64 	%rd558, %rd557;
	add.s64 	%rd560, %rd558, %rd308;
	mov.u32 	%r643, 0;
	st.global.u32 	[%rd560], %r643;
	ld.const.u64 	%rd561, [params+160];
	cvta.to.global.u64 	%rd562, %rd561;
	add.s64 	%rd563, %rd562, %rd308;
	st.global.f32 	[%rd563], %f2004;
	ld.const.u64 	%rd564, [params+168];
	cvta.to.global.u64 	%rd565, %rd564;
	add.s64 	%rd566, %rd565, %rd308;
	st.global.f32 	[%rd566], %f2005;
	ld.const.u64 	%rd567, [params+176];
	cvta.to.global.u64 	%rd568, %rd567;
	add.s64 	%rd569, %rd568, %rd308;
	st.global.f32 	[%rd569], %f2006;
	ld.const.u64 	%rd570, [params+72];
	cvta.to.global.u64 	%rd571, %rd570;
	add.s64 	%rd572, %rd571, %rd308;
	st.global.f32 	[%rd572], %f346;
	ld.const.u64 	%rd38, [params+96];
	setp.eq.s64 	%p51, %rd38, 0;
	@%p51 bra 	$L__BB6_99;

	cvta.to.global.u64 	%rd573, %rd38;
	add.s64 	%rd575, %rd573, %rd308;
	st.global.f32 	[%rd575], %f352;
	ld.const.u64 	%rd576, [params+104];
	cvta.to.global.u64 	%rd577, %rd576;
	add.s64 	%rd578, %rd577, %rd308;
	st.global.f32 	[%rd578], %f353;

$L__BB6_99:
	ld.const.u64 	%rd39, [params+112];
	setp.eq.s64 	%p52, %rd39, 0;
	@%p52 bra 	$L__BB6_101;

	cvta.to.global.u64 	%rd579, %rd39;
	add.s64 	%rd581, %rd579, %rd308;
	st.global.f32 	[%rd581], %f1998;
	ld.const.u64 	%rd582, [params+120];
	cvta.to.global.u64 	%rd583, %rd582;
	add.s64 	%rd584, %rd583, %rd308;
	st.global.f32 	[%rd584], %f1999;
	ld.const.u64 	%rd585, [params+128];
	cvta.to.global.u64 	%rd586, %rd585;
	add.s64 	%rd587, %rd586, %rd308;
	st.global.f32 	[%rd587], %f2000;

$L__BB6_101:
	ld.const.u64 	%rd40, [params+136];
	setp.eq.s64 	%p53, %rd40, 0;
	@%p53 bra 	$L__BB6_103;

	cvta.to.global.u64 	%rd588, %rd40;
	add.s64 	%rd590, %rd588, %rd308;
	st.global.f32 	[%rd590], %f2001;
	ld.const.u64 	%rd591, [params+144];
	cvta.to.global.u64 	%rd592, %rd591;
	add.s64 	%rd593, %rd592, %rd308;
	st.global.f32 	[%rd593], %f2002;
	ld.const.u64 	%rd594, [params+152];
	cvta.to.global.u64 	%rd595, %rd594;
	add.s64 	%rd596, %rd595, %rd308;
	st.global.f32 	[%rd596], %f2003;

$L__BB6_103:
	ld.const.u64 	%rd41, [params+184];
	setp.eq.s64 	%p54, %rd41, 0;
	@%p54 bra 	$L__BB6_105;

	cvta.to.global.u64 	%rd597, %rd41;
	add.s64 	%rd599, %rd597, %rd308;
	st.global.f32 	[%rd599], %f1995;
	ld.const.u64 	%rd600, [params+192];
	cvta.to.global.u64 	%rd601, %rd600;
	add.s64 	%rd602, %rd601, %rd308;
	st.global.f32 	[%rd602], %f1996;
	ld.const.u64 	%rd603, [params+200];
	cvta.to.global.u64 	%rd604, %rd603;
	add.s64 	%rd605, %rd604, %rd308;
	st.global.f32 	[%rd605], %f1997;
	ld.const.u64 	%rd606, [params+208];
	cvta.to.global.u64 	%rd607, %rd606;
	add.s64 	%rd608, %rd607, %rd308;
	st.global.f32 	[%rd608], %f1992;
	ld.const.u64 	%rd609, [params+216];
	cvta.to.global.u64 	%rd610, %rd609;
	add.s64 	%rd611, %rd610, %rd308;
	st.global.f32 	[%rd611], %f1993;
	ld.const.u64 	%rd612, [params+224];
	cvta.to.global.u64 	%rd613, %rd612;
	add.s64 	%rd614, %rd613, %rd308;
	st.global.f32 	[%rd614], %f1994;

$L__BB6_105:
	ld.const.u64 	%rd42, [params+232];
	setp.eq.s64 	%p55, %rd42, 0;
	@%p55 bra 	$L__BB6_107;

	cvta.to.global.u64 	%rd615, %rd42;
	add.s64 	%rd617, %rd615, %rd308;
	st.global.f32 	[%rd617], %f1989;
	ld.const.u64 	%rd618, [params+240];
	cvta.to.global.u64 	%rd619, %rd618;
	add.s64 	%rd620, %rd619, %rd308;
	st.global.f32 	[%rd620], %f1990;
	ld.const.u64 	%rd621, [params+248];
	cvta.to.global.u64 	%rd622, %rd621;
	add.s64 	%rd623, %rd622, %rd308;
	st.global.f32 	[%rd623], %f1991;
	ld.const.u64 	%rd624, [params+256];
	cvta.to.global.u64 	%rd625, %rd624;
	add.s64 	%rd626, %rd625, %rd308;
	st.global.f32 	[%rd626], %f1989;
	ld.const.u64 	%rd627, [params+264];
	cvta.to.global.u64 	%rd628, %rd627;
	add.s64 	%rd629, %rd628, %rd308;
	st.global.f32 	[%rd629], %f1990;
	ld.const.u64 	%rd630, [params+272];
	cvta.to.global.u64 	%rd631, %rd630;
	add.s64 	%rd632, %rd631, %rd308;
	st.global.f32 	[%rd632], %f1991;

$L__BB6_107:
	ld.const.u64 	%rd43, [params+280];
	setp.eq.s64 	%p56, %rd43, 0;
	@%p56 bra 	$L__BB6_109;

	cvta.to.global.u64 	%rd633, %rd43;
	add.s64 	%rd635, %rd633, %rd308;
	st.global.f32 	[%rd635], %f1989;
	ld.const.u64 	%rd636, [params+288];
	cvta.to.global.u64 	%rd637, %rd636;
	add.s64 	%rd638, %rd637, %rd308;
	st.global.f32 	[%rd638], %f1990;
	ld.const.u64 	%rd639, [params+296];
	cvta.to.global.u64 	%rd640, %rd639;
	add.s64 	%rd641, %rd640, %rd308;
	st.global.f32 	[%rd641], %f1991;
	ld.const.u64 	%rd642, [params+304];
	cvta.to.global.u64 	%rd643, %rd642;
	add.s64 	%rd644, %rd643, %rd308;
	st.global.f32 	[%rd644], %f1989;
	ld.const.u64 	%rd645, [params+312];
	cvta.to.global.u64 	%rd646, %rd645;
	add.s64 	%rd647, %rd646, %rd308;
	st.global.f32 	[%rd647], %f1990;
	ld.const.u64 	%rd648, [params+320];
	cvta.to.global.u64 	%rd649, %rd648;
	add.s64 	%rd650, %rd649, %rd308;
	st.global.f32 	[%rd650], %f1991;

$L__BB6_109:
	ret;

}
	// .globl	__intersection__sphere
.visible .entry __intersection__sphere()
{
	.reg .pred 	%p<43>;
	.reg .f32 	%f<971>;
	.reg .b32 	%r<323>;
	.reg .b64 	%rd<258>;


	// begin inline asm
	call (%rd16), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd1, [%rd16+8];
	// begin inline asm
	call (%f908), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f909), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f910), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r9), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p2, %r9, 0;
	@%p2 bra 	$L__BB7_21;

	// begin inline asm
	call (%r10), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f355), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p3, %r10, 0;
	@%p3 bra 	$L__BB7_19;

	mov.u32 	%r321, 0;

$L__BB7_3:
	.pragma "nounroll";
	// begin inline asm
	call (%rd17), _optix_get_transform_list_handle, (%r321);
	// end inline asm
	// begin inline asm
	call (%r13), _optix_get_transform_type_from_handle, (%rd17);
	// end inline asm
	or.b32  	%r14, %r13, 1;
	setp.eq.s32 	%p4, %r14, 3;
	@%p4 bra 	$L__BB7_9;
	bra.uni 	$L__BB7_4;

$L__BB7_9:
	setp.eq.s32 	%p7, %r13, 2;
	@%p7 bra 	$L__BB7_13;
	bra.uni 	$L__BB7_10;

$L__BB7_13:
	// begin inline asm
	call (%rd89), _optix_get_matrix_motion_transform_from_handle, (%rd17);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd91, %rd89;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd91];
	// end inline asm
	add.s64 	%rd95, %rd89, 16;
	// begin inline asm
	cvta.to.global.u64 %rd94, %rd95;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd94];
	// end inline asm
	add.s64 	%rd98, %rd89, 32;
	// begin inline asm
	cvta.to.global.u64 %rd97, %rd98;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd97];
	// end inline asm
	add.s64 	%rd101, %rd89, 48;
	// begin inline asm
	cvta.to.global.u64 %rd100, %rd101;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd100];
	// end inline asm
	add.s64 	%rd104, %rd89, 64;
	// begin inline asm
	cvta.to.global.u64 %rd103, %rd104;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd103];
	// end inline asm
	add.s64 	%rd107, %rd89, 80;
	// begin inline asm
	cvta.to.global.u64 %rd106, %rd107;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd106];
	// end inline asm
	add.s64 	%rd110, %rd89, 96;
	// begin inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd109];
	// end inline asm
	add.s64 	%rd113, %rd89, 112;
	// begin inline asm
	cvta.to.global.u64 %rd112, %rd113;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd112];
	// end inline asm
	mov.b32 	%f483, %r105;
	mov.b32 	%f484, %r106;
	and.b32  	%r146, %r104, 65535;
	add.s32 	%r147, %r146, -1;
	cvt.rn.f32.s32 	%f485, %r147;
	sub.f32 	%f486, %f355, %f483;
	mul.f32 	%f487, %f486, %f485;
	sub.f32 	%f488, %f484, %f483;
	div.rn.f32 	%f489, %f487, %f488;
	min.f32 	%f490, %f485, %f489;
	mov.f32 	%f491, 0f00000000;
	max.f32 	%f492, %f491, %f490;
	cvt.rmi.f32.f32 	%f493, %f492;
	sub.f32 	%f90, %f492, %f493;
	cvt.rzi.s32.f32 	%r148, %f493;
	mul.wide.s32 	%rd124, %r148, 48;
	add.s64 	%rd116, %rd98, %rd124;
	// begin inline asm
	cvta.to.global.u64 %rd115, %rd116;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd115];
	// end inline asm
	mov.b32 	%f863, %r134;
	mov.b32 	%f862, %r135;
	mov.b32 	%f861, %r136;
	mov.b32 	%f860, %r137;
	add.s64 	%rd119, %rd116, 16;
	// begin inline asm
	cvta.to.global.u64 %rd118, %rd119;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd118];
	// end inline asm
	mov.b32 	%f867, %r138;
	mov.b32 	%f866, %r139;
	mov.b32 	%f865, %r140;
	mov.b32 	%f864, %r141;
	add.s64 	%rd122, %rd116, 32;
	// begin inline asm
	cvta.to.global.u64 %rd121, %rd122;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd121];
	// end inline asm
	mov.b32 	%f871, %r142;
	mov.b32 	%f870, %r143;
	mov.b32 	%f869, %r144;
	mov.b32 	%f868, %r145;
	setp.leu.f32 	%p9, %f90, 0f00000000;
	@%p9 bra 	$L__BB7_15;

	cvt.rmi.f32.f32 	%f831, %f492;
	cvt.rzi.s32.f32 	%r320, %f831;
	cvt.s64.s32 	%rd255, %r320;
	mov.f32 	%f494, 0f3F800000;
	sub.f32 	%f495, %f494, %f90;
	mul.lo.s64 	%rd134, %rd255, 48;
	add.s64 	%rd135, %rd89, %rd134;
	add.s64 	%rd126, %rd135, 80;
	// begin inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd125];
	// end inline asm
	mov.b32 	%f496, %r149;
	mov.b32 	%f497, %r150;
	mov.b32 	%f498, %r151;
	mov.b32 	%f499, %r152;
	mul.f32 	%f500, %f90, %f496;
	mul.f32 	%f501, %f90, %f497;
	mul.f32 	%f502, %f90, %f498;
	mul.f32 	%f503, %f90, %f499;
	fma.rn.f32 	%f863, %f495, %f863, %f500;
	fma.rn.f32 	%f862, %f495, %f862, %f501;
	fma.rn.f32 	%f861, %f495, %f861, %f502;
	fma.rn.f32 	%f860, %f495, %f860, %f503;
	add.s64 	%rd129, %rd135, 96;
	// begin inline asm
	cvta.to.global.u64 %rd128, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd128];
	// end inline asm
	mov.b32 	%f504, %r153;
	mov.b32 	%f505, %r154;
	mov.b32 	%f506, %r155;
	mov.b32 	%f507, %r156;
	mul.f32 	%f508, %f90, %f504;
	mul.f32 	%f509, %f90, %f505;
	mul.f32 	%f510, %f90, %f506;
	mul.f32 	%f511, %f90, %f507;
	fma.rn.f32 	%f867, %f495, %f867, %f508;
	fma.rn.f32 	%f866, %f495, %f866, %f509;
	fma.rn.f32 	%f865, %f495, %f865, %f510;
	fma.rn.f32 	%f864, %f495, %f864, %f511;
	add.s64 	%rd132, %rd135, 112;
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd131];
	// end inline asm
	mov.b32 	%f512, %r157;
	mov.b32 	%f513, %r158;
	mov.b32 	%f514, %r159;
	mov.b32 	%f515, %r160;
	mul.f32 	%f516, %f90, %f512;
	mul.f32 	%f517, %f90, %f513;
	mul.f32 	%f518, %f90, %f514;
	mul.f32 	%f519, %f90, %f515;
	fma.rn.f32 	%f871, %f495, %f871, %f516;
	fma.rn.f32 	%f870, %f495, %f870, %f517;
	fma.rn.f32 	%f869, %f495, %f869, %f518;
	fma.rn.f32 	%f868, %f495, %f868, %f519;
	bra.uni 	$L__BB7_15;

$L__BB7_4:
	mov.f32 	%f872, 0f00000000;
	mov.f32 	%f875, 0f3F800000;
	setp.eq.s32 	%p5, %r13, 4;
	@%p5 bra 	$L__BB7_7;

	setp.ne.s32 	%p6, %r13, 1;
	mov.f32 	%f873, %f872;
	mov.f32 	%f874, %f872;
	mov.f32 	%f876, %f872;
	mov.f32 	%f877, %f872;
	mov.f32 	%f878, %f875;
	mov.f32 	%f879, %f872;
	mov.f32 	%f880, %f872;
	mov.f32 	%f881, %f875;
	mov.f32 	%f882, %f872;
	mov.f32 	%f883, %f872;
	@%p6 bra 	$L__BB7_16;

	// begin inline asm
	call (%rd19), _optix_get_static_transform_from_handle, (%rd17);
	// end inline asm
	add.s64 	%rd256, %rd19, 64;
	bra.uni 	$L__BB7_8;

$L__BB7_10:
	// begin inline asm
	call (%rd32), _optix_get_srt_motion_transform_from_handle, (%rd17);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd34, %rd32;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r27,%r28,%r29,%r30}, [%rd34];
	// end inline asm
	add.s64 	%rd38, %rd32, 16;
	// begin inline asm
	cvta.to.global.u64 %rd37, %rd38;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r31,%r32,%r33,%r34}, [%rd37];
	// end inline asm
	add.s64 	%rd41, %rd32, 32;
	// begin inline asm
	cvta.to.global.u64 %rd40, %rd41;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd40];
	// end inline asm
	add.s64 	%rd44, %rd32, 48;
	// begin inline asm
	cvta.to.global.u64 %rd43, %rd44;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd43];
	// end inline asm
	add.s64 	%rd47, %rd32, 64;
	// begin inline asm
	cvta.to.global.u64 %rd46, %rd47;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd46];
	// end inline asm
	add.s64 	%rd50, %rd32, 80;
	// begin inline asm
	cvta.to.global.u64 %rd49, %rd50;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd49];
	// end inline asm
	add.s64 	%rd53, %rd32, 96;
	// begin inline asm
	cvta.to.global.u64 %rd52, %rd53;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd52];
	// end inline asm
	add.s64 	%rd56, %rd32, 112;
	// begin inline asm
	cvta.to.global.u64 %rd55, %rd56;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd55];
	// end inline asm
	add.s64 	%rd59, %rd32, 128;
	// begin inline asm
	cvta.to.global.u64 %rd58, %rd59;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd58];
	// end inline asm
	add.s64 	%rd62, %rd32, 144;
	// begin inline asm
	cvta.to.global.u64 %rd61, %rd62;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd61];
	// end inline asm
	mov.b32 	%f370, %r30;
	mov.b32 	%f371, %r31;
	and.b32  	%r83, %r29, 65535;
	add.s32 	%r84, %r83, -1;
	cvt.rn.f32.s32 	%f372, %r84;
	sub.f32 	%f373, %f355, %f370;
	mul.f32 	%f374, %f373, %f372;
	sub.f32 	%f375, %f371, %f370;
	div.rn.f32 	%f376, %f374, %f375;
	min.f32 	%f377, %f372, %f376;
	mov.f32 	%f378, 0f00000000;
	max.f32 	%f379, %f378, %f377;
	cvt.rmi.f32.f32 	%f380, %f379;
	sub.f32 	%f29, %f379, %f380;
	cvt.rzi.s32.f32 	%r85, %f380;
	mul.wide.s32 	%rd76, %r85, 64;
	add.s64 	%rd65, %rd41, %rd76;
	// begin inline asm
	cvta.to.global.u64 %rd64, %rd65;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd64];
	// end inline asm
	mov.b32 	%f844, %r67;
	mov.b32 	%f845, %r68;
	mov.b32 	%f846, %r69;
	mov.b32 	%f847, %r70;
	add.s64 	%rd68, %rd65, 16;
	// begin inline asm
	cvta.to.global.u64 %rd67, %rd68;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd67];
	// end inline asm
	mov.b32 	%f848, %r71;
	mov.b32 	%f849, %r72;
	mov.b32 	%f850, %r73;
	mov.b32 	%f851, %r74;
	add.s64 	%rd71, %rd65, 32;
	// begin inline asm
	cvta.to.global.u64 %rd70, %rd71;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd70];
	// end inline asm
	mov.b32 	%f852, %r75;
	mov.b32 	%f853, %r76;
	mov.b32 	%f854, %r77;
	mov.b32 	%f855, %r78;
	add.s64 	%rd74, %rd65, 48;
	// begin inline asm
	cvta.to.global.u64 %rd73, %rd74;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd73];
	// end inline asm
	mov.b32 	%f856, %r79;
	mov.b32 	%f857, %r80;
	mov.b32 	%f858, %r81;
	mov.b32 	%f859, %r82;
	setp.leu.f32 	%p8, %f29, 0f00000000;
	@%p8 bra 	$L__BB7_12;

	mov.f32 	%f381, 0f3F800000;
	sub.f32 	%f382, %f381, %f29;
	add.s64 	%rd78, %rd65, 64;
	// begin inline asm
	cvta.to.global.u64 %rd77, %rd78;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r86,%r87,%r88,%r89}, [%rd77];
	// end inline asm
	mov.b32 	%f383, %r86;
	mov.b32 	%f384, %r87;
	mov.b32 	%f385, %r88;
	mov.b32 	%f386, %r89;
	mul.f32 	%f387, %f29, %f383;
	mul.f32 	%f388, %f29, %f384;
	mul.f32 	%f389, %f29, %f385;
	mul.f32 	%f390, %f29, %f386;
	fma.rn.f32 	%f844, %f382, %f844, %f387;
	fma.rn.f32 	%f845, %f382, %f845, %f388;
	fma.rn.f32 	%f846, %f382, %f846, %f389;
	fma.rn.f32 	%f847, %f382, %f847, %f390;
	add.s64 	%rd81, %rd65, 80;
	// begin inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd80];
	// end inline asm
	mov.b32 	%f391, %r90;
	mov.b32 	%f392, %r91;
	mov.b32 	%f393, %r92;
	mov.b32 	%f394, %r93;
	mul.f32 	%f395, %f29, %f391;
	mul.f32 	%f396, %f29, %f392;
	mul.f32 	%f397, %f29, %f393;
	mul.f32 	%f398, %f29, %f394;
	fma.rn.f32 	%f848, %f382, %f848, %f395;
	fma.rn.f32 	%f849, %f382, %f849, %f396;
	fma.rn.f32 	%f850, %f382, %f850, %f397;
	fma.rn.f32 	%f851, %f382, %f851, %f398;
	add.s64 	%rd84, %rd65, 96;
	// begin inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd83];
	// end inline asm
	mov.b32 	%f399, %r94;
	mov.b32 	%f400, %r95;
	mov.b32 	%f401, %r96;
	mov.b32 	%f402, %r97;
	mul.f32 	%f403, %f29, %f399;
	mul.f32 	%f404, %f29, %f400;
	mul.f32 	%f405, %f29, %f401;
	mul.f32 	%f406, %f29, %f402;
	fma.rn.f32 	%f852, %f382, %f852, %f403;
	fma.rn.f32 	%f407, %f382, %f853, %f404;
	fma.rn.f32 	%f408, %f382, %f854, %f405;
	fma.rn.f32 	%f409, %f382, %f855, %f406;
	add.s64 	%rd87, %rd65, 112;
	// begin inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd86];
	// end inline asm
	mov.b32 	%f410, %r98;
	mov.b32 	%f411, %r99;
	mov.b32 	%f412, %r100;
	mov.b32 	%f413, %r101;
	mul.f32 	%f414, %f29, %f410;
	mul.f32 	%f415, %f29, %f411;
	mul.f32 	%f416, %f29, %f412;
	mul.f32 	%f417, %f29, %f413;
	fma.rn.f32 	%f418, %f382, %f856, %f414;
	fma.rn.f32 	%f857, %f382, %f857, %f415;
	fma.rn.f32 	%f858, %f382, %f858, %f416;
	fma.rn.f32 	%f859, %f382, %f859, %f417;
	mul.f32 	%f419, %f408, %f408;
	fma.rn.f32 	%f420, %f407, %f407, %f419;
	fma.rn.f32 	%f421, %f409, %f409, %f420;
	fma.rn.f32 	%f422, %f418, %f418, %f421;
	sqrt.rn.f32 	%f423, %f422;
	rcp.rn.f32 	%f424, %f423;
	mul.f32 	%f853, %f407, %f424;
	mul.f32 	%f854, %f408, %f424;
	mul.f32 	%f855, %f409, %f424;
	mul.f32 	%f856, %f424, %f418;

$L__BB7_12:
	mul.f32 	%f425, %f854, %f854;
	fma.rn.f32 	%f426, %f853, %f853, %f425;
	fma.rn.f32 	%f427, %f855, %f855, %f426;
	fma.rn.f32 	%f428, %f856, %f856, %f427;
	rcp.rn.f32 	%f429, %f428;
	mul.f32 	%f430, %f853, %f429;
	mul.f32 	%f431, %f854, %f429;
	mul.f32 	%f432, %f855, %f429;
	mul.f32 	%f433, %f856, %f429;
	mul.f32 	%f434, %f853, %f430;
	mul.f32 	%f435, %f854, %f431;
	mul.f32 	%f436, %f855, %f432;
	mul.f32 	%f437, %f853, %f431;
	mul.f32 	%f438, %f855, %f433;
	mul.f32 	%f439, %f853, %f432;
	mul.f32 	%f440, %f854, %f433;
	mul.f32 	%f441, %f854, %f432;
	mul.f32 	%f442, %f853, %f433;
	sub.f32 	%f443, %f434, %f435;
	sub.f32 	%f444, %f443, %f436;
	fma.rn.f32 	%f445, %f856, %f433, %f444;
	sub.f32 	%f446, %f437, %f438;
	add.f32 	%f447, %f446, %f446;
	add.f32 	%f448, %f439, %f440;
	add.f32 	%f449, %f448, %f448;
	add.f32 	%f450, %f437, %f438;
	add.f32 	%f451, %f450, %f450;
	sub.f32 	%f452, %f435, %f434;
	sub.f32 	%f453, %f452, %f436;
	fma.rn.f32 	%f454, %f856, %f433, %f453;
	sub.f32 	%f455, %f441, %f442;
	add.f32 	%f456, %f455, %f455;
	sub.f32 	%f457, %f439, %f440;
	add.f32 	%f458, %f457, %f457;
	add.f32 	%f459, %f441, %f442;
	add.f32 	%f460, %f459, %f459;
	neg.f32 	%f461, %f434;
	sub.f32 	%f462, %f461, %f435;
	add.f32 	%f463, %f436, %f462;
	fma.rn.f32 	%f464, %f856, %f433, %f463;
	mul.f32 	%f465, %f847, %f445;
	fma.rn.f32 	%f466, %f850, %f447, %f465;
	fma.rn.f32 	%f467, %f852, %f449, %f466;
	sub.f32 	%f860, %f857, %f467;
	mul.f32 	%f468, %f850, %f454;
	fma.rn.f32 	%f469, %f847, %f451, %f468;
	fma.rn.f32 	%f470, %f852, %f456, %f469;
	sub.f32 	%f864, %f858, %f470;
	mul.f32 	%f471, %f850, %f460;
	fma.rn.f32 	%f472, %f847, %f458, %f471;
	fma.rn.f32 	%f473, %f852, %f464, %f472;
	sub.f32 	%f868, %f859, %f473;
	mul.f32 	%f474, %f846, %f445;
	fma.rn.f32 	%f475, %f849, %f447, %f474;
	fma.rn.f32 	%f861, %f851, %f449, %f475;
	mul.f32 	%f476, %f849, %f454;
	fma.rn.f32 	%f477, %f846, %f451, %f476;
	fma.rn.f32 	%f865, %f851, %f456, %f477;
	mul.f32 	%f478, %f849, %f460;
	fma.rn.f32 	%f479, %f846, %f458, %f478;
	fma.rn.f32 	%f869, %f851, %f464, %f479;
	mul.f32 	%f480, %f845, %f445;
	fma.rn.f32 	%f862, %f848, %f447, %f480;
	mul.f32 	%f481, %f848, %f454;
	fma.rn.f32 	%f866, %f845, %f451, %f481;
	mul.f32 	%f482, %f848, %f460;
	fma.rn.f32 	%f870, %f845, %f458, %f482;
	mul.f32 	%f863, %f844, %f445;
	mul.f32 	%f867, %f844, %f451;
	mul.f32 	%f871, %f844, %f458;

$L__BB7_15:
	mul.f32 	%f520, %f865, %f870;
	mul.f32 	%f521, %f866, %f869;
	sub.f32 	%f522, %f521, %f520;
	mul.f32 	%f523, %f863, %f522;
	mul.f32 	%f524, %f865, %f871;
	mul.f32 	%f525, %f867, %f869;
	sub.f32 	%f526, %f525, %f524;
	mul.f32 	%f527, %f862, %f526;
	sub.f32 	%f528, %f523, %f527;
	mul.f32 	%f529, %f866, %f871;
	mul.f32 	%f530, %f867, %f870;
	sub.f32 	%f531, %f530, %f529;
	fma.rn.f32 	%f532, %f861, %f531, %f528;
	rcp.rn.f32 	%f533, %f532;
	mul.f32 	%f875, %f522, %f533;
	mul.f32 	%f534, %f862, %f869;
	mul.f32 	%f535, %f861, %f870;
	sub.f32 	%f536, %f535, %f534;
	mul.f32 	%f874, %f536, %f533;
	mul.f32 	%f537, %f861, %f866;
	mul.f32 	%f538, %f862, %f865;
	sub.f32 	%f539, %f538, %f537;
	mul.f32 	%f873, %f539, %f533;
	sub.f32 	%f540, %f524, %f525;
	mul.f32 	%f879, %f540, %f533;
	mul.f32 	%f541, %f861, %f871;
	mul.f32 	%f542, %f863, %f869;
	sub.f32 	%f543, %f542, %f541;
	mul.f32 	%f878, %f543, %f533;
	mul.f32 	%f544, %f863, %f865;
	mul.f32 	%f545, %f861, %f867;
	sub.f32 	%f546, %f545, %f544;
	mul.f32 	%f877, %f546, %f533;
	mul.f32 	%f883, %f531, %f533;
	mul.f32 	%f547, %f863, %f870;
	mul.f32 	%f548, %f862, %f871;
	sub.f32 	%f549, %f548, %f547;
	mul.f32 	%f882, %f549, %f533;
	mul.f32 	%f550, %f862, %f867;
	mul.f32 	%f551, %f863, %f866;
	sub.f32 	%f552, %f551, %f550;
	mul.f32 	%f881, %f552, %f533;
	mul.f32 	%f553, %f860, %f875;
	neg.f32 	%f554, %f553;
	mul.f32 	%f555, %f864, %f874;
	sub.f32 	%f556, %f554, %f555;
	mul.f32 	%f557, %f868, %f873;
	sub.f32 	%f872, %f556, %f557;
	mul.f32 	%f558, %f860, %f879;
	neg.f32 	%f559, %f558;
	mul.f32 	%f560, %f864, %f878;
	sub.f32 	%f561, %f559, %f560;
	mul.f32 	%f562, %f868, %f877;
	sub.f32 	%f876, %f561, %f562;
	mul.f32 	%f563, %f860, %f883;
	neg.f32 	%f564, %f563;
	mul.f32 	%f565, %f864, %f882;
	sub.f32 	%f566, %f564, %f565;
	mul.f32 	%f567, %f868, %f881;
	sub.f32 	%f880, %f566, %f567;
	bra.uni 	$L__BB7_16;

$L__BB7_7:
	// begin inline asm
	call (%rd256), _optix_get_instance_inverse_transform_from_handle, (%rd17);
	// end inline asm

$L__BB7_8:
	// begin inline asm
	cvta.to.global.u64 %rd23, %rd256;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r15,%r16,%r17,%r18}, [%rd23];
	// end inline asm
	mov.b32 	%f875, %r15;
	mov.b32 	%f874, %r16;
	mov.b32 	%f873, %r17;
	mov.b32 	%f872, %r18;
	add.s64 	%rd27, %rd256, 16;
	// begin inline asm
	cvta.to.global.u64 %rd26, %rd27;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r19,%r20,%r21,%r22}, [%rd26];
	// end inline asm
	mov.b32 	%f879, %r19;
	mov.b32 	%f878, %r20;
	mov.b32 	%f877, %r21;
	mov.b32 	%f876, %r22;
	add.s64 	%rd30, %rd256, 32;
	// begin inline asm
	cvta.to.global.u64 %rd29, %rd30;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r23,%r24,%r25,%r26}, [%rd29];
	// end inline asm
	mov.b32 	%f883, %r23;
	mov.b32 	%f882, %r24;
	mov.b32 	%f881, %r25;
	mov.b32 	%f880, %r26;

$L__BB7_16:
	setp.eq.s32 	%p10, %r321, 0;
	@%p10 bra 	$L__BB7_18;

	mul.f32 	%f568, %f840, %f875;
	fma.rn.f32 	%f569, %f836, %f874, %f568;
	fma.rn.f32 	%f151, %f832, %f873, %f569;
	mul.f32 	%f570, %f841, %f875;
	fma.rn.f32 	%f571, %f837, %f874, %f570;
	fma.rn.f32 	%f152, %f833, %f873, %f571;
	mul.f32 	%f572, %f842, %f875;
	fma.rn.f32 	%f573, %f838, %f874, %f572;
	fma.rn.f32 	%f153, %f834, %f873, %f573;
	mul.f32 	%f574, %f843, %f875;
	fma.rn.f32 	%f575, %f839, %f874, %f574;
	fma.rn.f32 	%f576, %f835, %f873, %f575;
	add.f32 	%f872, %f872, %f576;
	mul.f32 	%f577, %f840, %f879;
	fma.rn.f32 	%f578, %f836, %f878, %f577;
	fma.rn.f32 	%f155, %f832, %f877, %f578;
	mul.f32 	%f579, %f841, %f879;
	fma.rn.f32 	%f580, %f837, %f878, %f579;
	fma.rn.f32 	%f156, %f833, %f877, %f580;
	mul.f32 	%f581, %f842, %f879;
	fma.rn.f32 	%f582, %f838, %f878, %f581;
	fma.rn.f32 	%f157, %f834, %f877, %f582;
	mul.f32 	%f583, %f843, %f879;
	fma.rn.f32 	%f584, %f839, %f878, %f583;
	fma.rn.f32 	%f585, %f835, %f877, %f584;
	add.f32 	%f876, %f876, %f585;
	mul.f32 	%f586, %f840, %f883;
	fma.rn.f32 	%f587, %f836, %f882, %f586;
	fma.rn.f32 	%f159, %f832, %f881, %f587;
	mul.f32 	%f588, %f841, %f883;
	fma.rn.f32 	%f589, %f837, %f882, %f588;
	fma.rn.f32 	%f160, %f833, %f881, %f589;
	mul.f32 	%f590, %f842, %f883;
	fma.rn.f32 	%f591, %f838, %f882, %f590;
	fma.rn.f32 	%f161, %f834, %f881, %f591;
	mul.f32 	%f592, %f843, %f883;
	fma.rn.f32 	%f593, %f839, %f882, %f592;
	fma.rn.f32 	%f594, %f835, %f881, %f593;
	add.f32 	%f880, %f880, %f594;
	mov.f32 	%f873, %f153;
	mov.f32 	%f874, %f152;
	mov.f32 	%f875, %f151;
	mov.f32 	%f877, %f157;
	mov.f32 	%f878, %f156;
	mov.f32 	%f879, %f155;
	mov.f32 	%f881, %f161;
	mov.f32 	%f882, %f160;
	mov.f32 	%f883, %f159;

$L__BB7_18:
	add.s32 	%r321, %r321, 1;
	setp.lt.u32 	%p11, %r321, %r10;
	mov.f32 	%f832, %f883;
	mov.f32 	%f833, %f882;
	mov.f32 	%f834, %f881;
	mov.f32 	%f835, %f880;
	mov.f32 	%f836, %f879;
	mov.f32 	%f837, %f878;
	mov.f32 	%f838, %f877;
	mov.f32 	%f839, %f876;
	mov.f32 	%f840, %f875;
	mov.f32 	%f841, %f874;
	mov.f32 	%f842, %f873;
	mov.f32 	%f843, %f872;
	@%p11 bra 	$L__BB7_3;

$L__BB7_19:
	mul.f32 	%f595, %f908, %f875;
	fma.rn.f32 	%f596, %f909, %f874, %f595;
	fma.rn.f32 	%f597, %f910, %f873, %f596;
	mul.f32 	%f598, %f908, %f879;
	fma.rn.f32 	%f599, %f909, %f878, %f598;
	fma.rn.f32 	%f600, %f910, %f877, %f599;
	mul.f32 	%f601, %f908, %f883;
	fma.rn.f32 	%f602, %f909, %f882, %f601;
	fma.rn.f32 	%f603, %f910, %f881, %f602;
	add.f32 	%f910, %f880, %f603;
	add.f32 	%f909, %f876, %f600;
	add.f32 	%f908, %f872, %f597;

$L__BB7_21:
	// begin inline asm
	call (%f966), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f967), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f606), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r161), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p12, %r161, 0;
	@%p12 bra 	$L__BB7_41;

	// begin inline asm
	call (%r162), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f607), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p13, %r162, 0;
	@%p13 bra 	$L__BB7_40;

	mov.u32 	%r322, 0;

$L__BB7_24:
	.pragma "nounroll";
	// begin inline asm
	call (%rd136), _optix_get_transform_list_handle, (%r322);
	// end inline asm
	// begin inline asm
	call (%r165), _optix_get_transform_type_from_handle, (%rd136);
	// end inline asm
	or.b32  	%r166, %r165, 1;
	setp.eq.s32 	%p14, %r166, 3;
	@%p14 bra 	$L__BB7_30;
	bra.uni 	$L__BB7_25;

$L__BB7_30:
	setp.eq.s32 	%p17, %r165, 2;
	@%p17 bra 	$L__BB7_34;
	bra.uni 	$L__BB7_31;

$L__BB7_34:
	// begin inline asm
	call (%rd208), _optix_get_matrix_motion_transform_from_handle, (%rd136);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd210, %rd208;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd210];
	// end inline asm
	add.s64 	%rd214, %rd208, 16;
	// begin inline asm
	cvta.to.global.u64 %rd213, %rd214;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd213];
	// end inline asm
	add.s64 	%rd217, %rd208, 32;
	// begin inline asm
	cvta.to.global.u64 %rd216, %rd217;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd216];
	// end inline asm
	add.s64 	%rd220, %rd208, 48;
	// begin inline asm
	cvta.to.global.u64 %rd219, %rd220;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd219];
	// end inline asm
	add.s64 	%rd223, %rd208, 64;
	// begin inline asm
	cvta.to.global.u64 %rd222, %rd223;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd222];
	// end inline asm
	add.s64 	%rd226, %rd208, 80;
	// begin inline asm
	cvta.to.global.u64 %rd225, %rd226;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd225];
	// end inline asm
	add.s64 	%rd229, %rd208, 96;
	// begin inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd228];
	// end inline asm
	add.s64 	%rd232, %rd208, 112;
	// begin inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd231];
	// end inline asm
	mov.b32 	%f711, %r257;
	mov.b32 	%f712, %r258;
	and.b32  	%r298, %r256, 65535;
	add.s32 	%r299, %r298, -1;
	cvt.rn.f32.s32 	%f713, %r299;
	sub.f32 	%f714, %f607, %f711;
	mul.f32 	%f715, %f714, %f713;
	sub.f32 	%f716, %f712, %f711;
	div.rn.f32 	%f717, %f715, %f716;
	min.f32 	%f718, %f713, %f717;
	mov.f32 	%f719, 0f00000000;
	max.f32 	%f720, %f719, %f718;
	cvt.rmi.f32.f32 	%f721, %f720;
	sub.f32 	%f258, %f720, %f721;
	cvt.rzi.s32.f32 	%r300, %f721;
	cvt.s64.s32 	%rd15, %r300;
	mul.wide.s32 	%rd243, %r300, 48;
	add.s64 	%rd235, %rd217, %rd243;
	// begin inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd234];
	// end inline asm
	mov.b32 	%f936, %r286;
	mov.b32 	%f937, %r287;
	mov.b32 	%f938, %r288;
	add.s64 	%rd238, %rd235, 16;
	// begin inline asm
	cvta.to.global.u64 %rd237, %rd238;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd237];
	// end inline asm
	mov.b32 	%f933, %r290;
	mov.b32 	%f934, %r291;
	mov.b32 	%f935, %r292;
	add.s64 	%rd241, %rd235, 32;
	// begin inline asm
	cvta.to.global.u64 %rd240, %rd241;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r294,%r295,%r296,%r297}, [%rd240];
	// end inline asm
	mov.b32 	%f930, %r294;
	mov.b32 	%f931, %r295;
	mov.b32 	%f932, %r296;
	setp.leu.f32 	%p19, %f258, 0f00000000;
	@%p19 bra 	$L__BB7_36;

	mov.f32 	%f722, 0f3F800000;
	sub.f32 	%f723, %f722, %f258;
	mul.lo.s64 	%rd253, %rd15, 48;
	add.s64 	%rd254, %rd208, %rd253;
	add.s64 	%rd245, %rd254, 80;
	// begin inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd244];
	// end inline asm
	mov.b32 	%f724, %r301;
	mov.b32 	%f725, %r302;
	mov.b32 	%f726, %r303;
	mul.f32 	%f727, %f258, %f724;
	mul.f32 	%f728, %f258, %f725;
	mul.f32 	%f729, %f258, %f726;
	fma.rn.f32 	%f936, %f723, %f936, %f727;
	fma.rn.f32 	%f937, %f723, %f937, %f728;
	fma.rn.f32 	%f938, %f723, %f938, %f729;
	add.s64 	%rd248, %rd254, 96;
	// begin inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd247];
	// end inline asm
	mov.b32 	%f730, %r305;
	mov.b32 	%f731, %r306;
	mov.b32 	%f732, %r307;
	mul.f32 	%f733, %f258, %f730;
	mul.f32 	%f734, %f258, %f731;
	mul.f32 	%f735, %f258, %f732;
	fma.rn.f32 	%f933, %f723, %f933, %f733;
	fma.rn.f32 	%f934, %f723, %f934, %f734;
	fma.rn.f32 	%f935, %f723, %f935, %f735;
	add.s64 	%rd251, %rd254, 112;
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r309,%r310,%r311,%r312}, [%rd250];
	// end inline asm
	mov.b32 	%f736, %r309;
	mov.b32 	%f737, %r310;
	mov.b32 	%f738, %r311;
	mul.f32 	%f739, %f258, %f736;
	mul.f32 	%f740, %f258, %f737;
	mul.f32 	%f741, %f258, %f738;
	fma.rn.f32 	%f930, %f723, %f930, %f739;
	fma.rn.f32 	%f931, %f723, %f931, %f740;
	fma.rn.f32 	%f932, %f723, %f932, %f741;
	bra.uni 	$L__BB7_36;

$L__BB7_25:
	mov.f32 	%f939, 0f00000000;
	mov.f32 	%f941, 0f3F800000;
	setp.eq.s32 	%p15, %r165, 4;
	@%p15 bra 	$L__BB7_28;

	setp.ne.s32 	%p16, %r165, 1;
	mov.f32 	%f940, %f939;
	mov.f32 	%f942, %f939;
	mov.f32 	%f943, %f941;
	mov.f32 	%f944, %f939;
	mov.f32 	%f945, %f941;
	mov.f32 	%f946, %f939;
	mov.f32 	%f947, %f939;
	@%p16 bra 	$L__BB7_37;

	// begin inline asm
	call (%rd138), _optix_get_static_transform_from_handle, (%rd136);
	// end inline asm
	add.s64 	%rd257, %rd138, 64;
	bra.uni 	$L__BB7_29;

$L__BB7_31:
	// begin inline asm
	call (%rd151), _optix_get_srt_motion_transform_from_handle, (%rd136);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd153, %rd151;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd153];
	// end inline asm
	add.s64 	%rd157, %rd151, 16;
	// begin inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd156];
	// end inline asm
	add.s64 	%rd160, %rd151, 32;
	// begin inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd159];
	// end inline asm
	add.s64 	%rd163, %rd151, 48;
	// begin inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd162];
	// end inline asm
	add.s64 	%rd166, %rd151, 64;
	// begin inline asm
	cvta.to.global.u64 %rd165, %rd166;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd165];
	// end inline asm
	add.s64 	%rd169, %rd151, 80;
	// begin inline asm
	cvta.to.global.u64 %rd168, %rd169;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd168];
	// end inline asm
	add.s64 	%rd172, %rd151, 96;
	// begin inline asm
	cvta.to.global.u64 %rd171, %rd172;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd171];
	// end inline asm
	add.s64 	%rd175, %rd151, 112;
	// begin inline asm
	cvta.to.global.u64 %rd174, %rd175;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd174];
	// end inline asm
	add.s64 	%rd178, %rd151, 128;
	// begin inline asm
	cvta.to.global.u64 %rd177, %rd178;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd177];
	// end inline asm
	add.s64 	%rd181, %rd151, 144;
	// begin inline asm
	cvta.to.global.u64 %rd180, %rd181;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd180];
	// end inline asm
	mov.b32 	%f619, %r182;
	mov.b32 	%f620, %r183;
	and.b32  	%r235, %r181, 65535;
	add.s32 	%r236, %r235, -1;
	cvt.rn.f32.s32 	%f621, %r236;
	sub.f32 	%f622, %f607, %f619;
	mul.f32 	%f623, %f622, %f621;
	sub.f32 	%f624, %f620, %f619;
	div.rn.f32 	%f625, %f623, %f624;
	min.f32 	%f626, %f621, %f625;
	mov.f32 	%f627, 0f00000000;
	max.f32 	%f628, %f627, %f626;
	cvt.rmi.f32.f32 	%f629, %f628;
	sub.f32 	%f218, %f628, %f629;
	cvt.rzi.s32.f32 	%r237, %f629;
	mul.wide.s32 	%rd195, %r237, 64;
	add.s64 	%rd184, %rd160, %rd195;
	// begin inline asm
	cvta.to.global.u64 %rd183, %rd184;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd183];
	// end inline asm
	mov.b32 	%f920, %r219;
	mov.b32 	%f921, %r220;
	mov.b32 	%f922, %r221;
	add.s64 	%rd187, %rd184, 16;
	// begin inline asm
	cvta.to.global.u64 %rd186, %rd187;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd186];
	// end inline asm
	mov.b32 	%f923, %r223;
	mov.b32 	%f924, %r224;
	mov.b32 	%f925, %r226;
	add.s64 	%rd190, %rd184, 32;
	// begin inline asm
	cvta.to.global.u64 %rd189, %rd190;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd189];
	// end inline asm
	mov.b32 	%f926, %r228;
	mov.b32 	%f927, %r229;
	mov.b32 	%f928, %r230;
	add.s64 	%rd193, %rd184, 48;
	// begin inline asm
	cvta.to.global.u64 %rd192, %rd193;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r231,%r232,%r233,%r234}, [%rd192];
	// end inline asm
	mov.b32 	%f929, %r231;
	setp.leu.f32 	%p18, %f218, 0f00000000;
	@%p18 bra 	$L__BB7_33;

	mov.f32 	%f630, 0f3F800000;
	sub.f32 	%f631, %f630, %f218;
	add.s64 	%rd197, %rd184, 64;
	// begin inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd196];
	// end inline asm
	mov.b32 	%f632, %r238;
	mov.b32 	%f633, %r239;
	mov.b32 	%f634, %r240;
	mul.f32 	%f635, %f218, %f632;
	mul.f32 	%f636, %f218, %f633;
	mul.f32 	%f637, %f218, %f634;
	fma.rn.f32 	%f920, %f631, %f920, %f635;
	fma.rn.f32 	%f921, %f631, %f921, %f636;
	fma.rn.f32 	%f922, %f631, %f922, %f637;
	add.s64 	%rd200, %rd184, 80;
	// begin inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd199];
	// end inline asm
	mov.b32 	%f638, %r242;
	mov.b32 	%f639, %r243;
	mov.b32 	%f640, %r245;
	mul.f32 	%f641, %f218, %f638;
	mul.f32 	%f642, %f218, %f639;
	mul.f32 	%f643, %f218, %f640;
	fma.rn.f32 	%f923, %f631, %f923, %f641;
	fma.rn.f32 	%f924, %f631, %f924, %f642;
	fma.rn.f32 	%f925, %f631, %f925, %f643;
	add.s64 	%rd203, %rd184, 96;
	// begin inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd202];
	// end inline asm
	mov.b32 	%f644, %r247;
	mov.b32 	%f645, %r248;
	mov.b32 	%f646, %r249;
	mul.f32 	%f647, %f218, %f644;
	mul.f32 	%f648, %f218, %f645;
	mul.f32 	%f649, %f218, %f646;
	fma.rn.f32 	%f650, %f631, %f926, %f647;
	fma.rn.f32 	%f651, %f631, %f927, %f648;
	fma.rn.f32 	%f652, %f631, %f928, %f649;
	add.s64 	%rd206, %rd184, 112;
	// begin inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd205];
	// end inline asm
	mov.b32 	%f653, %r250;
	mul.f32 	%f654, %f218, %f653;
	fma.rn.f32 	%f655, %f631, %f929, %f654;
	mul.f32 	%f656, %f651, %f651;
	fma.rn.f32 	%f657, %f650, %f650, %f656;
	fma.rn.f32 	%f658, %f652, %f652, %f657;
	fma.rn.f32 	%f659, %f655, %f655, %f658;
	sqrt.rn.f32 	%f660, %f659;
	rcp.rn.f32 	%f661, %f660;
	mul.f32 	%f926, %f650, %f661;
	mul.f32 	%f927, %f651, %f661;
	mul.f32 	%f928, %f652, %f661;
	mul.f32 	%f929, %f661, %f655;

$L__BB7_33:
	mul.f32 	%f662, %f927, %f927;
	fma.rn.f32 	%f663, %f926, %f926, %f662;
	fma.rn.f32 	%f664, %f928, %f928, %f663;
	fma.rn.f32 	%f665, %f929, %f929, %f664;
	rcp.rn.f32 	%f666, %f665;
	mul.f32 	%f667, %f926, %f666;
	mul.f32 	%f668, %f927, %f666;
	mul.f32 	%f669, %f928, %f666;
	mul.f32 	%f670, %f929, %f666;
	mul.f32 	%f671, %f926, %f667;
	mul.f32 	%f672, %f927, %f668;
	mul.f32 	%f673, %f928, %f669;
	mul.f32 	%f674, %f926, %f668;
	mul.f32 	%f675, %f928, %f670;
	mul.f32 	%f676, %f926, %f669;
	mul.f32 	%f677, %f927, %f670;
	mul.f32 	%f678, %f927, %f669;
	mul.f32 	%f679, %f926, %f670;
	sub.f32 	%f680, %f671, %f672;
	sub.f32 	%f681, %f680, %f673;
	fma.rn.f32 	%f682, %f929, %f670, %f681;
	sub.f32 	%f683, %f674, %f675;
	add.f32 	%f684, %f683, %f683;
	add.f32 	%f685, %f676, %f677;
	add.f32 	%f686, %f685, %f685;
	add.f32 	%f687, %f674, %f675;
	add.f32 	%f688, %f687, %f687;
	sub.f32 	%f689, %f672, %f671;
	sub.f32 	%f690, %f689, %f673;
	fma.rn.f32 	%f691, %f929, %f670, %f690;
	sub.f32 	%f692, %f678, %f679;
	add.f32 	%f693, %f692, %f692;
	sub.f32 	%f694, %f676, %f677;
	add.f32 	%f695, %f694, %f694;
	add.f32 	%f696, %f678, %f679;
	add.f32 	%f697, %f696, %f696;
	neg.f32 	%f698, %f671;
	sub.f32 	%f699, %f698, %f672;
	add.f32 	%f700, %f673, %f699;
	fma.rn.f32 	%f701, %f929, %f670, %f700;
	mul.f32 	%f702, %f922, %f682;
	fma.rn.f32 	%f703, %f924, %f684, %f702;
	fma.rn.f32 	%f938, %f925, %f686, %f703;
	mul.f32 	%f704, %f924, %f691;
	fma.rn.f32 	%f705, %f922, %f688, %f704;
	fma.rn.f32 	%f935, %f925, %f693, %f705;
	mul.f32 	%f706, %f924, %f697;
	fma.rn.f32 	%f707, %f922, %f695, %f706;
	fma.rn.f32 	%f932, %f925, %f701, %f707;
	mul.f32 	%f708, %f921, %f682;
	fma.rn.f32 	%f937, %f923, %f684, %f708;
	mul.f32 	%f709, %f923, %f691;
	fma.rn.f32 	%f934, %f921, %f688, %f709;
	mul.f32 	%f710, %f923, %f697;
	fma.rn.f32 	%f931, %f921, %f695, %f710;
	mul.f32 	%f936, %f920, %f682;
	mul.f32 	%f933, %f920, %f688;
	mul.f32 	%f930, %f920, %f695;

$L__BB7_36:
	mul.f32 	%f742, %f931, %f935;
	mul.f32 	%f743, %f932, %f934;
	sub.f32 	%f744, %f743, %f742;
	mul.f32 	%f745, %f936, %f744;
	mul.f32 	%f746, %f930, %f935;
	mul.f32 	%f747, %f932, %f933;
	sub.f32 	%f748, %f747, %f746;
	mul.f32 	%f749, %f748, %f937;
	sub.f32 	%f750, %f745, %f749;
	mul.f32 	%f751, %f930, %f934;
	mul.f32 	%f752, %f931, %f933;
	sub.f32 	%f753, %f752, %f751;
	fma.rn.f32 	%f754, %f753, %f938, %f750;
	rcp.rn.f32 	%f755, %f754;
	mul.f32 	%f945, %f744, %f755;
	mul.f32 	%f756, %f932, %f937;
	mul.f32 	%f757, %f931, %f938;
	sub.f32 	%f758, %f757, %f756;
	mul.f32 	%f946, %f758, %f755;
	mul.f32 	%f759, %f934, %f938;
	mul.f32 	%f760, %f935, %f937;
	sub.f32 	%f761, %f760, %f759;
	mul.f32 	%f947, %f761, %f755;
	sub.f32 	%f762, %f746, %f747;
	mul.f32 	%f942, %f762, %f755;
	mul.f32 	%f763, %f930, %f938;
	mul.f32 	%f764, %f932, %f936;
	sub.f32 	%f765, %f764, %f763;
	mul.f32 	%f943, %f765, %f755;
	mul.f32 	%f766, %f935, %f936;
	mul.f32 	%f767, %f933, %f938;
	sub.f32 	%f768, %f767, %f766;
	mul.f32 	%f944, %f768, %f755;
	mul.f32 	%f939, %f753, %f755;
	mul.f32 	%f769, %f931, %f936;
	mul.f32 	%f770, %f930, %f937;
	sub.f32 	%f771, %f770, %f769;
	mul.f32 	%f940, %f771, %f755;
	mul.f32 	%f772, %f933, %f937;
	mul.f32 	%f773, %f934, %f936;
	sub.f32 	%f774, %f773, %f772;
	mul.f32 	%f941, %f774, %f755;
	bra.uni 	$L__BB7_37;

$L__BB7_28:
	// begin inline asm
	call (%rd257), _optix_get_instance_inverse_transform_from_handle, (%rd136);
	// end inline asm

$L__BB7_29:
	// begin inline asm
	cvta.to.global.u64 %rd142, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd142];
	// end inline asm
	mov.b32 	%f945, %r167;
	mov.b32 	%f946, %r168;
	mov.b32 	%f947, %r169;
	add.s64 	%rd146, %rd257, 16;
	// begin inline asm
	cvta.to.global.u64 %rd145, %rd146;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd145];
	// end inline asm
	mov.b32 	%f942, %r171;
	mov.b32 	%f943, %r172;
	mov.b32 	%f944, %r173;
	add.s64 	%rd149, %rd257, 32;
	// begin inline asm
	cvta.to.global.u64 %rd148, %rd149;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd148];
	// end inline asm
	mov.b32 	%f939, %r175;
	mov.b32 	%f940, %r176;
	mov.b32 	%f941, %r177;

$L__BB7_37:
	setp.eq.s32 	%p20, %r322, 0;
	@%p20 bra 	$L__BB7_39;

	mul.f32 	%f775, %f916, %f946;
	fma.rn.f32 	%f776, %f913, %f945, %f775;
	fma.rn.f32 	%f304, %f919, %f947, %f776;
	mul.f32 	%f777, %f915, %f946;
	fma.rn.f32 	%f778, %f912, %f945, %f777;
	fma.rn.f32 	%f305, %f918, %f947, %f778;
	mul.f32 	%f779, %f914, %f946;
	fma.rn.f32 	%f780, %f911, %f945, %f779;
	fma.rn.f32 	%f947, %f917, %f947, %f780;
	mul.f32 	%f781, %f916, %f943;
	fma.rn.f32 	%f782, %f913, %f942, %f781;
	fma.rn.f32 	%f307, %f919, %f944, %f782;
	mul.f32 	%f783, %f915, %f943;
	fma.rn.f32 	%f784, %f912, %f942, %f783;
	fma.rn.f32 	%f308, %f918, %f944, %f784;
	mul.f32 	%f785, %f914, %f943;
	fma.rn.f32 	%f786, %f911, %f942, %f785;
	fma.rn.f32 	%f944, %f917, %f944, %f786;
	mul.f32 	%f787, %f916, %f940;
	fma.rn.f32 	%f788, %f913, %f939, %f787;
	fma.rn.f32 	%f310, %f919, %f941, %f788;
	mul.f32 	%f789, %f915, %f940;
	fma.rn.f32 	%f790, %f912, %f939, %f789;
	fma.rn.f32 	%f311, %f918, %f941, %f790;
	mul.f32 	%f791, %f914, %f940;
	fma.rn.f32 	%f792, %f911, %f939, %f791;
	fma.rn.f32 	%f941, %f917, %f941, %f792;
	mov.f32 	%f939, %f310;
	mov.f32 	%f940, %f311;
	mov.f32 	%f942, %f307;
	mov.f32 	%f943, %f308;
	mov.f32 	%f945, %f304;
	mov.f32 	%f946, %f305;

$L__BB7_39:
	add.s32 	%r322, %r322, 1;
	setp.lt.u32 	%p21, %r322, %r162;
	mov.f32 	%f911, %f947;
	mov.f32 	%f912, %f946;
	mov.f32 	%f913, %f945;
	mov.f32 	%f914, %f944;
	mov.f32 	%f915, %f943;
	mov.f32 	%f916, %f942;
	mov.f32 	%f917, %f941;
	mov.f32 	%f918, %f940;
	mov.f32 	%f919, %f939;
	@%p21 bra 	$L__BB7_24;

$L__BB7_40:
	mul.f32 	%f793, %f967, %f946;
	fma.rn.f32 	%f794, %f966, %f945, %f793;
	mul.f32 	%f795, %f967, %f943;
	fma.rn.f32 	%f796, %f966, %f942, %f795;
	mul.f32 	%f797, %f967, %f940;
	fma.rn.f32 	%f798, %f966, %f939, %f797;
	fma.rn.f32 	%f968, %f606, %f941, %f798;
	fma.rn.f32 	%f967, %f606, %f944, %f796;
	fma.rn.f32 	%f966, %f606, %f947, %f794;
	bra.uni 	$L__BB7_42;

$L__BB7_41:
	mov.f32 	%f968, %f606;

$L__BB7_42:
	// begin inline asm
	call (%f799), _optix_get_ray_tmin, ();
	// end inline asm
	// begin inline asm
	call (%f800), _optix_get_ray_tmax, ();
	// end inline asm
	ld.f32 	%f803, [%rd1+288];
	sub.f32 	%f804, %f908, %f803;
	ld.f32 	%f805, [%rd1+292];
	sub.f32 	%f806, %f909, %f805;
	ld.f32 	%f807, [%rd1+296];
	sub.f32 	%f808, %f910, %f807;
	mul.f32 	%f809, %f966, %f966;
	fma.rn.f32 	%f810, %f967, %f967, %f809;
	fma.rn.f32 	%f342, %f968, %f968, %f810;
	mul.f32 	%f811, %f804, %f966;
	fma.rn.f32 	%f812, %f806, %f967, %f811;
	fma.rn.f32 	%f813, %f808, %f968, %f812;
	add.f32 	%f343, %f813, %f813;
	mul.f32 	%f814, %f804, %f804;
	fma.rn.f32 	%f815, %f806, %f806, %f814;
	fma.rn.f32 	%f816, %f808, %f808, %f815;
	ld.f32 	%f817, [%rd1+304];
	mul.f32 	%f818, %f817, %f817;
	sub.f32 	%f344, %f816, %f818;
	setp.eq.f32 	%p23, %f342, 0f00000000;
	setp.eq.f32 	%p24, %f343, 0f00000000;
	and.pred  	%p25, %p23, %p24;
	mov.pred 	%p42, 0;
	@%p25 bra 	$L__BB7_45;

	neg.f32 	%f819, %f344;
	div.rn.f32 	%f969, %f819, %f343;
	mul.f32 	%f820, %f342, 0fC0800000;
	mul.f32 	%f821, %f820, %f344;
	fma.rn.f32 	%f346, %f343, %f343, %f821;
	setp.neu.f32 	%p27, %f342, 0f00000000;
	setp.lt.f32 	%p28, %f346, 0f00000000;
	and.pred  	%p29, %p28, %p27;
	mov.f32 	%f970, %f969;
	@%p29 bra 	$L__BB7_45;

	mov.b32 	%r313, %f343;
	and.b32  	%r314, %r313, -2147483648;
	sqrt.rn.f32 	%f822, %f346;
	mov.b32 	%r315, %f822;
	and.b32  	%r316, %r315, 2147483647;
	or.b32  	%r317, %r316, %r314;
	mov.b32 	%f823, %r317;
	add.f32 	%f824, %f343, %f823;
	mul.f32 	%f825, %f824, 0fBF000000;
	div.rn.f32 	%f826, %f825, %f342;
	div.rn.f32 	%f827, %f344, %f825;
	min.f32 	%f828, %f826, %f827;
	max.f32 	%f829, %f826, %f827;
	selp.f32 	%f347, %f969, %f828, %p23;
	selp.f32 	%f970, %f969, %f829, %p23;
	mov.pred 	%p42, -1;
	mov.f32 	%f969, %f347;

$L__BB7_45:
	setp.lt.f32 	%p32, %f969, %f799;
	selp.f32 	%f351, %f970, %f969, %p32;
	setp.ge.f32 	%p33, %f970, %f799;
	setp.le.f32 	%p34, %f969, %f800;
	and.pred  	%p35, %p34, %p33;
	and.pred  	%p36, %p42, %p35;
	setp.leu.f32 	%p37, %f970, %f800;
	setp.geu.f32 	%p38, %f969, %f799;
	or.pred  	%p39, %p37, %p38;
	and.pred  	%p40, %p39, %p36;
	not.pred 	%p41, %p40;
	@%p41 bra 	$L__BB7_47;

	mov.u32 	%r319, 254;
	// begin inline asm
	call (%r318), _optix_report_intersection_0, (%f351, %r319);
	// end inline asm

$L__BB7_47:
	ret;

}
	// .globl	__closesthit__sphere
.visible .entry __closesthit__sphere()
{
	.reg .pred 	%p<75>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<2144>;
	.reg .b32 	%r<660>;
	.reg .b64 	%rd<653>;


	// begin inline asm
	call (%r27), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r28), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r30), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r31), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r32), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r33, %r32, %r28, %r31;
	mad.lo.s32 	%r1, %r33, %r27, %r30;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64 	%p1, %rd1, 0;
	@%p1 bra 	$L__BB8_2;

	cvta.to.global.u64 	%rd44, %rd1;
	cvt.u64.u32 	%rd45, %r1;
	add.s64 	%rd46, %rd44, %rd45;
	mov.u16 	%rs2, 1;
	st.global.u8 	[%rd46], %rs2;
	bra.uni 	$L__BB8_117;

$L__BB8_2:
	// begin inline asm
	call (%rd47), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd3, [%rd47+8];
	// begin inline asm
	call (%f1916), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1917), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1918), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r34), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p2, %r34, 0;
	@%p2 bra 	$L__BB8_23;

	// begin inline asm
	call (%r35), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f734), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p3, %r35, 0;
	@%p3 bra 	$L__BB8_21;

	mov.u32 	%r655, 0;

$L__BB8_5:
	.pragma "nounroll";
	// begin inline asm
	call (%rd48), _optix_get_transform_list_handle, (%r655);
	// end inline asm
	// begin inline asm
	call (%r38), _optix_get_transform_type_from_handle, (%rd48);
	// end inline asm
	or.b32  	%r39, %r38, 1;
	setp.eq.s32 	%p4, %r39, 3;
	@%p4 bra 	$L__BB8_11;
	bra.uni 	$L__BB8_6;

$L__BB8_11:
	setp.eq.s32 	%p7, %r38, 2;
	@%p7 bra 	$L__BB8_15;
	bra.uni 	$L__BB8_12;

$L__BB8_15:
	// begin inline asm
	call (%rd120), _optix_get_matrix_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r127,%r128,%r129,%r130}, [%rd122];
	// end inline asm
	add.s64 	%rd126, %rd120, 16;
	// begin inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r131,%r132,%r133,%r134}, [%rd125];
	// end inline asm
	add.s64 	%rd129, %rd120, 32;
	// begin inline asm
	cvta.to.global.u64 %rd128, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r135,%r136,%r137,%r138}, [%rd128];
	// end inline asm
	add.s64 	%rd132, %rd120, 48;
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r139,%r140,%r141,%r142}, [%rd131];
	// end inline asm
	add.s64 	%rd135, %rd120, 64;
	// begin inline asm
	cvta.to.global.u64 %rd134, %rd135;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r143,%r144,%r145,%r146}, [%rd134];
	// end inline asm
	add.s64 	%rd138, %rd120, 80;
	// begin inline asm
	cvta.to.global.u64 %rd137, %rd138;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd137];
	// end inline asm
	add.s64 	%rd141, %rd120, 96;
	// begin inline asm
	cvta.to.global.u64 %rd140, %rd141;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd140];
	// end inline asm
	add.s64 	%rd144, %rd120, 112;
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd144;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd143];
	// end inline asm
	mov.b32 	%f862, %r130;
	mov.b32 	%f863, %r131;
	and.b32  	%r171, %r129, 65535;
	add.s32 	%r172, %r171, -1;
	cvt.rn.f32.s32 	%f864, %r172;
	sub.f32 	%f865, %f734, %f862;
	mul.f32 	%f866, %f865, %f864;
	sub.f32 	%f867, %f863, %f862;
	div.rn.f32 	%f868, %f866, %f867;
	min.f32 	%f869, %f864, %f868;
	mov.f32 	%f870, 0f00000000;
	max.f32 	%f871, %f870, %f869;
	cvt.rmi.f32.f32 	%f872, %f871;
	sub.f32 	%f90, %f871, %f872;
	cvt.rzi.s32.f32 	%r173, %f872;
	mul.wide.s32 	%rd155, %r173, 48;
	add.s64 	%rd147, %rd129, %rd155;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r159,%r160,%r161,%r162}, [%rd146];
	// end inline asm
	mov.b32 	%f1871, %r159;
	mov.b32 	%f1870, %r160;
	mov.b32 	%f1869, %r161;
	mov.b32 	%f1868, %r162;
	add.s64 	%rd150, %rd147, 16;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd149];
	// end inline asm
	mov.b32 	%f1875, %r163;
	mov.b32 	%f1874, %r164;
	mov.b32 	%f1873, %r165;
	mov.b32 	%f1872, %r166;
	add.s64 	%rd153, %rd147, 32;
	// begin inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd152];
	// end inline asm
	mov.b32 	%f1879, %r167;
	mov.b32 	%f1878, %r168;
	mov.b32 	%f1877, %r169;
	mov.b32 	%f1876, %r170;
	setp.leu.f32 	%p9, %f90, 0f00000000;
	@%p9 bra 	$L__BB8_17;

	cvt.rmi.f32.f32 	%f1839, %f871;
	cvt.rzi.s32.f32 	%r654, %f1839;
	cvt.s64.s32 	%rd648, %r654;
	mov.f32 	%f873, 0f3F800000;
	sub.f32 	%f874, %f873, %f90;
	mul.lo.s64 	%rd165, %rd648, 48;
	add.s64 	%rd166, %rd120, %rd165;
	add.s64 	%rd157, %rd166, 80;
	// begin inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r174,%r175,%r176,%r177}, [%rd156];
	// end inline asm
	mov.b32 	%f875, %r174;
	mov.b32 	%f876, %r175;
	mov.b32 	%f877, %r176;
	mov.b32 	%f878, %r177;
	mul.f32 	%f879, %f90, %f875;
	mul.f32 	%f880, %f90, %f876;
	mul.f32 	%f881, %f90, %f877;
	mul.f32 	%f882, %f90, %f878;
	fma.rn.f32 	%f1871, %f874, %f1871, %f879;
	fma.rn.f32 	%f1870, %f874, %f1870, %f880;
	fma.rn.f32 	%f1869, %f874, %f1869, %f881;
	fma.rn.f32 	%f1868, %f874, %f1868, %f882;
	add.s64 	%rd160, %rd166, 96;
	// begin inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r178,%r179,%r180,%r181}, [%rd159];
	// end inline asm
	mov.b32 	%f883, %r178;
	mov.b32 	%f884, %r179;
	mov.b32 	%f885, %r180;
	mov.b32 	%f886, %r181;
	mul.f32 	%f887, %f90, %f883;
	mul.f32 	%f888, %f90, %f884;
	mul.f32 	%f889, %f90, %f885;
	mul.f32 	%f890, %f90, %f886;
	fma.rn.f32 	%f1875, %f874, %f1875, %f887;
	fma.rn.f32 	%f1874, %f874, %f1874, %f888;
	fma.rn.f32 	%f1873, %f874, %f1873, %f889;
	fma.rn.f32 	%f1872, %f874, %f1872, %f890;
	add.s64 	%rd163, %rd166, 112;
	// begin inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r182,%r183,%r184,%r185}, [%rd162];
	// end inline asm
	mov.b32 	%f891, %r182;
	mov.b32 	%f892, %r183;
	mov.b32 	%f893, %r184;
	mov.b32 	%f894, %r185;
	mul.f32 	%f895, %f90, %f891;
	mul.f32 	%f896, %f90, %f892;
	mul.f32 	%f897, %f90, %f893;
	mul.f32 	%f898, %f90, %f894;
	fma.rn.f32 	%f1879, %f874, %f1879, %f895;
	fma.rn.f32 	%f1878, %f874, %f1878, %f896;
	fma.rn.f32 	%f1877, %f874, %f1877, %f897;
	fma.rn.f32 	%f1876, %f874, %f1876, %f898;
	bra.uni 	$L__BB8_17;

$L__BB8_6:
	mov.f32 	%f1880, 0f00000000;
	mov.f32 	%f1883, 0f3F800000;
	setp.eq.s32 	%p5, %r38, 4;
	@%p5 bra 	$L__BB8_9;

	setp.ne.s32 	%p6, %r38, 1;
	mov.f32 	%f1881, %f1880;
	mov.f32 	%f1882, %f1880;
	mov.f32 	%f1884, %f1880;
	mov.f32 	%f1885, %f1880;
	mov.f32 	%f1886, %f1883;
	mov.f32 	%f1887, %f1880;
	mov.f32 	%f1888, %f1880;
	mov.f32 	%f1889, %f1883;
	mov.f32 	%f1890, %f1880;
	mov.f32 	%f1891, %f1880;
	@%p6 bra 	$L__BB8_18;

	// begin inline asm
	call (%rd50), _optix_get_static_transform_from_handle, (%rd48);
	// end inline asm
	add.s64 	%rd649, %rd50, 64;
	bra.uni 	$L__BB8_10;

$L__BB8_12:
	// begin inline asm
	call (%rd63), _optix_get_srt_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r52,%r53,%r54,%r55}, [%rd65];
	// end inline asm
	add.s64 	%rd69, %rd63, 16;
	// begin inline asm
	cvta.to.global.u64 %rd68, %rd69;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r56,%r57,%r58,%r59}, [%rd68];
	// end inline asm
	add.s64 	%rd72, %rd63, 32;
	// begin inline asm
	cvta.to.global.u64 %rd71, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r60,%r61,%r62,%r63}, [%rd71];
	// end inline asm
	add.s64 	%rd75, %rd63, 48;
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd75;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r64,%r65,%r66,%r67}, [%rd74];
	// end inline asm
	add.s64 	%rd78, %rd63, 64;
	// begin inline asm
	cvta.to.global.u64 %rd77, %rd78;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r68,%r69,%r70,%r71}, [%rd77];
	// end inline asm
	add.s64 	%rd81, %rd63, 80;
	// begin inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r72,%r73,%r74,%r75}, [%rd80];
	// end inline asm
	add.s64 	%rd84, %rd63, 96;
	// begin inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r76,%r77,%r78,%r79}, [%rd83];
	// end inline asm
	add.s64 	%rd87, %rd63, 112;
	// begin inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r80,%r81,%r82,%r83}, [%rd86];
	// end inline asm
	add.s64 	%rd90, %rd63, 128;
	// begin inline asm
	cvta.to.global.u64 %rd89, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd89];
	// end inline asm
	add.s64 	%rd93, %rd63, 144;
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd93;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd92];
	// end inline asm
	mov.b32 	%f749, %r55;
	mov.b32 	%f750, %r56;
	and.b32  	%r108, %r54, 65535;
	add.s32 	%r109, %r108, -1;
	cvt.rn.f32.s32 	%f751, %r109;
	sub.f32 	%f752, %f734, %f749;
	mul.f32 	%f753, %f752, %f751;
	sub.f32 	%f754, %f750, %f749;
	div.rn.f32 	%f755, %f753, %f754;
	min.f32 	%f756, %f751, %f755;
	mov.f32 	%f757, 0f00000000;
	max.f32 	%f758, %f757, %f756;
	cvt.rmi.f32.f32 	%f759, %f758;
	sub.f32 	%f29, %f758, %f759;
	cvt.rzi.s32.f32 	%r110, %f759;
	mul.wide.s32 	%rd107, %r110, 64;
	add.s64 	%rd96, %rd72, %rd107;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd95];
	// end inline asm
	mov.b32 	%f1852, %r92;
	mov.b32 	%f1853, %r93;
	mov.b32 	%f1854, %r94;
	mov.b32 	%f1855, %r95;
	add.s64 	%rd99, %rd96, 16;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd98];
	// end inline asm
	mov.b32 	%f1856, %r96;
	mov.b32 	%f1857, %r97;
	mov.b32 	%f1858, %r98;
	mov.b32 	%f1859, %r99;
	add.s64 	%rd102, %rd96, 32;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd101];
	// end inline asm
	mov.b32 	%f1860, %r100;
	mov.b32 	%f1861, %r101;
	mov.b32 	%f1862, %r102;
	mov.b32 	%f1863, %r103;
	add.s64 	%rd105, %rd96, 48;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd104];
	// end inline asm
	mov.b32 	%f1864, %r104;
	mov.b32 	%f1865, %r105;
	mov.b32 	%f1866, %r106;
	mov.b32 	%f1867, %r107;
	setp.leu.f32 	%p8, %f29, 0f00000000;
	@%p8 bra 	$L__BB8_14;

	mov.f32 	%f760, 0f3F800000;
	sub.f32 	%f761, %f760, %f29;
	add.s64 	%rd109, %rd96, 64;
	// begin inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r111,%r112,%r113,%r114}, [%rd108];
	// end inline asm
	mov.b32 	%f762, %r111;
	mov.b32 	%f763, %r112;
	mov.b32 	%f764, %r113;
	mov.b32 	%f765, %r114;
	mul.f32 	%f766, %f29, %f762;
	mul.f32 	%f767, %f29, %f763;
	mul.f32 	%f768, %f29, %f764;
	mul.f32 	%f769, %f29, %f765;
	fma.rn.f32 	%f1852, %f761, %f1852, %f766;
	fma.rn.f32 	%f1853, %f761, %f1853, %f767;
	fma.rn.f32 	%f1854, %f761, %f1854, %f768;
	fma.rn.f32 	%f1855, %f761, %f1855, %f769;
	add.s64 	%rd112, %rd96, 80;
	// begin inline asm
	cvta.to.global.u64 %rd111, %rd112;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r115,%r116,%r117,%r118}, [%rd111];
	// end inline asm
	mov.b32 	%f770, %r115;
	mov.b32 	%f771, %r116;
	mov.b32 	%f772, %r117;
	mov.b32 	%f773, %r118;
	mul.f32 	%f774, %f29, %f770;
	mul.f32 	%f775, %f29, %f771;
	mul.f32 	%f776, %f29, %f772;
	mul.f32 	%f777, %f29, %f773;
	fma.rn.f32 	%f1856, %f761, %f1856, %f774;
	fma.rn.f32 	%f1857, %f761, %f1857, %f775;
	fma.rn.f32 	%f1858, %f761, %f1858, %f776;
	fma.rn.f32 	%f1859, %f761, %f1859, %f777;
	add.s64 	%rd115, %rd96, 96;
	// begin inline asm
	cvta.to.global.u64 %rd114, %rd115;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r119,%r120,%r121,%r122}, [%rd114];
	// end inline asm
	mov.b32 	%f778, %r119;
	mov.b32 	%f779, %r120;
	mov.b32 	%f780, %r121;
	mov.b32 	%f781, %r122;
	mul.f32 	%f782, %f29, %f778;
	mul.f32 	%f783, %f29, %f779;
	mul.f32 	%f784, %f29, %f780;
	mul.f32 	%f785, %f29, %f781;
	fma.rn.f32 	%f1860, %f761, %f1860, %f782;
	fma.rn.f32 	%f786, %f761, %f1861, %f783;
	fma.rn.f32 	%f787, %f761, %f1862, %f784;
	fma.rn.f32 	%f788, %f761, %f1863, %f785;
	add.s64 	%rd118, %rd96, 112;
	// begin inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r123,%r124,%r125,%r126}, [%rd117];
	// end inline asm
	mov.b32 	%f789, %r123;
	mov.b32 	%f790, %r124;
	mov.b32 	%f791, %r125;
	mov.b32 	%f792, %r126;
	mul.f32 	%f793, %f29, %f789;
	mul.f32 	%f794, %f29, %f790;
	mul.f32 	%f795, %f29, %f791;
	mul.f32 	%f796, %f29, %f792;
	fma.rn.f32 	%f797, %f761, %f1864, %f793;
	fma.rn.f32 	%f1865, %f761, %f1865, %f794;
	fma.rn.f32 	%f1866, %f761, %f1866, %f795;
	fma.rn.f32 	%f1867, %f761, %f1867, %f796;
	mul.f32 	%f798, %f787, %f787;
	fma.rn.f32 	%f799, %f786, %f786, %f798;
	fma.rn.f32 	%f800, %f788, %f788, %f799;
	fma.rn.f32 	%f801, %f797, %f797, %f800;
	sqrt.rn.f32 	%f802, %f801;
	rcp.rn.f32 	%f803, %f802;
	mul.f32 	%f1861, %f786, %f803;
	mul.f32 	%f1862, %f787, %f803;
	mul.f32 	%f1863, %f788, %f803;
	mul.f32 	%f1864, %f803, %f797;

$L__BB8_14:
	mul.f32 	%f804, %f1862, %f1862;
	fma.rn.f32 	%f805, %f1861, %f1861, %f804;
	fma.rn.f32 	%f806, %f1863, %f1863, %f805;
	fma.rn.f32 	%f807, %f1864, %f1864, %f806;
	rcp.rn.f32 	%f808, %f807;
	mul.f32 	%f809, %f1861, %f808;
	mul.f32 	%f810, %f1862, %f808;
	mul.f32 	%f811, %f1863, %f808;
	mul.f32 	%f812, %f1864, %f808;
	mul.f32 	%f813, %f1861, %f809;
	mul.f32 	%f814, %f1862, %f810;
	mul.f32 	%f815, %f1863, %f811;
	mul.f32 	%f816, %f1861, %f810;
	mul.f32 	%f817, %f1863, %f812;
	mul.f32 	%f818, %f1861, %f811;
	mul.f32 	%f819, %f1862, %f812;
	mul.f32 	%f820, %f1862, %f811;
	mul.f32 	%f821, %f1861, %f812;
	sub.f32 	%f822, %f813, %f814;
	sub.f32 	%f823, %f822, %f815;
	fma.rn.f32 	%f824, %f1864, %f812, %f823;
	sub.f32 	%f825, %f816, %f817;
	add.f32 	%f826, %f825, %f825;
	add.f32 	%f827, %f818, %f819;
	add.f32 	%f828, %f827, %f827;
	add.f32 	%f829, %f816, %f817;
	add.f32 	%f830, %f829, %f829;
	sub.f32 	%f831, %f814, %f813;
	sub.f32 	%f832, %f831, %f815;
	fma.rn.f32 	%f833, %f1864, %f812, %f832;
	sub.f32 	%f834, %f820, %f821;
	add.f32 	%f835, %f834, %f834;
	sub.f32 	%f836, %f818, %f819;
	add.f32 	%f837, %f836, %f836;
	add.f32 	%f838, %f820, %f821;
	add.f32 	%f839, %f838, %f838;
	neg.f32 	%f840, %f813;
	sub.f32 	%f841, %f840, %f814;
	add.f32 	%f842, %f815, %f841;
	fma.rn.f32 	%f843, %f1864, %f812, %f842;
	mul.f32 	%f844, %f1855, %f824;
	fma.rn.f32 	%f845, %f1858, %f826, %f844;
	fma.rn.f32 	%f846, %f1860, %f828, %f845;
	sub.f32 	%f1868, %f1865, %f846;
	mul.f32 	%f847, %f1858, %f833;
	fma.rn.f32 	%f848, %f1855, %f830, %f847;
	fma.rn.f32 	%f849, %f1860, %f835, %f848;
	sub.f32 	%f1872, %f1866, %f849;
	mul.f32 	%f850, %f1858, %f839;
	fma.rn.f32 	%f851, %f1855, %f837, %f850;
	fma.rn.f32 	%f852, %f1860, %f843, %f851;
	sub.f32 	%f1876, %f1867, %f852;
	mul.f32 	%f853, %f1854, %f824;
	fma.rn.f32 	%f854, %f1857, %f826, %f853;
	fma.rn.f32 	%f1869, %f1859, %f828, %f854;
	mul.f32 	%f855, %f1857, %f833;
	fma.rn.f32 	%f856, %f1854, %f830, %f855;
	fma.rn.f32 	%f1873, %f1859, %f835, %f856;
	mul.f32 	%f857, %f1857, %f839;
	fma.rn.f32 	%f858, %f1854, %f837, %f857;
	fma.rn.f32 	%f1877, %f1859, %f843, %f858;
	mul.f32 	%f859, %f1853, %f824;
	fma.rn.f32 	%f1870, %f1856, %f826, %f859;
	mul.f32 	%f860, %f1856, %f833;
	fma.rn.f32 	%f1874, %f1853, %f830, %f860;
	mul.f32 	%f861, %f1856, %f839;
	fma.rn.f32 	%f1878, %f1853, %f837, %f861;
	mul.f32 	%f1871, %f1852, %f824;
	mul.f32 	%f1875, %f1852, %f830;
	mul.f32 	%f1879, %f1852, %f837;

$L__BB8_17:
	mul.f32 	%f899, %f1873, %f1878;
	mul.f32 	%f900, %f1874, %f1877;
	sub.f32 	%f901, %f900, %f899;
	mul.f32 	%f902, %f1871, %f901;
	mul.f32 	%f903, %f1873, %f1879;
	mul.f32 	%f904, %f1875, %f1877;
	sub.f32 	%f905, %f904, %f903;
	mul.f32 	%f906, %f1870, %f905;
	sub.f32 	%f907, %f902, %f906;
	mul.f32 	%f908, %f1874, %f1879;
	mul.f32 	%f909, %f1875, %f1878;
	sub.f32 	%f910, %f909, %f908;
	fma.rn.f32 	%f911, %f1869, %f910, %f907;
	rcp.rn.f32 	%f912, %f911;
	mul.f32 	%f1883, %f901, %f912;
	mul.f32 	%f913, %f1870, %f1877;
	mul.f32 	%f914, %f1869, %f1878;
	sub.f32 	%f915, %f914, %f913;
	mul.f32 	%f1882, %f915, %f912;
	mul.f32 	%f916, %f1869, %f1874;
	mul.f32 	%f917, %f1870, %f1873;
	sub.f32 	%f918, %f917, %f916;
	mul.f32 	%f1881, %f918, %f912;
	sub.f32 	%f919, %f903, %f904;
	mul.f32 	%f1887, %f919, %f912;
	mul.f32 	%f920, %f1869, %f1879;
	mul.f32 	%f921, %f1871, %f1877;
	sub.f32 	%f922, %f921, %f920;
	mul.f32 	%f1886, %f922, %f912;
	mul.f32 	%f923, %f1871, %f1873;
	mul.f32 	%f924, %f1869, %f1875;
	sub.f32 	%f925, %f924, %f923;
	mul.f32 	%f1885, %f925, %f912;
	mul.f32 	%f1891, %f910, %f912;
	mul.f32 	%f926, %f1871, %f1878;
	mul.f32 	%f927, %f1870, %f1879;
	sub.f32 	%f928, %f927, %f926;
	mul.f32 	%f1890, %f928, %f912;
	mul.f32 	%f929, %f1870, %f1875;
	mul.f32 	%f930, %f1871, %f1874;
	sub.f32 	%f931, %f930, %f929;
	mul.f32 	%f1889, %f931, %f912;
	mul.f32 	%f932, %f1868, %f1883;
	neg.f32 	%f933, %f932;
	mul.f32 	%f934, %f1872, %f1882;
	sub.f32 	%f935, %f933, %f934;
	mul.f32 	%f936, %f1876, %f1881;
	sub.f32 	%f1880, %f935, %f936;
	mul.f32 	%f937, %f1868, %f1887;
	neg.f32 	%f938, %f937;
	mul.f32 	%f939, %f1872, %f1886;
	sub.f32 	%f940, %f938, %f939;
	mul.f32 	%f941, %f1876, %f1885;
	sub.f32 	%f1884, %f940, %f941;
	mul.f32 	%f942, %f1868, %f1891;
	neg.f32 	%f943, %f942;
	mul.f32 	%f944, %f1872, %f1890;
	sub.f32 	%f945, %f943, %f944;
	mul.f32 	%f946, %f1876, %f1889;
	sub.f32 	%f1888, %f945, %f946;
	bra.uni 	$L__BB8_18;

$L__BB8_9:
	// begin inline asm
	call (%rd649), _optix_get_instance_inverse_transform_from_handle, (%rd48);
	// end inline asm

$L__BB8_10:
	// begin inline asm
	cvta.to.global.u64 %rd54, %rd649;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r40,%r41,%r42,%r43}, [%rd54];
	// end inline asm
	mov.b32 	%f1883, %r40;
	mov.b32 	%f1882, %r41;
	mov.b32 	%f1881, %r42;
	mov.b32 	%f1880, %r43;
	add.s64 	%rd58, %rd649, 16;
	// begin inline asm
	cvta.to.global.u64 %rd57, %rd58;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r44,%r45,%r46,%r47}, [%rd57];
	// end inline asm
	mov.b32 	%f1887, %r44;
	mov.b32 	%f1886, %r45;
	mov.b32 	%f1885, %r46;
	mov.b32 	%f1884, %r47;
	add.s64 	%rd61, %rd649, 32;
	// begin inline asm
	cvta.to.global.u64 %rd60, %rd61;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r48,%r49,%r50,%r51}, [%rd60];
	// end inline asm
	mov.b32 	%f1891, %r48;
	mov.b32 	%f1890, %r49;
	mov.b32 	%f1889, %r50;
	mov.b32 	%f1888, %r51;

$L__BB8_18:
	setp.eq.s32 	%p10, %r655, 0;
	@%p10 bra 	$L__BB8_20;

	mul.f32 	%f947, %f1848, %f1883;
	fma.rn.f32 	%f948, %f1844, %f1882, %f947;
	fma.rn.f32 	%f151, %f1840, %f1881, %f948;
	mul.f32 	%f949, %f1849, %f1883;
	fma.rn.f32 	%f950, %f1845, %f1882, %f949;
	fma.rn.f32 	%f152, %f1841, %f1881, %f950;
	mul.f32 	%f951, %f1850, %f1883;
	fma.rn.f32 	%f952, %f1846, %f1882, %f951;
	fma.rn.f32 	%f153, %f1842, %f1881, %f952;
	mul.f32 	%f953, %f1851, %f1883;
	fma.rn.f32 	%f954, %f1847, %f1882, %f953;
	fma.rn.f32 	%f955, %f1843, %f1881, %f954;
	add.f32 	%f1880, %f1880, %f955;
	mul.f32 	%f956, %f1848, %f1887;
	fma.rn.f32 	%f957, %f1844, %f1886, %f956;
	fma.rn.f32 	%f155, %f1840, %f1885, %f957;
	mul.f32 	%f958, %f1849, %f1887;
	fma.rn.f32 	%f959, %f1845, %f1886, %f958;
	fma.rn.f32 	%f156, %f1841, %f1885, %f959;
	mul.f32 	%f960, %f1850, %f1887;
	fma.rn.f32 	%f961, %f1846, %f1886, %f960;
	fma.rn.f32 	%f157, %f1842, %f1885, %f961;
	mul.f32 	%f962, %f1851, %f1887;
	fma.rn.f32 	%f963, %f1847, %f1886, %f962;
	fma.rn.f32 	%f964, %f1843, %f1885, %f963;
	add.f32 	%f1884, %f1884, %f964;
	mul.f32 	%f965, %f1848, %f1891;
	fma.rn.f32 	%f966, %f1844, %f1890, %f965;
	fma.rn.f32 	%f159, %f1840, %f1889, %f966;
	mul.f32 	%f967, %f1849, %f1891;
	fma.rn.f32 	%f968, %f1845, %f1890, %f967;
	fma.rn.f32 	%f160, %f1841, %f1889, %f968;
	mul.f32 	%f969, %f1850, %f1891;
	fma.rn.f32 	%f970, %f1846, %f1890, %f969;
	fma.rn.f32 	%f161, %f1842, %f1889, %f970;
	mul.f32 	%f971, %f1851, %f1891;
	fma.rn.f32 	%f972, %f1847, %f1890, %f971;
	fma.rn.f32 	%f973, %f1843, %f1889, %f972;
	add.f32 	%f1888, %f1888, %f973;
	mov.f32 	%f1881, %f153;
	mov.f32 	%f1882, %f152;
	mov.f32 	%f1883, %f151;
	mov.f32 	%f1885, %f157;
	mov.f32 	%f1886, %f156;
	mov.f32 	%f1887, %f155;
	mov.f32 	%f1889, %f161;
	mov.f32 	%f1890, %f160;
	mov.f32 	%f1891, %f159;

$L__BB8_20:
	add.s32 	%r655, %r655, 1;
	setp.lt.u32 	%p11, %r655, %r35;
	mov.f32 	%f1840, %f1891;
	mov.f32 	%f1841, %f1890;
	mov.f32 	%f1842, %f1889;
	mov.f32 	%f1843, %f1888;
	mov.f32 	%f1844, %f1887;
	mov.f32 	%f1845, %f1886;
	mov.f32 	%f1846, %f1885;
	mov.f32 	%f1847, %f1884;
	mov.f32 	%f1848, %f1883;
	mov.f32 	%f1849, %f1882;
	mov.f32 	%f1850, %f1881;
	mov.f32 	%f1851, %f1880;
	@%p11 bra 	$L__BB8_5;

$L__BB8_21:
	mul.f32 	%f974, %f1916, %f1883;
	fma.rn.f32 	%f975, %f1917, %f1882, %f974;
	fma.rn.f32 	%f976, %f1918, %f1881, %f975;
	mul.f32 	%f977, %f1916, %f1887;
	fma.rn.f32 	%f978, %f1917, %f1886, %f977;
	fma.rn.f32 	%f979, %f1918, %f1885, %f978;
	mul.f32 	%f980, %f1916, %f1891;
	fma.rn.f32 	%f981, %f1917, %f1890, %f980;
	fma.rn.f32 	%f982, %f1918, %f1889, %f981;
	add.f32 	%f1918, %f1888, %f982;
	add.f32 	%f1917, %f1884, %f979;
	add.f32 	%f1916, %f1880, %f976;

$L__BB8_23:
	// begin inline asm
	call (%f1974), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1975), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f985), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r186), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p12, %r186, 0;
	@%p12 bra 	$L__BB8_43;

	// begin inline asm
	call (%r187), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f986), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p13, %r187, 0;
	@%p13 bra 	$L__BB8_42;

	mov.u32 	%r656, 0;

$L__BB8_26:
	.pragma "nounroll";
	// begin inline asm
	call (%rd167), _optix_get_transform_list_handle, (%r656);
	// end inline asm
	// begin inline asm
	call (%r190), _optix_get_transform_type_from_handle, (%rd167);
	// end inline asm
	or.b32  	%r191, %r190, 1;
	setp.eq.s32 	%p14, %r191, 3;
	@%p14 bra 	$L__BB8_32;
	bra.uni 	$L__BB8_27;

$L__BB8_32:
	setp.eq.s32 	%p17, %r190, 2;
	@%p17 bra 	$L__BB8_36;
	bra.uni 	$L__BB8_33;

$L__BB8_36:
	// begin inline asm
	call (%rd239), _optix_get_matrix_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r279,%r280,%r281,%r282}, [%rd241];
	// end inline asm
	add.s64 	%rd245, %rd239, 16;
	// begin inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r283,%r284,%r285,%r286}, [%rd244];
	// end inline asm
	add.s64 	%rd248, %rd239, 32;
	// begin inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r287,%r288,%r289,%r290}, [%rd247];
	// end inline asm
	add.s64 	%rd251, %rd239, 48;
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r291,%r292,%r293,%r294}, [%rd250];
	// end inline asm
	add.s64 	%rd254, %rd239, 64;
	// begin inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r295,%r296,%r297,%r298}, [%rd253];
	// end inline asm
	add.s64 	%rd257, %rd239, 80;
	// begin inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r299,%r300,%r301,%r302}, [%rd256];
	// end inline asm
	add.s64 	%rd260, %rd239, 96;
	// begin inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd259];
	// end inline asm
	add.s64 	%rd263, %rd239, 112;
	// begin inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd262];
	// end inline asm
	mov.b32 	%f1090, %r282;
	mov.b32 	%f1091, %r283;
	and.b32  	%r323, %r281, 65535;
	add.s32 	%r324, %r323, -1;
	cvt.rn.f32.s32 	%f1092, %r324;
	sub.f32 	%f1093, %f986, %f1090;
	mul.f32 	%f1094, %f1093, %f1092;
	sub.f32 	%f1095, %f1091, %f1090;
	div.rn.f32 	%f1096, %f1094, %f1095;
	min.f32 	%f1097, %f1092, %f1096;
	mov.f32 	%f1098, 0f00000000;
	max.f32 	%f1099, %f1098, %f1097;
	cvt.rmi.f32.f32 	%f1100, %f1099;
	sub.f32 	%f258, %f1099, %f1100;
	cvt.rzi.s32.f32 	%r325, %f1100;
	cvt.s64.s32 	%rd17, %r325;
	mul.wide.s32 	%rd274, %r325, 48;
	add.s64 	%rd266, %rd248, %rd274;
	// begin inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd265];
	// end inline asm
	mov.b32 	%f1944, %r311;
	mov.b32 	%f1945, %r312;
	mov.b32 	%f1946, %r313;
	add.s64 	%rd269, %rd266, 16;
	// begin inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r315,%r316,%r317,%r318}, [%rd268];
	// end inline asm
	mov.b32 	%f1941, %r315;
	mov.b32 	%f1942, %r316;
	mov.b32 	%f1943, %r317;
	add.s64 	%rd272, %rd266, 32;
	// begin inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r319,%r320,%r321,%r322}, [%rd271];
	// end inline asm
	mov.b32 	%f1938, %r319;
	mov.b32 	%f1939, %r320;
	mov.b32 	%f1940, %r321;
	setp.leu.f32 	%p19, %f258, 0f00000000;
	@%p19 bra 	$L__BB8_38;

	mov.f32 	%f1101, 0f3F800000;
	sub.f32 	%f1102, %f1101, %f258;
	mul.lo.s64 	%rd284, %rd17, 48;
	add.s64 	%rd285, %rd239, %rd284;
	add.s64 	%rd276, %rd285, 80;
	// begin inline asm
	cvta.to.global.u64 %rd275, %rd276;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r326,%r327,%r328,%r329}, [%rd275];
	// end inline asm
	mov.b32 	%f1103, %r326;
	mov.b32 	%f1104, %r327;
	mov.b32 	%f1105, %r328;
	mul.f32 	%f1106, %f258, %f1103;
	mul.f32 	%f1107, %f258, %f1104;
	mul.f32 	%f1108, %f258, %f1105;
	fma.rn.f32 	%f1944, %f1102, %f1944, %f1106;
	fma.rn.f32 	%f1945, %f1102, %f1945, %f1107;
	fma.rn.f32 	%f1946, %f1102, %f1946, %f1108;
	add.s64 	%rd279, %rd285, 96;
	// begin inline asm
	cvta.to.global.u64 %rd278, %rd279;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r330,%r331,%r332,%r333}, [%rd278];
	// end inline asm
	mov.b32 	%f1109, %r330;
	mov.b32 	%f1110, %r331;
	mov.b32 	%f1111, %r332;
	mul.f32 	%f1112, %f258, %f1109;
	mul.f32 	%f1113, %f258, %f1110;
	mul.f32 	%f1114, %f258, %f1111;
	fma.rn.f32 	%f1941, %f1102, %f1941, %f1112;
	fma.rn.f32 	%f1942, %f1102, %f1942, %f1113;
	fma.rn.f32 	%f1943, %f1102, %f1943, %f1114;
	add.s64 	%rd282, %rd285, 112;
	// begin inline asm
	cvta.to.global.u64 %rd281, %rd282;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r334,%r335,%r336,%r337}, [%rd281];
	// end inline asm
	mov.b32 	%f1115, %r334;
	mov.b32 	%f1116, %r335;
	mov.b32 	%f1117, %r336;
	mul.f32 	%f1118, %f258, %f1115;
	mul.f32 	%f1119, %f258, %f1116;
	mul.f32 	%f1120, %f258, %f1117;
	fma.rn.f32 	%f1938, %f1102, %f1938, %f1118;
	fma.rn.f32 	%f1939, %f1102, %f1939, %f1119;
	fma.rn.f32 	%f1940, %f1102, %f1940, %f1120;
	bra.uni 	$L__BB8_38;

$L__BB8_27:
	mov.f32 	%f1947, 0f00000000;
	mov.f32 	%f1949, 0f3F800000;
	setp.eq.s32 	%p15, %r190, 4;
	@%p15 bra 	$L__BB8_30;

	setp.ne.s32 	%p16, %r190, 1;
	mov.f32 	%f1948, %f1947;
	mov.f32 	%f1950, %f1947;
	mov.f32 	%f1951, %f1949;
	mov.f32 	%f1952, %f1947;
	mov.f32 	%f1953, %f1949;
	mov.f32 	%f1954, %f1947;
	mov.f32 	%f1955, %f1947;
	@%p16 bra 	$L__BB8_39;

	// begin inline asm
	call (%rd169), _optix_get_static_transform_from_handle, (%rd167);
	// end inline asm
	add.s64 	%rd650, %rd169, 64;
	bra.uni 	$L__BB8_31;

$L__BB8_33:
	// begin inline asm
	call (%rd182), _optix_get_srt_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r204,%r205,%r206,%r207}, [%rd184];
	// end inline asm
	add.s64 	%rd188, %rd182, 16;
	// begin inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r208,%r209,%r210,%r211}, [%rd187];
	// end inline asm
	add.s64 	%rd191, %rd182, 32;
	// begin inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r212,%r213,%r214,%r215}, [%rd190];
	// end inline asm
	add.s64 	%rd194, %rd182, 48;
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r216,%r217,%r218,%r219}, [%rd193];
	// end inline asm
	add.s64 	%rd197, %rd182, 64;
	// begin inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r220,%r221,%r222,%r223}, [%rd196];
	// end inline asm
	add.s64 	%rd200, %rd182, 80;
	// begin inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r224,%r225,%r226,%r227}, [%rd199];
	// end inline asm
	add.s64 	%rd203, %rd182, 96;
	// begin inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r228,%r229,%r230,%r231}, [%rd202];
	// end inline asm
	add.s64 	%rd206, %rd182, 112;
	// begin inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r232,%r233,%r234,%r235}, [%rd205];
	// end inline asm
	add.s64 	%rd209, %rd182, 128;
	// begin inline asm
	cvta.to.global.u64 %rd208, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r236,%r237,%r238,%r239}, [%rd208];
	// end inline asm
	add.s64 	%rd212, %rd182, 144;
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd212;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd211];
	// end inline asm
	mov.b32 	%f998, %r207;
	mov.b32 	%f999, %r208;
	and.b32  	%r260, %r206, 65535;
	add.s32 	%r261, %r260, -1;
	cvt.rn.f32.s32 	%f1000, %r261;
	sub.f32 	%f1001, %f986, %f998;
	mul.f32 	%f1002, %f1001, %f1000;
	sub.f32 	%f1003, %f999, %f998;
	div.rn.f32 	%f1004, %f1002, %f1003;
	min.f32 	%f1005, %f1000, %f1004;
	mov.f32 	%f1006, 0f00000000;
	max.f32 	%f1007, %f1006, %f1005;
	cvt.rmi.f32.f32 	%f1008, %f1007;
	sub.f32 	%f218, %f1007, %f1008;
	cvt.rzi.s32.f32 	%r262, %f1008;
	mul.wide.s32 	%rd226, %r262, 64;
	add.s64 	%rd215, %rd191, %rd226;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd214];
	// end inline asm
	mov.b32 	%f1928, %r244;
	mov.b32 	%f1929, %r245;
	mov.b32 	%f1930, %r246;
	add.s64 	%rd218, %rd215, 16;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd217];
	// end inline asm
	mov.b32 	%f1931, %r248;
	mov.b32 	%f1932, %r249;
	mov.b32 	%f1933, %r251;
	add.s64 	%rd221, %rd215, 32;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd220];
	// end inline asm
	mov.b32 	%f1934, %r253;
	mov.b32 	%f1935, %r254;
	mov.b32 	%f1936, %r255;
	add.s64 	%rd224, %rd215, 48;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd223];
	// end inline asm
	mov.b32 	%f1937, %r256;
	setp.leu.f32 	%p18, %f218, 0f00000000;
	@%p18 bra 	$L__BB8_35;

	mov.f32 	%f1009, 0f3F800000;
	sub.f32 	%f1010, %f1009, %f218;
	add.s64 	%rd228, %rd215, 64;
	// begin inline asm
	cvta.to.global.u64 %rd227, %rd228;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r263,%r264,%r265,%r266}, [%rd227];
	// end inline asm
	mov.b32 	%f1011, %r263;
	mov.b32 	%f1012, %r264;
	mov.b32 	%f1013, %r265;
	mul.f32 	%f1014, %f218, %f1011;
	mul.f32 	%f1015, %f218, %f1012;
	mul.f32 	%f1016, %f218, %f1013;
	fma.rn.f32 	%f1928, %f1010, %f1928, %f1014;
	fma.rn.f32 	%f1929, %f1010, %f1929, %f1015;
	fma.rn.f32 	%f1930, %f1010, %f1930, %f1016;
	add.s64 	%rd231, %rd215, 80;
	// begin inline asm
	cvta.to.global.u64 %rd230, %rd231;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r267,%r268,%r269,%r270}, [%rd230];
	// end inline asm
	mov.b32 	%f1017, %r267;
	mov.b32 	%f1018, %r268;
	mov.b32 	%f1019, %r270;
	mul.f32 	%f1020, %f218, %f1017;
	mul.f32 	%f1021, %f218, %f1018;
	mul.f32 	%f1022, %f218, %f1019;
	fma.rn.f32 	%f1931, %f1010, %f1931, %f1020;
	fma.rn.f32 	%f1932, %f1010, %f1932, %f1021;
	fma.rn.f32 	%f1933, %f1010, %f1933, %f1022;
	add.s64 	%rd234, %rd215, 96;
	// begin inline asm
	cvta.to.global.u64 %rd233, %rd234;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r271,%r272,%r273,%r274}, [%rd233];
	// end inline asm
	mov.b32 	%f1023, %r272;
	mov.b32 	%f1024, %r273;
	mov.b32 	%f1025, %r274;
	mul.f32 	%f1026, %f218, %f1023;
	mul.f32 	%f1027, %f218, %f1024;
	mul.f32 	%f1028, %f218, %f1025;
	fma.rn.f32 	%f1029, %f1010, %f1934, %f1026;
	fma.rn.f32 	%f1030, %f1010, %f1935, %f1027;
	fma.rn.f32 	%f1031, %f1010, %f1936, %f1028;
	add.s64 	%rd237, %rd215, 112;
	// begin inline asm
	cvta.to.global.u64 %rd236, %rd237;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r275,%r276,%r277,%r278}, [%rd236];
	// end inline asm
	mov.b32 	%f1032, %r275;
	mul.f32 	%f1033, %f218, %f1032;
	fma.rn.f32 	%f1034, %f1010, %f1937, %f1033;
	mul.f32 	%f1035, %f1030, %f1030;
	fma.rn.f32 	%f1036, %f1029, %f1029, %f1035;
	fma.rn.f32 	%f1037, %f1031, %f1031, %f1036;
	fma.rn.f32 	%f1038, %f1034, %f1034, %f1037;
	sqrt.rn.f32 	%f1039, %f1038;
	rcp.rn.f32 	%f1040, %f1039;
	mul.f32 	%f1934, %f1029, %f1040;
	mul.f32 	%f1935, %f1030, %f1040;
	mul.f32 	%f1936, %f1031, %f1040;
	mul.f32 	%f1937, %f1040, %f1034;

$L__BB8_35:
	mul.f32 	%f1041, %f1935, %f1935;
	fma.rn.f32 	%f1042, %f1934, %f1934, %f1041;
	fma.rn.f32 	%f1043, %f1936, %f1936, %f1042;
	fma.rn.f32 	%f1044, %f1937, %f1937, %f1043;
	rcp.rn.f32 	%f1045, %f1044;
	mul.f32 	%f1046, %f1934, %f1045;
	mul.f32 	%f1047, %f1935, %f1045;
	mul.f32 	%f1048, %f1936, %f1045;
	mul.f32 	%f1049, %f1937, %f1045;
	mul.f32 	%f1050, %f1934, %f1046;
	mul.f32 	%f1051, %f1935, %f1047;
	mul.f32 	%f1052, %f1936, %f1048;
	mul.f32 	%f1053, %f1934, %f1047;
	mul.f32 	%f1054, %f1936, %f1049;
	mul.f32 	%f1055, %f1934, %f1048;
	mul.f32 	%f1056, %f1935, %f1049;
	mul.f32 	%f1057, %f1935, %f1048;
	mul.f32 	%f1058, %f1934, %f1049;
	sub.f32 	%f1059, %f1050, %f1051;
	sub.f32 	%f1060, %f1059, %f1052;
	fma.rn.f32 	%f1061, %f1937, %f1049, %f1060;
	sub.f32 	%f1062, %f1053, %f1054;
	add.f32 	%f1063, %f1062, %f1062;
	add.f32 	%f1064, %f1055, %f1056;
	add.f32 	%f1065, %f1064, %f1064;
	add.f32 	%f1066, %f1053, %f1054;
	add.f32 	%f1067, %f1066, %f1066;
	sub.f32 	%f1068, %f1051, %f1050;
	sub.f32 	%f1069, %f1068, %f1052;
	fma.rn.f32 	%f1070, %f1937, %f1049, %f1069;
	sub.f32 	%f1071, %f1057, %f1058;
	add.f32 	%f1072, %f1071, %f1071;
	sub.f32 	%f1073, %f1055, %f1056;
	add.f32 	%f1074, %f1073, %f1073;
	add.f32 	%f1075, %f1057, %f1058;
	add.f32 	%f1076, %f1075, %f1075;
	neg.f32 	%f1077, %f1050;
	sub.f32 	%f1078, %f1077, %f1051;
	add.f32 	%f1079, %f1052, %f1078;
	fma.rn.f32 	%f1080, %f1937, %f1049, %f1079;
	mul.f32 	%f1081, %f1930, %f1061;
	fma.rn.f32 	%f1082, %f1932, %f1063, %f1081;
	fma.rn.f32 	%f1946, %f1933, %f1065, %f1082;
	mul.f32 	%f1083, %f1932, %f1070;
	fma.rn.f32 	%f1084, %f1930, %f1067, %f1083;
	fma.rn.f32 	%f1943, %f1933, %f1072, %f1084;
	mul.f32 	%f1085, %f1932, %f1076;
	fma.rn.f32 	%f1086, %f1930, %f1074, %f1085;
	fma.rn.f32 	%f1940, %f1933, %f1080, %f1086;
	mul.f32 	%f1087, %f1929, %f1061;
	fma.rn.f32 	%f1945, %f1931, %f1063, %f1087;
	mul.f32 	%f1088, %f1931, %f1070;
	fma.rn.f32 	%f1942, %f1929, %f1067, %f1088;
	mul.f32 	%f1089, %f1931, %f1076;
	fma.rn.f32 	%f1939, %f1929, %f1074, %f1089;
	mul.f32 	%f1944, %f1928, %f1061;
	mul.f32 	%f1941, %f1928, %f1067;
	mul.f32 	%f1938, %f1928, %f1074;

$L__BB8_38:
	mul.f32 	%f1121, %f1939, %f1943;
	mul.f32 	%f1122, %f1940, %f1942;
	sub.f32 	%f1123, %f1122, %f1121;
	mul.f32 	%f1124, %f1944, %f1123;
	mul.f32 	%f1125, %f1938, %f1943;
	mul.f32 	%f1126, %f1940, %f1941;
	sub.f32 	%f1127, %f1126, %f1125;
	mul.f32 	%f1128, %f1127, %f1945;
	sub.f32 	%f1129, %f1124, %f1128;
	mul.f32 	%f1130, %f1938, %f1942;
	mul.f32 	%f1131, %f1939, %f1941;
	sub.f32 	%f1132, %f1131, %f1130;
	fma.rn.f32 	%f1133, %f1132, %f1946, %f1129;
	rcp.rn.f32 	%f1134, %f1133;
	mul.f32 	%f1953, %f1123, %f1134;
	mul.f32 	%f1135, %f1940, %f1945;
	mul.f32 	%f1136, %f1939, %f1946;
	sub.f32 	%f1137, %f1136, %f1135;
	mul.f32 	%f1954, %f1137, %f1134;
	mul.f32 	%f1138, %f1942, %f1946;
	mul.f32 	%f1139, %f1943, %f1945;
	sub.f32 	%f1140, %f1139, %f1138;
	mul.f32 	%f1955, %f1140, %f1134;
	sub.f32 	%f1141, %f1125, %f1126;
	mul.f32 	%f1950, %f1141, %f1134;
	mul.f32 	%f1142, %f1938, %f1946;
	mul.f32 	%f1143, %f1940, %f1944;
	sub.f32 	%f1144, %f1143, %f1142;
	mul.f32 	%f1951, %f1144, %f1134;
	mul.f32 	%f1145, %f1943, %f1944;
	mul.f32 	%f1146, %f1941, %f1946;
	sub.f32 	%f1147, %f1146, %f1145;
	mul.f32 	%f1952, %f1147, %f1134;
	mul.f32 	%f1947, %f1132, %f1134;
	mul.f32 	%f1148, %f1939, %f1944;
	mul.f32 	%f1149, %f1938, %f1945;
	sub.f32 	%f1150, %f1149, %f1148;
	mul.f32 	%f1948, %f1150, %f1134;
	mul.f32 	%f1151, %f1941, %f1945;
	mul.f32 	%f1152, %f1942, %f1944;
	sub.f32 	%f1153, %f1152, %f1151;
	mul.f32 	%f1949, %f1153, %f1134;
	bra.uni 	$L__BB8_39;

$L__BB8_30:
	// begin inline asm
	call (%rd650), _optix_get_instance_inverse_transform_from_handle, (%rd167);
	// end inline asm

$L__BB8_31:
	// begin inline asm
	cvta.to.global.u64 %rd173, %rd650;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r192,%r193,%r194,%r195}, [%rd173];
	// end inline asm
	mov.b32 	%f1953, %r192;
	mov.b32 	%f1954, %r193;
	mov.b32 	%f1955, %r194;
	add.s64 	%rd177, %rd650, 16;
	// begin inline asm
	cvta.to.global.u64 %rd176, %rd177;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r196,%r197,%r198,%r199}, [%rd176];
	// end inline asm
	mov.b32 	%f1950, %r196;
	mov.b32 	%f1951, %r197;
	mov.b32 	%f1952, %r198;
	add.s64 	%rd180, %rd650, 32;
	// begin inline asm
	cvta.to.global.u64 %rd179, %rd180;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r200,%r201,%r202,%r203}, [%rd179];
	// end inline asm
	mov.b32 	%f1947, %r200;
	mov.b32 	%f1948, %r201;
	mov.b32 	%f1949, %r202;

$L__BB8_39:
	setp.eq.s32 	%p20, %r656, 0;
	@%p20 bra 	$L__BB8_41;

	mul.f32 	%f1154, %f1924, %f1954;
	fma.rn.f32 	%f1155, %f1921, %f1953, %f1154;
	fma.rn.f32 	%f304, %f1927, %f1955, %f1155;
	mul.f32 	%f1156, %f1923, %f1954;
	fma.rn.f32 	%f1157, %f1920, %f1953, %f1156;
	fma.rn.f32 	%f305, %f1926, %f1955, %f1157;
	mul.f32 	%f1158, %f1922, %f1954;
	fma.rn.f32 	%f1159, %f1919, %f1953, %f1158;
	fma.rn.f32 	%f1955, %f1925, %f1955, %f1159;
	mul.f32 	%f1160, %f1924, %f1951;
	fma.rn.f32 	%f1161, %f1921, %f1950, %f1160;
	fma.rn.f32 	%f307, %f1927, %f1952, %f1161;
	mul.f32 	%f1162, %f1923, %f1951;
	fma.rn.f32 	%f1163, %f1920, %f1950, %f1162;
	fma.rn.f32 	%f308, %f1926, %f1952, %f1163;
	mul.f32 	%f1164, %f1922, %f1951;
	fma.rn.f32 	%f1165, %f1919, %f1950, %f1164;
	fma.rn.f32 	%f1952, %f1925, %f1952, %f1165;
	mul.f32 	%f1166, %f1924, %f1948;
	fma.rn.f32 	%f1167, %f1921, %f1947, %f1166;
	fma.rn.f32 	%f310, %f1927, %f1949, %f1167;
	mul.f32 	%f1168, %f1923, %f1948;
	fma.rn.f32 	%f1169, %f1920, %f1947, %f1168;
	fma.rn.f32 	%f311, %f1926, %f1949, %f1169;
	mul.f32 	%f1170, %f1922, %f1948;
	fma.rn.f32 	%f1171, %f1919, %f1947, %f1170;
	fma.rn.f32 	%f1949, %f1925, %f1949, %f1171;
	mov.f32 	%f1947, %f310;
	mov.f32 	%f1948, %f311;
	mov.f32 	%f1950, %f307;
	mov.f32 	%f1951, %f308;
	mov.f32 	%f1953, %f304;
	mov.f32 	%f1954, %f305;

$L__BB8_41:
	add.s32 	%r656, %r656, 1;
	setp.lt.u32 	%p21, %r656, %r187;
	mov.f32 	%f1919, %f1955;
	mov.f32 	%f1920, %f1954;
	mov.f32 	%f1921, %f1953;
	mov.f32 	%f1922, %f1952;
	mov.f32 	%f1923, %f1951;
	mov.f32 	%f1924, %f1950;
	mov.f32 	%f1925, %f1949;
	mov.f32 	%f1926, %f1948;
	mov.f32 	%f1927, %f1947;
	@%p21 bra 	$L__BB8_26;

$L__BB8_42:
	mul.f32 	%f1172, %f1975, %f1954;
	fma.rn.f32 	%f1173, %f1974, %f1953, %f1172;
	mul.f32 	%f1174, %f1975, %f1951;
	fma.rn.f32 	%f1175, %f1974, %f1950, %f1174;
	mul.f32 	%f1176, %f1975, %f1948;
	fma.rn.f32 	%f1177, %f1974, %f1947, %f1176;
	fma.rn.f32 	%f1976, %f985, %f1949, %f1177;
	fma.rn.f32 	%f1975, %f985, %f1952, %f1175;
	fma.rn.f32 	%f1974, %f985, %f1955, %f1173;
	bra.uni 	$L__BB8_44;

$L__BB8_43:
	mov.f32 	%f1976, %f985;

$L__BB8_44:
	// begin inline asm
	call (%f1179), _optix_get_ray_tmax, ();
	// end inline asm
	ld.const.u64 	%rd286, [params+80];
	setp.eq.s64 	%p22, %rd286, 0;
	@%p22 bra 	$L__BB8_49;

	ld.u64 	%rd287, [%rd47];
	ld.const.u64 	%rd288, [params+328];
	cvta.to.global.u64 	%rd289, %rd288;
	cvt.u64.u32 	%rd18, %r1;
	mul.wide.u32 	%rd290, %r1, 8;
	add.s64 	%rd291, %rd289, %rd290;
	st.global.u64 	[%rd291], %rd287;
	ld.const.u64 	%rd292, [params+336];
	cvta.to.global.u64 	%rd293, %rd292;
	mul.wide.u32 	%rd294, %r1, 4;
	add.s64 	%rd295, %rd293, %rd294;
	mov.u32 	%r338, 0;
	st.global.u32 	[%rd295], %r338;
	ld.const.u64 	%rd296, [params+344];
	cvta.to.global.u64 	%rd297, %rd296;
	add.s64 	%rd19, %rd297, %rd294;
	ld.global.u32 	%r10, [%rd19];
	setp.eq.s32 	%p23, %r10, 0;
	@%p23 bra 	$L__BB8_48;

	// begin inline asm
	call (%r339), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p24, %r339, %r10;
	@%p24 bra 	$L__BB8_48;

	st.global.u32 	[%rd19], %r339;

$L__BB8_48:
	ld.const.u64 	%rd298, [params+72];
	cvta.to.global.u64 	%rd299, %rd298;
	shl.b64 	%rd300, %rd18, 2;
	add.s64 	%rd301, %rd299, %rd300;
	st.global.f32 	[%rd301], %f1179;
	bra.uni 	$L__BB8_117;

$L__BB8_49:
	fma.rn.f32 	%f1182, %f1179, %f1974, %f1916;
	fma.rn.f32 	%f1183, %f1179, %f1975, %f1917;
	fma.rn.f32 	%f1184, %f1179, %f1976, %f1918;
	add.s64 	%rd20, %rd3, 288;
	ld.f32 	%f1185, [%rd3+288];
	sub.f32 	%f1186, %f1182, %f1185;
	ld.f32 	%f1187, [%rd3+292];
	sub.f32 	%f1188, %f1183, %f1187;
	ld.f32 	%f1189, [%rd3+296];
	sub.f32 	%f1190, %f1184, %f1189;
	mul.f32 	%f1191, %f1186, %f1186;
	fma.rn.f32 	%f1192, %f1188, %f1188, %f1191;
	fma.rn.f32 	%f1193, %f1190, %f1190, %f1192;
	sqrt.rn.f32 	%f1194, %f1193;
	div.rn.f32 	%f1195, %f1186, %f1194;
	div.rn.f32 	%f1196, %f1188, %f1194;
	div.rn.f32 	%f1197, %f1190, %f1194;
	ld.u8 	%rs1, [%rd3+308];
	setp.eq.s16 	%p25, %rs1, 0;
	neg.f32 	%f1198, %f1195;
	neg.f32 	%f1199, %f1196;
	neg.f32 	%f1200, %f1197;
	selp.f32 	%f2110, %f1197, %f1200, %p25;
	selp.f32 	%f2109, %f1196, %f1199, %p25;
	selp.f32 	%f2108, %f1195, %f1198, %p25;
	ld.f32 	%f344, [%rd3+304];
	fma.rn.f32 	%f2141, %f344, %f2108, %f1185;
	fma.rn.f32 	%f2142, %f344, %f2109, %f1187;
	fma.rn.f32 	%f2143, %f344, %f2110, %f1189;
	ld.const.u64 	%rd21, [params+96];
	setp.eq.s64 	%p26, %rd21, 0;
	@%p26 bra 	$L__BB8_57;

	ld.v4.f32 	{%f1201, %f1202, %f1203, %f1204}, [%rd20+-80];
	ld.f32 	%f1208, [%rd20+-128];
	fma.rn.f32 	%f1209, %f2141, %f1208, %f1201;
	ld.f32 	%f1210, [%rd20+-124];
	fma.rn.f32 	%f1211, %f2141, %f1210, %f1202;
	ld.f32 	%f1212, [%rd20+-120];
	fma.rn.f32 	%f1213, %f2141, %f1212, %f1203;
	ld.f32 	%f1214, [%rd20+-112];
	fma.rn.f32 	%f1215, %f2142, %f1214, %f1209;
	ld.f32 	%f1216, [%rd20+-108];
	fma.rn.f32 	%f1217, %f2142, %f1216, %f1211;
	ld.f32 	%f1218, [%rd20+-104];
	fma.rn.f32 	%f1219, %f2142, %f1218, %f1213;
	ld.f32 	%f1220, [%rd20+-96];
	fma.rn.f32 	%f348, %f2143, %f1220, %f1215;
	ld.f32 	%f1221, [%rd20+-92];
	fma.rn.f32 	%f349, %f2143, %f1221, %f1217;
	ld.f32 	%f1222, [%rd20+-88];
	fma.rn.f32 	%f350, %f2143, %f1222, %f1219;
	mul.f32 	%f1223, %f349, %f349;
	fma.rn.f32 	%f351, %f348, %f348, %f1223;
	abs.f32 	%f352, %f348;
	abs.f32 	%f353, %f349;
	setp.eq.f32 	%p27, %f352, 0f00000000;
	setp.eq.f32 	%p28, %f353, 0f00000000;
	and.pred  	%p29, %p27, %p28;
	mov.b32 	%r12, %f348;
	mov.b32 	%r340, %f349;
	and.b32  	%r13, %r340, -2147483648;
	@%p29 bra 	$L__BB8_54;
	bra.uni 	$L__BB8_51;

$L__BB8_54:
	shr.s32 	%r345, %r12, 31;
	and.b32  	%r346, %r345, 1078530011;
	or.b32  	%r347, %r346, %r13;
	mov.b32 	%f1977, %r347;
	bra.uni 	$L__BB8_55;

$L__BB8_51:
	setp.eq.f32 	%p30, %f352, 0f7F800000;
	setp.eq.f32 	%p31, %f353, 0f7F800000;
	and.pred  	%p32, %p30, %p31;
	@%p32 bra 	$L__BB8_53;
	bra.uni 	$L__BB8_52;

$L__BB8_53:
	setp.lt.s32 	%p36, %r12, 0;
	selp.b32 	%r343, 1075235812, 1061752795, %p36;
	or.b32  	%r344, %r343, %r13;
	mov.b32 	%f1977, %r344;
	bra.uni 	$L__BB8_55;

$L__BB8_52:
	setp.lt.s32 	%p33, %r12, 0;
	min.f32 	%f1224, %f353, %f352;
	max.f32 	%f1225, %f353, %f352;
	div.rn.f32 	%f1226, %f1224, %f1225;
	mul.rn.f32 	%f1227, %f1226, %f1226;
	mov.f32 	%f1228, 0fC0B59883;
	mov.f32 	%f1229, 0fBF52C7EA;
	fma.rn.f32 	%f1230, %f1227, %f1229, %f1228;
	mov.f32 	%f1231, 0fC0D21907;
	fma.rn.f32 	%f1232, %f1230, %f1227, %f1231;
	mul.f32 	%f1233, %f1227, %f1232;
	mul.f32 	%f1234, %f1226, %f1233;
	add.f32 	%f1235, %f1227, 0f41355DC0;
	mov.f32 	%f1236, 0f41E6BD60;
	fma.rn.f32 	%f1237, %f1235, %f1227, %f1236;
	mov.f32 	%f1238, 0f419D92C8;
	fma.rn.f32 	%f1239, %f1237, %f1227, %f1238;
	rcp.rn.f32 	%f1240, %f1239;
	fma.rn.f32 	%f1241, %f1234, %f1240, %f1226;
	mov.f32 	%f1242, 0f3FC90FDB;
	sub.f32 	%f1243, %f1242, %f1241;
	setp.gt.f32 	%p34, %f353, %f352;
	selp.f32 	%f1244, %f1243, %f1241, %p34;
	mov.f32 	%f1245, 0f40490FDB;
	sub.f32 	%f1246, %f1245, %f1244;
	selp.f32 	%f1247, %f1246, %f1244, %p33;
	mov.b32 	%r341, %f1247;
	or.b32  	%r342, %r13, %r341;
	mov.b32 	%f1248, %r342;
	add.f32 	%f1249, %f352, %f353;
	setp.le.f32 	%p35, %f1249, 0f7F800000;
	selp.f32 	%f1977, %f1248, %f1249, %p35;

$L__BB8_55:
	abs.f32 	%f1251, %f350;
	setp.gt.f32 	%p37, %f1251, 0f3F11EB85;
	mov.f32 	%f1252, 0f3F800000;
	sub.f32 	%f1253, %f1252, %f1251;
	mul.f32 	%f1254, %f1253, 0f3F000000;
	sqrt.rn.f32 	%f1255, %f1254;
	selp.f32 	%f1256, %f1255, %f1251, %p37;
	mul.f32 	%f1257, %f1256, %f1256;
	mov.f32 	%f1258, 0f3C94D2E9;
	mov.f32 	%f1259, 0f3D53F941;
	fma.rn.f32 	%f1260, %f1259, %f1257, %f1258;
	mov.f32 	%f1261, 0f3D3F841F;
	fma.rn.f32 	%f1262, %f1260, %f1257, %f1261;
	mov.f32 	%f1263, 0f3D994929;
	fma.rn.f32 	%f1264, %f1262, %f1257, %f1263;
	mov.f32 	%f1265, 0f3E2AAB94;
	fma.rn.f32 	%f1266, %f1264, %f1257, %f1265;
	mul.f32 	%f1267, %f1257, %f1266;
	fma.rn.f32 	%f1268, %f1267, %f1256, %f1256;
	mov.f32 	%f1269, 0f3FC90FDB;
	sub.f32 	%f1270, %f1269, %f1268;
	add.f32 	%f1271, %f1268, %f1268;
	selp.f32 	%f1272, %f1271, %f1270, %p37;
	add.f32 	%f1273, %f1977, 0f40C90FDB;
	setp.lt.f32 	%p38, %f1977, 0f00000000;
	selp.f32 	%f1274, %f1273, %f1977, %p38;
	mul.f32 	%f1985, %f1274, 0f3E22F983;
	mov.f32 	%f1275, 0f40490FDB;
	sub.f32 	%f1276, %f1275, %f1272;
	setp.lt.f32 	%p39, %f350, 0f00000000;
	selp.f32 	%f1277, %f1276, %f1272, %p39;
	mul.f32 	%f1984, %f1277, 0f3EA2F983;
	ld.const.u64 	%rd302, [params+184];
	setp.eq.s64 	%p40, %rd302, 0;
	@%p40 bra 	$L__BB8_57;

	neg.f32 	%f1278, %f349;
	sqrt.rn.f32 	%f1279, %f351;
	rcp.rn.f32 	%f1280, %f1279;
	mul.f32 	%f1281, %f348, %f1280;
	mul.f32 	%f1282, %f349, %f1280;
	mul.f32 	%f1283, %f350, %f1281;
	mul.f32 	%f1284, %f350, %f1282;
	neg.f32 	%f1285, %f1279;
	setp.eq.f32 	%p41, %f1279, 0f00000000;
	mov.f32 	%f1286, 0f00000000;
	selp.f32 	%f1287, 0f00000000, %f1285, %p41;
	selp.f32 	%f1288, 0f00000000, %f1284, %p41;
	selp.f32 	%f1289, 0f3F800000, %f1283, %p41;
	ld.v4.f32 	{%f1290, %f1291, %f1292, %f1293}, [%rd20+-256];
	mul.f32 	%f1297, %f1290, %f1278;
	mul.f32 	%f1298, %f1291, %f1278;
	mul.f32 	%f1299, %f1292, %f1278;
	ld.v4.f32 	{%f1300, %f1301, %f1302, %f1303}, [%rd20+-240];
	fma.rn.f32 	%f1307, %f348, %f1300, %f1297;
	fma.rn.f32 	%f1308, %f348, %f1301, %f1298;
	fma.rn.f32 	%f1309, %f348, %f1302, %f1299;
	ld.f32 	%f1310, [%rd20+-224];
	fma.rn.f32 	%f1311, %f1286, %f1310, %f1307;
	ld.f32 	%f1312, [%rd20+-220];
	fma.rn.f32 	%f1313, %f1286, %f1312, %f1308;
	ld.f32 	%f1314, [%rd20+-216];
	fma.rn.f32 	%f1315, %f1286, %f1314, %f1309;
	mul.f32 	%f2132, %f1311, 0f40C90FDB;
	mul.f32 	%f2133, %f1313, 0f40C90FDB;
	mul.f32 	%f2134, %f1315, 0f40C90FDB;
	mul.f32 	%f1316, %f1289, %f1290;
	mul.f32 	%f1317, %f1289, %f1291;
	mul.f32 	%f1318, %f1289, %f1292;
	fma.rn.f32 	%f1319, %f1288, %f1300, %f1316;
	fma.rn.f32 	%f1320, %f1288, %f1301, %f1317;
	fma.rn.f32 	%f1321, %f1288, %f1302, %f1318;
	fma.rn.f32 	%f1322, %f1287, %f1310, %f1319;
	fma.rn.f32 	%f1323, %f1287, %f1312, %f1320;
	fma.rn.f32 	%f1324, %f1287, %f1314, %f1321;
	mul.f32 	%f2129, %f1322, 0f40490FDB;
	mul.f32 	%f2130, %f1323, 0f40490FDB;
	mul.f32 	%f2131, %f1324, 0f40490FDB;

$L__BB8_57:
	selp.f32 	%f1325, 0f3F800000, 0fBF800000, %p25;
	div.rn.f32 	%f1326, %f1325, %f344;
	mul.f32 	%f2120, %f2132, %f1326;
	mul.f32 	%f2121, %f2133, %f1326;
	mul.f32 	%f2122, %f2134, %f1326;
	mul.f32 	%f2117, %f2129, %f1326;
	mul.f32 	%f2118, %f2130, %f1326;
	mul.f32 	%f2119, %f2131, %f1326;
	ld.u64 	%rd22, [%rd47];
	ld.const.u64 	%rd303, [params+344];
	cvta.to.global.u64 	%rd304, %rd303;
	cvt.u64.u32 	%rd23, %r1;
	mul.wide.u32 	%rd305, %r1, 4;
	add.s64 	%rd24, %rd304, %rd305;
	ld.global.u32 	%r14, [%rd24];
	setp.eq.s32 	%p43, %r14, 0;
	mov.f32 	%f2138, %f2108;
	mov.f32 	%f2139, %f2109;
	mov.f32 	%f2140, %f2110;
	@%p43 bra 	$L__BB8_105;

	// begin inline asm
	call (%r348), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p44, %r348, %r14;
	mov.f32 	%f2138, %f2108;
	mov.f32 	%f2139, %f2109;
	mov.f32 	%f2140, %f2110;
	@%p44 bra 	$L__BB8_105;

	// begin inline asm
	call (%r349), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p45, %r349, 0;
	mov.f32 	%f2085, 0f00000000;
	mov.f32 	%f2084, 0f3F800000;
	mov.f32 	%f2022, %f2084;
	mov.f32 	%f2023, %f2085;
	mov.f32 	%f2024, %f2085;
	mov.f32 	%f2025, %f2085;
	mov.f32 	%f2018, %f2085;
	mov.f32 	%f2019, %f2084;
	mov.f32 	%f2020, %f2085;
	mov.f32 	%f2021, %f2085;
	mov.f32 	%f2014, %f2085;
	mov.f32 	%f2015, %f2085;
	mov.f32 	%f2016, %f2084;
	mov.f32 	%f2017, %f2085;
	@%p45 bra 	$L__BB8_77;

	// begin inline asm
	call (%r350), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1339), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p46, %r350, 1;
	@%p46 bra 	$L__BB8_77;

	add.s32 	%r657, %r350, 1;
	mov.u32 	%r658, 1;

$L__BB8_62:
	.pragma "nounroll";
	add.s32 	%r352, %r657, -2;
	// begin inline asm
	call (%rd306), _optix_get_transform_list_handle, (%r352);
	// end inline asm
	// begin inline asm
	call (%r353), _optix_get_transform_type_from_handle, (%rd306);
	// end inline asm
	or.b32  	%r354, %r353, 1;
	setp.eq.s32 	%p47, %r354, 3;
	@%p47 bra 	$L__BB8_68;
	bra.uni 	$L__BB8_63;

$L__BB8_68:
	setp.eq.s32 	%p50, %r353, 2;
	@%p50 bra 	$L__BB8_72;
	bra.uni 	$L__BB8_69;

$L__BB8_72:
	// begin inline asm
	call (%rd378), _optix_get_matrix_motion_transform_from_handle, (%rd306);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd380, %rd378;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r442,%r443,%r444,%r445}, [%rd380];
	// end inline asm
	add.s64 	%rd384, %rd378, 16;
	// begin inline asm
	cvta.to.global.u64 %rd383, %rd384;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r446,%r447,%r448,%r449}, [%rd383];
	// end inline asm
	add.s64 	%rd387, %rd378, 32;
	// begin inline asm
	cvta.to.global.u64 %rd386, %rd387;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r450,%r451,%r452,%r453}, [%rd386];
	// end inline asm
	add.s64 	%rd390, %rd378, 48;
	// begin inline asm
	cvta.to.global.u64 %rd389, %rd390;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r454,%r455,%r456,%r457}, [%rd389];
	// end inline asm
	add.s64 	%rd393, %rd378, 64;
	// begin inline asm
	cvta.to.global.u64 %rd392, %rd393;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r458,%r459,%r460,%r461}, [%rd392];
	// end inline asm
	add.s64 	%rd396, %rd378, 80;
	// begin inline asm
	cvta.to.global.u64 %rd395, %rd396;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r462,%r463,%r464,%r465}, [%rd395];
	// end inline asm
	add.s64 	%rd399, %rd378, 96;
	// begin inline asm
	cvta.to.global.u64 %rd398, %rd399;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r466,%r467,%r468,%r469}, [%rd398];
	// end inline asm
	add.s64 	%rd402, %rd378, 112;
	// begin inline asm
	cvta.to.global.u64 %rd401, %rd402;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r470,%r471,%r472,%r473}, [%rd401];
	// end inline asm
	mov.b32 	%f1467, %r445;
	mov.b32 	%f1468, %r446;
	and.b32  	%r486, %r444, 65535;
	add.s32 	%r487, %r486, -1;
	cvt.rn.f32.s32 	%f1469, %r487;
	sub.f32 	%f1470, %f1339, %f1467;
	mul.f32 	%f1471, %f1470, %f1469;
	sub.f32 	%f1472, %f1468, %f1467;
	div.rn.f32 	%f1473, %f1471, %f1472;
	min.f32 	%f1474, %f1469, %f1473;
	mov.f32 	%f1475, 0f00000000;
	max.f32 	%f1476, %f1475, %f1474;
	cvt.rmi.f32.f32 	%f1477, %f1476;
	sub.f32 	%f466, %f1476, %f1477;
	cvt.rzi.s32.f32 	%r488, %f1477;
	cvt.s64.s32 	%rd31, %r488;
	mul.wide.s32 	%rd413, %r488, 48;
	add.s64 	%rd405, %rd387, %rd413;
	// begin inline asm
	cvta.to.global.u64 %rd404, %rd405;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r474,%r475,%r476,%r477}, [%rd404];
	// end inline asm
	mov.b32 	%f2022, %r474;
	mov.b32 	%f2023, %r475;
	mov.b32 	%f2024, %r476;
	mov.b32 	%f2025, %r477;
	add.s64 	%rd408, %rd405, 16;
	// begin inline asm
	cvta.to.global.u64 %rd407, %rd408;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r478,%r479,%r480,%r481}, [%rd407];
	// end inline asm
	mov.b32 	%f2018, %r478;
	mov.b32 	%f2019, %r479;
	mov.b32 	%f2020, %r480;
	mov.b32 	%f2021, %r481;
	add.s64 	%rd411, %rd405, 32;
	// begin inline asm
	cvta.to.global.u64 %rd410, %rd411;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r482,%r483,%r484,%r485}, [%rd410];
	// end inline asm
	mov.b32 	%f2014, %r482;
	mov.b32 	%f2015, %r483;
	mov.b32 	%f2016, %r484;
	mov.b32 	%f2017, %r485;
	setp.leu.f32 	%p52, %f466, 0f00000000;
	@%p52 bra 	$L__BB8_74;

	mov.f32 	%f1478, 0f3F800000;
	sub.f32 	%f1479, %f1478, %f466;
	mul.lo.s64 	%rd423, %rd31, 48;
	add.s64 	%rd424, %rd378, %rd423;
	add.s64 	%rd415, %rd424, 80;
	// begin inline asm
	cvta.to.global.u64 %rd414, %rd415;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r489,%r490,%r491,%r492}, [%rd414];
	// end inline asm
	mov.b32 	%f1480, %r489;
	mov.b32 	%f1481, %r490;
	mov.b32 	%f1482, %r491;
	mov.b32 	%f1483, %r492;
	mul.f32 	%f1484, %f466, %f1480;
	mul.f32 	%f1485, %f466, %f1481;
	mul.f32 	%f1486, %f466, %f1482;
	mul.f32 	%f1487, %f466, %f1483;
	fma.rn.f32 	%f2022, %f1479, %f2022, %f1484;
	fma.rn.f32 	%f2023, %f1479, %f2023, %f1485;
	fma.rn.f32 	%f2024, %f1479, %f2024, %f1486;
	fma.rn.f32 	%f2025, %f1479, %f2025, %f1487;
	add.s64 	%rd418, %rd424, 96;
	// begin inline asm
	cvta.to.global.u64 %rd417, %rd418;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r493,%r494,%r495,%r496}, [%rd417];
	// end inline asm
	mov.b32 	%f1488, %r493;
	mov.b32 	%f1489, %r494;
	mov.b32 	%f1490, %r495;
	mov.b32 	%f1491, %r496;
	mul.f32 	%f1492, %f466, %f1488;
	mul.f32 	%f1493, %f466, %f1489;
	mul.f32 	%f1494, %f466, %f1490;
	mul.f32 	%f1495, %f466, %f1491;
	fma.rn.f32 	%f2018, %f1479, %f2018, %f1492;
	fma.rn.f32 	%f2019, %f1479, %f2019, %f1493;
	fma.rn.f32 	%f2020, %f1479, %f2020, %f1494;
	fma.rn.f32 	%f2021, %f1479, %f2021, %f1495;
	add.s64 	%rd421, %rd424, 112;
	// begin inline asm
	cvta.to.global.u64 %rd420, %rd421;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd420];
	// end inline asm
	mov.b32 	%f1496, %r497;
	mov.b32 	%f1497, %r498;
	mov.b32 	%f1498, %r499;
	mov.b32 	%f1499, %r500;
	mul.f32 	%f1500, %f466, %f1496;
	mul.f32 	%f1501, %f466, %f1497;
	mul.f32 	%f1502, %f466, %f1498;
	mul.f32 	%f1503, %f466, %f1499;
	fma.rn.f32 	%f2014, %f1479, %f2014, %f1500;
	fma.rn.f32 	%f2015, %f1479, %f2015, %f1501;
	fma.rn.f32 	%f2016, %f1479, %f2016, %f1502;
	fma.rn.f32 	%f2017, %f1479, %f2017, %f1503;
	bra.uni 	$L__BB8_74;

$L__BB8_63:
	mov.f32 	%f2014, 0f00000000;
	mov.f32 	%f2016, 0f3F800000;
	setp.eq.s32 	%p48, %r353, 4;
	@%p48 bra 	$L__BB8_66;

	setp.ne.s32 	%p49, %r353, 1;
	mov.f32 	%f2015, %f2014;
	mov.f32 	%f2017, %f2014;
	mov.f32 	%f2018, %f2014;
	mov.f32 	%f2019, %f2016;
	mov.f32 	%f2020, %f2014;
	mov.f32 	%f2021, %f2014;
	mov.f32 	%f2022, %f2016;
	mov.f32 	%f2023, %f2014;
	mov.f32 	%f2024, %f2014;
	mov.f32 	%f2025, %f2014;
	@%p49 bra 	$L__BB8_74;

	// begin inline asm
	call (%rd308), _optix_get_static_transform_from_handle, (%rd306);
	// end inline asm
	add.s64 	%rd651, %rd308, 16;
	bra.uni 	$L__BB8_67;

$L__BB8_69:
	// begin inline asm
	call (%rd321), _optix_get_srt_motion_transform_from_handle, (%rd306);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd323, %rd321;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r367,%r368,%r369,%r370}, [%rd323];
	// end inline asm
	add.s64 	%rd327, %rd321, 16;
	// begin inline asm
	cvta.to.global.u64 %rd326, %rd327;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r371,%r372,%r373,%r374}, [%rd326];
	// end inline asm
	add.s64 	%rd330, %rd321, 32;
	// begin inline asm
	cvta.to.global.u64 %rd329, %rd330;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r375,%r376,%r377,%r378}, [%rd329];
	// end inline asm
	add.s64 	%rd333, %rd321, 48;
	// begin inline asm
	cvta.to.global.u64 %rd332, %rd333;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r379,%r380,%r381,%r382}, [%rd332];
	// end inline asm
	add.s64 	%rd336, %rd321, 64;
	// begin inline asm
	cvta.to.global.u64 %rd335, %rd336;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r383,%r384,%r385,%r386}, [%rd335];
	// end inline asm
	add.s64 	%rd339, %rd321, 80;
	// begin inline asm
	cvta.to.global.u64 %rd338, %rd339;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r387,%r388,%r389,%r390}, [%rd338];
	// end inline asm
	add.s64 	%rd342, %rd321, 96;
	// begin inline asm
	cvta.to.global.u64 %rd341, %rd342;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r391,%r392,%r393,%r394}, [%rd341];
	// end inline asm
	add.s64 	%rd345, %rd321, 112;
	// begin inline asm
	cvta.to.global.u64 %rd344, %rd345;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r395,%r396,%r397,%r398}, [%rd344];
	// end inline asm
	add.s64 	%rd348, %rd321, 128;
	// begin inline asm
	cvta.to.global.u64 %rd347, %rd348;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r399,%r400,%r401,%r402}, [%rd347];
	// end inline asm
	add.s64 	%rd351, %rd321, 144;
	// begin inline asm
	cvta.to.global.u64 %rd350, %rd351;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r403,%r404,%r405,%r406}, [%rd350];
	// end inline asm
	mov.b32 	%f1354, %r370;
	mov.b32 	%f1355, %r371;
	and.b32  	%r423, %r369, 65535;
	add.s32 	%r424, %r423, -1;
	cvt.rn.f32.s32 	%f1356, %r424;
	sub.f32 	%f1357, %f1339, %f1354;
	mul.f32 	%f1358, %f1357, %f1356;
	sub.f32 	%f1359, %f1355, %f1354;
	div.rn.f32 	%f1360, %f1358, %f1359;
	min.f32 	%f1361, %f1356, %f1360;
	mov.f32 	%f1362, 0f00000000;
	max.f32 	%f1363, %f1362, %f1361;
	cvt.rmi.f32.f32 	%f1364, %f1363;
	sub.f32 	%f405, %f1363, %f1364;
	cvt.rzi.s32.f32 	%r425, %f1364;
	mul.wide.s32 	%rd365, %r425, 64;
	add.s64 	%rd354, %rd330, %rd365;
	// begin inline asm
	cvta.to.global.u64 %rd353, %rd354;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r407,%r408,%r409,%r410}, [%rd353];
	// end inline asm
	mov.b32 	%f1998, %r407;
	mov.b32 	%f1999, %r408;
	mov.b32 	%f2000, %r409;
	mov.b32 	%f2001, %r410;
	add.s64 	%rd357, %rd354, 16;
	// begin inline asm
	cvta.to.global.u64 %rd356, %rd357;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r411,%r412,%r413,%r414}, [%rd356];
	// end inline asm
	mov.b32 	%f2002, %r411;
	mov.b32 	%f2003, %r412;
	mov.b32 	%f2004, %r413;
	mov.b32 	%f2005, %r414;
	add.s64 	%rd360, %rd354, 32;
	// begin inline asm
	cvta.to.global.u64 %rd359, %rd360;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r415,%r416,%r417,%r418}, [%rd359];
	// end inline asm
	mov.b32 	%f2006, %r415;
	mov.b32 	%f2007, %r416;
	mov.b32 	%f2008, %r417;
	mov.b32 	%f2009, %r418;
	add.s64 	%rd363, %rd354, 48;
	// begin inline asm
	cvta.to.global.u64 %rd362, %rd363;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r419,%r420,%r421,%r422}, [%rd362];
	// end inline asm
	mov.b32 	%f2010, %r419;
	mov.b32 	%f2011, %r420;
	mov.b32 	%f2012, %r421;
	mov.b32 	%f2013, %r422;
	setp.leu.f32 	%p51, %f405, 0f00000000;
	@%p51 bra 	$L__BB8_71;

	mov.f32 	%f1365, 0f3F800000;
	sub.f32 	%f1366, %f1365, %f405;
	add.s64 	%rd367, %rd354, 64;
	// begin inline asm
	cvta.to.global.u64 %rd366, %rd367;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r426,%r427,%r428,%r429}, [%rd366];
	// end inline asm
	mov.b32 	%f1367, %r426;
	mov.b32 	%f1368, %r427;
	mov.b32 	%f1369, %r428;
	mov.b32 	%f1370, %r429;
	mul.f32 	%f1371, %f405, %f1367;
	mul.f32 	%f1372, %f405, %f1368;
	mul.f32 	%f1373, %f405, %f1369;
	mul.f32 	%f1374, %f405, %f1370;
	fma.rn.f32 	%f1998, %f1366, %f1998, %f1371;
	fma.rn.f32 	%f1999, %f1366, %f1999, %f1372;
	fma.rn.f32 	%f2000, %f1366, %f2000, %f1373;
	fma.rn.f32 	%f2001, %f1366, %f2001, %f1374;
	add.s64 	%rd370, %rd354, 80;
	// begin inline asm
	cvta.to.global.u64 %rd369, %rd370;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r430,%r431,%r432,%r433}, [%rd369];
	// end inline asm
	mov.b32 	%f1375, %r430;
	mov.b32 	%f1376, %r431;
	mov.b32 	%f1377, %r432;
	mov.b32 	%f1378, %r433;
	mul.f32 	%f1379, %f405, %f1375;
	mul.f32 	%f1380, %f405, %f1376;
	mul.f32 	%f1381, %f405, %f1377;
	mul.f32 	%f1382, %f405, %f1378;
	fma.rn.f32 	%f2002, %f1366, %f2002, %f1379;
	fma.rn.f32 	%f2003, %f1366, %f2003, %f1380;
	fma.rn.f32 	%f2004, %f1366, %f2004, %f1381;
	fma.rn.f32 	%f2005, %f1366, %f2005, %f1382;
	add.s64 	%rd373, %rd354, 96;
	// begin inline asm
	cvta.to.global.u64 %rd372, %rd373;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r434,%r435,%r436,%r437}, [%rd372];
	// end inline asm
	mov.b32 	%f1383, %r434;
	mov.b32 	%f1384, %r435;
	mov.b32 	%f1385, %r436;
	mov.b32 	%f1386, %r437;
	mul.f32 	%f1387, %f405, %f1383;
	mul.f32 	%f1388, %f405, %f1384;
	mul.f32 	%f1389, %f405, %f1385;
	mul.f32 	%f1390, %f405, %f1386;
	fma.rn.f32 	%f2006, %f1366, %f2006, %f1387;
	fma.rn.f32 	%f1391, %f1366, %f2007, %f1388;
	fma.rn.f32 	%f1392, %f1366, %f2008, %f1389;
	fma.rn.f32 	%f1393, %f1366, %f2009, %f1390;
	add.s64 	%rd376, %rd354, 112;
	// begin inline asm
	cvta.to.global.u64 %rd375, %rd376;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r438,%r439,%r440,%r441}, [%rd375];
	// end inline asm
	mov.b32 	%f1394, %r438;
	mov.b32 	%f1395, %r439;
	mov.b32 	%f1396, %r440;
	mov.b32 	%f1397, %r441;
	mul.f32 	%f1398, %f405, %f1394;
	mul.f32 	%f1399, %f405, %f1395;
	mul.f32 	%f1400, %f405, %f1396;
	mul.f32 	%f1401, %f405, %f1397;
	fma.rn.f32 	%f1402, %f1366, %f2010, %f1398;
	fma.rn.f32 	%f2011, %f1366, %f2011, %f1399;
	fma.rn.f32 	%f2012, %f1366, %f2012, %f1400;
	fma.rn.f32 	%f2013, %f1366, %f2013, %f1401;
	mul.f32 	%f1403, %f1392, %f1392;
	fma.rn.f32 	%f1404, %f1391, %f1391, %f1403;
	fma.rn.f32 	%f1405, %f1393, %f1393, %f1404;
	fma.rn.f32 	%f1406, %f1402, %f1402, %f1405;
	sqrt.rn.f32 	%f1407, %f1406;
	rcp.rn.f32 	%f1408, %f1407;
	mul.f32 	%f2007, %f1391, %f1408;
	mul.f32 	%f2008, %f1392, %f1408;
	mul.f32 	%f2009, %f1393, %f1408;
	mul.f32 	%f2010, %f1408, %f1402;

$L__BB8_71:
	mul.f32 	%f1409, %f2008, %f2008;
	fma.rn.f32 	%f1410, %f2007, %f2007, %f1409;
	fma.rn.f32 	%f1411, %f2009, %f2009, %f1410;
	fma.rn.f32 	%f1412, %f2010, %f2010, %f1411;
	rcp.rn.f32 	%f1413, %f1412;
	mul.f32 	%f1414, %f2007, %f1413;
	mul.f32 	%f1415, %f2008, %f1413;
	mul.f32 	%f1416, %f2009, %f1413;
	mul.f32 	%f1417, %f2010, %f1413;
	mul.f32 	%f1418, %f2007, %f1414;
	mul.f32 	%f1419, %f2008, %f1415;
	mul.f32 	%f1420, %f2009, %f1416;
	mul.f32 	%f1421, %f2007, %f1415;
	mul.f32 	%f1422, %f2009, %f1417;
	mul.f32 	%f1423, %f2007, %f1416;
	mul.f32 	%f1424, %f2008, %f1417;
	mul.f32 	%f1425, %f2008, %f1416;
	mul.f32 	%f1426, %f2007, %f1417;
	sub.f32 	%f1427, %f1418, %f1419;
	sub.f32 	%f1428, %f1427, %f1420;
	fma.rn.f32 	%f1429, %f2010, %f1417, %f1428;
	sub.f32 	%f1430, %f1421, %f1422;
	add.f32 	%f1431, %f1430, %f1430;
	add.f32 	%f1432, %f1423, %f1424;
	add.f32 	%f1433, %f1432, %f1432;
	add.f32 	%f1434, %f1421, %f1422;
	add.f32 	%f1435, %f1434, %f1434;
	sub.f32 	%f1436, %f1419, %f1418;
	sub.f32 	%f1437, %f1436, %f1420;
	fma.rn.f32 	%f1438, %f2010, %f1417, %f1437;
	sub.f32 	%f1439, %f1425, %f1426;
	add.f32 	%f1440, %f1439, %f1439;
	sub.f32 	%f1441, %f1423, %f1424;
	add.f32 	%f1442, %f1441, %f1441;
	add.f32 	%f1443, %f1425, %f1426;
	add.f32 	%f1444, %f1443, %f1443;
	neg.f32 	%f1445, %f1418;
	sub.f32 	%f1446, %f1445, %f1419;
	add.f32 	%f1447, %f1420, %f1446;
	fma.rn.f32 	%f1448, %f2010, %f1417, %f1447;
	mul.f32 	%f1449, %f2001, %f1429;
	fma.rn.f32 	%f1450, %f2004, %f1431, %f1449;
	fma.rn.f32 	%f1451, %f2006, %f1433, %f1450;
	sub.f32 	%f2025, %f2011, %f1451;
	mul.f32 	%f1452, %f2004, %f1438;
	fma.rn.f32 	%f1453, %f2001, %f1435, %f1452;
	fma.rn.f32 	%f1454, %f2006, %f1440, %f1453;
	sub.f32 	%f2021, %f2012, %f1454;
	mul.f32 	%f1455, %f2004, %f1444;
	fma.rn.f32 	%f1456, %f2001, %f1442, %f1455;
	fma.rn.f32 	%f1457, %f2006, %f1448, %f1456;
	sub.f32 	%f2017, %f2013, %f1457;
	mul.f32 	%f1458, %f2000, %f1429;
	fma.rn.f32 	%f1459, %f2003, %f1431, %f1458;
	fma.rn.f32 	%f2024, %f2005, %f1433, %f1459;
	mul.f32 	%f1460, %f2003, %f1438;
	fma.rn.f32 	%f1461, %f2000, %f1435, %f1460;
	fma.rn.f32 	%f2020, %f2005, %f1440, %f1461;
	mul.f32 	%f1462, %f2003, %f1444;
	fma.rn.f32 	%f1463, %f2000, %f1442, %f1462;
	fma.rn.f32 	%f2016, %f2005, %f1448, %f1463;
	mul.f32 	%f1464, %f1999, %f1429;
	fma.rn.f32 	%f2023, %f2002, %f1431, %f1464;
	mul.f32 	%f1465, %f2002, %f1438;
	fma.rn.f32 	%f2019, %f1999, %f1435, %f1465;
	mul.f32 	%f1466, %f2002, %f1444;
	fma.rn.f32 	%f2015, %f1999, %f1442, %f1466;
	mul.f32 	%f2022, %f1998, %f1429;
	mul.f32 	%f2018, %f1998, %f1435;
	mul.f32 	%f2014, %f1998, %f1442;
	bra.uni 	$L__BB8_74;

$L__BB8_66:
	// begin inline asm
	call (%rd651), _optix_get_instance_transform_from_handle, (%rd306);
	// end inline asm

$L__BB8_67:
	// begin inline asm
	cvta.to.global.u64 %rd312, %rd651;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r355,%r356,%r357,%r358}, [%rd312];
	// end inline asm
	mov.b32 	%f2022, %r355;
	mov.b32 	%f2023, %r356;
	mov.b32 	%f2024, %r357;
	mov.b32 	%f2025, %r358;
	add.s64 	%rd316, %rd651, 16;
	// begin inline asm
	cvta.to.global.u64 %rd315, %rd316;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r359,%r360,%r361,%r362}, [%rd315];
	// end inline asm
	mov.b32 	%f2018, %r359;
	mov.b32 	%f2019, %r360;
	mov.b32 	%f2020, %r361;
	mov.b32 	%f2021, %r362;
	add.s64 	%rd319, %rd651, 32;
	// begin inline asm
	cvta.to.global.u64 %rd318, %rd319;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r363,%r364,%r365,%r366}, [%rd318];
	// end inline asm
	mov.b32 	%f2014, %r363;
	mov.b32 	%f2015, %r364;
	mov.b32 	%f2016, %r365;
	mov.b32 	%f2017, %r366;

$L__BB8_74:
	setp.eq.s32 	%p53, %r658, 1;
	@%p53 bra 	$L__BB8_76;

	mul.f32 	%f1504, %f1993, %f2023;
	fma.rn.f32 	%f1505, %f1989, %f2022, %f1504;
	fma.rn.f32 	%f503, %f1997, %f2024, %f1505;
	mul.f32 	%f1506, %f1992, %f2023;
	fma.rn.f32 	%f1507, %f1988, %f2022, %f1506;
	fma.rn.f32 	%f504, %f1996, %f2024, %f1507;
	mul.f32 	%f1508, %f1991, %f2023;
	fma.rn.f32 	%f1509, %f1987, %f2022, %f1508;
	fma.rn.f32 	%f505, %f1995, %f2024, %f1509;
	mul.f32 	%f1510, %f1990, %f2023;
	fma.rn.f32 	%f1511, %f1986, %f2022, %f1510;
	fma.rn.f32 	%f1512, %f1994, %f2024, %f1511;
	add.f32 	%f2025, %f2025, %f1512;
	mul.f32 	%f1513, %f1993, %f2019;
	fma.rn.f32 	%f1514, %f1989, %f2018, %f1513;
	fma.rn.f32 	%f507, %f1997, %f2020, %f1514;
	mul.f32 	%f1515, %f1992, %f2019;
	fma.rn.f32 	%f1516, %f1988, %f2018, %f1515;
	fma.rn.f32 	%f508, %f1996, %f2020, %f1516;
	mul.f32 	%f1517, %f1991, %f2019;
	fma.rn.f32 	%f1518, %f1987, %f2018, %f1517;
	fma.rn.f32 	%f509, %f1995, %f2020, %f1518;
	mul.f32 	%f1519, %f1990, %f2019;
	fma.rn.f32 	%f1520, %f1986, %f2018, %f1519;
	fma.rn.f32 	%f1521, %f1994, %f2020, %f1520;
	add.f32 	%f2021, %f2021, %f1521;
	mul.f32 	%f1522, %f1993, %f2015;
	fma.rn.f32 	%f1523, %f1989, %f2014, %f1522;
	fma.rn.f32 	%f511, %f1997, %f2016, %f1523;
	mul.f32 	%f1524, %f1992, %f2015;
	fma.rn.f32 	%f1525, %f1988, %f2014, %f1524;
	fma.rn.f32 	%f512, %f1996, %f2016, %f1525;
	mul.f32 	%f1526, %f1991, %f2015;
	fma.rn.f32 	%f1527, %f1987, %f2014, %f1526;
	fma.rn.f32 	%f513, %f1995, %f2016, %f1527;
	mul.f32 	%f1528, %f1990, %f2015;
	fma.rn.f32 	%f1529, %f1986, %f2014, %f1528;
	fma.rn.f32 	%f1530, %f1994, %f2016, %f1529;
	add.f32 	%f2017, %f2017, %f1530;
	mov.f32 	%f2014, %f511;
	mov.f32 	%f2015, %f512;
	mov.f32 	%f2016, %f513;
	mov.f32 	%f2018, %f507;
	mov.f32 	%f2019, %f508;
	mov.f32 	%f2020, %f509;
	mov.f32 	%f2022, %f503;
	mov.f32 	%f2023, %f504;
	mov.f32 	%f2024, %f505;

$L__BB8_76:
	add.s32 	%r658, %r658, -1;
	add.s32 	%r657, %r657, -1;
	setp.gt.s32 	%p54, %r657, 1;
	mov.f32 	%f1986, %f2025;
	mov.f32 	%f1987, %f2024;
	mov.f32 	%f1988, %f2023;
	mov.f32 	%f1989, %f2022;
	mov.f32 	%f1990, %f2021;
	mov.f32 	%f1991, %f2020;
	mov.f32 	%f1992, %f2019;
	mov.f32 	%f1993, %f2018;
	mov.f32 	%f1994, %f2017;
	mov.f32 	%f1995, %f2016;
	mov.f32 	%f1996, %f2015;
	mov.f32 	%f1997, %f2014;
	@%p54 bra 	$L__BB8_62;

$L__BB8_77:
	// begin inline asm
	call (%r501), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p55, %r501, 0;
	mov.f32 	%f2086, %f2085;
	mov.f32 	%f2081, %f2085;
	mov.f32 	%f2082, %f2084;
	mov.f32 	%f2083, %f2085;
	mov.f32 	%f2078, %f2085;
	mov.f32 	%f2079, %f2085;
	mov.f32 	%f2080, %f2084;
	@%p55 bra 	$L__BB8_96;

	// begin inline asm
	call (%r502), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1540), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p56, %r502, 0;
	@%p56 bra 	$L__BB8_96;

	mov.u32 	%r659, 0;

$L__BB8_80:
	.pragma "nounroll";
	// begin inline asm
	call (%rd425), _optix_get_transform_list_handle, (%r659);
	// end inline asm
	// begin inline asm
	call (%r505), _optix_get_transform_type_from_handle, (%rd425);
	// end inline asm
	or.b32  	%r506, %r505, 1;
	setp.eq.s32 	%p57, %r506, 3;
	@%p57 bra 	$L__BB8_86;
	bra.uni 	$L__BB8_81;

$L__BB8_86:
	setp.eq.s32 	%p60, %r505, 2;
	@%p60 bra 	$L__BB8_90;
	bra.uni 	$L__BB8_87;

$L__BB8_90:
	// begin inline asm
	call (%rd497), _optix_get_matrix_motion_transform_from_handle, (%rd425);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd499, %rd497;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r594,%r595,%r596,%r597}, [%rd499];
	// end inline asm
	add.s64 	%rd503, %rd497, 16;
	// begin inline asm
	cvta.to.global.u64 %rd502, %rd503;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r598,%r599,%r600,%r601}, [%rd502];
	// end inline asm
	add.s64 	%rd506, %rd497, 32;
	// begin inline asm
	cvta.to.global.u64 %rd505, %rd506;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r602,%r603,%r604,%r605}, [%rd505];
	// end inline asm
	add.s64 	%rd509, %rd497, 48;
	// begin inline asm
	cvta.to.global.u64 %rd508, %rd509;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r606,%r607,%r608,%r609}, [%rd508];
	// end inline asm
	add.s64 	%rd512, %rd497, 64;
	// begin inline asm
	cvta.to.global.u64 %rd511, %rd512;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r610,%r611,%r612,%r613}, [%rd511];
	// end inline asm
	add.s64 	%rd515, %rd497, 80;
	// begin inline asm
	cvta.to.global.u64 %rd514, %rd515;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r614,%r615,%r616,%r617}, [%rd514];
	// end inline asm
	add.s64 	%rd518, %rd497, 96;
	// begin inline asm
	cvta.to.global.u64 %rd517, %rd518;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r618,%r619,%r620,%r621}, [%rd517];
	// end inline asm
	add.s64 	%rd521, %rd497, 112;
	// begin inline asm
	cvta.to.global.u64 %rd520, %rd521;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r622,%r623,%r624,%r625}, [%rd520];
	// end inline asm
	mov.b32 	%f1644, %r597;
	mov.b32 	%f1645, %r598;
	and.b32  	%r638, %r596, 65535;
	add.s32 	%r639, %r638, -1;
	cvt.rn.f32.s32 	%f1646, %r639;
	sub.f32 	%f1647, %f1540, %f1644;
	mul.f32 	%f1648, %f1647, %f1646;
	sub.f32 	%f1649, %f1645, %f1644;
	div.rn.f32 	%f1650, %f1648, %f1649;
	min.f32 	%f1651, %f1646, %f1650;
	mov.f32 	%f1652, 0f00000000;
	max.f32 	%f1653, %f1652, %f1651;
	cvt.rmi.f32.f32 	%f1654, %f1653;
	sub.f32 	%f598, %f1653, %f1654;
	cvt.rzi.s32.f32 	%r640, %f1654;
	cvt.s64.s32 	%rd38, %r640;
	mul.wide.s32 	%rd532, %r640, 48;
	add.s64 	%rd524, %rd506, %rd532;
	// begin inline asm
	cvta.to.global.u64 %rd523, %rd524;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r626,%r627,%r628,%r629}, [%rd523];
	// end inline asm
	mov.b32 	%f2075, %r626;
	mov.b32 	%f2076, %r627;
	mov.b32 	%f2077, %r628;
	add.s64 	%rd527, %rd524, 16;
	// begin inline asm
	cvta.to.global.u64 %rd526, %rd527;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r630,%r631,%r632,%r633}, [%rd526];
	// end inline asm
	mov.b32 	%f2072, %r630;
	mov.b32 	%f2073, %r631;
	mov.b32 	%f2074, %r632;
	add.s64 	%rd530, %rd524, 32;
	// begin inline asm
	cvta.to.global.u64 %rd529, %rd530;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r634,%r635,%r636,%r637}, [%rd529];
	// end inline asm
	mov.b32 	%f2069, %r634;
	mov.b32 	%f2070, %r635;
	mov.b32 	%f2071, %r636;
	setp.leu.f32 	%p62, %f598, 0f00000000;
	@%p62 bra 	$L__BB8_92;

	mov.f32 	%f1655, 0f3F800000;
	sub.f32 	%f1656, %f1655, %f598;
	mul.lo.s64 	%rd542, %rd38, 48;
	add.s64 	%rd543, %rd497, %rd542;
	add.s64 	%rd534, %rd543, 80;
	// begin inline asm
	cvta.to.global.u64 %rd533, %rd534;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r641,%r642,%r643,%r644}, [%rd533];
	// end inline asm
	mov.b32 	%f1657, %r641;
	mov.b32 	%f1658, %r642;
	mov.b32 	%f1659, %r643;
	mul.f32 	%f1660, %f598, %f1657;
	mul.f32 	%f1661, %f598, %f1658;
	mul.f32 	%f1662, %f598, %f1659;
	fma.rn.f32 	%f2075, %f1656, %f2075, %f1660;
	fma.rn.f32 	%f2076, %f1656, %f2076, %f1661;
	fma.rn.f32 	%f2077, %f1656, %f2077, %f1662;
	add.s64 	%rd537, %rd543, 96;
	// begin inline asm
	cvta.to.global.u64 %rd536, %rd537;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r645,%r646,%r647,%r648}, [%rd536];
	// end inline asm
	mov.b32 	%f1663, %r645;
	mov.b32 	%f1664, %r646;
	mov.b32 	%f1665, %r647;
	mul.f32 	%f1666, %f598, %f1663;
	mul.f32 	%f1667, %f598, %f1664;
	mul.f32 	%f1668, %f598, %f1665;
	fma.rn.f32 	%f2072, %f1656, %f2072, %f1666;
	fma.rn.f32 	%f2073, %f1656, %f2073, %f1667;
	fma.rn.f32 	%f2074, %f1656, %f2074, %f1668;
	add.s64 	%rd540, %rd543, 112;
	// begin inline asm
	cvta.to.global.u64 %rd539, %rd540;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r649,%r650,%r651,%r652}, [%rd539];
	// end inline asm
	mov.b32 	%f1669, %r649;
	mov.b32 	%f1670, %r650;
	mov.b32 	%f1671, %r651;
	mul.f32 	%f1672, %f598, %f1669;
	mul.f32 	%f1673, %f598, %f1670;
	mul.f32 	%f1674, %f598, %f1671;
	fma.rn.f32 	%f2069, %f1656, %f2069, %f1672;
	fma.rn.f32 	%f2070, %f1656, %f2070, %f1673;
	fma.rn.f32 	%f2071, %f1656, %f2071, %f1674;
	bra.uni 	$L__BB8_92;

$L__BB8_81:
	mov.f32 	%f2078, 0f00000000;
	mov.f32 	%f2080, 0f3F800000;
	setp.eq.s32 	%p58, %r505, 4;
	@%p58 bra 	$L__BB8_84;

	setp.ne.s32 	%p59, %r505, 1;
	mov.f32 	%f2079, %f2078;
	mov.f32 	%f2081, %f2078;
	mov.f32 	%f2082, %f2080;
	mov.f32 	%f2083, %f2078;
	mov.f32 	%f2084, %f2080;
	mov.f32 	%f2085, %f2078;
	mov.f32 	%f2086, %f2078;
	@%p59 bra 	$L__BB8_93;

	// begin inline asm
	call (%rd427), _optix_get_static_transform_from_handle, (%rd425);
	// end inline asm
	add.s64 	%rd652, %rd427, 64;
	bra.uni 	$L__BB8_85;

$L__BB8_87:
	// begin inline asm
	call (%rd440), _optix_get_srt_motion_transform_from_handle, (%rd425);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd442, %rd440;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r519,%r520,%r521,%r522}, [%rd442];
	// end inline asm
	add.s64 	%rd446, %rd440, 16;
	// begin inline asm
	cvta.to.global.u64 %rd445, %rd446;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r523,%r524,%r525,%r526}, [%rd445];
	// end inline asm
	add.s64 	%rd449, %rd440, 32;
	// begin inline asm
	cvta.to.global.u64 %rd448, %rd449;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r527,%r528,%r529,%r530}, [%rd448];
	// end inline asm
	add.s64 	%rd452, %rd440, 48;
	// begin inline asm
	cvta.to.global.u64 %rd451, %rd452;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r531,%r532,%r533,%r534}, [%rd451];
	// end inline asm
	add.s64 	%rd455, %rd440, 64;
	// begin inline asm
	cvta.to.global.u64 %rd454, %rd455;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r535,%r536,%r537,%r538}, [%rd454];
	// end inline asm
	add.s64 	%rd458, %rd440, 80;
	// begin inline asm
	cvta.to.global.u64 %rd457, %rd458;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r539,%r540,%r541,%r542}, [%rd457];
	// end inline asm
	add.s64 	%rd461, %rd440, 96;
	// begin inline asm
	cvta.to.global.u64 %rd460, %rd461;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r543,%r544,%r545,%r546}, [%rd460];
	// end inline asm
	add.s64 	%rd464, %rd440, 112;
	// begin inline asm
	cvta.to.global.u64 %rd463, %rd464;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r547,%r548,%r549,%r550}, [%rd463];
	// end inline asm
	add.s64 	%rd467, %rd440, 128;
	// begin inline asm
	cvta.to.global.u64 %rd466, %rd467;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r551,%r552,%r553,%r554}, [%rd466];
	// end inline asm
	add.s64 	%rd470, %rd440, 144;
	// begin inline asm
	cvta.to.global.u64 %rd469, %rd470;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r555,%r556,%r557,%r558}, [%rd469];
	// end inline asm
	mov.b32 	%f1552, %r522;
	mov.b32 	%f1553, %r523;
	and.b32  	%r575, %r521, 65535;
	add.s32 	%r576, %r575, -1;
	cvt.rn.f32.s32 	%f1554, %r576;
	sub.f32 	%f1555, %f1540, %f1552;
	mul.f32 	%f1556, %f1555, %f1554;
	sub.f32 	%f1557, %f1553, %f1552;
	div.rn.f32 	%f1558, %f1556, %f1557;
	min.f32 	%f1559, %f1554, %f1558;
	mov.f32 	%f1560, 0f00000000;
	max.f32 	%f1561, %f1560, %f1559;
	cvt.rmi.f32.f32 	%f1562, %f1561;
	sub.f32 	%f558, %f1561, %f1562;
	cvt.rzi.s32.f32 	%r577, %f1562;
	mul.wide.s32 	%rd484, %r577, 64;
	add.s64 	%rd473, %rd449, %rd484;
	// begin inline asm
	cvta.to.global.u64 %rd472, %rd473;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r559,%r560,%r561,%r562}, [%rd472];
	// end inline asm
	mov.b32 	%f2059, %r559;
	mov.b32 	%f2060, %r560;
	mov.b32 	%f2061, %r561;
	add.s64 	%rd476, %rd473, 16;
	// begin inline asm
	cvta.to.global.u64 %rd475, %rd476;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r563,%r564,%r565,%r566}, [%rd475];
	// end inline asm
	mov.b32 	%f2062, %r563;
	mov.b32 	%f2063, %r564;
	mov.b32 	%f2064, %r566;
	add.s64 	%rd479, %rd473, 32;
	// begin inline asm
	cvta.to.global.u64 %rd478, %rd479;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r567,%r568,%r569,%r570}, [%rd478];
	// end inline asm
	mov.b32 	%f2065, %r568;
	mov.b32 	%f2066, %r569;
	mov.b32 	%f2067, %r570;
	add.s64 	%rd482, %rd473, 48;
	// begin inline asm
	cvta.to.global.u64 %rd481, %rd482;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r571,%r572,%r573,%r574}, [%rd481];
	// end inline asm
	mov.b32 	%f2068, %r571;
	setp.leu.f32 	%p61, %f558, 0f00000000;
	@%p61 bra 	$L__BB8_89;

	mov.f32 	%f1563, 0f3F800000;
	sub.f32 	%f1564, %f1563, %f558;
	add.s64 	%rd486, %rd473, 64;
	// begin inline asm
	cvta.to.global.u64 %rd485, %rd486;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r578,%r579,%r580,%r581}, [%rd485];
	// end inline asm
	mov.b32 	%f1565, %r578;
	mov.b32 	%f1566, %r579;
	mov.b32 	%f1567, %r580;
	mul.f32 	%f1568, %f558, %f1565;
	mul.f32 	%f1569, %f558, %f1566;
	mul.f32 	%f1570, %f558, %f1567;
	fma.rn.f32 	%f2059, %f1564, %f2059, %f1568;
	fma.rn.f32 	%f2060, %f1564, %f2060, %f1569;
	fma.rn.f32 	%f2061, %f1564, %f2061, %f1570;
	add.s64 	%rd489, %rd473, 80;
	// begin inline asm
	cvta.to.global.u64 %rd488, %rd489;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r582,%r583,%r584,%r585}, [%rd488];
	// end inline asm
	mov.b32 	%f1571, %r582;
	mov.b32 	%f1572, %r583;
	mov.b32 	%f1573, %r585;
	mul.f32 	%f1574, %f558, %f1571;
	mul.f32 	%f1575, %f558, %f1572;
	mul.f32 	%f1576, %f558, %f1573;
	fma.rn.f32 	%f2062, %f1564, %f2062, %f1574;
	fma.rn.f32 	%f2063, %f1564, %f2063, %f1575;
	fma.rn.f32 	%f2064, %f1564, %f2064, %f1576;
	add.s64 	%rd492, %rd473, 96;
	// begin inline asm
	cvta.to.global.u64 %rd491, %rd492;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r586,%r587,%r588,%r589}, [%rd491];
	// end inline asm
	mov.b32 	%f1577, %r587;
	mov.b32 	%f1578, %r588;
	mov.b32 	%f1579, %r589;
	mul.f32 	%f1580, %f558, %f1577;
	mul.f32 	%f1581, %f558, %f1578;
	mul.f32 	%f1582, %f558, %f1579;
	fma.rn.f32 	%f1583, %f1564, %f2065, %f1580;
	fma.rn.f32 	%f1584, %f1564, %f2066, %f1581;
	fma.rn.f32 	%f1585, %f1564, %f2067, %f1582;
	add.s64 	%rd495, %rd473, 112;
	// begin inline asm
	cvta.to.global.u64 %rd494, %rd495;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r590,%r591,%r592,%r593}, [%rd494];
	// end inline asm
	mov.b32 	%f1586, %r590;
	mul.f32 	%f1587, %f558, %f1586;
	fma.rn.f32 	%f1588, %f1564, %f2068, %f1587;
	mul.f32 	%f1589, %f1584, %f1584;
	fma.rn.f32 	%f1590, %f1583, %f1583, %f1589;
	fma.rn.f32 	%f1591, %f1585, %f1585, %f1590;
	fma.rn.f32 	%f1592, %f1588, %f1588, %f1591;
	sqrt.rn.f32 	%f1593, %f1592;
	rcp.rn.f32 	%f1594, %f1593;
	mul.f32 	%f2065, %f1583, %f1594;
	mul.f32 	%f2066, %f1584, %f1594;
	mul.f32 	%f2067, %f1585, %f1594;
	mul.f32 	%f2068, %f1594, %f1588;

$L__BB8_89:
	mul.f32 	%f1595, %f2066, %f2066;
	fma.rn.f32 	%f1596, %f2065, %f2065, %f1595;
	fma.rn.f32 	%f1597, %f2067, %f2067, %f1596;
	fma.rn.f32 	%f1598, %f2068, %f2068, %f1597;
	rcp.rn.f32 	%f1599, %f1598;
	mul.f32 	%f1600, %f2065, %f1599;
	mul.f32 	%f1601, %f2066, %f1599;
	mul.f32 	%f1602, %f2067, %f1599;
	mul.f32 	%f1603, %f2068, %f1599;
	mul.f32 	%f1604, %f2065, %f1600;
	mul.f32 	%f1605, %f2066, %f1601;
	mul.f32 	%f1606, %f2067, %f1602;
	mul.f32 	%f1607, %f2065, %f1601;
	mul.f32 	%f1608, %f2067, %f1603;
	mul.f32 	%f1609, %f2065, %f1602;
	mul.f32 	%f1610, %f2066, %f1603;
	mul.f32 	%f1611, %f2066, %f1602;
	mul.f32 	%f1612, %f2065, %f1603;
	sub.f32 	%f1613, %f1604, %f1605;
	sub.f32 	%f1614, %f1613, %f1606;
	fma.rn.f32 	%f1615, %f2068, %f1603, %f1614;
	sub.f32 	%f1616, %f1607, %f1608;
	add.f32 	%f1617, %f1616, %f1616;
	add.f32 	%f1618, %f1609, %f1610;
	add.f32 	%f1619, %f1618, %f1618;
	add.f32 	%f1620, %f1607, %f1608;
	add.f32 	%f1621, %f1620, %f1620;
	sub.f32 	%f1622, %f1605, %f1604;
	sub.f32 	%f1623, %f1622, %f1606;
	fma.rn.f32 	%f1624, %f2068, %f1603, %f1623;
	sub.f32 	%f1625, %f1611, %f1612;
	add.f32 	%f1626, %f1625, %f1625;
	sub.f32 	%f1627, %f1609, %f1610;
	add.f32 	%f1628, %f1627, %f1627;
	add.f32 	%f1629, %f1611, %f1612;
	add.f32 	%f1630, %f1629, %f1629;
	neg.f32 	%f1631, %f1604;
	sub.f32 	%f1632, %f1631, %f1605;
	add.f32 	%f1633, %f1606, %f1632;
	fma.rn.f32 	%f1634, %f2068, %f1603, %f1633;
	mul.f32 	%f1635, %f2061, %f1615;
	fma.rn.f32 	%f1636, %f2063, %f1617, %f1635;
	fma.rn.f32 	%f2077, %f2064, %f1619, %f1636;
	mul.f32 	%f1637, %f2063, %f1624;
	fma.rn.f32 	%f1638, %f2061, %f1621, %f1637;
	fma.rn.f32 	%f2074, %f2064, %f1626, %f1638;
	mul.f32 	%f1639, %f2063, %f1630;
	fma.rn.f32 	%f1640, %f2061, %f1628, %f1639;
	fma.rn.f32 	%f2071, %f2064, %f1634, %f1640;
	mul.f32 	%f1641, %f2060, %f1615;
	fma.rn.f32 	%f2076, %f2062, %f1617, %f1641;
	mul.f32 	%f1642, %f2062, %f1624;
	fma.rn.f32 	%f2073, %f2060, %f1621, %f1642;
	mul.f32 	%f1643, %f2062, %f1630;
	fma.rn.f32 	%f2070, %f2060, %f1628, %f1643;
	mul.f32 	%f2075, %f2059, %f1615;
	mul.f32 	%f2072, %f2059, %f1621;
	mul.f32 	%f2069, %f2059, %f1628;

$L__BB8_92:
	mul.f32 	%f1675, %f2070, %f2074;
	mul.f32 	%f1676, %f2071, %f2073;
	sub.f32 	%f1677, %f1676, %f1675;
	mul.f32 	%f1678, %f2075, %f1677;
	mul.f32 	%f1679, %f2069, %f2074;
	mul.f32 	%f1680, %f2071, %f2072;
	sub.f32 	%f1681, %f1680, %f1679;
	mul.f32 	%f1682, %f1681, %f2076;
	sub.f32 	%f1683, %f1678, %f1682;
	mul.f32 	%f1684, %f2069, %f2073;
	mul.f32 	%f1685, %f2070, %f2072;
	sub.f32 	%f1686, %f1685, %f1684;
	fma.rn.f32 	%f1687, %f1686, %f2077, %f1683;
	rcp.rn.f32 	%f1688, %f1687;
	mul.f32 	%f2084, %f1677, %f1688;
	mul.f32 	%f1689, %f2071, %f2076;
	mul.f32 	%f1690, %f2070, %f2077;
	sub.f32 	%f1691, %f1690, %f1689;
	mul.f32 	%f2085, %f1691, %f1688;
	mul.f32 	%f1692, %f2073, %f2077;
	mul.f32 	%f1693, %f2074, %f2076;
	sub.f32 	%f1694, %f1693, %f1692;
	mul.f32 	%f2086, %f1694, %f1688;
	sub.f32 	%f1695, %f1679, %f1680;
	mul.f32 	%f2081, %f1695, %f1688;
	mul.f32 	%f1696, %f2069, %f2077;
	mul.f32 	%f1697, %f2071, %f2075;
	sub.f32 	%f1698, %f1697, %f1696;
	mul.f32 	%f2082, %f1698, %f1688;
	mul.f32 	%f1699, %f2074, %f2075;
	mul.f32 	%f1700, %f2072, %f2077;
	sub.f32 	%f1701, %f1700, %f1699;
	mul.f32 	%f2083, %f1701, %f1688;
	mul.f32 	%f2078, %f1686, %f1688;
	mul.f32 	%f1702, %f2070, %f2075;
	mul.f32 	%f1703, %f2069, %f2076;
	sub.f32 	%f1704, %f1703, %f1702;
	mul.f32 	%f2079, %f1704, %f1688;
	mul.f32 	%f1705, %f2072, %f2076;
	mul.f32 	%f1706, %f2073, %f2075;
	sub.f32 	%f1707, %f1706, %f1705;
	mul.f32 	%f2080, %f1707, %f1688;
	bra.uni 	$L__BB8_93;

$L__BB8_84:
	// begin inline asm
	call (%rd652), _optix_get_instance_inverse_transform_from_handle, (%rd425);
	// end inline asm

$L__BB8_85:
	// begin inline asm
	cvta.to.global.u64 %rd431, %rd652;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r507,%r508,%r509,%r510}, [%rd431];
	// end inline asm
	mov.b32 	%f2084, %r507;
	mov.b32 	%f2085, %r508;
	mov.b32 	%f2086, %r509;
	add.s64 	%rd435, %rd652, 16;
	// begin inline asm
	cvta.to.global.u64 %rd434, %rd435;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r511,%r512,%r513,%r514}, [%rd434];
	// end inline asm
	mov.b32 	%f2081, %r511;
	mov.b32 	%f2082, %r512;
	mov.b32 	%f2083, %r513;
	add.s64 	%rd438, %rd652, 32;
	// begin inline asm
	cvta.to.global.u64 %rd437, %rd438;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r515,%r516,%r517,%r518}, [%rd437];
	// end inline asm
	mov.b32 	%f2078, %r515;
	mov.b32 	%f2079, %r516;
	mov.b32 	%f2080, %r517;

$L__BB8_93:
	setp.eq.s32 	%p63, %r659, 0;
	@%p63 bra 	$L__BB8_95;

	mul.f32 	%f1708, %f2055, %f2085;
	fma.rn.f32 	%f1709, %f2052, %f2084, %f1708;
	fma.rn.f32 	%f644, %f2058, %f2086, %f1709;
	mul.f32 	%f1710, %f2054, %f2085;
	fma.rn.f32 	%f1711, %f2051, %f2084, %f1710;
	fma.rn.f32 	%f645, %f2057, %f2086, %f1711;
	mul.f32 	%f1712, %f2053, %f2085;
	fma.rn.f32 	%f1713, %f2050, %f2084, %f1712;
	fma.rn.f32 	%f2086, %f2056, %f2086, %f1713;
	mul.f32 	%f1714, %f2055, %f2082;
	fma.rn.f32 	%f1715, %f2052, %f2081, %f1714;
	fma.rn.f32 	%f647, %f2058, %f2083, %f1715;
	mul.f32 	%f1716, %f2054, %f2082;
	fma.rn.f32 	%f1717, %f2051, %f2081, %f1716;
	fma.rn.f32 	%f648, %f2057, %f2083, %f1717;
	mul.f32 	%f1718, %f2053, %f2082;
	fma.rn.f32 	%f1719, %f2050, %f2081, %f1718;
	fma.rn.f32 	%f2083, %f2056, %f2083, %f1719;
	mul.f32 	%f1720, %f2055, %f2079;
	fma.rn.f32 	%f1721, %f2052, %f2078, %f1720;
	fma.rn.f32 	%f650, %f2058, %f2080, %f1721;
	mul.f32 	%f1722, %f2054, %f2079;
	fma.rn.f32 	%f1723, %f2051, %f2078, %f1722;
	fma.rn.f32 	%f651, %f2057, %f2080, %f1723;
	mul.f32 	%f1724, %f2053, %f2079;
	fma.rn.f32 	%f1725, %f2050, %f2078, %f1724;
	fma.rn.f32 	%f2080, %f2056, %f2080, %f1725;
	mov.f32 	%f2078, %f650;
	mov.f32 	%f2079, %f651;
	mov.f32 	%f2081, %f647;
	mov.f32 	%f2082, %f648;
	mov.f32 	%f2084, %f644;
	mov.f32 	%f2085, %f645;

$L__BB8_95:
	add.s32 	%r659, %r659, 1;
	setp.lt.u32 	%p64, %r659, %r502;
	mov.f32 	%f2050, %f2086;
	mov.f32 	%f2051, %f2085;
	mov.f32 	%f2052, %f2084;
	mov.f32 	%f2053, %f2083;
	mov.f32 	%f2054, %f2082;
	mov.f32 	%f2055, %f2081;
	mov.f32 	%f2056, %f2080;
	mov.f32 	%f2057, %f2079;
	mov.f32 	%f2058, %f2078;
	@%p64 bra 	$L__BB8_80;

$L__BB8_96:
	fma.rn.f32 	%f1726, %f2141, %f2022, %f2025;
	fma.rn.f32 	%f1727, %f2142, %f2023, %f1726;
	fma.rn.f32 	%f1728, %f2141, %f2018, %f2021;
	fma.rn.f32 	%f1729, %f2142, %f2019, %f1728;
	fma.rn.f32 	%f1730, %f2141, %f2014, %f2017;
	fma.rn.f32 	%f1731, %f2142, %f2015, %f1730;
	fma.rn.f32 	%f2141, %f2143, %f2024, %f1727;
	fma.rn.f32 	%f2142, %f2143, %f2020, %f1729;
	fma.rn.f32 	%f2143, %f2143, %f2016, %f1731;
	ld.const.u64 	%rd544, [params+112];
	setp.eq.s64 	%p65, %rd544, 0;
	mov.f32 	%f2105, %f2108;
	mov.f32 	%f2106, %f2109;
	mov.f32 	%f2107, %f2110;
	@%p65 bra 	$L__BB8_98;

	mul.f32 	%f1732, %f2108, %f2084;
	fma.rn.f32 	%f1733, %f2109, %f2081, %f1732;
	mul.f32 	%f1734, %f2108, %f2085;
	fma.rn.f32 	%f1735, %f2109, %f2082, %f1734;
	mul.f32 	%f1736, %f2108, %f2086;
	fma.rn.f32 	%f1737, %f2109, %f2083, %f1736;
	fma.rn.f32 	%f1738, %f2110, %f2078, %f1733;
	fma.rn.f32 	%f1739, %f2110, %f2079, %f1735;
	fma.rn.f32 	%f1740, %f2110, %f2080, %f1737;
	mul.f32 	%f1741, %f1738, %f1738;
	fma.rn.f32 	%f1742, %f1739, %f1739, %f1741;
	fma.rn.f32 	%f1743, %f1740, %f1740, %f1742;
	sqrt.rn.f32 	%f1744, %f1743;
	div.rn.f32 	%f2105, %f1738, %f1744;
	div.rn.f32 	%f2106, %f1739, %f1744;
	div.rn.f32 	%f2107, %f1740, %f1744;

$L__BB8_98:
	ld.const.u64 	%rd545, [params+136];
	setp.eq.s64 	%p66, %rd545, 0;
	@%p66 bra 	$L__BB8_100;

	mul.f32 	%f1745, %f2108, %f2084;
	fma.rn.f32 	%f1746, %f2109, %f2081, %f1745;
	mul.f32 	%f1747, %f2108, %f2085;
	fma.rn.f32 	%f1748, %f2109, %f2082, %f1747;
	mul.f32 	%f1749, %f2108, %f2086;
	fma.rn.f32 	%f1750, %f2109, %f2083, %f1749;
	fma.rn.f32 	%f1751, %f2110, %f2078, %f1746;
	fma.rn.f32 	%f1752, %f2110, %f2079, %f1748;
	fma.rn.f32 	%f1753, %f2110, %f2080, %f1750;
	mul.f32 	%f1754, %f1751, %f1751;
	fma.rn.f32 	%f1755, %f1752, %f1752, %f1754;
	fma.rn.f32 	%f1756, %f1753, %f1753, %f1755;
	sqrt.rn.f32 	%f1757, %f1756;
	div.rn.f32 	%f2108, %f1751, %f1757;
	div.rn.f32 	%f2109, %f1752, %f1757;
	div.rn.f32 	%f2110, %f1753, %f1757;

$L__BB8_100:
	mov.f32 	%f2140, %f2110;
	mov.f32 	%f2139, %f2109;
	mov.f32 	%f2138, %f2108;
	ld.const.u64 	%rd546, [params+184];
	setp.eq.s64 	%p67, %rd546, 0;
	@%p67 bra 	$L__BB8_102;

	mul.f32 	%f1758, %f2132, %f2022;
	fma.rn.f32 	%f1759, %f2133, %f2023, %f1758;
	mul.f32 	%f1760, %f2132, %f2018;
	fma.rn.f32 	%f1761, %f2133, %f2019, %f1760;
	mul.f32 	%f1762, %f2132, %f2014;
	fma.rn.f32 	%f1763, %f2133, %f2015, %f1762;
	fma.rn.f32 	%f2132, %f2134, %f2024, %f1759;
	fma.rn.f32 	%f2133, %f2134, %f2020, %f1761;
	fma.rn.f32 	%f2134, %f2134, %f2016, %f1763;
	mul.f32 	%f1764, %f2129, %f2022;
	fma.rn.f32 	%f1765, %f2130, %f2023, %f1764;
	mul.f32 	%f1766, %f2129, %f2018;
	fma.rn.f32 	%f1767, %f2130, %f2019, %f1766;
	mul.f32 	%f1768, %f2129, %f2014;
	fma.rn.f32 	%f1769, %f2130, %f2015, %f1768;
	fma.rn.f32 	%f2129, %f2131, %f2024, %f1765;
	fma.rn.f32 	%f2130, %f2131, %f2020, %f1767;
	fma.rn.f32 	%f2131, %f2131, %f2016, %f1769;

$L__BB8_102:
	ld.const.u64 	%rd547, [params+232];
	ld.const.u64 	%rd548, [params+280];
	or.b64  	%rd549, %rd547, %rd548;
	setp.eq.s64 	%p68, %rd549, 0;
	@%p68 bra 	$L__BB8_104;

	mul.f32 	%f1770, %f2138, %f2022;
	fma.rn.f32 	%f1771, %f2139, %f2018, %f1770;
	mul.f32 	%f1772, %f2138, %f2023;
	fma.rn.f32 	%f1773, %f2139, %f2019, %f1772;
	mul.f32 	%f1774, %f2138, %f2024;
	fma.rn.f32 	%f1775, %f2139, %f2020, %f1774;
	fma.rn.f32 	%f1776, %f2140, %f2014, %f1771;
	fma.rn.f32 	%f1777, %f2140, %f2015, %f1773;
	fma.rn.f32 	%f1778, %f2140, %f2016, %f1775;
	mul.f32 	%f1779, %f1776, %f1776;
	fma.rn.f32 	%f1780, %f1777, %f1777, %f1779;
	fma.rn.f32 	%f1781, %f1778, %f1778, %f1780;
	sqrt.rn.f32 	%f1782, %f1781;
	div.rn.f32 	%f1783, %f1776, %f1782;
	div.rn.f32 	%f1784, %f1777, %f1782;
	div.rn.f32 	%f1785, %f1778, %f1782;
	mul.f32 	%f1786, %f1783, %f2084;
	mul.f32 	%f1787, %f1783, %f2085;
	mul.f32 	%f1788, %f1783, %f2086;
	fma.rn.f32 	%f1789, %f1784, %f2081, %f1786;
	fma.rn.f32 	%f1790, %f1784, %f2082, %f1787;
	fma.rn.f32 	%f1791, %f1784, %f2083, %f1788;
	fma.rn.f32 	%f1792, %f1785, %f2078, %f1789;
	fma.rn.f32 	%f1793, %f1785, %f2079, %f1790;
	fma.rn.f32 	%f1794, %f1785, %f2080, %f1791;
	mul.f32 	%f1795, %f1792, %f1792;
	fma.rn.f32 	%f1796, %f1793, %f1793, %f1795;
	fma.rn.f32 	%f1797, %f1794, %f1794, %f1796;
	sqrt.rn.f32 	%f1798, %f1797;
	rcp.rn.f32 	%f1799, %f1798;
	mul.f32 	%f1800, %f1799, %f1792;
	mul.f32 	%f1801, %f1799, %f1793;
	mul.f32 	%f1802, %f1799, %f1794;
	mul.f32 	%f1803, %f2120, %f2084;
	fma.rn.f32 	%f1804, %f2121, %f2081, %f1803;
	mul.f32 	%f1805, %f2120, %f2085;
	fma.rn.f32 	%f1806, %f2121, %f2082, %f1805;
	mul.f32 	%f1807, %f2120, %f2086;
	fma.rn.f32 	%f1808, %f2121, %f2083, %f1807;
	fma.rn.f32 	%f1809, %f2122, %f2078, %f1804;
	fma.rn.f32 	%f1810, %f2122, %f2079, %f1806;
	fma.rn.f32 	%f1811, %f2122, %f2080, %f1808;
	mul.f32 	%f1812, %f1809, %f1799;
	mul.f32 	%f1813, %f1810, %f1799;
	mul.f32 	%f1814, %f1811, %f1799;
	mul.f32 	%f1815, %f2117, %f2084;
	fma.rn.f32 	%f1816, %f2118, %f2081, %f1815;
	mul.f32 	%f1817, %f2117, %f2085;
	fma.rn.f32 	%f1818, %f2118, %f2082, %f1817;
	mul.f32 	%f1819, %f2117, %f2086;
	fma.rn.f32 	%f1820, %f2118, %f2083, %f1819;
	fma.rn.f32 	%f1821, %f2119, %f2078, %f1816;
	fma.rn.f32 	%f1822, %f2119, %f2079, %f1818;
	fma.rn.f32 	%f1823, %f2119, %f2080, %f1820;
	mul.f32 	%f1824, %f1821, %f1799;
	mul.f32 	%f1825, %f1822, %f1799;
	mul.f32 	%f1826, %f1823, %f1799;
	mul.f32 	%f1827, %f1800, %f1812;
	fma.rn.f32 	%f1828, %f1801, %f1813, %f1827;
	fma.rn.f32 	%f1829, %f1802, %f1814, %f1828;
	mul.f32 	%f1830, %f1800, %f1829;
	mul.f32 	%f1831, %f1801, %f1829;
	mul.f32 	%f1832, %f1802, %f1829;
	sub.f32 	%f2120, %f1812, %f1830;
	sub.f32 	%f2121, %f1813, %f1831;
	sub.f32 	%f2122, %f1814, %f1832;
	mul.f32 	%f1833, %f1800, %f1824;
	fma.rn.f32 	%f1834, %f1801, %f1825, %f1833;
	fma.rn.f32 	%f1835, %f1802, %f1826, %f1834;
	mul.f32 	%f1836, %f1800, %f1835;
	mul.f32 	%f1837, %f1801, %f1835;
	mul.f32 	%f1838, %f1802, %f1835;
	sub.f32 	%f2117, %f1824, %f1836;
	sub.f32 	%f2118, %f1825, %f1837;
	sub.f32 	%f2119, %f1826, %f1838;

$L__BB8_104:
	st.global.u32 	[%rd24], %r348;
	mov.f32 	%f2108, %f2105;
	mov.f32 	%f2109, %f2106;
	mov.f32 	%f2110, %f2107;

$L__BB8_105:
	ld.const.u64 	%rd550, [params+328];
	cvta.to.global.u64 	%rd551, %rd550;
	shl.b64 	%rd552, %rd23, 3;
	add.s64 	%rd553, %rd551, %rd552;
	st.global.u64 	[%rd553], %rd22;
	ld.const.u64 	%rd554, [params+336];
	cvta.to.global.u64 	%rd555, %rd554;
	shl.b64 	%rd556, %rd23, 2;
	add.s64 	%rd557, %rd555, %rd556;
	mov.u32 	%r653, 0;
	st.global.u32 	[%rd557], %r653;
	ld.const.u64 	%rd558, [params+160];
	cvta.to.global.u64 	%rd559, %rd558;
	add.s64 	%rd560, %rd559, %rd556;
	st.global.f32 	[%rd560], %f2141;
	ld.const.u64 	%rd561, [params+168];
	cvta.to.global.u64 	%rd562, %rd561;
	add.s64 	%rd563, %rd562, %rd556;
	st.global.f32 	[%rd563], %f2142;
	ld.const.u64 	%rd564, [params+176];
	cvta.to.global.u64 	%rd565, %rd564;
	add.s64 	%rd566, %rd565, %rd556;
	st.global.f32 	[%rd566], %f2143;
	ld.const.u64 	%rd567, [params+72];
	cvta.to.global.u64 	%rd568, %rd567;
	add.s64 	%rd569, %rd568, %rd556;
	st.global.f32 	[%rd569], %f1179;
	@%p26 bra 	$L__BB8_107;

	cvta.to.global.u64 	%rd570, %rd21;
	add.s64 	%rd572, %rd570, %rd556;
	st.global.f32 	[%rd572], %f1985;
	ld.const.u64 	%rd573, [params+104];
	cvta.to.global.u64 	%rd574, %rd573;
	add.s64 	%rd575, %rd574, %rd556;
	st.global.f32 	[%rd575], %f1984;

$L__BB8_107:
	ld.const.u64 	%rd39, [params+112];
	setp.eq.s64 	%p70, %rd39, 0;
	@%p70 bra 	$L__BB8_109;

	cvta.to.global.u64 	%rd576, %rd39;
	add.s64 	%rd578, %rd576, %rd556;
	st.global.f32 	[%rd578], %f2108;
	ld.const.u64 	%rd579, [params+120];
	cvta.to.global.u64 	%rd580, %rd579;
	add.s64 	%rd581, %rd580, %rd556;
	st.global.f32 	[%rd581], %f2109;
	ld.const.u64 	%rd582, [params+128];
	cvta.to.global.u64 	%rd583, %rd582;
	add.s64 	%rd584, %rd583, %rd556;
	st.global.f32 	[%rd584], %f2110;

$L__BB8_109:
	ld.const.u64 	%rd40, [params+136];
	setp.eq.s64 	%p71, %rd40, 0;
	@%p71 bra 	$L__BB8_111;

	cvta.to.global.u64 	%rd585, %rd40;
	add.s64 	%rd587, %rd585, %rd556;
	st.global.f32 	[%rd587], %f2138;
	ld.const.u64 	%rd588, [params+144];
	cvta.to.global.u64 	%rd589, %rd588;
	add.s64 	%rd590, %rd589, %rd556;
	st.global.f32 	[%rd590], %f2139;
	ld.const.u64 	%rd591, [params+152];
	cvta.to.global.u64 	%rd592, %rd591;
	add.s64 	%rd593, %rd592, %rd556;
	st.global.f32 	[%rd593], %f2140;

$L__BB8_111:
	ld.const.u64 	%rd41, [params+184];
	setp.eq.s64 	%p72, %rd41, 0;
	@%p72 bra 	$L__BB8_113;

	cvta.to.global.u64 	%rd594, %rd41;
	add.s64 	%rd596, %rd594, %rd556;
	st.global.f32 	[%rd596], %f2132;
	ld.const.u64 	%rd597, [params+192];
	cvta.to.global.u64 	%rd598, %rd597;
	add.s64 	%rd599, %rd598, %rd556;
	st.global.f32 	[%rd599], %f2133;
	ld.const.u64 	%rd600, [params+200];
	cvta.to.global.u64 	%rd601, %rd600;
	add.s64 	%rd602, %rd601, %rd556;
	st.global.f32 	[%rd602], %f2134;
	ld.const.u64 	%rd603, [params+208];
	cvta.to.global.u64 	%rd604, %rd603;
	add.s64 	%rd605, %rd604, %rd556;
	st.global.f32 	[%rd605], %f2129;
	ld.const.u64 	%rd606, [params+216];
	cvta.to.global.u64 	%rd607, %rd606;
	add.s64 	%rd608, %rd607, %rd556;
	st.global.f32 	[%rd608], %f2130;
	ld.const.u64 	%rd609, [params+224];
	cvta.to.global.u64 	%rd610, %rd609;
	add.s64 	%rd611, %rd610, %rd556;
	st.global.f32 	[%rd611], %f2131;

$L__BB8_113:
	ld.const.u64 	%rd42, [params+232];
	setp.eq.s64 	%p73, %rd42, 0;
	@%p73 bra 	$L__BB8_115;

	cvta.to.global.u64 	%rd612, %rd42;
	add.s64 	%rd614, %rd612, %rd556;
	st.global.f32 	[%rd614], %f2120;
	ld.const.u64 	%rd615, [params+240];
	cvta.to.global.u64 	%rd616, %rd615;
	add.s64 	%rd617, %rd616, %rd556;
	st.global.f32 	[%rd617], %f2121;
	ld.const.u64 	%rd618, [params+248];
	cvta.to.global.u64 	%rd619, %rd618;
	add.s64 	%rd620, %rd619, %rd556;
	st.global.f32 	[%rd620], %f2122;
	ld.const.u64 	%rd621, [params+256];
	cvta.to.global.u64 	%rd622, %rd621;
	add.s64 	%rd623, %rd622, %rd556;
	st.global.f32 	[%rd623], %f2117;
	ld.const.u64 	%rd624, [params+264];
	cvta.to.global.u64 	%rd625, %rd624;
	add.s64 	%rd626, %rd625, %rd556;
	st.global.f32 	[%rd626], %f2118;
	ld.const.u64 	%rd627, [params+272];
	cvta.to.global.u64 	%rd628, %rd627;
	add.s64 	%rd629, %rd628, %rd556;
	st.global.f32 	[%rd629], %f2119;

$L__BB8_115:
	ld.const.u64 	%rd43, [params+280];
	setp.eq.s64 	%p74, %rd43, 0;
	@%p74 bra 	$L__BB8_117;

	cvta.to.global.u64 	%rd630, %rd43;
	add.s64 	%rd632, %rd630, %rd556;
	st.global.f32 	[%rd632], %f2120;
	ld.const.u64 	%rd633, [params+288];
	cvta.to.global.u64 	%rd634, %rd633;
	add.s64 	%rd635, %rd634, %rd556;
	st.global.f32 	[%rd635], %f2121;
	ld.const.u64 	%rd636, [params+296];
	cvta.to.global.u64 	%rd637, %rd636;
	add.s64 	%rd638, %rd637, %rd556;
	st.global.f32 	[%rd638], %f2122;
	ld.const.u64 	%rd639, [params+304];
	cvta.to.global.u64 	%rd640, %rd639;
	add.s64 	%rd641, %rd640, %rd556;
	st.global.f32 	[%rd641], %f2117;
	ld.const.u64 	%rd642, [params+312];
	cvta.to.global.u64 	%rd643, %rd642;
	add.s64 	%rd644, %rd643, %rd556;
	st.global.f32 	[%rd644], %f2118;
	ld.const.u64 	%rd645, [params+320];
	cvta.to.global.u64 	%rd646, %rd645;
	add.s64 	%rd647, %rd646, %rd556;
	st.global.f32 	[%rd647], %f2119;

$L__BB8_117:
	ret;

}
	// .globl	__intersection__asphsurf
.visible .entry __intersection__asphsurf()
{
	.reg .pred 	%p<47>;
	.reg .f32 	%f<1036>;
	.reg .b32 	%r<323>;
	.reg .b64 	%rd<259>;


	// begin inline asm
	call (%rd17), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd1, [%rd17+8];
	// begin inline asm
	call (%f973), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f974), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f975), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r9), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p5, %r9, 0;
	@%p5 bra 	$L__BB9_21;

	// begin inline asm
	call (%r10), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f363), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p6, %r10, 0;
	@%p6 bra 	$L__BB9_19;

	mov.u32 	%r321, 0;

$L__BB9_3:
	.pragma "nounroll";
	// begin inline asm
	call (%rd18), _optix_get_transform_list_handle, (%r321);
	// end inline asm
	// begin inline asm
	call (%r13), _optix_get_transform_type_from_handle, (%rd18);
	// end inline asm
	or.b32  	%r14, %r13, 1;
	setp.eq.s32 	%p7, %r14, 3;
	@%p7 bra 	$L__BB9_9;
	bra.uni 	$L__BB9_4;

$L__BB9_9:
	setp.eq.s32 	%p10, %r13, 2;
	@%p10 bra 	$L__BB9_13;
	bra.uni 	$L__BB9_10;

$L__BB9_13:
	// begin inline asm
	call (%rd90), _optix_get_matrix_motion_transform_from_handle, (%rd18);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd92];
	// end inline asm
	add.s64 	%rd96, %rd90, 16;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r106,%r107,%r108,%r109}, [%rd95];
	// end inline asm
	add.s64 	%rd99, %rd90, 32;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r110,%r111,%r112,%r113}, [%rd98];
	// end inline asm
	add.s64 	%rd102, %rd90, 48;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r114,%r115,%r116,%r117}, [%rd101];
	// end inline asm
	add.s64 	%rd105, %rd90, 64;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r118,%r119,%r120,%r121}, [%rd104];
	// end inline asm
	add.s64 	%rd108, %rd90, 80;
	// begin inline asm
	cvta.to.global.u64 %rd107, %rd108;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r122,%r123,%r124,%r125}, [%rd107];
	// end inline asm
	add.s64 	%rd111, %rd90, 96;
	// begin inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r126,%r127,%r128,%r129}, [%rd110];
	// end inline asm
	add.s64 	%rd114, %rd90, 112;
	// begin inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r130,%r131,%r132,%r133}, [%rd113];
	// end inline asm
	mov.b32 	%f491, %r105;
	mov.b32 	%f492, %r106;
	and.b32  	%r146, %r104, 65535;
	add.s32 	%r147, %r146, -1;
	cvt.rn.f32.s32 	%f493, %r147;
	sub.f32 	%f494, %f363, %f491;
	mul.f32 	%f495, %f494, %f493;
	sub.f32 	%f496, %f492, %f491;
	div.rn.f32 	%f497, %f495, %f496;
	min.f32 	%f498, %f493, %f497;
	mov.f32 	%f499, 0f00000000;
	max.f32 	%f500, %f499, %f498;
	cvt.rmi.f32.f32 	%f501, %f500;
	sub.f32 	%f90, %f500, %f501;
	cvt.rzi.s32.f32 	%r148, %f501;
	mul.wide.s32 	%rd125, %r148, 48;
	add.s64 	%rd117, %rd99, %rd125;
	// begin inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r134,%r135,%r136,%r137}, [%rd116];
	// end inline asm
	mov.b32 	%f928, %r134;
	mov.b32 	%f927, %r135;
	mov.b32 	%f926, %r136;
	mov.b32 	%f925, %r137;
	add.s64 	%rd120, %rd117, 16;
	// begin inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r138,%r139,%r140,%r141}, [%rd119];
	// end inline asm
	mov.b32 	%f932, %r138;
	mov.b32 	%f931, %r139;
	mov.b32 	%f930, %r140;
	mov.b32 	%f929, %r141;
	add.s64 	%rd123, %rd117, 32;
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r142,%r143,%r144,%r145}, [%rd122];
	// end inline asm
	mov.b32 	%f936, %r142;
	mov.b32 	%f935, %r143;
	mov.b32 	%f934, %r144;
	mov.b32 	%f933, %r145;
	setp.leu.f32 	%p12, %f90, 0f00000000;
	@%p12 bra 	$L__BB9_15;

	cvt.rmi.f32.f32 	%f896, %f500;
	cvt.rzi.s32.f32 	%r320, %f896;
	cvt.s64.s32 	%rd256, %r320;
	mov.f32 	%f502, 0f3F800000;
	sub.f32 	%f503, %f502, %f90;
	mul.lo.s64 	%rd135, %rd256, 48;
	add.s64 	%rd136, %rd90, %rd135;
	add.s64 	%rd127, %rd136, 80;
	// begin inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd126];
	// end inline asm
	mov.b32 	%f504, %r149;
	mov.b32 	%f505, %r150;
	mov.b32 	%f506, %r151;
	mov.b32 	%f507, %r152;
	mul.f32 	%f508, %f90, %f504;
	mul.f32 	%f509, %f90, %f505;
	mul.f32 	%f510, %f90, %f506;
	mul.f32 	%f511, %f90, %f507;
	fma.rn.f32 	%f928, %f503, %f928, %f508;
	fma.rn.f32 	%f927, %f503, %f927, %f509;
	fma.rn.f32 	%f926, %f503, %f926, %f510;
	fma.rn.f32 	%f925, %f503, %f925, %f511;
	add.s64 	%rd130, %rd136, 96;
	// begin inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd129];
	// end inline asm
	mov.b32 	%f512, %r153;
	mov.b32 	%f513, %r154;
	mov.b32 	%f514, %r155;
	mov.b32 	%f515, %r156;
	mul.f32 	%f516, %f90, %f512;
	mul.f32 	%f517, %f90, %f513;
	mul.f32 	%f518, %f90, %f514;
	mul.f32 	%f519, %f90, %f515;
	fma.rn.f32 	%f932, %f503, %f932, %f516;
	fma.rn.f32 	%f931, %f503, %f931, %f517;
	fma.rn.f32 	%f930, %f503, %f930, %f518;
	fma.rn.f32 	%f929, %f503, %f929, %f519;
	add.s64 	%rd133, %rd136, 112;
	// begin inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd132];
	// end inline asm
	mov.b32 	%f520, %r157;
	mov.b32 	%f521, %r158;
	mov.b32 	%f522, %r159;
	mov.b32 	%f523, %r160;
	mul.f32 	%f524, %f90, %f520;
	mul.f32 	%f525, %f90, %f521;
	mul.f32 	%f526, %f90, %f522;
	mul.f32 	%f527, %f90, %f523;
	fma.rn.f32 	%f936, %f503, %f936, %f524;
	fma.rn.f32 	%f935, %f503, %f935, %f525;
	fma.rn.f32 	%f934, %f503, %f934, %f526;
	fma.rn.f32 	%f933, %f503, %f933, %f527;
	bra.uni 	$L__BB9_15;

$L__BB9_4:
	mov.f32 	%f937, 0f00000000;
	mov.f32 	%f940, 0f3F800000;
	setp.eq.s32 	%p8, %r13, 4;
	@%p8 bra 	$L__BB9_7;

	setp.ne.s32 	%p9, %r13, 1;
	mov.f32 	%f938, %f937;
	mov.f32 	%f939, %f937;
	mov.f32 	%f941, %f937;
	mov.f32 	%f942, %f937;
	mov.f32 	%f943, %f940;
	mov.f32 	%f944, %f937;
	mov.f32 	%f945, %f937;
	mov.f32 	%f946, %f940;
	mov.f32 	%f947, %f937;
	mov.f32 	%f948, %f937;
	@%p9 bra 	$L__BB9_16;

	// begin inline asm
	call (%rd20), _optix_get_static_transform_from_handle, (%rd18);
	// end inline asm
	add.s64 	%rd257, %rd20, 64;
	bra.uni 	$L__BB9_8;

$L__BB9_10:
	// begin inline asm
	call (%rd33), _optix_get_srt_motion_transform_from_handle, (%rd18);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd35, %rd33;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r27,%r28,%r29,%r30}, [%rd35];
	// end inline asm
	add.s64 	%rd39, %rd33, 16;
	// begin inline asm
	cvta.to.global.u64 %rd38, %rd39;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r31,%r32,%r33,%r34}, [%rd38];
	// end inline asm
	add.s64 	%rd42, %rd33, 32;
	// begin inline asm
	cvta.to.global.u64 %rd41, %rd42;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r35,%r36,%r37,%r38}, [%rd41];
	// end inline asm
	add.s64 	%rd45, %rd33, 48;
	// begin inline asm
	cvta.to.global.u64 %rd44, %rd45;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r39,%r40,%r41,%r42}, [%rd44];
	// end inline asm
	add.s64 	%rd48, %rd33, 64;
	// begin inline asm
	cvta.to.global.u64 %rd47, %rd48;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r43,%r44,%r45,%r46}, [%rd47];
	// end inline asm
	add.s64 	%rd51, %rd33, 80;
	// begin inline asm
	cvta.to.global.u64 %rd50, %rd51;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r47,%r48,%r49,%r50}, [%rd50];
	// end inline asm
	add.s64 	%rd54, %rd33, 96;
	// begin inline asm
	cvta.to.global.u64 %rd53, %rd54;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r51,%r52,%r53,%r54}, [%rd53];
	// end inline asm
	add.s64 	%rd57, %rd33, 112;
	// begin inline asm
	cvta.to.global.u64 %rd56, %rd57;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r55,%r56,%r57,%r58}, [%rd56];
	// end inline asm
	add.s64 	%rd60, %rd33, 128;
	// begin inline asm
	cvta.to.global.u64 %rd59, %rd60;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r59,%r60,%r61,%r62}, [%rd59];
	// end inline asm
	add.s64 	%rd63, %rd33, 144;
	// begin inline asm
	cvta.to.global.u64 %rd62, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r63,%r64,%r65,%r66}, [%rd62];
	// end inline asm
	mov.b32 	%f378, %r30;
	mov.b32 	%f379, %r31;
	and.b32  	%r83, %r29, 65535;
	add.s32 	%r84, %r83, -1;
	cvt.rn.f32.s32 	%f380, %r84;
	sub.f32 	%f381, %f363, %f378;
	mul.f32 	%f382, %f381, %f380;
	sub.f32 	%f383, %f379, %f378;
	div.rn.f32 	%f384, %f382, %f383;
	min.f32 	%f385, %f380, %f384;
	mov.f32 	%f386, 0f00000000;
	max.f32 	%f387, %f386, %f385;
	cvt.rmi.f32.f32 	%f388, %f387;
	sub.f32 	%f29, %f387, %f388;
	cvt.rzi.s32.f32 	%r85, %f388;
	mul.wide.s32 	%rd77, %r85, 64;
	add.s64 	%rd66, %rd42, %rd77;
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd66;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r67,%r68,%r69,%r70}, [%rd65];
	// end inline asm
	mov.b32 	%f909, %r67;
	mov.b32 	%f910, %r68;
	mov.b32 	%f911, %r69;
	mov.b32 	%f912, %r70;
	add.s64 	%rd69, %rd66, 16;
	// begin inline asm
	cvta.to.global.u64 %rd68, %rd69;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r71,%r72,%r73,%r74}, [%rd68];
	// end inline asm
	mov.b32 	%f913, %r71;
	mov.b32 	%f914, %r72;
	mov.b32 	%f915, %r73;
	mov.b32 	%f916, %r74;
	add.s64 	%rd72, %rd66, 32;
	// begin inline asm
	cvta.to.global.u64 %rd71, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r75,%r76,%r77,%r78}, [%rd71];
	// end inline asm
	mov.b32 	%f917, %r75;
	mov.b32 	%f918, %r76;
	mov.b32 	%f919, %r77;
	mov.b32 	%f920, %r78;
	add.s64 	%rd75, %rd66, 48;
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd75;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r79,%r80,%r81,%r82}, [%rd74];
	// end inline asm
	mov.b32 	%f921, %r79;
	mov.b32 	%f922, %r80;
	mov.b32 	%f923, %r81;
	mov.b32 	%f924, %r82;
	setp.leu.f32 	%p11, %f29, 0f00000000;
	@%p11 bra 	$L__BB9_12;

	mov.f32 	%f389, 0f3F800000;
	sub.f32 	%f390, %f389, %f29;
	add.s64 	%rd79, %rd66, 64;
	// begin inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r86,%r87,%r88,%r89}, [%rd78];
	// end inline asm
	mov.b32 	%f391, %r86;
	mov.b32 	%f392, %r87;
	mov.b32 	%f393, %r88;
	mov.b32 	%f394, %r89;
	mul.f32 	%f395, %f29, %f391;
	mul.f32 	%f396, %f29, %f392;
	mul.f32 	%f397, %f29, %f393;
	mul.f32 	%f398, %f29, %f394;
	fma.rn.f32 	%f909, %f390, %f909, %f395;
	fma.rn.f32 	%f910, %f390, %f910, %f396;
	fma.rn.f32 	%f911, %f390, %f911, %f397;
	fma.rn.f32 	%f912, %f390, %f912, %f398;
	add.s64 	%rd82, %rd66, 80;
	// begin inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd81];
	// end inline asm
	mov.b32 	%f399, %r90;
	mov.b32 	%f400, %r91;
	mov.b32 	%f401, %r92;
	mov.b32 	%f402, %r93;
	mul.f32 	%f403, %f29, %f399;
	mul.f32 	%f404, %f29, %f400;
	mul.f32 	%f405, %f29, %f401;
	mul.f32 	%f406, %f29, %f402;
	fma.rn.f32 	%f913, %f390, %f913, %f403;
	fma.rn.f32 	%f914, %f390, %f914, %f404;
	fma.rn.f32 	%f915, %f390, %f915, %f405;
	fma.rn.f32 	%f916, %f390, %f916, %f406;
	add.s64 	%rd85, %rd66, 96;
	// begin inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd84];
	// end inline asm
	mov.b32 	%f407, %r94;
	mov.b32 	%f408, %r95;
	mov.b32 	%f409, %r96;
	mov.b32 	%f410, %r97;
	mul.f32 	%f411, %f29, %f407;
	mul.f32 	%f412, %f29, %f408;
	mul.f32 	%f413, %f29, %f409;
	mul.f32 	%f414, %f29, %f410;
	fma.rn.f32 	%f917, %f390, %f917, %f411;
	fma.rn.f32 	%f415, %f390, %f918, %f412;
	fma.rn.f32 	%f416, %f390, %f919, %f413;
	fma.rn.f32 	%f417, %f390, %f920, %f414;
	add.s64 	%rd88, %rd66, 112;
	// begin inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd87];
	// end inline asm
	mov.b32 	%f418, %r98;
	mov.b32 	%f419, %r99;
	mov.b32 	%f420, %r100;
	mov.b32 	%f421, %r101;
	mul.f32 	%f422, %f29, %f418;
	mul.f32 	%f423, %f29, %f419;
	mul.f32 	%f424, %f29, %f420;
	mul.f32 	%f425, %f29, %f421;
	fma.rn.f32 	%f426, %f390, %f921, %f422;
	fma.rn.f32 	%f922, %f390, %f922, %f423;
	fma.rn.f32 	%f923, %f390, %f923, %f424;
	fma.rn.f32 	%f924, %f390, %f924, %f425;
	mul.f32 	%f427, %f416, %f416;
	fma.rn.f32 	%f428, %f415, %f415, %f427;
	fma.rn.f32 	%f429, %f417, %f417, %f428;
	fma.rn.f32 	%f430, %f426, %f426, %f429;
	sqrt.rn.f32 	%f431, %f430;
	rcp.rn.f32 	%f432, %f431;
	mul.f32 	%f918, %f415, %f432;
	mul.f32 	%f919, %f416, %f432;
	mul.f32 	%f920, %f417, %f432;
	mul.f32 	%f921, %f432, %f426;

$L__BB9_12:
	mul.f32 	%f433, %f919, %f919;
	fma.rn.f32 	%f434, %f918, %f918, %f433;
	fma.rn.f32 	%f435, %f920, %f920, %f434;
	fma.rn.f32 	%f436, %f921, %f921, %f435;
	rcp.rn.f32 	%f437, %f436;
	mul.f32 	%f438, %f918, %f437;
	mul.f32 	%f439, %f919, %f437;
	mul.f32 	%f440, %f920, %f437;
	mul.f32 	%f441, %f921, %f437;
	mul.f32 	%f442, %f918, %f438;
	mul.f32 	%f443, %f919, %f439;
	mul.f32 	%f444, %f920, %f440;
	mul.f32 	%f445, %f918, %f439;
	mul.f32 	%f446, %f920, %f441;
	mul.f32 	%f447, %f918, %f440;
	mul.f32 	%f448, %f919, %f441;
	mul.f32 	%f449, %f919, %f440;
	mul.f32 	%f450, %f918, %f441;
	sub.f32 	%f451, %f442, %f443;
	sub.f32 	%f452, %f451, %f444;
	fma.rn.f32 	%f453, %f921, %f441, %f452;
	sub.f32 	%f454, %f445, %f446;
	add.f32 	%f455, %f454, %f454;
	add.f32 	%f456, %f447, %f448;
	add.f32 	%f457, %f456, %f456;
	add.f32 	%f458, %f445, %f446;
	add.f32 	%f459, %f458, %f458;
	sub.f32 	%f460, %f443, %f442;
	sub.f32 	%f461, %f460, %f444;
	fma.rn.f32 	%f462, %f921, %f441, %f461;
	sub.f32 	%f463, %f449, %f450;
	add.f32 	%f464, %f463, %f463;
	sub.f32 	%f465, %f447, %f448;
	add.f32 	%f466, %f465, %f465;
	add.f32 	%f467, %f449, %f450;
	add.f32 	%f468, %f467, %f467;
	neg.f32 	%f469, %f442;
	sub.f32 	%f470, %f469, %f443;
	add.f32 	%f471, %f444, %f470;
	fma.rn.f32 	%f472, %f921, %f441, %f471;
	mul.f32 	%f473, %f912, %f453;
	fma.rn.f32 	%f474, %f915, %f455, %f473;
	fma.rn.f32 	%f475, %f917, %f457, %f474;
	sub.f32 	%f925, %f922, %f475;
	mul.f32 	%f476, %f915, %f462;
	fma.rn.f32 	%f477, %f912, %f459, %f476;
	fma.rn.f32 	%f478, %f917, %f464, %f477;
	sub.f32 	%f929, %f923, %f478;
	mul.f32 	%f479, %f915, %f468;
	fma.rn.f32 	%f480, %f912, %f466, %f479;
	fma.rn.f32 	%f481, %f917, %f472, %f480;
	sub.f32 	%f933, %f924, %f481;
	mul.f32 	%f482, %f911, %f453;
	fma.rn.f32 	%f483, %f914, %f455, %f482;
	fma.rn.f32 	%f926, %f916, %f457, %f483;
	mul.f32 	%f484, %f914, %f462;
	fma.rn.f32 	%f485, %f911, %f459, %f484;
	fma.rn.f32 	%f930, %f916, %f464, %f485;
	mul.f32 	%f486, %f914, %f468;
	fma.rn.f32 	%f487, %f911, %f466, %f486;
	fma.rn.f32 	%f934, %f916, %f472, %f487;
	mul.f32 	%f488, %f910, %f453;
	fma.rn.f32 	%f927, %f913, %f455, %f488;
	mul.f32 	%f489, %f913, %f462;
	fma.rn.f32 	%f931, %f910, %f459, %f489;
	mul.f32 	%f490, %f913, %f468;
	fma.rn.f32 	%f935, %f910, %f466, %f490;
	mul.f32 	%f928, %f909, %f453;
	mul.f32 	%f932, %f909, %f459;
	mul.f32 	%f936, %f909, %f466;

$L__BB9_15:
	mul.f32 	%f528, %f930, %f935;
	mul.f32 	%f529, %f931, %f934;
	sub.f32 	%f530, %f529, %f528;
	mul.f32 	%f531, %f928, %f530;
	mul.f32 	%f532, %f930, %f936;
	mul.f32 	%f533, %f932, %f934;
	sub.f32 	%f534, %f533, %f532;
	mul.f32 	%f535, %f927, %f534;
	sub.f32 	%f536, %f531, %f535;
	mul.f32 	%f537, %f931, %f936;
	mul.f32 	%f538, %f932, %f935;
	sub.f32 	%f539, %f538, %f537;
	fma.rn.f32 	%f540, %f926, %f539, %f536;
	rcp.rn.f32 	%f541, %f540;
	mul.f32 	%f940, %f530, %f541;
	mul.f32 	%f542, %f927, %f934;
	mul.f32 	%f543, %f926, %f935;
	sub.f32 	%f544, %f543, %f542;
	mul.f32 	%f939, %f544, %f541;
	mul.f32 	%f545, %f926, %f931;
	mul.f32 	%f546, %f927, %f930;
	sub.f32 	%f547, %f546, %f545;
	mul.f32 	%f938, %f547, %f541;
	sub.f32 	%f548, %f532, %f533;
	mul.f32 	%f944, %f548, %f541;
	mul.f32 	%f549, %f926, %f936;
	mul.f32 	%f550, %f928, %f934;
	sub.f32 	%f551, %f550, %f549;
	mul.f32 	%f943, %f551, %f541;
	mul.f32 	%f552, %f928, %f930;
	mul.f32 	%f553, %f926, %f932;
	sub.f32 	%f554, %f553, %f552;
	mul.f32 	%f942, %f554, %f541;
	mul.f32 	%f948, %f539, %f541;
	mul.f32 	%f555, %f928, %f935;
	mul.f32 	%f556, %f927, %f936;
	sub.f32 	%f557, %f556, %f555;
	mul.f32 	%f947, %f557, %f541;
	mul.f32 	%f558, %f927, %f932;
	mul.f32 	%f559, %f928, %f931;
	sub.f32 	%f560, %f559, %f558;
	mul.f32 	%f946, %f560, %f541;
	mul.f32 	%f561, %f925, %f940;
	neg.f32 	%f562, %f561;
	mul.f32 	%f563, %f929, %f939;
	sub.f32 	%f564, %f562, %f563;
	mul.f32 	%f565, %f933, %f938;
	sub.f32 	%f937, %f564, %f565;
	mul.f32 	%f566, %f925, %f944;
	neg.f32 	%f567, %f566;
	mul.f32 	%f568, %f929, %f943;
	sub.f32 	%f569, %f567, %f568;
	mul.f32 	%f570, %f933, %f942;
	sub.f32 	%f941, %f569, %f570;
	mul.f32 	%f571, %f925, %f948;
	neg.f32 	%f572, %f571;
	mul.f32 	%f573, %f929, %f947;
	sub.f32 	%f574, %f572, %f573;
	mul.f32 	%f575, %f933, %f946;
	sub.f32 	%f945, %f574, %f575;
	bra.uni 	$L__BB9_16;

$L__BB9_7:
	// begin inline asm
	call (%rd257), _optix_get_instance_inverse_transform_from_handle, (%rd18);
	// end inline asm

$L__BB9_8:
	// begin inline asm
	cvta.to.global.u64 %rd24, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r15,%r16,%r17,%r18}, [%rd24];
	// end inline asm
	mov.b32 	%f940, %r15;
	mov.b32 	%f939, %r16;
	mov.b32 	%f938, %r17;
	mov.b32 	%f937, %r18;
	add.s64 	%rd28, %rd257, 16;
	// begin inline asm
	cvta.to.global.u64 %rd27, %rd28;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r19,%r20,%r21,%r22}, [%rd27];
	// end inline asm
	mov.b32 	%f944, %r19;
	mov.b32 	%f943, %r20;
	mov.b32 	%f942, %r21;
	mov.b32 	%f941, %r22;
	add.s64 	%rd31, %rd257, 32;
	// begin inline asm
	cvta.to.global.u64 %rd30, %rd31;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r23,%r24,%r25,%r26}, [%rd30];
	// end inline asm
	mov.b32 	%f948, %r23;
	mov.b32 	%f947, %r24;
	mov.b32 	%f946, %r25;
	mov.b32 	%f945, %r26;

$L__BB9_16:
	setp.eq.s32 	%p13, %r321, 0;
	@%p13 bra 	$L__BB9_18;

	mul.f32 	%f576, %f905, %f940;
	fma.rn.f32 	%f577, %f901, %f939, %f576;
	fma.rn.f32 	%f151, %f897, %f938, %f577;
	mul.f32 	%f578, %f906, %f940;
	fma.rn.f32 	%f579, %f902, %f939, %f578;
	fma.rn.f32 	%f152, %f898, %f938, %f579;
	mul.f32 	%f580, %f907, %f940;
	fma.rn.f32 	%f581, %f903, %f939, %f580;
	fma.rn.f32 	%f153, %f899, %f938, %f581;
	mul.f32 	%f582, %f908, %f940;
	fma.rn.f32 	%f583, %f904, %f939, %f582;
	fma.rn.f32 	%f584, %f900, %f938, %f583;
	add.f32 	%f937, %f937, %f584;
	mul.f32 	%f585, %f905, %f944;
	fma.rn.f32 	%f586, %f901, %f943, %f585;
	fma.rn.f32 	%f155, %f897, %f942, %f586;
	mul.f32 	%f587, %f906, %f944;
	fma.rn.f32 	%f588, %f902, %f943, %f587;
	fma.rn.f32 	%f156, %f898, %f942, %f588;
	mul.f32 	%f589, %f907, %f944;
	fma.rn.f32 	%f590, %f903, %f943, %f589;
	fma.rn.f32 	%f157, %f899, %f942, %f590;
	mul.f32 	%f591, %f908, %f944;
	fma.rn.f32 	%f592, %f904, %f943, %f591;
	fma.rn.f32 	%f593, %f900, %f942, %f592;
	add.f32 	%f941, %f941, %f593;
	mul.f32 	%f594, %f905, %f948;
	fma.rn.f32 	%f595, %f901, %f947, %f594;
	fma.rn.f32 	%f159, %f897, %f946, %f595;
	mul.f32 	%f596, %f906, %f948;
	fma.rn.f32 	%f597, %f902, %f947, %f596;
	fma.rn.f32 	%f160, %f898, %f946, %f597;
	mul.f32 	%f598, %f907, %f948;
	fma.rn.f32 	%f599, %f903, %f947, %f598;
	fma.rn.f32 	%f161, %f899, %f946, %f599;
	mul.f32 	%f600, %f908, %f948;
	fma.rn.f32 	%f601, %f904, %f947, %f600;
	fma.rn.f32 	%f602, %f900, %f946, %f601;
	add.f32 	%f945, %f945, %f602;
	mov.f32 	%f938, %f153;
	mov.f32 	%f939, %f152;
	mov.f32 	%f940, %f151;
	mov.f32 	%f942, %f157;
	mov.f32 	%f943, %f156;
	mov.f32 	%f944, %f155;
	mov.f32 	%f946, %f161;
	mov.f32 	%f947, %f160;
	mov.f32 	%f948, %f159;

$L__BB9_18:
	add.s32 	%r321, %r321, 1;
	setp.lt.u32 	%p14, %r321, %r10;
	mov.f32 	%f897, %f948;
	mov.f32 	%f898, %f947;
	mov.f32 	%f899, %f946;
	mov.f32 	%f900, %f945;
	mov.f32 	%f901, %f944;
	mov.f32 	%f902, %f943;
	mov.f32 	%f903, %f942;
	mov.f32 	%f904, %f941;
	mov.f32 	%f905, %f940;
	mov.f32 	%f906, %f939;
	mov.f32 	%f907, %f938;
	mov.f32 	%f908, %f937;
	@%p14 bra 	$L__BB9_3;

$L__BB9_19:
	mul.f32 	%f603, %f973, %f940;
	fma.rn.f32 	%f604, %f974, %f939, %f603;
	fma.rn.f32 	%f605, %f975, %f938, %f604;
	mul.f32 	%f606, %f973, %f944;
	fma.rn.f32 	%f607, %f974, %f943, %f606;
	fma.rn.f32 	%f608, %f975, %f942, %f607;
	mul.f32 	%f609, %f973, %f948;
	fma.rn.f32 	%f610, %f974, %f947, %f609;
	fma.rn.f32 	%f611, %f975, %f946, %f610;
	add.f32 	%f975, %f945, %f611;
	add.f32 	%f974, %f941, %f608;
	add.f32 	%f973, %f937, %f605;

$L__BB9_21:
	// begin inline asm
	call (%f1031), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1032), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f614), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r161), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p15, %r161, 0;
	@%p15 bra 	$L__BB9_41;

	// begin inline asm
	call (%r162), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f615), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p16, %r162, 0;
	@%p16 bra 	$L__BB9_40;

	mov.u32 	%r322, 0;

$L__BB9_24:
	.pragma "nounroll";
	// begin inline asm
	call (%rd137), _optix_get_transform_list_handle, (%r322);
	// end inline asm
	// begin inline asm
	call (%r165), _optix_get_transform_type_from_handle, (%rd137);
	// end inline asm
	or.b32  	%r166, %r165, 1;
	setp.eq.s32 	%p17, %r166, 3;
	@%p17 bra 	$L__BB9_30;
	bra.uni 	$L__BB9_25;

$L__BB9_30:
	setp.eq.s32 	%p20, %r165, 2;
	@%p20 bra 	$L__BB9_34;
	bra.uni 	$L__BB9_31;

$L__BB9_34:
	// begin inline asm
	call (%rd209), _optix_get_matrix_motion_transform_from_handle, (%rd137);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd211];
	// end inline asm
	add.s64 	%rd215, %rd209, 16;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r258,%r259,%r260,%r261}, [%rd214];
	// end inline asm
	add.s64 	%rd218, %rd209, 32;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r262,%r263,%r264,%r265}, [%rd217];
	// end inline asm
	add.s64 	%rd221, %rd209, 48;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r266,%r267,%r268,%r269}, [%rd220];
	// end inline asm
	add.s64 	%rd224, %rd209, 64;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r270,%r271,%r272,%r273}, [%rd223];
	// end inline asm
	add.s64 	%rd227, %rd209, 80;
	// begin inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r274,%r275,%r276,%r277}, [%rd226];
	// end inline asm
	add.s64 	%rd230, %rd209, 96;
	// begin inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r278,%r279,%r280,%r281}, [%rd229];
	// end inline asm
	add.s64 	%rd233, %rd209, 112;
	// begin inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r282,%r283,%r284,%r285}, [%rd232];
	// end inline asm
	mov.b32 	%f719, %r257;
	mov.b32 	%f720, %r258;
	and.b32  	%r298, %r256, 65535;
	add.s32 	%r299, %r298, -1;
	cvt.rn.f32.s32 	%f721, %r299;
	sub.f32 	%f722, %f615, %f719;
	mul.f32 	%f723, %f722, %f721;
	sub.f32 	%f724, %f720, %f719;
	div.rn.f32 	%f725, %f723, %f724;
	min.f32 	%f726, %f721, %f725;
	mov.f32 	%f727, 0f00000000;
	max.f32 	%f728, %f727, %f726;
	cvt.rmi.f32.f32 	%f729, %f728;
	sub.f32 	%f261, %f728, %f729;
	cvt.rzi.s32.f32 	%r300, %f729;
	cvt.s64.s32 	%rd15, %r300;
	mul.wide.s32 	%rd244, %r300, 48;
	add.s64 	%rd236, %rd218, %rd244;
	// begin inline asm
	cvta.to.global.u64 %rd235, %rd236;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r286,%r287,%r288,%r289}, [%rd235];
	// end inline asm
	mov.b32 	%f1001, %r286;
	mov.b32 	%f1002, %r287;
	mov.b32 	%f1003, %r288;
	add.s64 	%rd239, %rd236, 16;
	// begin inline asm
	cvta.to.global.u64 %rd238, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r290,%r291,%r292,%r293}, [%rd238];
	// end inline asm
	mov.b32 	%f998, %r290;
	mov.b32 	%f999, %r291;
	mov.b32 	%f1000, %r292;
	add.s64 	%rd242, %rd236, 32;
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd242;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r294,%r295,%r296,%r297}, [%rd241];
	// end inline asm
	mov.b32 	%f995, %r294;
	mov.b32 	%f996, %r295;
	mov.b32 	%f997, %r296;
	setp.leu.f32 	%p22, %f261, 0f00000000;
	@%p22 bra 	$L__BB9_36;

	mov.f32 	%f730, 0f3F800000;
	sub.f32 	%f731, %f730, %f261;
	mul.lo.s64 	%rd254, %rd15, 48;
	add.s64 	%rd255, %rd209, %rd254;
	add.s64 	%rd246, %rd255, 80;
	// begin inline asm
	cvta.to.global.u64 %rd245, %rd246;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd245];
	// end inline asm
	mov.b32 	%f732, %r301;
	mov.b32 	%f733, %r302;
	mov.b32 	%f734, %r303;
	mul.f32 	%f735, %f261, %f732;
	mul.f32 	%f736, %f261, %f733;
	mul.f32 	%f737, %f261, %f734;
	fma.rn.f32 	%f1001, %f731, %f1001, %f735;
	fma.rn.f32 	%f1002, %f731, %f1002, %f736;
	fma.rn.f32 	%f1003, %f731, %f1003, %f737;
	add.s64 	%rd249, %rd255, 96;
	// begin inline asm
	cvta.to.global.u64 %rd248, %rd249;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd248];
	// end inline asm
	mov.b32 	%f738, %r305;
	mov.b32 	%f739, %r306;
	mov.b32 	%f740, %r307;
	mul.f32 	%f741, %f261, %f738;
	mul.f32 	%f742, %f261, %f739;
	mul.f32 	%f743, %f261, %f740;
	fma.rn.f32 	%f998, %f731, %f998, %f741;
	fma.rn.f32 	%f999, %f731, %f999, %f742;
	fma.rn.f32 	%f1000, %f731, %f1000, %f743;
	add.s64 	%rd252, %rd255, 112;
	// begin inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r309,%r310,%r311,%r312}, [%rd251];
	// end inline asm
	mov.b32 	%f744, %r309;
	mov.b32 	%f745, %r310;
	mov.b32 	%f746, %r311;
	mul.f32 	%f747, %f261, %f744;
	mul.f32 	%f748, %f261, %f745;
	mul.f32 	%f749, %f261, %f746;
	fma.rn.f32 	%f995, %f731, %f995, %f747;
	fma.rn.f32 	%f996, %f731, %f996, %f748;
	fma.rn.f32 	%f997, %f731, %f997, %f749;
	bra.uni 	$L__BB9_36;

$L__BB9_25:
	mov.f32 	%f1004, 0f00000000;
	mov.f32 	%f1006, 0f3F800000;
	setp.eq.s32 	%p18, %r165, 4;
	@%p18 bra 	$L__BB9_28;

	setp.ne.s32 	%p19, %r165, 1;
	mov.f32 	%f1005, %f1004;
	mov.f32 	%f1007, %f1004;
	mov.f32 	%f1008, %f1006;
	mov.f32 	%f1009, %f1004;
	mov.f32 	%f1010, %f1006;
	mov.f32 	%f1011, %f1004;
	mov.f32 	%f1012, %f1004;
	@%p19 bra 	$L__BB9_37;

	// begin inline asm
	call (%rd139), _optix_get_static_transform_from_handle, (%rd137);
	// end inline asm
	add.s64 	%rd258, %rd139, 64;
	bra.uni 	$L__BB9_29;

$L__BB9_31:
	// begin inline asm
	call (%rd152), _optix_get_srt_motion_transform_from_handle, (%rd137);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd154, %rd152;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r179,%r180,%r181,%r182}, [%rd154];
	// end inline asm
	add.s64 	%rd158, %rd152, 16;
	// begin inline asm
	cvta.to.global.u64 %rd157, %rd158;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r183,%r184,%r185,%r186}, [%rd157];
	// end inline asm
	add.s64 	%rd161, %rd152, 32;
	// begin inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r187,%r188,%r189,%r190}, [%rd160];
	// end inline asm
	add.s64 	%rd164, %rd152, 48;
	// begin inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r191,%r192,%r193,%r194}, [%rd163];
	// end inline asm
	add.s64 	%rd167, %rd152, 64;
	// begin inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r195,%r196,%r197,%r198}, [%rd166];
	// end inline asm
	add.s64 	%rd170, %rd152, 80;
	// begin inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r199,%r200,%r201,%r202}, [%rd169];
	// end inline asm
	add.s64 	%rd173, %rd152, 96;
	// begin inline asm
	cvta.to.global.u64 %rd172, %rd173;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r203,%r204,%r205,%r206}, [%rd172];
	// end inline asm
	add.s64 	%rd176, %rd152, 112;
	// begin inline asm
	cvta.to.global.u64 %rd175, %rd176;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r207,%r208,%r209,%r210}, [%rd175];
	// end inline asm
	add.s64 	%rd179, %rd152, 128;
	// begin inline asm
	cvta.to.global.u64 %rd178, %rd179;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r211,%r212,%r213,%r214}, [%rd178];
	// end inline asm
	add.s64 	%rd182, %rd152, 144;
	// begin inline asm
	cvta.to.global.u64 %rd181, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r215,%r216,%r217,%r218}, [%rd181];
	// end inline asm
	mov.b32 	%f627, %r182;
	mov.b32 	%f628, %r183;
	and.b32  	%r235, %r181, 65535;
	add.s32 	%r236, %r235, -1;
	cvt.rn.f32.s32 	%f629, %r236;
	sub.f32 	%f630, %f615, %f627;
	mul.f32 	%f631, %f630, %f629;
	sub.f32 	%f632, %f628, %f627;
	div.rn.f32 	%f633, %f631, %f632;
	min.f32 	%f634, %f629, %f633;
	mov.f32 	%f635, 0f00000000;
	max.f32 	%f636, %f635, %f634;
	cvt.rmi.f32.f32 	%f637, %f636;
	sub.f32 	%f221, %f636, %f637;
	cvt.rzi.s32.f32 	%r237, %f637;
	mul.wide.s32 	%rd196, %r237, 64;
	add.s64 	%rd185, %rd161, %rd196;
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd185;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r219,%r220,%r221,%r222}, [%rd184];
	// end inline asm
	mov.b32 	%f985, %r219;
	mov.b32 	%f986, %r220;
	mov.b32 	%f987, %r221;
	add.s64 	%rd188, %rd185, 16;
	// begin inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r223,%r224,%r225,%r226}, [%rd187];
	// end inline asm
	mov.b32 	%f988, %r223;
	mov.b32 	%f989, %r224;
	mov.b32 	%f990, %r226;
	add.s64 	%rd191, %rd185, 32;
	// begin inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r227,%r228,%r229,%r230}, [%rd190];
	// end inline asm
	mov.b32 	%f991, %r228;
	mov.b32 	%f992, %r229;
	mov.b32 	%f993, %r230;
	add.s64 	%rd194, %rd185, 48;
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r231,%r232,%r233,%r234}, [%rd193];
	// end inline asm
	mov.b32 	%f994, %r231;
	setp.leu.f32 	%p21, %f221, 0f00000000;
	@%p21 bra 	$L__BB9_33;

	mov.f32 	%f638, 0f3F800000;
	sub.f32 	%f639, %f638, %f221;
	add.s64 	%rd198, %rd185, 64;
	// begin inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd197];
	// end inline asm
	mov.b32 	%f640, %r238;
	mov.b32 	%f641, %r239;
	mov.b32 	%f642, %r240;
	mul.f32 	%f643, %f221, %f640;
	mul.f32 	%f644, %f221, %f641;
	mul.f32 	%f645, %f221, %f642;
	fma.rn.f32 	%f985, %f639, %f985, %f643;
	fma.rn.f32 	%f986, %f639, %f986, %f644;
	fma.rn.f32 	%f987, %f639, %f987, %f645;
	add.s64 	%rd201, %rd185, 80;
	// begin inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd200];
	// end inline asm
	mov.b32 	%f646, %r242;
	mov.b32 	%f647, %r243;
	mov.b32 	%f648, %r245;
	mul.f32 	%f649, %f221, %f646;
	mul.f32 	%f650, %f221, %f647;
	mul.f32 	%f651, %f221, %f648;
	fma.rn.f32 	%f988, %f639, %f988, %f649;
	fma.rn.f32 	%f989, %f639, %f989, %f650;
	fma.rn.f32 	%f990, %f639, %f990, %f651;
	add.s64 	%rd204, %rd185, 96;
	// begin inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd203];
	// end inline asm
	mov.b32 	%f652, %r247;
	mov.b32 	%f653, %r248;
	mov.b32 	%f654, %r249;
	mul.f32 	%f655, %f221, %f652;
	mul.f32 	%f656, %f221, %f653;
	mul.f32 	%f657, %f221, %f654;
	fma.rn.f32 	%f658, %f639, %f991, %f655;
	fma.rn.f32 	%f659, %f639, %f992, %f656;
	fma.rn.f32 	%f660, %f639, %f993, %f657;
	add.s64 	%rd207, %rd185, 112;
	// begin inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd206];
	// end inline asm
	mov.b32 	%f661, %r250;
	mul.f32 	%f662, %f221, %f661;
	fma.rn.f32 	%f663, %f639, %f994, %f662;
	mul.f32 	%f664, %f659, %f659;
	fma.rn.f32 	%f665, %f658, %f658, %f664;
	fma.rn.f32 	%f666, %f660, %f660, %f665;
	fma.rn.f32 	%f667, %f663, %f663, %f666;
	sqrt.rn.f32 	%f668, %f667;
	rcp.rn.f32 	%f669, %f668;
	mul.f32 	%f991, %f658, %f669;
	mul.f32 	%f992, %f659, %f669;
	mul.f32 	%f993, %f660, %f669;
	mul.f32 	%f994, %f669, %f663;

$L__BB9_33:
	mul.f32 	%f670, %f992, %f992;
	fma.rn.f32 	%f671, %f991, %f991, %f670;
	fma.rn.f32 	%f672, %f993, %f993, %f671;
	fma.rn.f32 	%f673, %f994, %f994, %f672;
	rcp.rn.f32 	%f674, %f673;
	mul.f32 	%f675, %f991, %f674;
	mul.f32 	%f676, %f992, %f674;
	mul.f32 	%f677, %f993, %f674;
	mul.f32 	%f678, %f994, %f674;
	mul.f32 	%f679, %f991, %f675;
	mul.f32 	%f680, %f992, %f676;
	mul.f32 	%f681, %f993, %f677;
	mul.f32 	%f682, %f991, %f676;
	mul.f32 	%f683, %f993, %f678;
	mul.f32 	%f684, %f991, %f677;
	mul.f32 	%f685, %f992, %f678;
	mul.f32 	%f686, %f992, %f677;
	mul.f32 	%f687, %f991, %f678;
	sub.f32 	%f688, %f679, %f680;
	sub.f32 	%f689, %f688, %f681;
	fma.rn.f32 	%f690, %f994, %f678, %f689;
	sub.f32 	%f691, %f682, %f683;
	add.f32 	%f692, %f691, %f691;
	add.f32 	%f693, %f684, %f685;
	add.f32 	%f694, %f693, %f693;
	add.f32 	%f695, %f682, %f683;
	add.f32 	%f696, %f695, %f695;
	sub.f32 	%f697, %f680, %f679;
	sub.f32 	%f698, %f697, %f681;
	fma.rn.f32 	%f699, %f994, %f678, %f698;
	sub.f32 	%f700, %f686, %f687;
	add.f32 	%f701, %f700, %f700;
	sub.f32 	%f702, %f684, %f685;
	add.f32 	%f703, %f702, %f702;
	add.f32 	%f704, %f686, %f687;
	add.f32 	%f705, %f704, %f704;
	neg.f32 	%f706, %f679;
	sub.f32 	%f707, %f706, %f680;
	add.f32 	%f708, %f681, %f707;
	fma.rn.f32 	%f709, %f994, %f678, %f708;
	mul.f32 	%f710, %f987, %f690;
	fma.rn.f32 	%f711, %f989, %f692, %f710;
	fma.rn.f32 	%f1003, %f990, %f694, %f711;
	mul.f32 	%f712, %f989, %f699;
	fma.rn.f32 	%f713, %f987, %f696, %f712;
	fma.rn.f32 	%f1000, %f990, %f701, %f713;
	mul.f32 	%f714, %f989, %f705;
	fma.rn.f32 	%f715, %f987, %f703, %f714;
	fma.rn.f32 	%f997, %f990, %f709, %f715;
	mul.f32 	%f716, %f986, %f690;
	fma.rn.f32 	%f1002, %f988, %f692, %f716;
	mul.f32 	%f717, %f988, %f699;
	fma.rn.f32 	%f999, %f986, %f696, %f717;
	mul.f32 	%f718, %f988, %f705;
	fma.rn.f32 	%f996, %f986, %f703, %f718;
	mul.f32 	%f1001, %f985, %f690;
	mul.f32 	%f998, %f985, %f696;
	mul.f32 	%f995, %f985, %f703;

$L__BB9_36:
	mul.f32 	%f750, %f996, %f1000;
	mul.f32 	%f751, %f997, %f999;
	sub.f32 	%f752, %f751, %f750;
	mul.f32 	%f753, %f1001, %f752;
	mul.f32 	%f754, %f995, %f1000;
	mul.f32 	%f755, %f997, %f998;
	sub.f32 	%f756, %f755, %f754;
	mul.f32 	%f757, %f756, %f1002;
	sub.f32 	%f758, %f753, %f757;
	mul.f32 	%f759, %f995, %f999;
	mul.f32 	%f760, %f996, %f998;
	sub.f32 	%f761, %f760, %f759;
	fma.rn.f32 	%f762, %f761, %f1003, %f758;
	rcp.rn.f32 	%f763, %f762;
	mul.f32 	%f1010, %f752, %f763;
	mul.f32 	%f764, %f997, %f1002;
	mul.f32 	%f765, %f996, %f1003;
	sub.f32 	%f766, %f765, %f764;
	mul.f32 	%f1011, %f766, %f763;
	mul.f32 	%f767, %f999, %f1003;
	mul.f32 	%f768, %f1000, %f1002;
	sub.f32 	%f769, %f768, %f767;
	mul.f32 	%f1012, %f769, %f763;
	sub.f32 	%f770, %f754, %f755;
	mul.f32 	%f1007, %f770, %f763;
	mul.f32 	%f771, %f995, %f1003;
	mul.f32 	%f772, %f997, %f1001;
	sub.f32 	%f773, %f772, %f771;
	mul.f32 	%f1008, %f773, %f763;
	mul.f32 	%f774, %f1000, %f1001;
	mul.f32 	%f775, %f998, %f1003;
	sub.f32 	%f776, %f775, %f774;
	mul.f32 	%f1009, %f776, %f763;
	mul.f32 	%f1004, %f761, %f763;
	mul.f32 	%f777, %f996, %f1001;
	mul.f32 	%f778, %f995, %f1002;
	sub.f32 	%f779, %f778, %f777;
	mul.f32 	%f1005, %f779, %f763;
	mul.f32 	%f780, %f998, %f1002;
	mul.f32 	%f781, %f999, %f1001;
	sub.f32 	%f782, %f781, %f780;
	mul.f32 	%f1006, %f782, %f763;
	bra.uni 	$L__BB9_37;

$L__BB9_28:
	// begin inline asm
	call (%rd258), _optix_get_instance_inverse_transform_from_handle, (%rd137);
	// end inline asm

$L__BB9_29:
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd258;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r167,%r168,%r169,%r170}, [%rd143];
	// end inline asm
	mov.b32 	%f1010, %r167;
	mov.b32 	%f1011, %r168;
	mov.b32 	%f1012, %r169;
	add.s64 	%rd147, %rd258, 16;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r171,%r172,%r173,%r174}, [%rd146];
	// end inline asm
	mov.b32 	%f1007, %r171;
	mov.b32 	%f1008, %r172;
	mov.b32 	%f1009, %r173;
	add.s64 	%rd150, %rd258, 32;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r175,%r176,%r177,%r178}, [%rd149];
	// end inline asm
	mov.b32 	%f1004, %r175;
	mov.b32 	%f1005, %r176;
	mov.b32 	%f1006, %r177;

$L__BB9_37:
	setp.eq.s32 	%p23, %r322, 0;
	@%p23 bra 	$L__BB9_39;

	mul.f32 	%f783, %f981, %f1011;
	fma.rn.f32 	%f784, %f978, %f1010, %f783;
	fma.rn.f32 	%f307, %f984, %f1012, %f784;
	mul.f32 	%f785, %f980, %f1011;
	fma.rn.f32 	%f786, %f977, %f1010, %f785;
	fma.rn.f32 	%f308, %f983, %f1012, %f786;
	mul.f32 	%f787, %f979, %f1011;
	fma.rn.f32 	%f788, %f976, %f1010, %f787;
	fma.rn.f32 	%f1012, %f982, %f1012, %f788;
	mul.f32 	%f789, %f981, %f1008;
	fma.rn.f32 	%f790, %f978, %f1007, %f789;
	fma.rn.f32 	%f310, %f984, %f1009, %f790;
	mul.f32 	%f791, %f980, %f1008;
	fma.rn.f32 	%f792, %f977, %f1007, %f791;
	fma.rn.f32 	%f311, %f983, %f1009, %f792;
	mul.f32 	%f793, %f979, %f1008;
	fma.rn.f32 	%f794, %f976, %f1007, %f793;
	fma.rn.f32 	%f1009, %f982, %f1009, %f794;
	mul.f32 	%f795, %f981, %f1005;
	fma.rn.f32 	%f796, %f978, %f1004, %f795;
	fma.rn.f32 	%f313, %f984, %f1006, %f796;
	mul.f32 	%f797, %f980, %f1005;
	fma.rn.f32 	%f798, %f977, %f1004, %f797;
	fma.rn.f32 	%f314, %f983, %f1006, %f798;
	mul.f32 	%f799, %f979, %f1005;
	fma.rn.f32 	%f800, %f976, %f1004, %f799;
	fma.rn.f32 	%f1006, %f982, %f1006, %f800;
	mov.f32 	%f1004, %f313;
	mov.f32 	%f1005, %f314;
	mov.f32 	%f1007, %f310;
	mov.f32 	%f1008, %f311;
	mov.f32 	%f1010, %f307;
	mov.f32 	%f1011, %f308;

$L__BB9_39:
	add.s32 	%r322, %r322, 1;
	setp.lt.u32 	%p24, %r322, %r162;
	mov.f32 	%f976, %f1012;
	mov.f32 	%f977, %f1011;
	mov.f32 	%f978, %f1010;
	mov.f32 	%f979, %f1009;
	mov.f32 	%f980, %f1008;
	mov.f32 	%f981, %f1007;
	mov.f32 	%f982, %f1006;
	mov.f32 	%f983, %f1005;
	mov.f32 	%f984, %f1004;
	@%p24 bra 	$L__BB9_24;

$L__BB9_40:
	mul.f32 	%f801, %f1032, %f1011;
	fma.rn.f32 	%f802, %f1031, %f1010, %f801;
	mul.f32 	%f803, %f1032, %f1008;
	fma.rn.f32 	%f804, %f1031, %f1007, %f803;
	mul.f32 	%f805, %f1032, %f1005;
	fma.rn.f32 	%f806, %f1031, %f1004, %f805;
	fma.rn.f32 	%f1033, %f614, %f1006, %f806;
	fma.rn.f32 	%f1032, %f614, %f1009, %f804;
	fma.rn.f32 	%f1031, %f614, %f1012, %f802;
	bra.uni 	$L__BB9_42;

$L__BB9_41:
	mov.f32 	%f1033, %f614;

$L__BB9_42:
	// begin inline asm
	call (%f807), _optix_get_ray_tmin, ();
	// end inline asm
	// begin inline asm
	call (%f808), _optix_get_ray_tmax, ();
	// end inline asm
	add.s64 	%rd16, %rd1, 288;
	ld.v4.f32 	{%f811, %f812, %f813, %f814}, [%rd1+288];
	ld.v2.f32 	{%f815, %f816}, [%rd1+304];
	add.f32 	%f819, %f815, 0f3F800000;
	mul.f32 	%f820, %f1033, %f1033;
	mul.f32 	%f821, %f819, %f820;
	fma.rn.f32 	%f822, %f1031, %f1031, %f821;
	fma.rn.f32 	%f351, %f1032, %f1032, %f822;
	add.f32 	%f823, %f819, %f819;
	mul.f32 	%f824, %f823, %f975;
	mul.f32 	%f825, %f1033, %f824;
	mul.f32 	%f826, %f819, 0fC0000000;
	mul.f32 	%f827, %f813, %f826;
	fma.rn.f32 	%f828, %f1033, %f827, %f825;
	add.f32 	%f829, %f973, %f973;
	fma.rn.f32 	%f830, %f1031, %f829, %f828;
	add.f32 	%f831, %f811, %f811;
	mul.f32 	%f832, %f831, %f1031;
	sub.f32 	%f833, %f830, %f832;
	add.f32 	%f834, %f974, %f974;
	fma.rn.f32 	%f835, %f1032, %f834, %f833;
	add.f32 	%f836, %f812, %f812;
	mul.f32 	%f837, %f836, %f1032;
	sub.f32 	%f838, %f835, %f837;
	add.f32 	%f839, %f1033, %f1033;
	div.rn.f32 	%f840, %f839, %f816;
	sub.f32 	%f352, %f838, %f840;
	mul.f32 	%f841, %f975, %f975;
	mul.f32 	%f842, %f819, %f841;
	fma.rn.f32 	%f843, %f827, %f975, %f842;
	mul.f32 	%f844, %f813, %f813;
	fma.rn.f32 	%f845, %f844, %f819, %f843;
	fma.rn.f32 	%f846, %f973, %f973, %f845;
	mul.f32 	%f847, %f831, %f973;
	sub.f32 	%f848, %f846, %f847;
	fma.rn.f32 	%f849, %f811, %f811, %f848;
	fma.rn.f32 	%f850, %f974, %f974, %f849;
	mul.f32 	%f851, %f836, %f974;
	sub.f32 	%f852, %f850, %f851;
	fma.rn.f32 	%f853, %f812, %f812, %f852;
	add.f32 	%f854, %f975, %f975;
	div.rn.f32 	%f855, %f854, %f816;
	sub.f32 	%f856, %f853, %f855;
	mul.f32 	%f857, %f813, 0fC0000000;
	div.rn.f32 	%f858, %f857, %f816;
	sub.f32 	%f353, %f856, %f858;
	setp.eq.f32 	%p26, %f351, 0f00000000;
	setp.eq.f32 	%p27, %f352, 0f00000000;
	and.pred  	%p28, %p26, %p27;
	mov.pred 	%p45, -1;
	@%p28 bra 	$L__BB9_45;

	neg.f32 	%f859, %f353;
	div.rn.f32 	%f1034, %f859, %f352;
	mul.f32 	%f860, %f351, 0fC0800000;
	mul.f32 	%f861, %f860, %f353;
	fma.rn.f32 	%f355, %f352, %f352, %f861;
	setp.neu.f32 	%p30, %f351, 0f00000000;
	setp.lt.f32 	%p31, %f355, 0f00000000;
	and.pred  	%p32, %p31, %p30;
	mov.f32 	%f1035, %f1034;
	@%p32 bra 	$L__BB9_45;

	mov.b32 	%r313, %f352;
	and.b32  	%r314, %r313, -2147483648;
	sqrt.rn.f32 	%f862, %f355;
	mov.b32 	%r315, %f862;
	and.b32  	%r316, %r315, 2147483647;
	or.b32  	%r317, %r316, %r314;
	mov.b32 	%f863, %r317;
	add.f32 	%f864, %f352, %f863;
	mul.f32 	%f865, %f864, 0fBF000000;
	div.rn.f32 	%f866, %f865, %f351;
	div.rn.f32 	%f867, %f353, %f865;
	min.f32 	%f868, %f866, %f867;
	max.f32 	%f869, %f866, %f867;
	selp.f32 	%f356, %f1034, %f868, %p26;
	selp.f32 	%f1035, %f1034, %f869, %p26;
	mov.pred 	%p45, 0;
	mov.f32 	%f1034, %f356;

$L__BB9_45:
	@%p45 bra 	$L__BB9_50;

	fma.rn.f32 	%f870, %f1034, %f1031, %f973;
	sub.f32 	%f871, %f870, %f811;
	fma.rn.f32 	%f872, %f1034, %f1032, %f974;
	sub.f32 	%f873, %f872, %f812;
	fma.rn.f32 	%f874, %f1034, %f1033, %f975;
	sub.f32 	%f875, %f874, %f813;
	mul.f32 	%f876, %f873, %f873;
	fma.rn.f32 	%f877, %f871, %f871, %f876;
	fma.rn.f32 	%f878, %f875, %f875, %f877;
	sqrt.rn.f32 	%f879, %f878;
	ld.f32 	%f880, [%rd16+28];
	mul.f32 	%f881, %f880, %f880;
	ld.f32 	%f882, [%rd16+32];
	fma.rn.f32 	%f883, %f882, %f882, %f881;
	sqrt.rn.f32 	%f884, %f883;
	setp.le.f32 	%p36, %f879, %f884;
	setp.lt.f32 	%p37, %f1034, %f808;
	setp.ge.f32 	%p38, %f1034, %f807;
	and.pred  	%p39, %p38, %p37;
	and.pred  	%p2, %p39, %p36;
	fma.rn.f32 	%f885, %f1035, %f1031, %f973;
	sub.f32 	%f886, %f885, %f811;
	fma.rn.f32 	%f887, %f1035, %f1032, %f974;
	sub.f32 	%f888, %f887, %f812;
	fma.rn.f32 	%f889, %f1035, %f1033, %f975;
	sub.f32 	%f890, %f889, %f813;
	mul.f32 	%f891, %f888, %f888;
	fma.rn.f32 	%f892, %f886, %f886, %f891;
	fma.rn.f32 	%f893, %f890, %f890, %f892;
	sqrt.rn.f32 	%f894, %f893;
	setp.gtu.f32 	%p40, %f894, %f884;
	mov.pred 	%p46, 0;
	@%p40 bra 	$L__BB9_48;

	setp.ge.f32 	%p41, %f1035, %f807;
	setp.lt.f32 	%p42, %f1035, %f808;
	and.pred  	%p46, %p41, %p42;

$L__BB9_48:
	or.pred  	%p43, %p2, %p46;
	not.pred 	%p44, %p43;
	@%p44 bra 	$L__BB9_50;

	selp.f32 	%f895, %f1034, %f1035, %p2;
	mov.u32 	%r319, 254;
	// begin inline asm
	call (%r318), _optix_report_intersection_0, (%f895, %r319);
	// end inline asm

$L__BB9_50:
	ret;

}
	// .globl	__closesthit__asphsurf
.visible .entry __closesthit__asphsurf()
{
	.reg .pred 	%p<59>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<2059>;
	.reg .b32 	%r<650>;
	.reg .b64 	%rd<652>;


	// begin inline asm
	call (%r25), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r26), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r28), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r29), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r30), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r31, %r30, %r26, %r29;
	mad.lo.s32 	%r1, %r31, %r25, %r28;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64 	%p1, %rd1, 0;
	@%p1 bra 	$L__BB10_2;

	cvta.to.global.u64 	%rd44, %rd1;
	cvt.u64.u32 	%rd45, %r1;
	add.s64 	%rd46, %rd44, %rd45;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd46], %rs1;
	bra.uni 	$L__BB10_114;

$L__BB10_2:
	// begin inline asm
	call (%rd47), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd3, [%rd47+8];
	// begin inline asm
	call (%f1835), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1836), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1837), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r32), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p2, %r32, 0;
	@%p2 bra 	$L__BB10_23;

	// begin inline asm
	call (%r33), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f714), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p3, %r33, 0;
	@%p3 bra 	$L__BB10_21;

	mov.u32 	%r645, 0;

$L__BB10_5:
	.pragma "nounroll";
	// begin inline asm
	call (%rd48), _optix_get_transform_list_handle, (%r645);
	// end inline asm
	// begin inline asm
	call (%r36), _optix_get_transform_type_from_handle, (%rd48);
	// end inline asm
	or.b32  	%r37, %r36, 1;
	setp.eq.s32 	%p4, %r37, 3;
	@%p4 bra 	$L__BB10_11;
	bra.uni 	$L__BB10_6;

$L__BB10_11:
	setp.eq.s32 	%p7, %r36, 2;
	@%p7 bra 	$L__BB10_15;
	bra.uni 	$L__BB10_12;

$L__BB10_15:
	// begin inline asm
	call (%rd120), _optix_get_matrix_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r125,%r126,%r127,%r128}, [%rd122];
	// end inline asm
	add.s64 	%rd126, %rd120, 16;
	// begin inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r129,%r130,%r131,%r132}, [%rd125];
	// end inline asm
	add.s64 	%rd129, %rd120, 32;
	// begin inline asm
	cvta.to.global.u64 %rd128, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r133,%r134,%r135,%r136}, [%rd128];
	// end inline asm
	add.s64 	%rd132, %rd120, 48;
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r137,%r138,%r139,%r140}, [%rd131];
	// end inline asm
	add.s64 	%rd135, %rd120, 64;
	// begin inline asm
	cvta.to.global.u64 %rd134, %rd135;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r141,%r142,%r143,%r144}, [%rd134];
	// end inline asm
	add.s64 	%rd138, %rd120, 80;
	// begin inline asm
	cvta.to.global.u64 %rd137, %rd138;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r145,%r146,%r147,%r148}, [%rd137];
	// end inline asm
	add.s64 	%rd141, %rd120, 96;
	// begin inline asm
	cvta.to.global.u64 %rd140, %rd141;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd140];
	// end inline asm
	add.s64 	%rd144, %rd120, 112;
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd144;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd143];
	// end inline asm
	mov.b32 	%f842, %r128;
	mov.b32 	%f843, %r129;
	and.b32  	%r169, %r127, 65535;
	add.s32 	%r170, %r169, -1;
	cvt.rn.f32.s32 	%f844, %r170;
	sub.f32 	%f845, %f714, %f842;
	mul.f32 	%f846, %f845, %f844;
	sub.f32 	%f847, %f843, %f842;
	div.rn.f32 	%f848, %f846, %f847;
	min.f32 	%f849, %f844, %f848;
	mov.f32 	%f850, 0f00000000;
	max.f32 	%f851, %f850, %f849;
	cvt.rmi.f32.f32 	%f852, %f851;
	sub.f32 	%f90, %f851, %f852;
	cvt.rzi.s32.f32 	%r171, %f852;
	mul.wide.s32 	%rd155, %r171, 48;
	add.s64 	%rd147, %rd129, %rd155;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd146];
	// end inline asm
	mov.b32 	%f1790, %r157;
	mov.b32 	%f1789, %r158;
	mov.b32 	%f1788, %r159;
	mov.b32 	%f1787, %r160;
	add.s64 	%rd150, %rd147, 16;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r161,%r162,%r163,%r164}, [%rd149];
	// end inline asm
	mov.b32 	%f1794, %r161;
	mov.b32 	%f1793, %r162;
	mov.b32 	%f1792, %r163;
	mov.b32 	%f1791, %r164;
	add.s64 	%rd153, %rd147, 32;
	// begin inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r165,%r166,%r167,%r168}, [%rd152];
	// end inline asm
	mov.b32 	%f1798, %r165;
	mov.b32 	%f1797, %r166;
	mov.b32 	%f1796, %r167;
	mov.b32 	%f1795, %r168;
	setp.leu.f32 	%p9, %f90, 0f00000000;
	@%p9 bra 	$L__BB10_17;

	cvt.rmi.f32.f32 	%f1758, %f851;
	cvt.rzi.s32.f32 	%r644, %f1758;
	cvt.s64.s32 	%rd647, %r644;
	mov.f32 	%f853, 0f3F800000;
	sub.f32 	%f854, %f853, %f90;
	mul.lo.s64 	%rd165, %rd647, 48;
	add.s64 	%rd166, %rd120, %rd165;
	add.s64 	%rd157, %rd166, 80;
	// begin inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r172,%r173,%r174,%r175}, [%rd156];
	// end inline asm
	mov.b32 	%f855, %r172;
	mov.b32 	%f856, %r173;
	mov.b32 	%f857, %r174;
	mov.b32 	%f858, %r175;
	mul.f32 	%f859, %f90, %f855;
	mul.f32 	%f860, %f90, %f856;
	mul.f32 	%f861, %f90, %f857;
	mul.f32 	%f862, %f90, %f858;
	fma.rn.f32 	%f1790, %f854, %f1790, %f859;
	fma.rn.f32 	%f1789, %f854, %f1789, %f860;
	fma.rn.f32 	%f1788, %f854, %f1788, %f861;
	fma.rn.f32 	%f1787, %f854, %f1787, %f862;
	add.s64 	%rd160, %rd166, 96;
	// begin inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r176,%r177,%r178,%r179}, [%rd159];
	// end inline asm
	mov.b32 	%f863, %r176;
	mov.b32 	%f864, %r177;
	mov.b32 	%f865, %r178;
	mov.b32 	%f866, %r179;
	mul.f32 	%f867, %f90, %f863;
	mul.f32 	%f868, %f90, %f864;
	mul.f32 	%f869, %f90, %f865;
	mul.f32 	%f870, %f90, %f866;
	fma.rn.f32 	%f1794, %f854, %f1794, %f867;
	fma.rn.f32 	%f1793, %f854, %f1793, %f868;
	fma.rn.f32 	%f1792, %f854, %f1792, %f869;
	fma.rn.f32 	%f1791, %f854, %f1791, %f870;
	add.s64 	%rd163, %rd166, 112;
	// begin inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r180,%r181,%r182,%r183}, [%rd162];
	// end inline asm
	mov.b32 	%f871, %r180;
	mov.b32 	%f872, %r181;
	mov.b32 	%f873, %r182;
	mov.b32 	%f874, %r183;
	mul.f32 	%f875, %f90, %f871;
	mul.f32 	%f876, %f90, %f872;
	mul.f32 	%f877, %f90, %f873;
	mul.f32 	%f878, %f90, %f874;
	fma.rn.f32 	%f1798, %f854, %f1798, %f875;
	fma.rn.f32 	%f1797, %f854, %f1797, %f876;
	fma.rn.f32 	%f1796, %f854, %f1796, %f877;
	fma.rn.f32 	%f1795, %f854, %f1795, %f878;
	bra.uni 	$L__BB10_17;

$L__BB10_6:
	mov.f32 	%f1799, 0f00000000;
	mov.f32 	%f1802, 0f3F800000;
	setp.eq.s32 	%p5, %r36, 4;
	@%p5 bra 	$L__BB10_9;

	setp.ne.s32 	%p6, %r36, 1;
	mov.f32 	%f1800, %f1799;
	mov.f32 	%f1801, %f1799;
	mov.f32 	%f1803, %f1799;
	mov.f32 	%f1804, %f1799;
	mov.f32 	%f1805, %f1802;
	mov.f32 	%f1806, %f1799;
	mov.f32 	%f1807, %f1799;
	mov.f32 	%f1808, %f1802;
	mov.f32 	%f1809, %f1799;
	mov.f32 	%f1810, %f1799;
	@%p6 bra 	$L__BB10_18;

	// begin inline asm
	call (%rd50), _optix_get_static_transform_from_handle, (%rd48);
	// end inline asm
	add.s64 	%rd648, %rd50, 64;
	bra.uni 	$L__BB10_10;

$L__BB10_12:
	// begin inline asm
	call (%rd63), _optix_get_srt_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r50,%r51,%r52,%r53}, [%rd65];
	// end inline asm
	add.s64 	%rd69, %rd63, 16;
	// begin inline asm
	cvta.to.global.u64 %rd68, %rd69;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r54,%r55,%r56,%r57}, [%rd68];
	// end inline asm
	add.s64 	%rd72, %rd63, 32;
	// begin inline asm
	cvta.to.global.u64 %rd71, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r58,%r59,%r60,%r61}, [%rd71];
	// end inline asm
	add.s64 	%rd75, %rd63, 48;
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd75;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r62,%r63,%r64,%r65}, [%rd74];
	// end inline asm
	add.s64 	%rd78, %rd63, 64;
	// begin inline asm
	cvta.to.global.u64 %rd77, %rd78;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r66,%r67,%r68,%r69}, [%rd77];
	// end inline asm
	add.s64 	%rd81, %rd63, 80;
	// begin inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r70,%r71,%r72,%r73}, [%rd80];
	// end inline asm
	add.s64 	%rd84, %rd63, 96;
	// begin inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r74,%r75,%r76,%r77}, [%rd83];
	// end inline asm
	add.s64 	%rd87, %rd63, 112;
	// begin inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r78,%r79,%r80,%r81}, [%rd86];
	// end inline asm
	add.s64 	%rd90, %rd63, 128;
	// begin inline asm
	cvta.to.global.u64 %rd89, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r82,%r83,%r84,%r85}, [%rd89];
	// end inline asm
	add.s64 	%rd93, %rd63, 144;
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd93;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r86,%r87,%r88,%r89}, [%rd92];
	// end inline asm
	mov.b32 	%f729, %r53;
	mov.b32 	%f730, %r54;
	and.b32  	%r106, %r52, 65535;
	add.s32 	%r107, %r106, -1;
	cvt.rn.f32.s32 	%f731, %r107;
	sub.f32 	%f732, %f714, %f729;
	mul.f32 	%f733, %f732, %f731;
	sub.f32 	%f734, %f730, %f729;
	div.rn.f32 	%f735, %f733, %f734;
	min.f32 	%f736, %f731, %f735;
	mov.f32 	%f737, 0f00000000;
	max.f32 	%f738, %f737, %f736;
	cvt.rmi.f32.f32 	%f739, %f738;
	sub.f32 	%f29, %f738, %f739;
	cvt.rzi.s32.f32 	%r108, %f739;
	mul.wide.s32 	%rd107, %r108, 64;
	add.s64 	%rd96, %rd72, %rd107;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd95];
	// end inline asm
	mov.b32 	%f1771, %r90;
	mov.b32 	%f1772, %r91;
	mov.b32 	%f1773, %r92;
	mov.b32 	%f1774, %r93;
	add.s64 	%rd99, %rd96, 16;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd98];
	// end inline asm
	mov.b32 	%f1775, %r94;
	mov.b32 	%f1776, %r95;
	mov.b32 	%f1777, %r96;
	mov.b32 	%f1778, %r97;
	add.s64 	%rd102, %rd96, 32;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd101];
	// end inline asm
	mov.b32 	%f1779, %r98;
	mov.b32 	%f1780, %r99;
	mov.b32 	%f1781, %r100;
	mov.b32 	%f1782, %r101;
	add.s64 	%rd105, %rd96, 48;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd104];
	// end inline asm
	mov.b32 	%f1783, %r102;
	mov.b32 	%f1784, %r103;
	mov.b32 	%f1785, %r104;
	mov.b32 	%f1786, %r105;
	setp.leu.f32 	%p8, %f29, 0f00000000;
	@%p8 bra 	$L__BB10_14;

	mov.f32 	%f740, 0f3F800000;
	sub.f32 	%f741, %f740, %f29;
	add.s64 	%rd109, %rd96, 64;
	// begin inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r109,%r110,%r111,%r112}, [%rd108];
	// end inline asm
	mov.b32 	%f742, %r109;
	mov.b32 	%f743, %r110;
	mov.b32 	%f744, %r111;
	mov.b32 	%f745, %r112;
	mul.f32 	%f746, %f29, %f742;
	mul.f32 	%f747, %f29, %f743;
	mul.f32 	%f748, %f29, %f744;
	mul.f32 	%f749, %f29, %f745;
	fma.rn.f32 	%f1771, %f741, %f1771, %f746;
	fma.rn.f32 	%f1772, %f741, %f1772, %f747;
	fma.rn.f32 	%f1773, %f741, %f1773, %f748;
	fma.rn.f32 	%f1774, %f741, %f1774, %f749;
	add.s64 	%rd112, %rd96, 80;
	// begin inline asm
	cvta.to.global.u64 %rd111, %rd112;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r113,%r114,%r115,%r116}, [%rd111];
	// end inline asm
	mov.b32 	%f750, %r113;
	mov.b32 	%f751, %r114;
	mov.b32 	%f752, %r115;
	mov.b32 	%f753, %r116;
	mul.f32 	%f754, %f29, %f750;
	mul.f32 	%f755, %f29, %f751;
	mul.f32 	%f756, %f29, %f752;
	mul.f32 	%f757, %f29, %f753;
	fma.rn.f32 	%f1775, %f741, %f1775, %f754;
	fma.rn.f32 	%f1776, %f741, %f1776, %f755;
	fma.rn.f32 	%f1777, %f741, %f1777, %f756;
	fma.rn.f32 	%f1778, %f741, %f1778, %f757;
	add.s64 	%rd115, %rd96, 96;
	// begin inline asm
	cvta.to.global.u64 %rd114, %rd115;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r117,%r118,%r119,%r120}, [%rd114];
	// end inline asm
	mov.b32 	%f758, %r117;
	mov.b32 	%f759, %r118;
	mov.b32 	%f760, %r119;
	mov.b32 	%f761, %r120;
	mul.f32 	%f762, %f29, %f758;
	mul.f32 	%f763, %f29, %f759;
	mul.f32 	%f764, %f29, %f760;
	mul.f32 	%f765, %f29, %f761;
	fma.rn.f32 	%f1779, %f741, %f1779, %f762;
	fma.rn.f32 	%f766, %f741, %f1780, %f763;
	fma.rn.f32 	%f767, %f741, %f1781, %f764;
	fma.rn.f32 	%f768, %f741, %f1782, %f765;
	add.s64 	%rd118, %rd96, 112;
	// begin inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r121,%r122,%r123,%r124}, [%rd117];
	// end inline asm
	mov.b32 	%f769, %r121;
	mov.b32 	%f770, %r122;
	mov.b32 	%f771, %r123;
	mov.b32 	%f772, %r124;
	mul.f32 	%f773, %f29, %f769;
	mul.f32 	%f774, %f29, %f770;
	mul.f32 	%f775, %f29, %f771;
	mul.f32 	%f776, %f29, %f772;
	fma.rn.f32 	%f777, %f741, %f1783, %f773;
	fma.rn.f32 	%f1784, %f741, %f1784, %f774;
	fma.rn.f32 	%f1785, %f741, %f1785, %f775;
	fma.rn.f32 	%f1786, %f741, %f1786, %f776;
	mul.f32 	%f778, %f767, %f767;
	fma.rn.f32 	%f779, %f766, %f766, %f778;
	fma.rn.f32 	%f780, %f768, %f768, %f779;
	fma.rn.f32 	%f781, %f777, %f777, %f780;
	sqrt.rn.f32 	%f782, %f781;
	rcp.rn.f32 	%f783, %f782;
	mul.f32 	%f1780, %f766, %f783;
	mul.f32 	%f1781, %f767, %f783;
	mul.f32 	%f1782, %f768, %f783;
	mul.f32 	%f1783, %f783, %f777;

$L__BB10_14:
	mul.f32 	%f784, %f1781, %f1781;
	fma.rn.f32 	%f785, %f1780, %f1780, %f784;
	fma.rn.f32 	%f786, %f1782, %f1782, %f785;
	fma.rn.f32 	%f787, %f1783, %f1783, %f786;
	rcp.rn.f32 	%f788, %f787;
	mul.f32 	%f789, %f1780, %f788;
	mul.f32 	%f790, %f1781, %f788;
	mul.f32 	%f791, %f1782, %f788;
	mul.f32 	%f792, %f1783, %f788;
	mul.f32 	%f793, %f1780, %f789;
	mul.f32 	%f794, %f1781, %f790;
	mul.f32 	%f795, %f1782, %f791;
	mul.f32 	%f796, %f1780, %f790;
	mul.f32 	%f797, %f1782, %f792;
	mul.f32 	%f798, %f1780, %f791;
	mul.f32 	%f799, %f1781, %f792;
	mul.f32 	%f800, %f1781, %f791;
	mul.f32 	%f801, %f1780, %f792;
	sub.f32 	%f802, %f793, %f794;
	sub.f32 	%f803, %f802, %f795;
	fma.rn.f32 	%f804, %f1783, %f792, %f803;
	sub.f32 	%f805, %f796, %f797;
	add.f32 	%f806, %f805, %f805;
	add.f32 	%f807, %f798, %f799;
	add.f32 	%f808, %f807, %f807;
	add.f32 	%f809, %f796, %f797;
	add.f32 	%f810, %f809, %f809;
	sub.f32 	%f811, %f794, %f793;
	sub.f32 	%f812, %f811, %f795;
	fma.rn.f32 	%f813, %f1783, %f792, %f812;
	sub.f32 	%f814, %f800, %f801;
	add.f32 	%f815, %f814, %f814;
	sub.f32 	%f816, %f798, %f799;
	add.f32 	%f817, %f816, %f816;
	add.f32 	%f818, %f800, %f801;
	add.f32 	%f819, %f818, %f818;
	neg.f32 	%f820, %f793;
	sub.f32 	%f821, %f820, %f794;
	add.f32 	%f822, %f795, %f821;
	fma.rn.f32 	%f823, %f1783, %f792, %f822;
	mul.f32 	%f824, %f1774, %f804;
	fma.rn.f32 	%f825, %f1777, %f806, %f824;
	fma.rn.f32 	%f826, %f1779, %f808, %f825;
	sub.f32 	%f1787, %f1784, %f826;
	mul.f32 	%f827, %f1777, %f813;
	fma.rn.f32 	%f828, %f1774, %f810, %f827;
	fma.rn.f32 	%f829, %f1779, %f815, %f828;
	sub.f32 	%f1791, %f1785, %f829;
	mul.f32 	%f830, %f1777, %f819;
	fma.rn.f32 	%f831, %f1774, %f817, %f830;
	fma.rn.f32 	%f832, %f1779, %f823, %f831;
	sub.f32 	%f1795, %f1786, %f832;
	mul.f32 	%f833, %f1773, %f804;
	fma.rn.f32 	%f834, %f1776, %f806, %f833;
	fma.rn.f32 	%f1788, %f1778, %f808, %f834;
	mul.f32 	%f835, %f1776, %f813;
	fma.rn.f32 	%f836, %f1773, %f810, %f835;
	fma.rn.f32 	%f1792, %f1778, %f815, %f836;
	mul.f32 	%f837, %f1776, %f819;
	fma.rn.f32 	%f838, %f1773, %f817, %f837;
	fma.rn.f32 	%f1796, %f1778, %f823, %f838;
	mul.f32 	%f839, %f1772, %f804;
	fma.rn.f32 	%f1789, %f1775, %f806, %f839;
	mul.f32 	%f840, %f1775, %f813;
	fma.rn.f32 	%f1793, %f1772, %f810, %f840;
	mul.f32 	%f841, %f1775, %f819;
	fma.rn.f32 	%f1797, %f1772, %f817, %f841;
	mul.f32 	%f1790, %f1771, %f804;
	mul.f32 	%f1794, %f1771, %f810;
	mul.f32 	%f1798, %f1771, %f817;

$L__BB10_17:
	mul.f32 	%f879, %f1792, %f1797;
	mul.f32 	%f880, %f1793, %f1796;
	sub.f32 	%f881, %f880, %f879;
	mul.f32 	%f882, %f1790, %f881;
	mul.f32 	%f883, %f1792, %f1798;
	mul.f32 	%f884, %f1794, %f1796;
	sub.f32 	%f885, %f884, %f883;
	mul.f32 	%f886, %f1789, %f885;
	sub.f32 	%f887, %f882, %f886;
	mul.f32 	%f888, %f1793, %f1798;
	mul.f32 	%f889, %f1794, %f1797;
	sub.f32 	%f890, %f889, %f888;
	fma.rn.f32 	%f891, %f1788, %f890, %f887;
	rcp.rn.f32 	%f892, %f891;
	mul.f32 	%f1802, %f881, %f892;
	mul.f32 	%f893, %f1789, %f1796;
	mul.f32 	%f894, %f1788, %f1797;
	sub.f32 	%f895, %f894, %f893;
	mul.f32 	%f1801, %f895, %f892;
	mul.f32 	%f896, %f1788, %f1793;
	mul.f32 	%f897, %f1789, %f1792;
	sub.f32 	%f898, %f897, %f896;
	mul.f32 	%f1800, %f898, %f892;
	sub.f32 	%f899, %f883, %f884;
	mul.f32 	%f1806, %f899, %f892;
	mul.f32 	%f900, %f1788, %f1798;
	mul.f32 	%f901, %f1790, %f1796;
	sub.f32 	%f902, %f901, %f900;
	mul.f32 	%f1805, %f902, %f892;
	mul.f32 	%f903, %f1790, %f1792;
	mul.f32 	%f904, %f1788, %f1794;
	sub.f32 	%f905, %f904, %f903;
	mul.f32 	%f1804, %f905, %f892;
	mul.f32 	%f1810, %f890, %f892;
	mul.f32 	%f906, %f1790, %f1797;
	mul.f32 	%f907, %f1789, %f1798;
	sub.f32 	%f908, %f907, %f906;
	mul.f32 	%f1809, %f908, %f892;
	mul.f32 	%f909, %f1789, %f1794;
	mul.f32 	%f910, %f1790, %f1793;
	sub.f32 	%f911, %f910, %f909;
	mul.f32 	%f1808, %f911, %f892;
	mul.f32 	%f912, %f1787, %f1802;
	neg.f32 	%f913, %f912;
	mul.f32 	%f914, %f1791, %f1801;
	sub.f32 	%f915, %f913, %f914;
	mul.f32 	%f916, %f1795, %f1800;
	sub.f32 	%f1799, %f915, %f916;
	mul.f32 	%f917, %f1787, %f1806;
	neg.f32 	%f918, %f917;
	mul.f32 	%f919, %f1791, %f1805;
	sub.f32 	%f920, %f918, %f919;
	mul.f32 	%f921, %f1795, %f1804;
	sub.f32 	%f1803, %f920, %f921;
	mul.f32 	%f922, %f1787, %f1810;
	neg.f32 	%f923, %f922;
	mul.f32 	%f924, %f1791, %f1809;
	sub.f32 	%f925, %f923, %f924;
	mul.f32 	%f926, %f1795, %f1808;
	sub.f32 	%f1807, %f925, %f926;
	bra.uni 	$L__BB10_18;

$L__BB10_9:
	// begin inline asm
	call (%rd648), _optix_get_instance_inverse_transform_from_handle, (%rd48);
	// end inline asm

$L__BB10_10:
	// begin inline asm
	cvta.to.global.u64 %rd54, %rd648;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r38,%r39,%r40,%r41}, [%rd54];
	// end inline asm
	mov.b32 	%f1802, %r38;
	mov.b32 	%f1801, %r39;
	mov.b32 	%f1800, %r40;
	mov.b32 	%f1799, %r41;
	add.s64 	%rd58, %rd648, 16;
	// begin inline asm
	cvta.to.global.u64 %rd57, %rd58;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r42,%r43,%r44,%r45}, [%rd57];
	// end inline asm
	mov.b32 	%f1806, %r42;
	mov.b32 	%f1805, %r43;
	mov.b32 	%f1804, %r44;
	mov.b32 	%f1803, %r45;
	add.s64 	%rd61, %rd648, 32;
	// begin inline asm
	cvta.to.global.u64 %rd60, %rd61;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r46,%r47,%r48,%r49}, [%rd60];
	// end inline asm
	mov.b32 	%f1810, %r46;
	mov.b32 	%f1809, %r47;
	mov.b32 	%f1808, %r48;
	mov.b32 	%f1807, %r49;

$L__BB10_18:
	setp.eq.s32 	%p10, %r645, 0;
	@%p10 bra 	$L__BB10_20;

	mul.f32 	%f927, %f1767, %f1802;
	fma.rn.f32 	%f928, %f1763, %f1801, %f927;
	fma.rn.f32 	%f151, %f1759, %f1800, %f928;
	mul.f32 	%f929, %f1768, %f1802;
	fma.rn.f32 	%f930, %f1764, %f1801, %f929;
	fma.rn.f32 	%f152, %f1760, %f1800, %f930;
	mul.f32 	%f931, %f1769, %f1802;
	fma.rn.f32 	%f932, %f1765, %f1801, %f931;
	fma.rn.f32 	%f153, %f1761, %f1800, %f932;
	mul.f32 	%f933, %f1770, %f1802;
	fma.rn.f32 	%f934, %f1766, %f1801, %f933;
	fma.rn.f32 	%f935, %f1762, %f1800, %f934;
	add.f32 	%f1799, %f1799, %f935;
	mul.f32 	%f936, %f1767, %f1806;
	fma.rn.f32 	%f937, %f1763, %f1805, %f936;
	fma.rn.f32 	%f155, %f1759, %f1804, %f937;
	mul.f32 	%f938, %f1768, %f1806;
	fma.rn.f32 	%f939, %f1764, %f1805, %f938;
	fma.rn.f32 	%f156, %f1760, %f1804, %f939;
	mul.f32 	%f940, %f1769, %f1806;
	fma.rn.f32 	%f941, %f1765, %f1805, %f940;
	fma.rn.f32 	%f157, %f1761, %f1804, %f941;
	mul.f32 	%f942, %f1770, %f1806;
	fma.rn.f32 	%f943, %f1766, %f1805, %f942;
	fma.rn.f32 	%f944, %f1762, %f1804, %f943;
	add.f32 	%f1803, %f1803, %f944;
	mul.f32 	%f945, %f1767, %f1810;
	fma.rn.f32 	%f946, %f1763, %f1809, %f945;
	fma.rn.f32 	%f159, %f1759, %f1808, %f946;
	mul.f32 	%f947, %f1768, %f1810;
	fma.rn.f32 	%f948, %f1764, %f1809, %f947;
	fma.rn.f32 	%f160, %f1760, %f1808, %f948;
	mul.f32 	%f949, %f1769, %f1810;
	fma.rn.f32 	%f950, %f1765, %f1809, %f949;
	fma.rn.f32 	%f161, %f1761, %f1808, %f950;
	mul.f32 	%f951, %f1770, %f1810;
	fma.rn.f32 	%f952, %f1766, %f1809, %f951;
	fma.rn.f32 	%f953, %f1762, %f1808, %f952;
	add.f32 	%f1807, %f1807, %f953;
	mov.f32 	%f1800, %f153;
	mov.f32 	%f1801, %f152;
	mov.f32 	%f1802, %f151;
	mov.f32 	%f1804, %f157;
	mov.f32 	%f1805, %f156;
	mov.f32 	%f1806, %f155;
	mov.f32 	%f1808, %f161;
	mov.f32 	%f1809, %f160;
	mov.f32 	%f1810, %f159;

$L__BB10_20:
	add.s32 	%r645, %r645, 1;
	setp.lt.u32 	%p11, %r645, %r33;
	mov.f32 	%f1759, %f1810;
	mov.f32 	%f1760, %f1809;
	mov.f32 	%f1761, %f1808;
	mov.f32 	%f1762, %f1807;
	mov.f32 	%f1763, %f1806;
	mov.f32 	%f1764, %f1805;
	mov.f32 	%f1765, %f1804;
	mov.f32 	%f1766, %f1803;
	mov.f32 	%f1767, %f1802;
	mov.f32 	%f1768, %f1801;
	mov.f32 	%f1769, %f1800;
	mov.f32 	%f1770, %f1799;
	@%p11 bra 	$L__BB10_5;

$L__BB10_21:
	mul.f32 	%f954, %f1835, %f1802;
	fma.rn.f32 	%f955, %f1836, %f1801, %f954;
	fma.rn.f32 	%f956, %f1837, %f1800, %f955;
	mul.f32 	%f957, %f1835, %f1806;
	fma.rn.f32 	%f958, %f1836, %f1805, %f957;
	fma.rn.f32 	%f959, %f1837, %f1804, %f958;
	mul.f32 	%f960, %f1835, %f1810;
	fma.rn.f32 	%f961, %f1836, %f1809, %f960;
	fma.rn.f32 	%f962, %f1837, %f1808, %f961;
	add.f32 	%f1837, %f1807, %f962;
	add.f32 	%f1836, %f1803, %f959;
	add.f32 	%f1835, %f1799, %f956;

$L__BB10_23:
	// begin inline asm
	call (%f1893), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1894), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f965), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r184), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p12, %r184, 0;
	@%p12 bra 	$L__BB10_43;

	// begin inline asm
	call (%r185), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f966), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p13, %r185, 0;
	@%p13 bra 	$L__BB10_42;

	mov.u32 	%r646, 0;

$L__BB10_26:
	.pragma "nounroll";
	// begin inline asm
	call (%rd167), _optix_get_transform_list_handle, (%r646);
	// end inline asm
	// begin inline asm
	call (%r188), _optix_get_transform_type_from_handle, (%rd167);
	// end inline asm
	or.b32  	%r189, %r188, 1;
	setp.eq.s32 	%p14, %r189, 3;
	@%p14 bra 	$L__BB10_32;
	bra.uni 	$L__BB10_27;

$L__BB10_32:
	setp.eq.s32 	%p17, %r188, 2;
	@%p17 bra 	$L__BB10_36;
	bra.uni 	$L__BB10_33;

$L__BB10_36:
	// begin inline asm
	call (%rd239), _optix_get_matrix_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r277,%r278,%r279,%r280}, [%rd241];
	// end inline asm
	add.s64 	%rd245, %rd239, 16;
	// begin inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r281,%r282,%r283,%r284}, [%rd244];
	// end inline asm
	add.s64 	%rd248, %rd239, 32;
	// begin inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r285,%r286,%r287,%r288}, [%rd247];
	// end inline asm
	add.s64 	%rd251, %rd239, 48;
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r289,%r290,%r291,%r292}, [%rd250];
	// end inline asm
	add.s64 	%rd254, %rd239, 64;
	// begin inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r293,%r294,%r295,%r296}, [%rd253];
	// end inline asm
	add.s64 	%rd257, %rd239, 80;
	// begin inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r297,%r298,%r299,%r300}, [%rd256];
	// end inline asm
	add.s64 	%rd260, %rd239, 96;
	// begin inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd259];
	// end inline asm
	add.s64 	%rd263, %rd239, 112;
	// begin inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd262];
	// end inline asm
	mov.b32 	%f1070, %r280;
	mov.b32 	%f1071, %r281;
	and.b32  	%r321, %r279, 65535;
	add.s32 	%r322, %r321, -1;
	cvt.rn.f32.s32 	%f1072, %r322;
	sub.f32 	%f1073, %f966, %f1070;
	mul.f32 	%f1074, %f1073, %f1072;
	sub.f32 	%f1075, %f1071, %f1070;
	div.rn.f32 	%f1076, %f1074, %f1075;
	min.f32 	%f1077, %f1072, %f1076;
	mov.f32 	%f1078, 0f00000000;
	max.f32 	%f1079, %f1078, %f1077;
	cvt.rmi.f32.f32 	%f1080, %f1079;
	sub.f32 	%f258, %f1079, %f1080;
	cvt.rzi.s32.f32 	%r323, %f1080;
	cvt.s64.s32 	%rd17, %r323;
	mul.wide.s32 	%rd274, %r323, 48;
	add.s64 	%rd266, %rd248, %rd274;
	// begin inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r309,%r310,%r311,%r312}, [%rd265];
	// end inline asm
	mov.b32 	%f1863, %r309;
	mov.b32 	%f1864, %r310;
	mov.b32 	%f1865, %r311;
	add.s64 	%rd269, %rd266, 16;
	// begin inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r313,%r314,%r315,%r316}, [%rd268];
	// end inline asm
	mov.b32 	%f1860, %r313;
	mov.b32 	%f1861, %r314;
	mov.b32 	%f1862, %r315;
	add.s64 	%rd272, %rd266, 32;
	// begin inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r317,%r318,%r319,%r320}, [%rd271];
	// end inline asm
	mov.b32 	%f1857, %r317;
	mov.b32 	%f1858, %r318;
	mov.b32 	%f1859, %r319;
	setp.leu.f32 	%p19, %f258, 0f00000000;
	@%p19 bra 	$L__BB10_38;

	mov.f32 	%f1081, 0f3F800000;
	sub.f32 	%f1082, %f1081, %f258;
	mul.lo.s64 	%rd284, %rd17, 48;
	add.s64 	%rd285, %rd239, %rd284;
	add.s64 	%rd276, %rd285, 80;
	// begin inline asm
	cvta.to.global.u64 %rd275, %rd276;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r324,%r325,%r326,%r327}, [%rd275];
	// end inline asm
	mov.b32 	%f1083, %r324;
	mov.b32 	%f1084, %r325;
	mov.b32 	%f1085, %r326;
	mul.f32 	%f1086, %f258, %f1083;
	mul.f32 	%f1087, %f258, %f1084;
	mul.f32 	%f1088, %f258, %f1085;
	fma.rn.f32 	%f1863, %f1082, %f1863, %f1086;
	fma.rn.f32 	%f1864, %f1082, %f1864, %f1087;
	fma.rn.f32 	%f1865, %f1082, %f1865, %f1088;
	add.s64 	%rd279, %rd285, 96;
	// begin inline asm
	cvta.to.global.u64 %rd278, %rd279;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r328,%r329,%r330,%r331}, [%rd278];
	// end inline asm
	mov.b32 	%f1089, %r328;
	mov.b32 	%f1090, %r329;
	mov.b32 	%f1091, %r330;
	mul.f32 	%f1092, %f258, %f1089;
	mul.f32 	%f1093, %f258, %f1090;
	mul.f32 	%f1094, %f258, %f1091;
	fma.rn.f32 	%f1860, %f1082, %f1860, %f1092;
	fma.rn.f32 	%f1861, %f1082, %f1861, %f1093;
	fma.rn.f32 	%f1862, %f1082, %f1862, %f1094;
	add.s64 	%rd282, %rd285, 112;
	// begin inline asm
	cvta.to.global.u64 %rd281, %rd282;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r332,%r333,%r334,%r335}, [%rd281];
	// end inline asm
	mov.b32 	%f1095, %r332;
	mov.b32 	%f1096, %r333;
	mov.b32 	%f1097, %r334;
	mul.f32 	%f1098, %f258, %f1095;
	mul.f32 	%f1099, %f258, %f1096;
	mul.f32 	%f1100, %f258, %f1097;
	fma.rn.f32 	%f1857, %f1082, %f1857, %f1098;
	fma.rn.f32 	%f1858, %f1082, %f1858, %f1099;
	fma.rn.f32 	%f1859, %f1082, %f1859, %f1100;
	bra.uni 	$L__BB10_38;

$L__BB10_27:
	mov.f32 	%f1866, 0f00000000;
	mov.f32 	%f1868, 0f3F800000;
	setp.eq.s32 	%p15, %r188, 4;
	@%p15 bra 	$L__BB10_30;

	setp.ne.s32 	%p16, %r188, 1;
	mov.f32 	%f1867, %f1866;
	mov.f32 	%f1869, %f1866;
	mov.f32 	%f1870, %f1868;
	mov.f32 	%f1871, %f1866;
	mov.f32 	%f1872, %f1868;
	mov.f32 	%f1873, %f1866;
	mov.f32 	%f1874, %f1866;
	@%p16 bra 	$L__BB10_39;

	// begin inline asm
	call (%rd169), _optix_get_static_transform_from_handle, (%rd167);
	// end inline asm
	add.s64 	%rd649, %rd169, 64;
	bra.uni 	$L__BB10_31;

$L__BB10_33:
	// begin inline asm
	call (%rd182), _optix_get_srt_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r202,%r203,%r204,%r205}, [%rd184];
	// end inline asm
	add.s64 	%rd188, %rd182, 16;
	// begin inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r206,%r207,%r208,%r209}, [%rd187];
	// end inline asm
	add.s64 	%rd191, %rd182, 32;
	// begin inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r210,%r211,%r212,%r213}, [%rd190];
	// end inline asm
	add.s64 	%rd194, %rd182, 48;
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r214,%r215,%r216,%r217}, [%rd193];
	// end inline asm
	add.s64 	%rd197, %rd182, 64;
	// begin inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r218,%r219,%r220,%r221}, [%rd196];
	// end inline asm
	add.s64 	%rd200, %rd182, 80;
	// begin inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r222,%r223,%r224,%r225}, [%rd199];
	// end inline asm
	add.s64 	%rd203, %rd182, 96;
	// begin inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r226,%r227,%r228,%r229}, [%rd202];
	// end inline asm
	add.s64 	%rd206, %rd182, 112;
	// begin inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r230,%r231,%r232,%r233}, [%rd205];
	// end inline asm
	add.s64 	%rd209, %rd182, 128;
	// begin inline asm
	cvta.to.global.u64 %rd208, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r234,%r235,%r236,%r237}, [%rd208];
	// end inline asm
	add.s64 	%rd212, %rd182, 144;
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd212;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd211];
	// end inline asm
	mov.b32 	%f978, %r205;
	mov.b32 	%f979, %r206;
	and.b32  	%r258, %r204, 65535;
	add.s32 	%r259, %r258, -1;
	cvt.rn.f32.s32 	%f980, %r259;
	sub.f32 	%f981, %f966, %f978;
	mul.f32 	%f982, %f981, %f980;
	sub.f32 	%f983, %f979, %f978;
	div.rn.f32 	%f984, %f982, %f983;
	min.f32 	%f985, %f980, %f984;
	mov.f32 	%f986, 0f00000000;
	max.f32 	%f987, %f986, %f985;
	cvt.rmi.f32.f32 	%f988, %f987;
	sub.f32 	%f218, %f987, %f988;
	cvt.rzi.s32.f32 	%r260, %f988;
	mul.wide.s32 	%rd226, %r260, 64;
	add.s64 	%rd215, %rd191, %rd226;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd214];
	// end inline asm
	mov.b32 	%f1847, %r242;
	mov.b32 	%f1848, %r243;
	mov.b32 	%f1849, %r244;
	add.s64 	%rd218, %rd215, 16;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd217];
	// end inline asm
	mov.b32 	%f1850, %r246;
	mov.b32 	%f1851, %r247;
	mov.b32 	%f1852, %r249;
	add.s64 	%rd221, %rd215, 32;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd220];
	// end inline asm
	mov.b32 	%f1853, %r251;
	mov.b32 	%f1854, %r252;
	mov.b32 	%f1855, %r253;
	add.s64 	%rd224, %rd215, 48;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd223];
	// end inline asm
	mov.b32 	%f1856, %r254;
	setp.leu.f32 	%p18, %f218, 0f00000000;
	@%p18 bra 	$L__BB10_35;

	mov.f32 	%f989, 0f3F800000;
	sub.f32 	%f990, %f989, %f218;
	add.s64 	%rd228, %rd215, 64;
	// begin inline asm
	cvta.to.global.u64 %rd227, %rd228;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r261,%r262,%r263,%r264}, [%rd227];
	// end inline asm
	mov.b32 	%f991, %r261;
	mov.b32 	%f992, %r262;
	mov.b32 	%f993, %r263;
	mul.f32 	%f994, %f218, %f991;
	mul.f32 	%f995, %f218, %f992;
	mul.f32 	%f996, %f218, %f993;
	fma.rn.f32 	%f1847, %f990, %f1847, %f994;
	fma.rn.f32 	%f1848, %f990, %f1848, %f995;
	fma.rn.f32 	%f1849, %f990, %f1849, %f996;
	add.s64 	%rd231, %rd215, 80;
	// begin inline asm
	cvta.to.global.u64 %rd230, %rd231;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r265,%r266,%r267,%r268}, [%rd230];
	// end inline asm
	mov.b32 	%f997, %r265;
	mov.b32 	%f998, %r266;
	mov.b32 	%f999, %r268;
	mul.f32 	%f1000, %f218, %f997;
	mul.f32 	%f1001, %f218, %f998;
	mul.f32 	%f1002, %f218, %f999;
	fma.rn.f32 	%f1850, %f990, %f1850, %f1000;
	fma.rn.f32 	%f1851, %f990, %f1851, %f1001;
	fma.rn.f32 	%f1852, %f990, %f1852, %f1002;
	add.s64 	%rd234, %rd215, 96;
	// begin inline asm
	cvta.to.global.u64 %rd233, %rd234;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r269,%r270,%r271,%r272}, [%rd233];
	// end inline asm
	mov.b32 	%f1003, %r270;
	mov.b32 	%f1004, %r271;
	mov.b32 	%f1005, %r272;
	mul.f32 	%f1006, %f218, %f1003;
	mul.f32 	%f1007, %f218, %f1004;
	mul.f32 	%f1008, %f218, %f1005;
	fma.rn.f32 	%f1009, %f990, %f1853, %f1006;
	fma.rn.f32 	%f1010, %f990, %f1854, %f1007;
	fma.rn.f32 	%f1011, %f990, %f1855, %f1008;
	add.s64 	%rd237, %rd215, 112;
	// begin inline asm
	cvta.to.global.u64 %rd236, %rd237;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r273,%r274,%r275,%r276}, [%rd236];
	// end inline asm
	mov.b32 	%f1012, %r273;
	mul.f32 	%f1013, %f218, %f1012;
	fma.rn.f32 	%f1014, %f990, %f1856, %f1013;
	mul.f32 	%f1015, %f1010, %f1010;
	fma.rn.f32 	%f1016, %f1009, %f1009, %f1015;
	fma.rn.f32 	%f1017, %f1011, %f1011, %f1016;
	fma.rn.f32 	%f1018, %f1014, %f1014, %f1017;
	sqrt.rn.f32 	%f1019, %f1018;
	rcp.rn.f32 	%f1020, %f1019;
	mul.f32 	%f1853, %f1009, %f1020;
	mul.f32 	%f1854, %f1010, %f1020;
	mul.f32 	%f1855, %f1011, %f1020;
	mul.f32 	%f1856, %f1020, %f1014;

$L__BB10_35:
	mul.f32 	%f1021, %f1854, %f1854;
	fma.rn.f32 	%f1022, %f1853, %f1853, %f1021;
	fma.rn.f32 	%f1023, %f1855, %f1855, %f1022;
	fma.rn.f32 	%f1024, %f1856, %f1856, %f1023;
	rcp.rn.f32 	%f1025, %f1024;
	mul.f32 	%f1026, %f1853, %f1025;
	mul.f32 	%f1027, %f1854, %f1025;
	mul.f32 	%f1028, %f1855, %f1025;
	mul.f32 	%f1029, %f1856, %f1025;
	mul.f32 	%f1030, %f1853, %f1026;
	mul.f32 	%f1031, %f1854, %f1027;
	mul.f32 	%f1032, %f1855, %f1028;
	mul.f32 	%f1033, %f1853, %f1027;
	mul.f32 	%f1034, %f1855, %f1029;
	mul.f32 	%f1035, %f1853, %f1028;
	mul.f32 	%f1036, %f1854, %f1029;
	mul.f32 	%f1037, %f1854, %f1028;
	mul.f32 	%f1038, %f1853, %f1029;
	sub.f32 	%f1039, %f1030, %f1031;
	sub.f32 	%f1040, %f1039, %f1032;
	fma.rn.f32 	%f1041, %f1856, %f1029, %f1040;
	sub.f32 	%f1042, %f1033, %f1034;
	add.f32 	%f1043, %f1042, %f1042;
	add.f32 	%f1044, %f1035, %f1036;
	add.f32 	%f1045, %f1044, %f1044;
	add.f32 	%f1046, %f1033, %f1034;
	add.f32 	%f1047, %f1046, %f1046;
	sub.f32 	%f1048, %f1031, %f1030;
	sub.f32 	%f1049, %f1048, %f1032;
	fma.rn.f32 	%f1050, %f1856, %f1029, %f1049;
	sub.f32 	%f1051, %f1037, %f1038;
	add.f32 	%f1052, %f1051, %f1051;
	sub.f32 	%f1053, %f1035, %f1036;
	add.f32 	%f1054, %f1053, %f1053;
	add.f32 	%f1055, %f1037, %f1038;
	add.f32 	%f1056, %f1055, %f1055;
	neg.f32 	%f1057, %f1030;
	sub.f32 	%f1058, %f1057, %f1031;
	add.f32 	%f1059, %f1032, %f1058;
	fma.rn.f32 	%f1060, %f1856, %f1029, %f1059;
	mul.f32 	%f1061, %f1849, %f1041;
	fma.rn.f32 	%f1062, %f1851, %f1043, %f1061;
	fma.rn.f32 	%f1865, %f1852, %f1045, %f1062;
	mul.f32 	%f1063, %f1851, %f1050;
	fma.rn.f32 	%f1064, %f1849, %f1047, %f1063;
	fma.rn.f32 	%f1862, %f1852, %f1052, %f1064;
	mul.f32 	%f1065, %f1851, %f1056;
	fma.rn.f32 	%f1066, %f1849, %f1054, %f1065;
	fma.rn.f32 	%f1859, %f1852, %f1060, %f1066;
	mul.f32 	%f1067, %f1848, %f1041;
	fma.rn.f32 	%f1864, %f1850, %f1043, %f1067;
	mul.f32 	%f1068, %f1850, %f1050;
	fma.rn.f32 	%f1861, %f1848, %f1047, %f1068;
	mul.f32 	%f1069, %f1850, %f1056;
	fma.rn.f32 	%f1858, %f1848, %f1054, %f1069;
	mul.f32 	%f1863, %f1847, %f1041;
	mul.f32 	%f1860, %f1847, %f1047;
	mul.f32 	%f1857, %f1847, %f1054;

$L__BB10_38:
	mul.f32 	%f1101, %f1858, %f1862;
	mul.f32 	%f1102, %f1859, %f1861;
	sub.f32 	%f1103, %f1102, %f1101;
	mul.f32 	%f1104, %f1863, %f1103;
	mul.f32 	%f1105, %f1857, %f1862;
	mul.f32 	%f1106, %f1859, %f1860;
	sub.f32 	%f1107, %f1106, %f1105;
	mul.f32 	%f1108, %f1107, %f1864;
	sub.f32 	%f1109, %f1104, %f1108;
	mul.f32 	%f1110, %f1857, %f1861;
	mul.f32 	%f1111, %f1858, %f1860;
	sub.f32 	%f1112, %f1111, %f1110;
	fma.rn.f32 	%f1113, %f1112, %f1865, %f1109;
	rcp.rn.f32 	%f1114, %f1113;
	mul.f32 	%f1872, %f1103, %f1114;
	mul.f32 	%f1115, %f1859, %f1864;
	mul.f32 	%f1116, %f1858, %f1865;
	sub.f32 	%f1117, %f1116, %f1115;
	mul.f32 	%f1873, %f1117, %f1114;
	mul.f32 	%f1118, %f1861, %f1865;
	mul.f32 	%f1119, %f1862, %f1864;
	sub.f32 	%f1120, %f1119, %f1118;
	mul.f32 	%f1874, %f1120, %f1114;
	sub.f32 	%f1121, %f1105, %f1106;
	mul.f32 	%f1869, %f1121, %f1114;
	mul.f32 	%f1122, %f1857, %f1865;
	mul.f32 	%f1123, %f1859, %f1863;
	sub.f32 	%f1124, %f1123, %f1122;
	mul.f32 	%f1870, %f1124, %f1114;
	mul.f32 	%f1125, %f1862, %f1863;
	mul.f32 	%f1126, %f1860, %f1865;
	sub.f32 	%f1127, %f1126, %f1125;
	mul.f32 	%f1871, %f1127, %f1114;
	mul.f32 	%f1866, %f1112, %f1114;
	mul.f32 	%f1128, %f1858, %f1863;
	mul.f32 	%f1129, %f1857, %f1864;
	sub.f32 	%f1130, %f1129, %f1128;
	mul.f32 	%f1867, %f1130, %f1114;
	mul.f32 	%f1131, %f1860, %f1864;
	mul.f32 	%f1132, %f1861, %f1863;
	sub.f32 	%f1133, %f1132, %f1131;
	mul.f32 	%f1868, %f1133, %f1114;
	bra.uni 	$L__BB10_39;

$L__BB10_30:
	// begin inline asm
	call (%rd649), _optix_get_instance_inverse_transform_from_handle, (%rd167);
	// end inline asm

$L__BB10_31:
	// begin inline asm
	cvta.to.global.u64 %rd173, %rd649;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r190,%r191,%r192,%r193}, [%rd173];
	// end inline asm
	mov.b32 	%f1872, %r190;
	mov.b32 	%f1873, %r191;
	mov.b32 	%f1874, %r192;
	add.s64 	%rd177, %rd649, 16;
	// begin inline asm
	cvta.to.global.u64 %rd176, %rd177;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r194,%r195,%r196,%r197}, [%rd176];
	// end inline asm
	mov.b32 	%f1869, %r194;
	mov.b32 	%f1870, %r195;
	mov.b32 	%f1871, %r196;
	add.s64 	%rd180, %rd649, 32;
	// begin inline asm
	cvta.to.global.u64 %rd179, %rd180;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r198,%r199,%r200,%r201}, [%rd179];
	// end inline asm
	mov.b32 	%f1866, %r198;
	mov.b32 	%f1867, %r199;
	mov.b32 	%f1868, %r200;

$L__BB10_39:
	setp.eq.s32 	%p20, %r646, 0;
	@%p20 bra 	$L__BB10_41;

	mul.f32 	%f1134, %f1843, %f1873;
	fma.rn.f32 	%f1135, %f1840, %f1872, %f1134;
	fma.rn.f32 	%f304, %f1846, %f1874, %f1135;
	mul.f32 	%f1136, %f1842, %f1873;
	fma.rn.f32 	%f1137, %f1839, %f1872, %f1136;
	fma.rn.f32 	%f305, %f1845, %f1874, %f1137;
	mul.f32 	%f1138, %f1841, %f1873;
	fma.rn.f32 	%f1139, %f1838, %f1872, %f1138;
	fma.rn.f32 	%f1874, %f1844, %f1874, %f1139;
	mul.f32 	%f1140, %f1843, %f1870;
	fma.rn.f32 	%f1141, %f1840, %f1869, %f1140;
	fma.rn.f32 	%f307, %f1846, %f1871, %f1141;
	mul.f32 	%f1142, %f1842, %f1870;
	fma.rn.f32 	%f1143, %f1839, %f1869, %f1142;
	fma.rn.f32 	%f308, %f1845, %f1871, %f1143;
	mul.f32 	%f1144, %f1841, %f1870;
	fma.rn.f32 	%f1145, %f1838, %f1869, %f1144;
	fma.rn.f32 	%f1871, %f1844, %f1871, %f1145;
	mul.f32 	%f1146, %f1843, %f1867;
	fma.rn.f32 	%f1147, %f1840, %f1866, %f1146;
	fma.rn.f32 	%f310, %f1846, %f1868, %f1147;
	mul.f32 	%f1148, %f1842, %f1867;
	fma.rn.f32 	%f1149, %f1839, %f1866, %f1148;
	fma.rn.f32 	%f311, %f1845, %f1868, %f1149;
	mul.f32 	%f1150, %f1841, %f1867;
	fma.rn.f32 	%f1151, %f1838, %f1866, %f1150;
	fma.rn.f32 	%f1868, %f1844, %f1868, %f1151;
	mov.f32 	%f1866, %f310;
	mov.f32 	%f1867, %f311;
	mov.f32 	%f1869, %f307;
	mov.f32 	%f1870, %f308;
	mov.f32 	%f1872, %f304;
	mov.f32 	%f1873, %f305;

$L__BB10_41:
	add.s32 	%r646, %r646, 1;
	setp.lt.u32 	%p21, %r646, %r185;
	mov.f32 	%f1838, %f1874;
	mov.f32 	%f1839, %f1873;
	mov.f32 	%f1840, %f1872;
	mov.f32 	%f1841, %f1871;
	mov.f32 	%f1842, %f1870;
	mov.f32 	%f1843, %f1869;
	mov.f32 	%f1844, %f1868;
	mov.f32 	%f1845, %f1867;
	mov.f32 	%f1846, %f1866;
	@%p21 bra 	$L__BB10_26;

$L__BB10_42:
	mul.f32 	%f1152, %f1894, %f1873;
	fma.rn.f32 	%f1153, %f1893, %f1872, %f1152;
	mul.f32 	%f1154, %f1894, %f1870;
	fma.rn.f32 	%f1155, %f1893, %f1869, %f1154;
	mul.f32 	%f1156, %f1894, %f1867;
	fma.rn.f32 	%f1157, %f1893, %f1866, %f1156;
	fma.rn.f32 	%f1895, %f965, %f1868, %f1157;
	fma.rn.f32 	%f1894, %f965, %f1871, %f1155;
	fma.rn.f32 	%f1893, %f965, %f1874, %f1153;
	bra.uni 	$L__BB10_44;

$L__BB10_43:
	mov.f32 	%f1895, %f965;

$L__BB10_44:
	// begin inline asm
	call (%f1159), _optix_get_ray_tmax, ();
	// end inline asm
	ld.const.u64 	%rd286, [params+80];
	setp.eq.s64 	%p22, %rd286, 0;
	@%p22 bra 	$L__BB10_49;

	ld.u64 	%rd287, [%rd47];
	ld.const.u64 	%rd288, [params+328];
	cvta.to.global.u64 	%rd289, %rd288;
	cvt.u64.u32 	%rd18, %r1;
	mul.wide.u32 	%rd290, %r1, 8;
	add.s64 	%rd291, %rd289, %rd290;
	st.global.u64 	[%rd291], %rd287;
	ld.const.u64 	%rd292, [params+336];
	cvta.to.global.u64 	%rd293, %rd292;
	mul.wide.u32 	%rd294, %r1, 4;
	add.s64 	%rd295, %rd293, %rd294;
	mov.u32 	%r336, 0;
	st.global.u32 	[%rd295], %r336;
	ld.const.u64 	%rd296, [params+344];
	cvta.to.global.u64 	%rd297, %rd296;
	add.s64 	%rd19, %rd297, %rd294;
	ld.global.u32 	%r10, [%rd19];
	setp.eq.s32 	%p23, %r10, 0;
	@%p23 bra 	$L__BB10_48;

	// begin inline asm
	call (%r337), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p24, %r337, %r10;
	@%p24 bra 	$L__BB10_48;

	st.global.u32 	[%rd19], %r337;

$L__BB10_48:
	ld.const.u64 	%rd298, [params+72];
	cvta.to.global.u64 	%rd299, %rd298;
	shl.b64 	%rd300, %rd18, 2;
	add.s64 	%rd301, %rd299, %rd300;
	st.global.f32 	[%rd301], %f1159;
	bra.uni 	$L__BB10_114;

$L__BB10_49:
	fma.rn.f32 	%f2056, %f1159, %f1893, %f1835;
	fma.rn.f32 	%f2057, %f1159, %f1894, %f1836;
	fma.rn.f32 	%f2058, %f1159, %f1895, %f1837;
	add.s64 	%rd20, %rd3, 288;
	ld.f32 	%f1161, [%rd3+288];
	sub.f32 	%f1162, %f2056, %f1161;
	ld.f32 	%f1163, [%rd3+292];
	sub.f32 	%f1164, %f2057, %f1163;
	ld.v2.f32 	{%f1165, %f1166}, [%rd3+304];
	mul.f32 	%f1169, %f1162, %f1166;
	add.f32 	%f1170, %f1165, 0f3F800000;
	mov.f32 	%f2040, 0f3F800000;
	mul.f32 	%f1172, %f1164, %f1164;
	fma.rn.f32 	%f1173, %f1162, %f1162, %f1172;
	mul.f32 	%f1174, %f1173, %f1170;
	mul.f32 	%f1175, %f1166, %f1166;
	mul.f32 	%f1176, %f1174, %f1175;
	sub.f32 	%f1177, %f2040, %f1176;
	sqrt.rn.f32 	%f1178, %f1177;
	div.rn.f32 	%f2035, %f1169, %f1178;
	mul.f32 	%f1179, %f1164, %f1166;
	div.rn.f32 	%f2032, %f1179, %f1178;
	ld.u8 	%rs2, [%rd3+324];
	setp.eq.s16 	%p25, %rs2, 0;
	mul.f32 	%f346, %f2035, %f2035;
	@%p25 bra 	$L__BB10_51;

	neg.f32 	%f1180, %f2035;
	neg.f32 	%f1181, %f2032;
	fma.rn.f32 	%f1182, %f1181, %f1181, %f346;
	fma.rn.f32 	%f1184, %f2040, %f2040, %f1182;
	sqrt.rn.f32 	%f1185, %f1184;
	div.rn.f32 	%f2050, %f1180, %f1185;
	div.rn.f32 	%f2051, %f1181, %f1185;
	rcp.rn.f32 	%f2052, %f1185;
	bra.uni 	$L__BB10_52;

$L__BB10_51:
	fma.rn.f32 	%f1186, %f2032, %f2032, %f346;
	mov.f32 	%f1187, 0fBF800000;
	fma.rn.f32 	%f1188, %f1187, %f1187, %f1186;
	sqrt.rn.f32 	%f1189, %f1188;
	div.rn.f32 	%f2050, %f2035, %f1189;
	div.rn.f32 	%f2051, %f2032, %f1189;
	div.rn.f32 	%f2052, %f1187, %f1189;

$L__BB10_52:
	ld.const.u64 	%rd21, [params+96];
	setp.eq.s64 	%p26, %rd21, 0;
	@%p26 bra 	$L__BB10_54;

	ld.v4.f32 	{%f1191, %f1192, %f1193, %f1194}, [%rd20+-80];
	ld.f32 	%f1197, [%rd20+-128];
	fma.rn.f32 	%f1198, %f2056, %f1197, %f1191;
	ld.f32 	%f1199, [%rd20+-124];
	fma.rn.f32 	%f1200, %f2056, %f1199, %f1192;
	ld.f32 	%f1201, [%rd20+-112];
	fma.rn.f32 	%f1202, %f2057, %f1201, %f1198;
	ld.f32 	%f1203, [%rd20+-108];
	fma.rn.f32 	%f1204, %f2057, %f1203, %f1200;
	ld.f32 	%f1205, [%rd20+-96];
	fma.rn.f32 	%f1206, %f2058, %f1205, %f1202;
	ld.f32 	%f1207, [%rd20+-92];
	fma.rn.f32 	%f1208, %f2058, %f1207, %f1204;
	ld.f32 	%f1209, [%rd20+24];
	div.rn.f32 	%f1900, %f1206, %f1209;
	div.rn.f32 	%f1899, %f1208, %f1209;

$L__BB10_54:
	ld.u64 	%rd22, [%rd47];
	ld.const.u64 	%rd302, [params+344];
	cvta.to.global.u64 	%rd303, %rd302;
	cvt.u64.u32 	%rd23, %r1;
	mul.wide.u32 	%rd304, %r1, 4;
	add.s64 	%rd24, %rd303, %rd304;
	ld.global.u32 	%r12, [%rd24];
	setp.eq.s32 	%p27, %r12, 0;
	mov.f32 	%f2039, 0f00000000;
	mov.f32 	%f2042, 0f3F800000;
	mov.f32 	%f2043, 0f00000000;
	mov.f32 	%f2045, 0f00000000;
	mov.f32 	%f2046, 0f3F800000;
	mov.f32 	%f2048, 0f3F800000;
	mov.f32 	%f2049, 0f00000000;
	mov.f32 	%f2044, %f2032;
	mov.f32 	%f2047, %f2035;
	mov.f32 	%f2053, %f2050;
	mov.f32 	%f2054, %f2051;
	mov.f32 	%f2055, %f2052;
	@%p27 bra 	$L__BB10_102;

	// begin inline asm
	call (%r338), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p28, %r338, %r12;
	mov.f32 	%f2044, %f2032;
	mov.f32 	%f2047, %f2035;
	mov.f32 	%f2053, %f2050;
	mov.f32 	%f2054, %f2051;
	mov.f32 	%f2055, %f2052;
	@%p28 bra 	$L__BB10_102;

	// begin inline asm
	call (%r339), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p29, %r339, 0;
	mov.f32 	%f2000, 0f00000000;
	mov.f32 	%f1999, 0f3F800000;
	mov.f32 	%f1937, %f1999;
	mov.f32 	%f1938, %f2000;
	mov.f32 	%f1939, %f2000;
	mov.f32 	%f1940, %f2000;
	mov.f32 	%f1933, %f2000;
	mov.f32 	%f1934, %f1999;
	mov.f32 	%f1935, %f2000;
	mov.f32 	%f1936, %f2000;
	mov.f32 	%f1929, %f2000;
	mov.f32 	%f1930, %f2000;
	mov.f32 	%f1931, %f1999;
	mov.f32 	%f1932, %f2000;
	@%p29 bra 	$L__BB10_74;

	// begin inline asm
	call (%r340), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1238), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p30, %r340, 1;
	@%p30 bra 	$L__BB10_74;

	add.s32 	%r647, %r340, 1;
	mov.u32 	%r648, 1;

$L__BB10_59:
	.pragma "nounroll";
	add.s32 	%r342, %r647, -2;
	// begin inline asm
	call (%rd305), _optix_get_transform_list_handle, (%r342);
	// end inline asm
	// begin inline asm
	call (%r343), _optix_get_transform_type_from_handle, (%rd305);
	// end inline asm
	or.b32  	%r344, %r343, 1;
	setp.eq.s32 	%p31, %r344, 3;
	@%p31 bra 	$L__BB10_65;
	bra.uni 	$L__BB10_60;

$L__BB10_65:
	setp.eq.s32 	%p34, %r343, 2;
	@%p34 bra 	$L__BB10_69;
	bra.uni 	$L__BB10_66;

$L__BB10_69:
	// begin inline asm
	call (%rd377), _optix_get_matrix_motion_transform_from_handle, (%rd305);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd379, %rd377;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r432,%r433,%r434,%r435}, [%rd379];
	// end inline asm
	add.s64 	%rd383, %rd377, 16;
	// begin inline asm
	cvta.to.global.u64 %rd382, %rd383;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r436,%r437,%r438,%r439}, [%rd382];
	// end inline asm
	add.s64 	%rd386, %rd377, 32;
	// begin inline asm
	cvta.to.global.u64 %rd385, %rd386;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r440,%r441,%r442,%r443}, [%rd385];
	// end inline asm
	add.s64 	%rd389, %rd377, 48;
	// begin inline asm
	cvta.to.global.u64 %rd388, %rd389;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r444,%r445,%r446,%r447}, [%rd388];
	// end inline asm
	add.s64 	%rd392, %rd377, 64;
	// begin inline asm
	cvta.to.global.u64 %rd391, %rd392;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r448,%r449,%r450,%r451}, [%rd391];
	// end inline asm
	add.s64 	%rd395, %rd377, 80;
	// begin inline asm
	cvta.to.global.u64 %rd394, %rd395;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r452,%r453,%r454,%r455}, [%rd394];
	// end inline asm
	add.s64 	%rd398, %rd377, 96;
	// begin inline asm
	cvta.to.global.u64 %rd397, %rd398;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r456,%r457,%r458,%r459}, [%rd397];
	// end inline asm
	add.s64 	%rd401, %rd377, 112;
	// begin inline asm
	cvta.to.global.u64 %rd400, %rd401;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r460,%r461,%r462,%r463}, [%rd400];
	// end inline asm
	mov.b32 	%f1366, %r435;
	mov.b32 	%f1367, %r436;
	and.b32  	%r476, %r434, 65535;
	add.s32 	%r477, %r476, -1;
	cvt.rn.f32.s32 	%f1368, %r477;
	sub.f32 	%f1369, %f1238, %f1366;
	mul.f32 	%f1370, %f1369, %f1368;
	sub.f32 	%f1371, %f1367, %f1366;
	div.rn.f32 	%f1372, %f1370, %f1371;
	min.f32 	%f1373, %f1368, %f1372;
	mov.f32 	%f1374, 0f00000000;
	max.f32 	%f1375, %f1374, %f1373;
	cvt.rmi.f32.f32 	%f1376, %f1375;
	sub.f32 	%f446, %f1375, %f1376;
	cvt.rzi.s32.f32 	%r478, %f1376;
	cvt.s64.s32 	%rd31, %r478;
	mul.wide.s32 	%rd412, %r478, 48;
	add.s64 	%rd404, %rd386, %rd412;
	// begin inline asm
	cvta.to.global.u64 %rd403, %rd404;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r464,%r465,%r466,%r467}, [%rd403];
	// end inline asm
	mov.b32 	%f1937, %r464;
	mov.b32 	%f1938, %r465;
	mov.b32 	%f1939, %r466;
	mov.b32 	%f1940, %r467;
	add.s64 	%rd407, %rd404, 16;
	// begin inline asm
	cvta.to.global.u64 %rd406, %rd407;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r468,%r469,%r470,%r471}, [%rd406];
	// end inline asm
	mov.b32 	%f1933, %r468;
	mov.b32 	%f1934, %r469;
	mov.b32 	%f1935, %r470;
	mov.b32 	%f1936, %r471;
	add.s64 	%rd410, %rd404, 32;
	// begin inline asm
	cvta.to.global.u64 %rd409, %rd410;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r472,%r473,%r474,%r475}, [%rd409];
	// end inline asm
	mov.b32 	%f1929, %r472;
	mov.b32 	%f1930, %r473;
	mov.b32 	%f1931, %r474;
	mov.b32 	%f1932, %r475;
	setp.leu.f32 	%p36, %f446, 0f00000000;
	@%p36 bra 	$L__BB10_71;

	mov.f32 	%f1377, 0f3F800000;
	sub.f32 	%f1378, %f1377, %f446;
	mul.lo.s64 	%rd422, %rd31, 48;
	add.s64 	%rd423, %rd377, %rd422;
	add.s64 	%rd414, %rd423, 80;
	// begin inline asm
	cvta.to.global.u64 %rd413, %rd414;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r479,%r480,%r481,%r482}, [%rd413];
	// end inline asm
	mov.b32 	%f1379, %r479;
	mov.b32 	%f1380, %r480;
	mov.b32 	%f1381, %r481;
	mov.b32 	%f1382, %r482;
	mul.f32 	%f1383, %f446, %f1379;
	mul.f32 	%f1384, %f446, %f1380;
	mul.f32 	%f1385, %f446, %f1381;
	mul.f32 	%f1386, %f446, %f1382;
	fma.rn.f32 	%f1937, %f1378, %f1937, %f1383;
	fma.rn.f32 	%f1938, %f1378, %f1938, %f1384;
	fma.rn.f32 	%f1939, %f1378, %f1939, %f1385;
	fma.rn.f32 	%f1940, %f1378, %f1940, %f1386;
	add.s64 	%rd417, %rd423, 96;
	// begin inline asm
	cvta.to.global.u64 %rd416, %rd417;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r483,%r484,%r485,%r486}, [%rd416];
	// end inline asm
	mov.b32 	%f1387, %r483;
	mov.b32 	%f1388, %r484;
	mov.b32 	%f1389, %r485;
	mov.b32 	%f1390, %r486;
	mul.f32 	%f1391, %f446, %f1387;
	mul.f32 	%f1392, %f446, %f1388;
	mul.f32 	%f1393, %f446, %f1389;
	mul.f32 	%f1394, %f446, %f1390;
	fma.rn.f32 	%f1933, %f1378, %f1933, %f1391;
	fma.rn.f32 	%f1934, %f1378, %f1934, %f1392;
	fma.rn.f32 	%f1935, %f1378, %f1935, %f1393;
	fma.rn.f32 	%f1936, %f1378, %f1936, %f1394;
	add.s64 	%rd420, %rd423, 112;
	// begin inline asm
	cvta.to.global.u64 %rd419, %rd420;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r487,%r488,%r489,%r490}, [%rd419];
	// end inline asm
	mov.b32 	%f1395, %r487;
	mov.b32 	%f1396, %r488;
	mov.b32 	%f1397, %r489;
	mov.b32 	%f1398, %r490;
	mul.f32 	%f1399, %f446, %f1395;
	mul.f32 	%f1400, %f446, %f1396;
	mul.f32 	%f1401, %f446, %f1397;
	mul.f32 	%f1402, %f446, %f1398;
	fma.rn.f32 	%f1929, %f1378, %f1929, %f1399;
	fma.rn.f32 	%f1930, %f1378, %f1930, %f1400;
	fma.rn.f32 	%f1931, %f1378, %f1931, %f1401;
	fma.rn.f32 	%f1932, %f1378, %f1932, %f1402;
	bra.uni 	$L__BB10_71;

$L__BB10_60:
	mov.f32 	%f1929, 0f00000000;
	mov.f32 	%f1931, 0f3F800000;
	setp.eq.s32 	%p32, %r343, 4;
	@%p32 bra 	$L__BB10_63;

	setp.ne.s32 	%p33, %r343, 1;
	mov.f32 	%f1930, %f1929;
	mov.f32 	%f1932, %f1929;
	mov.f32 	%f1933, %f1929;
	mov.f32 	%f1934, %f1931;
	mov.f32 	%f1935, %f1929;
	mov.f32 	%f1936, %f1929;
	mov.f32 	%f1937, %f1931;
	mov.f32 	%f1938, %f1929;
	mov.f32 	%f1939, %f1929;
	mov.f32 	%f1940, %f1929;
	@%p33 bra 	$L__BB10_71;

	// begin inline asm
	call (%rd307), _optix_get_static_transform_from_handle, (%rd305);
	// end inline asm
	add.s64 	%rd650, %rd307, 16;
	bra.uni 	$L__BB10_64;

$L__BB10_66:
	// begin inline asm
	call (%rd320), _optix_get_srt_motion_transform_from_handle, (%rd305);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd322, %rd320;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r357,%r358,%r359,%r360}, [%rd322];
	// end inline asm
	add.s64 	%rd326, %rd320, 16;
	// begin inline asm
	cvta.to.global.u64 %rd325, %rd326;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r361,%r362,%r363,%r364}, [%rd325];
	// end inline asm
	add.s64 	%rd329, %rd320, 32;
	// begin inline asm
	cvta.to.global.u64 %rd328, %rd329;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r365,%r366,%r367,%r368}, [%rd328];
	// end inline asm
	add.s64 	%rd332, %rd320, 48;
	// begin inline asm
	cvta.to.global.u64 %rd331, %rd332;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r369,%r370,%r371,%r372}, [%rd331];
	// end inline asm
	add.s64 	%rd335, %rd320, 64;
	// begin inline asm
	cvta.to.global.u64 %rd334, %rd335;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r373,%r374,%r375,%r376}, [%rd334];
	// end inline asm
	add.s64 	%rd338, %rd320, 80;
	// begin inline asm
	cvta.to.global.u64 %rd337, %rd338;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r377,%r378,%r379,%r380}, [%rd337];
	// end inline asm
	add.s64 	%rd341, %rd320, 96;
	// begin inline asm
	cvta.to.global.u64 %rd340, %rd341;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r381,%r382,%r383,%r384}, [%rd340];
	// end inline asm
	add.s64 	%rd344, %rd320, 112;
	// begin inline asm
	cvta.to.global.u64 %rd343, %rd344;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r385,%r386,%r387,%r388}, [%rd343];
	// end inline asm
	add.s64 	%rd347, %rd320, 128;
	// begin inline asm
	cvta.to.global.u64 %rd346, %rd347;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r389,%r390,%r391,%r392}, [%rd346];
	// end inline asm
	add.s64 	%rd350, %rd320, 144;
	// begin inline asm
	cvta.to.global.u64 %rd349, %rd350;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r393,%r394,%r395,%r396}, [%rd349];
	// end inline asm
	mov.b32 	%f1253, %r360;
	mov.b32 	%f1254, %r361;
	and.b32  	%r413, %r359, 65535;
	add.s32 	%r414, %r413, -1;
	cvt.rn.f32.s32 	%f1255, %r414;
	sub.f32 	%f1256, %f1238, %f1253;
	mul.f32 	%f1257, %f1256, %f1255;
	sub.f32 	%f1258, %f1254, %f1253;
	div.rn.f32 	%f1259, %f1257, %f1258;
	min.f32 	%f1260, %f1255, %f1259;
	mov.f32 	%f1261, 0f00000000;
	max.f32 	%f1262, %f1261, %f1260;
	cvt.rmi.f32.f32 	%f1263, %f1262;
	sub.f32 	%f385, %f1262, %f1263;
	cvt.rzi.s32.f32 	%r415, %f1263;
	mul.wide.s32 	%rd364, %r415, 64;
	add.s64 	%rd353, %rd329, %rd364;
	// begin inline asm
	cvta.to.global.u64 %rd352, %rd353;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r397,%r398,%r399,%r400}, [%rd352];
	// end inline asm
	mov.b32 	%f1913, %r397;
	mov.b32 	%f1914, %r398;
	mov.b32 	%f1915, %r399;
	mov.b32 	%f1916, %r400;
	add.s64 	%rd356, %rd353, 16;
	// begin inline asm
	cvta.to.global.u64 %rd355, %rd356;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r401,%r402,%r403,%r404}, [%rd355];
	// end inline asm
	mov.b32 	%f1917, %r401;
	mov.b32 	%f1918, %r402;
	mov.b32 	%f1919, %r403;
	mov.b32 	%f1920, %r404;
	add.s64 	%rd359, %rd353, 32;
	// begin inline asm
	cvta.to.global.u64 %rd358, %rd359;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r405,%r406,%r407,%r408}, [%rd358];
	// end inline asm
	mov.b32 	%f1921, %r405;
	mov.b32 	%f1922, %r406;
	mov.b32 	%f1923, %r407;
	mov.b32 	%f1924, %r408;
	add.s64 	%rd362, %rd353, 48;
	// begin inline asm
	cvta.to.global.u64 %rd361, %rd362;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r409,%r410,%r411,%r412}, [%rd361];
	// end inline asm
	mov.b32 	%f1925, %r409;
	mov.b32 	%f1926, %r410;
	mov.b32 	%f1927, %r411;
	mov.b32 	%f1928, %r412;
	setp.leu.f32 	%p35, %f385, 0f00000000;
	@%p35 bra 	$L__BB10_68;

	mov.f32 	%f1264, 0f3F800000;
	sub.f32 	%f1265, %f1264, %f385;
	add.s64 	%rd366, %rd353, 64;
	// begin inline asm
	cvta.to.global.u64 %rd365, %rd366;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r416,%r417,%r418,%r419}, [%rd365];
	// end inline asm
	mov.b32 	%f1266, %r416;
	mov.b32 	%f1267, %r417;
	mov.b32 	%f1268, %r418;
	mov.b32 	%f1269, %r419;
	mul.f32 	%f1270, %f385, %f1266;
	mul.f32 	%f1271, %f385, %f1267;
	mul.f32 	%f1272, %f385, %f1268;
	mul.f32 	%f1273, %f385, %f1269;
	fma.rn.f32 	%f1913, %f1265, %f1913, %f1270;
	fma.rn.f32 	%f1914, %f1265, %f1914, %f1271;
	fma.rn.f32 	%f1915, %f1265, %f1915, %f1272;
	fma.rn.f32 	%f1916, %f1265, %f1916, %f1273;
	add.s64 	%rd369, %rd353, 80;
	// begin inline asm
	cvta.to.global.u64 %rd368, %rd369;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r420,%r421,%r422,%r423}, [%rd368];
	// end inline asm
	mov.b32 	%f1274, %r420;
	mov.b32 	%f1275, %r421;
	mov.b32 	%f1276, %r422;
	mov.b32 	%f1277, %r423;
	mul.f32 	%f1278, %f385, %f1274;
	mul.f32 	%f1279, %f385, %f1275;
	mul.f32 	%f1280, %f385, %f1276;
	mul.f32 	%f1281, %f385, %f1277;
	fma.rn.f32 	%f1917, %f1265, %f1917, %f1278;
	fma.rn.f32 	%f1918, %f1265, %f1918, %f1279;
	fma.rn.f32 	%f1919, %f1265, %f1919, %f1280;
	fma.rn.f32 	%f1920, %f1265, %f1920, %f1281;
	add.s64 	%rd372, %rd353, 96;
	// begin inline asm
	cvta.to.global.u64 %rd371, %rd372;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r424,%r425,%r426,%r427}, [%rd371];
	// end inline asm
	mov.b32 	%f1282, %r424;
	mov.b32 	%f1283, %r425;
	mov.b32 	%f1284, %r426;
	mov.b32 	%f1285, %r427;
	mul.f32 	%f1286, %f385, %f1282;
	mul.f32 	%f1287, %f385, %f1283;
	mul.f32 	%f1288, %f385, %f1284;
	mul.f32 	%f1289, %f385, %f1285;
	fma.rn.f32 	%f1921, %f1265, %f1921, %f1286;
	fma.rn.f32 	%f1290, %f1265, %f1922, %f1287;
	fma.rn.f32 	%f1291, %f1265, %f1923, %f1288;
	fma.rn.f32 	%f1292, %f1265, %f1924, %f1289;
	add.s64 	%rd375, %rd353, 112;
	// begin inline asm
	cvta.to.global.u64 %rd374, %rd375;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r428,%r429,%r430,%r431}, [%rd374];
	// end inline asm
	mov.b32 	%f1293, %r428;
	mov.b32 	%f1294, %r429;
	mov.b32 	%f1295, %r430;
	mov.b32 	%f1296, %r431;
	mul.f32 	%f1297, %f385, %f1293;
	mul.f32 	%f1298, %f385, %f1294;
	mul.f32 	%f1299, %f385, %f1295;
	mul.f32 	%f1300, %f385, %f1296;
	fma.rn.f32 	%f1301, %f1265, %f1925, %f1297;
	fma.rn.f32 	%f1926, %f1265, %f1926, %f1298;
	fma.rn.f32 	%f1927, %f1265, %f1927, %f1299;
	fma.rn.f32 	%f1928, %f1265, %f1928, %f1300;
	mul.f32 	%f1302, %f1291, %f1291;
	fma.rn.f32 	%f1303, %f1290, %f1290, %f1302;
	fma.rn.f32 	%f1304, %f1292, %f1292, %f1303;
	fma.rn.f32 	%f1305, %f1301, %f1301, %f1304;
	sqrt.rn.f32 	%f1306, %f1305;
	rcp.rn.f32 	%f1307, %f1306;
	mul.f32 	%f1922, %f1290, %f1307;
	mul.f32 	%f1923, %f1291, %f1307;
	mul.f32 	%f1924, %f1292, %f1307;
	mul.f32 	%f1925, %f1307, %f1301;

$L__BB10_68:
	mul.f32 	%f1308, %f1923, %f1923;
	fma.rn.f32 	%f1309, %f1922, %f1922, %f1308;
	fma.rn.f32 	%f1310, %f1924, %f1924, %f1309;
	fma.rn.f32 	%f1311, %f1925, %f1925, %f1310;
	rcp.rn.f32 	%f1312, %f1311;
	mul.f32 	%f1313, %f1922, %f1312;
	mul.f32 	%f1314, %f1923, %f1312;
	mul.f32 	%f1315, %f1924, %f1312;
	mul.f32 	%f1316, %f1925, %f1312;
	mul.f32 	%f1317, %f1922, %f1313;
	mul.f32 	%f1318, %f1923, %f1314;
	mul.f32 	%f1319, %f1924, %f1315;
	mul.f32 	%f1320, %f1922, %f1314;
	mul.f32 	%f1321, %f1924, %f1316;
	mul.f32 	%f1322, %f1922, %f1315;
	mul.f32 	%f1323, %f1923, %f1316;
	mul.f32 	%f1324, %f1923, %f1315;
	mul.f32 	%f1325, %f1922, %f1316;
	sub.f32 	%f1326, %f1317, %f1318;
	sub.f32 	%f1327, %f1326, %f1319;
	fma.rn.f32 	%f1328, %f1925, %f1316, %f1327;
	sub.f32 	%f1329, %f1320, %f1321;
	add.f32 	%f1330, %f1329, %f1329;
	add.f32 	%f1331, %f1322, %f1323;
	add.f32 	%f1332, %f1331, %f1331;
	add.f32 	%f1333, %f1320, %f1321;
	add.f32 	%f1334, %f1333, %f1333;
	sub.f32 	%f1335, %f1318, %f1317;
	sub.f32 	%f1336, %f1335, %f1319;
	fma.rn.f32 	%f1337, %f1925, %f1316, %f1336;
	sub.f32 	%f1338, %f1324, %f1325;
	add.f32 	%f1339, %f1338, %f1338;
	sub.f32 	%f1340, %f1322, %f1323;
	add.f32 	%f1341, %f1340, %f1340;
	add.f32 	%f1342, %f1324, %f1325;
	add.f32 	%f1343, %f1342, %f1342;
	neg.f32 	%f1344, %f1317;
	sub.f32 	%f1345, %f1344, %f1318;
	add.f32 	%f1346, %f1319, %f1345;
	fma.rn.f32 	%f1347, %f1925, %f1316, %f1346;
	mul.f32 	%f1348, %f1916, %f1328;
	fma.rn.f32 	%f1349, %f1919, %f1330, %f1348;
	fma.rn.f32 	%f1350, %f1921, %f1332, %f1349;
	sub.f32 	%f1940, %f1926, %f1350;
	mul.f32 	%f1351, %f1919, %f1337;
	fma.rn.f32 	%f1352, %f1916, %f1334, %f1351;
	fma.rn.f32 	%f1353, %f1921, %f1339, %f1352;
	sub.f32 	%f1936, %f1927, %f1353;
	mul.f32 	%f1354, %f1919, %f1343;
	fma.rn.f32 	%f1355, %f1916, %f1341, %f1354;
	fma.rn.f32 	%f1356, %f1921, %f1347, %f1355;
	sub.f32 	%f1932, %f1928, %f1356;
	mul.f32 	%f1357, %f1915, %f1328;
	fma.rn.f32 	%f1358, %f1918, %f1330, %f1357;
	fma.rn.f32 	%f1939, %f1920, %f1332, %f1358;
	mul.f32 	%f1359, %f1918, %f1337;
	fma.rn.f32 	%f1360, %f1915, %f1334, %f1359;
	fma.rn.f32 	%f1935, %f1920, %f1339, %f1360;
	mul.f32 	%f1361, %f1918, %f1343;
	fma.rn.f32 	%f1362, %f1915, %f1341, %f1361;
	fma.rn.f32 	%f1931, %f1920, %f1347, %f1362;
	mul.f32 	%f1363, %f1914, %f1328;
	fma.rn.f32 	%f1938, %f1917, %f1330, %f1363;
	mul.f32 	%f1364, %f1917, %f1337;
	fma.rn.f32 	%f1934, %f1914, %f1334, %f1364;
	mul.f32 	%f1365, %f1917, %f1343;
	fma.rn.f32 	%f1930, %f1914, %f1341, %f1365;
	mul.f32 	%f1937, %f1913, %f1328;
	mul.f32 	%f1933, %f1913, %f1334;
	mul.f32 	%f1929, %f1913, %f1341;
	bra.uni 	$L__BB10_71;

$L__BB10_63:
	// begin inline asm
	call (%rd650), _optix_get_instance_transform_from_handle, (%rd305);
	// end inline asm

$L__BB10_64:
	// begin inline asm
	cvta.to.global.u64 %rd311, %rd650;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r345,%r346,%r347,%r348}, [%rd311];
	// end inline asm
	mov.b32 	%f1937, %r345;
	mov.b32 	%f1938, %r346;
	mov.b32 	%f1939, %r347;
	mov.b32 	%f1940, %r348;
	add.s64 	%rd315, %rd650, 16;
	// begin inline asm
	cvta.to.global.u64 %rd314, %rd315;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r349,%r350,%r351,%r352}, [%rd314];
	// end inline asm
	mov.b32 	%f1933, %r349;
	mov.b32 	%f1934, %r350;
	mov.b32 	%f1935, %r351;
	mov.b32 	%f1936, %r352;
	add.s64 	%rd318, %rd650, 32;
	// begin inline asm
	cvta.to.global.u64 %rd317, %rd318;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r353,%r354,%r355,%r356}, [%rd317];
	// end inline asm
	mov.b32 	%f1929, %r353;
	mov.b32 	%f1930, %r354;
	mov.b32 	%f1931, %r355;
	mov.b32 	%f1932, %r356;

$L__BB10_71:
	setp.eq.s32 	%p37, %r648, 1;
	@%p37 bra 	$L__BB10_73;

	mul.f32 	%f1403, %f1908, %f1938;
	fma.rn.f32 	%f1404, %f1904, %f1937, %f1403;
	fma.rn.f32 	%f483, %f1912, %f1939, %f1404;
	mul.f32 	%f1405, %f1907, %f1938;
	fma.rn.f32 	%f1406, %f1903, %f1937, %f1405;
	fma.rn.f32 	%f484, %f1911, %f1939, %f1406;
	mul.f32 	%f1407, %f1906, %f1938;
	fma.rn.f32 	%f1408, %f1902, %f1937, %f1407;
	fma.rn.f32 	%f485, %f1910, %f1939, %f1408;
	mul.f32 	%f1409, %f1905, %f1938;
	fma.rn.f32 	%f1410, %f1901, %f1937, %f1409;
	fma.rn.f32 	%f1411, %f1909, %f1939, %f1410;
	add.f32 	%f1940, %f1940, %f1411;
	mul.f32 	%f1412, %f1908, %f1934;
	fma.rn.f32 	%f1413, %f1904, %f1933, %f1412;
	fma.rn.f32 	%f487, %f1912, %f1935, %f1413;
	mul.f32 	%f1414, %f1907, %f1934;
	fma.rn.f32 	%f1415, %f1903, %f1933, %f1414;
	fma.rn.f32 	%f488, %f1911, %f1935, %f1415;
	mul.f32 	%f1416, %f1906, %f1934;
	fma.rn.f32 	%f1417, %f1902, %f1933, %f1416;
	fma.rn.f32 	%f489, %f1910, %f1935, %f1417;
	mul.f32 	%f1418, %f1905, %f1934;
	fma.rn.f32 	%f1419, %f1901, %f1933, %f1418;
	fma.rn.f32 	%f1420, %f1909, %f1935, %f1419;
	add.f32 	%f1936, %f1936, %f1420;
	mul.f32 	%f1421, %f1908, %f1930;
	fma.rn.f32 	%f1422, %f1904, %f1929, %f1421;
	fma.rn.f32 	%f491, %f1912, %f1931, %f1422;
	mul.f32 	%f1423, %f1907, %f1930;
	fma.rn.f32 	%f1424, %f1903, %f1929, %f1423;
	fma.rn.f32 	%f492, %f1911, %f1931, %f1424;
	mul.f32 	%f1425, %f1906, %f1930;
	fma.rn.f32 	%f1426, %f1902, %f1929, %f1425;
	fma.rn.f32 	%f493, %f1910, %f1931, %f1426;
	mul.f32 	%f1427, %f1905, %f1930;
	fma.rn.f32 	%f1428, %f1901, %f1929, %f1427;
	fma.rn.f32 	%f1429, %f1909, %f1931, %f1428;
	add.f32 	%f1932, %f1932, %f1429;
	mov.f32 	%f1929, %f491;
	mov.f32 	%f1930, %f492;
	mov.f32 	%f1931, %f493;
	mov.f32 	%f1933, %f487;
	mov.f32 	%f1934, %f488;
	mov.f32 	%f1935, %f489;
	mov.f32 	%f1937, %f483;
	mov.f32 	%f1938, %f484;
	mov.f32 	%f1939, %f485;

$L__BB10_73:
	add.s32 	%r648, %r648, -1;
	add.s32 	%r647, %r647, -1;
	setp.gt.s32 	%p38, %r647, 1;
	mov.f32 	%f1901, %f1940;
	mov.f32 	%f1902, %f1939;
	mov.f32 	%f1903, %f1938;
	mov.f32 	%f1904, %f1937;
	mov.f32 	%f1905, %f1936;
	mov.f32 	%f1906, %f1935;
	mov.f32 	%f1907, %f1934;
	mov.f32 	%f1908, %f1933;
	mov.f32 	%f1909, %f1932;
	mov.f32 	%f1910, %f1931;
	mov.f32 	%f1911, %f1930;
	mov.f32 	%f1912, %f1929;
	@%p38 bra 	$L__BB10_59;

$L__BB10_74:
	// begin inline asm
	call (%r491), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p39, %r491, 0;
	mov.f32 	%f2001, %f2000;
	mov.f32 	%f1996, %f2000;
	mov.f32 	%f1997, %f1999;
	mov.f32 	%f1998, %f2000;
	mov.f32 	%f1993, %f2000;
	mov.f32 	%f1994, %f2000;
	mov.f32 	%f1995, %f1999;
	@%p39 bra 	$L__BB10_93;

	// begin inline asm
	call (%r492), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1439), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p40, %r492, 0;
	@%p40 bra 	$L__BB10_93;

	mov.u32 	%r649, 0;

$L__BB10_77:
	.pragma "nounroll";
	// begin inline asm
	call (%rd424), _optix_get_transform_list_handle, (%r649);
	// end inline asm
	// begin inline asm
	call (%r495), _optix_get_transform_type_from_handle, (%rd424);
	// end inline asm
	or.b32  	%r496, %r495, 1;
	setp.eq.s32 	%p41, %r496, 3;
	@%p41 bra 	$L__BB10_83;
	bra.uni 	$L__BB10_78;

$L__BB10_83:
	setp.eq.s32 	%p44, %r495, 2;
	@%p44 bra 	$L__BB10_87;
	bra.uni 	$L__BB10_84;

$L__BB10_87:
	// begin inline asm
	call (%rd496), _optix_get_matrix_motion_transform_from_handle, (%rd424);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd498, %rd496;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd498];
	// end inline asm
	add.s64 	%rd502, %rd496, 16;
	// begin inline asm
	cvta.to.global.u64 %rd501, %rd502;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r588,%r589,%r590,%r591}, [%rd501];
	// end inline asm
	add.s64 	%rd505, %rd496, 32;
	// begin inline asm
	cvta.to.global.u64 %rd504, %rd505;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd504];
	// end inline asm
	add.s64 	%rd508, %rd496, 48;
	// begin inline asm
	cvta.to.global.u64 %rd507, %rd508;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd507];
	// end inline asm
	add.s64 	%rd511, %rd496, 64;
	// begin inline asm
	cvta.to.global.u64 %rd510, %rd511;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd510];
	// end inline asm
	add.s64 	%rd514, %rd496, 80;
	// begin inline asm
	cvta.to.global.u64 %rd513, %rd514;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd513];
	// end inline asm
	add.s64 	%rd517, %rd496, 96;
	// begin inline asm
	cvta.to.global.u64 %rd516, %rd517;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd516];
	// end inline asm
	add.s64 	%rd520, %rd496, 112;
	// begin inline asm
	cvta.to.global.u64 %rd519, %rd520;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r612,%r613,%r614,%r615}, [%rd519];
	// end inline asm
	mov.b32 	%f1543, %r587;
	mov.b32 	%f1544, %r588;
	and.b32  	%r628, %r586, 65535;
	add.s32 	%r629, %r628, -1;
	cvt.rn.f32.s32 	%f1545, %r629;
	sub.f32 	%f1546, %f1439, %f1543;
	mul.f32 	%f1547, %f1546, %f1545;
	sub.f32 	%f1548, %f1544, %f1543;
	div.rn.f32 	%f1549, %f1547, %f1548;
	min.f32 	%f1550, %f1545, %f1549;
	mov.f32 	%f1551, 0f00000000;
	max.f32 	%f1552, %f1551, %f1550;
	cvt.rmi.f32.f32 	%f1553, %f1552;
	sub.f32 	%f578, %f1552, %f1553;
	cvt.rzi.s32.f32 	%r630, %f1553;
	cvt.s64.s32 	%rd38, %r630;
	mul.wide.s32 	%rd531, %r630, 48;
	add.s64 	%rd523, %rd505, %rd531;
	// begin inline asm
	cvta.to.global.u64 %rd522, %rd523;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r616,%r617,%r618,%r619}, [%rd522];
	// end inline asm
	mov.b32 	%f1990, %r616;
	mov.b32 	%f1991, %r617;
	mov.b32 	%f1992, %r618;
	add.s64 	%rd526, %rd523, 16;
	// begin inline asm
	cvta.to.global.u64 %rd525, %rd526;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r620,%r621,%r622,%r623}, [%rd525];
	// end inline asm
	mov.b32 	%f1987, %r620;
	mov.b32 	%f1988, %r621;
	mov.b32 	%f1989, %r622;
	add.s64 	%rd529, %rd523, 32;
	// begin inline asm
	cvta.to.global.u64 %rd528, %rd529;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r624,%r625,%r626,%r627}, [%rd528];
	// end inline asm
	mov.b32 	%f1984, %r624;
	mov.b32 	%f1985, %r625;
	mov.b32 	%f1986, %r626;
	setp.leu.f32 	%p46, %f578, 0f00000000;
	@%p46 bra 	$L__BB10_89;

	mov.f32 	%f1554, 0f3F800000;
	sub.f32 	%f1555, %f1554, %f578;
	mul.lo.s64 	%rd541, %rd38, 48;
	add.s64 	%rd542, %rd496, %rd541;
	add.s64 	%rd533, %rd542, 80;
	// begin inline asm
	cvta.to.global.u64 %rd532, %rd533;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r631,%r632,%r633,%r634}, [%rd532];
	// end inline asm
	mov.b32 	%f1556, %r631;
	mov.b32 	%f1557, %r632;
	mov.b32 	%f1558, %r633;
	mul.f32 	%f1559, %f578, %f1556;
	mul.f32 	%f1560, %f578, %f1557;
	mul.f32 	%f1561, %f578, %f1558;
	fma.rn.f32 	%f1990, %f1555, %f1990, %f1559;
	fma.rn.f32 	%f1991, %f1555, %f1991, %f1560;
	fma.rn.f32 	%f1992, %f1555, %f1992, %f1561;
	add.s64 	%rd536, %rd542, 96;
	// begin inline asm
	cvta.to.global.u64 %rd535, %rd536;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r635,%r636,%r637,%r638}, [%rd535];
	// end inline asm
	mov.b32 	%f1562, %r635;
	mov.b32 	%f1563, %r636;
	mov.b32 	%f1564, %r637;
	mul.f32 	%f1565, %f578, %f1562;
	mul.f32 	%f1566, %f578, %f1563;
	mul.f32 	%f1567, %f578, %f1564;
	fma.rn.f32 	%f1987, %f1555, %f1987, %f1565;
	fma.rn.f32 	%f1988, %f1555, %f1988, %f1566;
	fma.rn.f32 	%f1989, %f1555, %f1989, %f1567;
	add.s64 	%rd539, %rd542, 112;
	// begin inline asm
	cvta.to.global.u64 %rd538, %rd539;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r639,%r640,%r641,%r642}, [%rd538];
	// end inline asm
	mov.b32 	%f1568, %r639;
	mov.b32 	%f1569, %r640;
	mov.b32 	%f1570, %r641;
	mul.f32 	%f1571, %f578, %f1568;
	mul.f32 	%f1572, %f578, %f1569;
	mul.f32 	%f1573, %f578, %f1570;
	fma.rn.f32 	%f1984, %f1555, %f1984, %f1571;
	fma.rn.f32 	%f1985, %f1555, %f1985, %f1572;
	fma.rn.f32 	%f1986, %f1555, %f1986, %f1573;
	bra.uni 	$L__BB10_89;

$L__BB10_78:
	mov.f32 	%f1993, 0f00000000;
	mov.f32 	%f1995, 0f3F800000;
	setp.eq.s32 	%p42, %r495, 4;
	@%p42 bra 	$L__BB10_81;

	setp.ne.s32 	%p43, %r495, 1;
	mov.f32 	%f1994, %f1993;
	mov.f32 	%f1996, %f1993;
	mov.f32 	%f1997, %f1995;
	mov.f32 	%f1998, %f1993;
	mov.f32 	%f1999, %f1995;
	mov.f32 	%f2000, %f1993;
	mov.f32 	%f2001, %f1993;
	@%p43 bra 	$L__BB10_90;

	// begin inline asm
	call (%rd426), _optix_get_static_transform_from_handle, (%rd424);
	// end inline asm
	add.s64 	%rd651, %rd426, 64;
	bra.uni 	$L__BB10_82;

$L__BB10_84:
	// begin inline asm
	call (%rd439), _optix_get_srt_motion_transform_from_handle, (%rd424);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd441, %rd439;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd441];
	// end inline asm
	add.s64 	%rd445, %rd439, 16;
	// begin inline asm
	cvta.to.global.u64 %rd444, %rd445;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r513,%r514,%r515,%r516}, [%rd444];
	// end inline asm
	add.s64 	%rd448, %rd439, 32;
	// begin inline asm
	cvta.to.global.u64 %rd447, %rd448;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r517,%r518,%r519,%r520}, [%rd447];
	// end inline asm
	add.s64 	%rd451, %rd439, 48;
	// begin inline asm
	cvta.to.global.u64 %rd450, %rd451;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r521,%r522,%r523,%r524}, [%rd450];
	// end inline asm
	add.s64 	%rd454, %rd439, 64;
	// begin inline asm
	cvta.to.global.u64 %rd453, %rd454;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r525,%r526,%r527,%r528}, [%rd453];
	// end inline asm
	add.s64 	%rd457, %rd439, 80;
	// begin inline asm
	cvta.to.global.u64 %rd456, %rd457;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r529,%r530,%r531,%r532}, [%rd456];
	// end inline asm
	add.s64 	%rd460, %rd439, 96;
	// begin inline asm
	cvta.to.global.u64 %rd459, %rd460;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r533,%r534,%r535,%r536}, [%rd459];
	// end inline asm
	add.s64 	%rd463, %rd439, 112;
	// begin inline asm
	cvta.to.global.u64 %rd462, %rd463;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r537,%r538,%r539,%r540}, [%rd462];
	// end inline asm
	add.s64 	%rd466, %rd439, 128;
	// begin inline asm
	cvta.to.global.u64 %rd465, %rd466;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r541,%r542,%r543,%r544}, [%rd465];
	// end inline asm
	add.s64 	%rd469, %rd439, 144;
	// begin inline asm
	cvta.to.global.u64 %rd468, %rd469;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r545,%r546,%r547,%r548}, [%rd468];
	// end inline asm
	mov.b32 	%f1451, %r512;
	mov.b32 	%f1452, %r513;
	and.b32  	%r565, %r511, 65535;
	add.s32 	%r566, %r565, -1;
	cvt.rn.f32.s32 	%f1453, %r566;
	sub.f32 	%f1454, %f1439, %f1451;
	mul.f32 	%f1455, %f1454, %f1453;
	sub.f32 	%f1456, %f1452, %f1451;
	div.rn.f32 	%f1457, %f1455, %f1456;
	min.f32 	%f1458, %f1453, %f1457;
	mov.f32 	%f1459, 0f00000000;
	max.f32 	%f1460, %f1459, %f1458;
	cvt.rmi.f32.f32 	%f1461, %f1460;
	sub.f32 	%f538, %f1460, %f1461;
	cvt.rzi.s32.f32 	%r567, %f1461;
	mul.wide.s32 	%rd483, %r567, 64;
	add.s64 	%rd472, %rd448, %rd483;
	// begin inline asm
	cvta.to.global.u64 %rd471, %rd472;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r549,%r550,%r551,%r552}, [%rd471];
	// end inline asm
	mov.b32 	%f1974, %r549;
	mov.b32 	%f1975, %r550;
	mov.b32 	%f1976, %r551;
	add.s64 	%rd475, %rd472, 16;
	// begin inline asm
	cvta.to.global.u64 %rd474, %rd475;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r553,%r554,%r555,%r556}, [%rd474];
	// end inline asm
	mov.b32 	%f1977, %r553;
	mov.b32 	%f1978, %r554;
	mov.b32 	%f1979, %r556;
	add.s64 	%rd478, %rd472, 32;
	// begin inline asm
	cvta.to.global.u64 %rd477, %rd478;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r557,%r558,%r559,%r560}, [%rd477];
	// end inline asm
	mov.b32 	%f1980, %r558;
	mov.b32 	%f1981, %r559;
	mov.b32 	%f1982, %r560;
	add.s64 	%rd481, %rd472, 48;
	// begin inline asm
	cvta.to.global.u64 %rd480, %rd481;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r561,%r562,%r563,%r564}, [%rd480];
	// end inline asm
	mov.b32 	%f1983, %r561;
	setp.leu.f32 	%p45, %f538, 0f00000000;
	@%p45 bra 	$L__BB10_86;

	mov.f32 	%f1462, 0f3F800000;
	sub.f32 	%f1463, %f1462, %f538;
	add.s64 	%rd485, %rd472, 64;
	// begin inline asm
	cvta.to.global.u64 %rd484, %rd485;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd484];
	// end inline asm
	mov.b32 	%f1464, %r568;
	mov.b32 	%f1465, %r569;
	mov.b32 	%f1466, %r570;
	mul.f32 	%f1467, %f538, %f1464;
	mul.f32 	%f1468, %f538, %f1465;
	mul.f32 	%f1469, %f538, %f1466;
	fma.rn.f32 	%f1974, %f1463, %f1974, %f1467;
	fma.rn.f32 	%f1975, %f1463, %f1975, %f1468;
	fma.rn.f32 	%f1976, %f1463, %f1976, %f1469;
	add.s64 	%rd488, %rd472, 80;
	// begin inline asm
	cvta.to.global.u64 %rd487, %rd488;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd487];
	// end inline asm
	mov.b32 	%f1470, %r572;
	mov.b32 	%f1471, %r573;
	mov.b32 	%f1472, %r575;
	mul.f32 	%f1473, %f538, %f1470;
	mul.f32 	%f1474, %f538, %f1471;
	mul.f32 	%f1475, %f538, %f1472;
	fma.rn.f32 	%f1977, %f1463, %f1977, %f1473;
	fma.rn.f32 	%f1978, %f1463, %f1978, %f1474;
	fma.rn.f32 	%f1979, %f1463, %f1979, %f1475;
	add.s64 	%rd491, %rd472, 96;
	// begin inline asm
	cvta.to.global.u64 %rd490, %rd491;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd490];
	// end inline asm
	mov.b32 	%f1476, %r577;
	mov.b32 	%f1477, %r578;
	mov.b32 	%f1478, %r579;
	mul.f32 	%f1479, %f538, %f1476;
	mul.f32 	%f1480, %f538, %f1477;
	mul.f32 	%f1481, %f538, %f1478;
	fma.rn.f32 	%f1482, %f1463, %f1980, %f1479;
	fma.rn.f32 	%f1483, %f1463, %f1981, %f1480;
	fma.rn.f32 	%f1484, %f1463, %f1982, %f1481;
	add.s64 	%rd494, %rd472, 112;
	// begin inline asm
	cvta.to.global.u64 %rd493, %rd494;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd493];
	// end inline asm
	mov.b32 	%f1485, %r580;
	mul.f32 	%f1486, %f538, %f1485;
	fma.rn.f32 	%f1487, %f1463, %f1983, %f1486;
	mul.f32 	%f1488, %f1483, %f1483;
	fma.rn.f32 	%f1489, %f1482, %f1482, %f1488;
	fma.rn.f32 	%f1490, %f1484, %f1484, %f1489;
	fma.rn.f32 	%f1491, %f1487, %f1487, %f1490;
	sqrt.rn.f32 	%f1492, %f1491;
	rcp.rn.f32 	%f1493, %f1492;
	mul.f32 	%f1980, %f1482, %f1493;
	mul.f32 	%f1981, %f1483, %f1493;
	mul.f32 	%f1982, %f1484, %f1493;
	mul.f32 	%f1983, %f1493, %f1487;

$L__BB10_86:
	mul.f32 	%f1494, %f1981, %f1981;
	fma.rn.f32 	%f1495, %f1980, %f1980, %f1494;
	fma.rn.f32 	%f1496, %f1982, %f1982, %f1495;
	fma.rn.f32 	%f1497, %f1983, %f1983, %f1496;
	rcp.rn.f32 	%f1498, %f1497;
	mul.f32 	%f1499, %f1980, %f1498;
	mul.f32 	%f1500, %f1981, %f1498;
	mul.f32 	%f1501, %f1982, %f1498;
	mul.f32 	%f1502, %f1983, %f1498;
	mul.f32 	%f1503, %f1980, %f1499;
	mul.f32 	%f1504, %f1981, %f1500;
	mul.f32 	%f1505, %f1982, %f1501;
	mul.f32 	%f1506, %f1980, %f1500;
	mul.f32 	%f1507, %f1982, %f1502;
	mul.f32 	%f1508, %f1980, %f1501;
	mul.f32 	%f1509, %f1981, %f1502;
	mul.f32 	%f1510, %f1981, %f1501;
	mul.f32 	%f1511, %f1980, %f1502;
	sub.f32 	%f1512, %f1503, %f1504;
	sub.f32 	%f1513, %f1512, %f1505;
	fma.rn.f32 	%f1514, %f1983, %f1502, %f1513;
	sub.f32 	%f1515, %f1506, %f1507;
	add.f32 	%f1516, %f1515, %f1515;
	add.f32 	%f1517, %f1508, %f1509;
	add.f32 	%f1518, %f1517, %f1517;
	add.f32 	%f1519, %f1506, %f1507;
	add.f32 	%f1520, %f1519, %f1519;
	sub.f32 	%f1521, %f1504, %f1503;
	sub.f32 	%f1522, %f1521, %f1505;
	fma.rn.f32 	%f1523, %f1983, %f1502, %f1522;
	sub.f32 	%f1524, %f1510, %f1511;
	add.f32 	%f1525, %f1524, %f1524;
	sub.f32 	%f1526, %f1508, %f1509;
	add.f32 	%f1527, %f1526, %f1526;
	add.f32 	%f1528, %f1510, %f1511;
	add.f32 	%f1529, %f1528, %f1528;
	neg.f32 	%f1530, %f1503;
	sub.f32 	%f1531, %f1530, %f1504;
	add.f32 	%f1532, %f1505, %f1531;
	fma.rn.f32 	%f1533, %f1983, %f1502, %f1532;
	mul.f32 	%f1534, %f1976, %f1514;
	fma.rn.f32 	%f1535, %f1978, %f1516, %f1534;
	fma.rn.f32 	%f1992, %f1979, %f1518, %f1535;
	mul.f32 	%f1536, %f1978, %f1523;
	fma.rn.f32 	%f1537, %f1976, %f1520, %f1536;
	fma.rn.f32 	%f1989, %f1979, %f1525, %f1537;
	mul.f32 	%f1538, %f1978, %f1529;
	fma.rn.f32 	%f1539, %f1976, %f1527, %f1538;
	fma.rn.f32 	%f1986, %f1979, %f1533, %f1539;
	mul.f32 	%f1540, %f1975, %f1514;
	fma.rn.f32 	%f1991, %f1977, %f1516, %f1540;
	mul.f32 	%f1541, %f1977, %f1523;
	fma.rn.f32 	%f1988, %f1975, %f1520, %f1541;
	mul.f32 	%f1542, %f1977, %f1529;
	fma.rn.f32 	%f1985, %f1975, %f1527, %f1542;
	mul.f32 	%f1990, %f1974, %f1514;
	mul.f32 	%f1987, %f1974, %f1520;
	mul.f32 	%f1984, %f1974, %f1527;

$L__BB10_89:
	mul.f32 	%f1574, %f1985, %f1989;
	mul.f32 	%f1575, %f1986, %f1988;
	sub.f32 	%f1576, %f1575, %f1574;
	mul.f32 	%f1577, %f1990, %f1576;
	mul.f32 	%f1578, %f1984, %f1989;
	mul.f32 	%f1579, %f1986, %f1987;
	sub.f32 	%f1580, %f1579, %f1578;
	mul.f32 	%f1581, %f1580, %f1991;
	sub.f32 	%f1582, %f1577, %f1581;
	mul.f32 	%f1583, %f1984, %f1988;
	mul.f32 	%f1584, %f1985, %f1987;
	sub.f32 	%f1585, %f1584, %f1583;
	fma.rn.f32 	%f1586, %f1585, %f1992, %f1582;
	rcp.rn.f32 	%f1587, %f1586;
	mul.f32 	%f1999, %f1576, %f1587;
	mul.f32 	%f1588, %f1986, %f1991;
	mul.f32 	%f1589, %f1985, %f1992;
	sub.f32 	%f1590, %f1589, %f1588;
	mul.f32 	%f2000, %f1590, %f1587;
	mul.f32 	%f1591, %f1988, %f1992;
	mul.f32 	%f1592, %f1989, %f1991;
	sub.f32 	%f1593, %f1592, %f1591;
	mul.f32 	%f2001, %f1593, %f1587;
	sub.f32 	%f1594, %f1578, %f1579;
	mul.f32 	%f1996, %f1594, %f1587;
	mul.f32 	%f1595, %f1984, %f1992;
	mul.f32 	%f1596, %f1986, %f1990;
	sub.f32 	%f1597, %f1596, %f1595;
	mul.f32 	%f1997, %f1597, %f1587;
	mul.f32 	%f1598, %f1989, %f1990;
	mul.f32 	%f1599, %f1987, %f1992;
	sub.f32 	%f1600, %f1599, %f1598;
	mul.f32 	%f1998, %f1600, %f1587;
	mul.f32 	%f1993, %f1585, %f1587;
	mul.f32 	%f1601, %f1985, %f1990;
	mul.f32 	%f1602, %f1984, %f1991;
	sub.f32 	%f1603, %f1602, %f1601;
	mul.f32 	%f1994, %f1603, %f1587;
	mul.f32 	%f1604, %f1987, %f1991;
	mul.f32 	%f1605, %f1988, %f1990;
	sub.f32 	%f1606, %f1605, %f1604;
	mul.f32 	%f1995, %f1606, %f1587;
	bra.uni 	$L__BB10_90;

$L__BB10_81:
	// begin inline asm
	call (%rd651), _optix_get_instance_inverse_transform_from_handle, (%rd424);
	// end inline asm

$L__BB10_82:
	// begin inline asm
	cvta.to.global.u64 %rd430, %rd651;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd430];
	// end inline asm
	mov.b32 	%f1999, %r497;
	mov.b32 	%f2000, %r498;
	mov.b32 	%f2001, %r499;
	add.s64 	%rd434, %rd651, 16;
	// begin inline asm
	cvta.to.global.u64 %rd433, %rd434;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd433];
	// end inline asm
	mov.b32 	%f1996, %r501;
	mov.b32 	%f1997, %r502;
	mov.b32 	%f1998, %r503;
	add.s64 	%rd437, %rd651, 32;
	// begin inline asm
	cvta.to.global.u64 %rd436, %rd437;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd436];
	// end inline asm
	mov.b32 	%f1993, %r505;
	mov.b32 	%f1994, %r506;
	mov.b32 	%f1995, %r507;

$L__BB10_90:
	setp.eq.s32 	%p47, %r649, 0;
	@%p47 bra 	$L__BB10_92;

	mul.f32 	%f1607, %f1970, %f2000;
	fma.rn.f32 	%f1608, %f1967, %f1999, %f1607;
	fma.rn.f32 	%f624, %f1973, %f2001, %f1608;
	mul.f32 	%f1609, %f1969, %f2000;
	fma.rn.f32 	%f1610, %f1966, %f1999, %f1609;
	fma.rn.f32 	%f625, %f1972, %f2001, %f1610;
	mul.f32 	%f1611, %f1968, %f2000;
	fma.rn.f32 	%f1612, %f1965, %f1999, %f1611;
	fma.rn.f32 	%f2001, %f1971, %f2001, %f1612;
	mul.f32 	%f1613, %f1970, %f1997;
	fma.rn.f32 	%f1614, %f1967, %f1996, %f1613;
	fma.rn.f32 	%f627, %f1973, %f1998, %f1614;
	mul.f32 	%f1615, %f1969, %f1997;
	fma.rn.f32 	%f1616, %f1966, %f1996, %f1615;
	fma.rn.f32 	%f628, %f1972, %f1998, %f1616;
	mul.f32 	%f1617, %f1968, %f1997;
	fma.rn.f32 	%f1618, %f1965, %f1996, %f1617;
	fma.rn.f32 	%f1998, %f1971, %f1998, %f1618;
	mul.f32 	%f1619, %f1970, %f1994;
	fma.rn.f32 	%f1620, %f1967, %f1993, %f1619;
	fma.rn.f32 	%f630, %f1973, %f1995, %f1620;
	mul.f32 	%f1621, %f1969, %f1994;
	fma.rn.f32 	%f1622, %f1966, %f1993, %f1621;
	fma.rn.f32 	%f631, %f1972, %f1995, %f1622;
	mul.f32 	%f1623, %f1968, %f1994;
	fma.rn.f32 	%f1624, %f1965, %f1993, %f1623;
	fma.rn.f32 	%f1995, %f1971, %f1995, %f1624;
	mov.f32 	%f1993, %f630;
	mov.f32 	%f1994, %f631;
	mov.f32 	%f1996, %f627;
	mov.f32 	%f1997, %f628;
	mov.f32 	%f1999, %f624;
	mov.f32 	%f2000, %f625;

$L__BB10_92:
	add.s32 	%r649, %r649, 1;
	setp.lt.u32 	%p48, %r649, %r492;
	mov.f32 	%f1965, %f2001;
	mov.f32 	%f1966, %f2000;
	mov.f32 	%f1967, %f1999;
	mov.f32 	%f1968, %f1998;
	mov.f32 	%f1969, %f1997;
	mov.f32 	%f1970, %f1996;
	mov.f32 	%f1971, %f1995;
	mov.f32 	%f1972, %f1994;
	mov.f32 	%f1973, %f1993;
	@%p48 bra 	$L__BB10_77;

$L__BB10_93:
	fma.rn.f32 	%f1625, %f2056, %f1937, %f1940;
	fma.rn.f32 	%f1626, %f2057, %f1938, %f1625;
	fma.rn.f32 	%f1627, %f2056, %f1933, %f1936;
	fma.rn.f32 	%f1628, %f2057, %f1934, %f1627;
	fma.rn.f32 	%f1629, %f2056, %f1929, %f1932;
	fma.rn.f32 	%f1630, %f2057, %f1930, %f1629;
	fma.rn.f32 	%f2056, %f2058, %f1939, %f1626;
	fma.rn.f32 	%f2057, %f2058, %f1935, %f1628;
	fma.rn.f32 	%f2058, %f2058, %f1931, %f1630;
	ld.const.u64 	%rd543, [params+112];
	setp.eq.s64 	%p49, %rd543, 0;
	mov.f32 	%f2020, %f2050;
	mov.f32 	%f2021, %f2051;
	mov.f32 	%f2022, %f2052;
	@%p49 bra 	$L__BB10_95;

	mul.f32 	%f1631, %f2050, %f1999;
	fma.rn.f32 	%f1632, %f2051, %f1996, %f1631;
	mul.f32 	%f1633, %f2050, %f2000;
	fma.rn.f32 	%f1634, %f2051, %f1997, %f1633;
	mul.f32 	%f1635, %f2050, %f2001;
	fma.rn.f32 	%f1636, %f2051, %f1998, %f1635;
	fma.rn.f32 	%f1637, %f2052, %f1993, %f1632;
	fma.rn.f32 	%f1638, %f2052, %f1994, %f1634;
	fma.rn.f32 	%f1639, %f2052, %f1995, %f1636;
	mul.f32 	%f1640, %f1637, %f1637;
	fma.rn.f32 	%f1641, %f1638, %f1638, %f1640;
	fma.rn.f32 	%f1642, %f1639, %f1639, %f1641;
	sqrt.rn.f32 	%f1643, %f1642;
	div.rn.f32 	%f2020, %f1637, %f1643;
	div.rn.f32 	%f2021, %f1638, %f1643;
	div.rn.f32 	%f2022, %f1639, %f1643;

$L__BB10_95:
	ld.const.u64 	%rd544, [params+136];
	setp.eq.s64 	%p50, %rd544, 0;
	@%p50 bra 	$L__BB10_97;

	mul.f32 	%f1644, %f2050, %f1999;
	fma.rn.f32 	%f1645, %f2051, %f1996, %f1644;
	mul.f32 	%f1646, %f2050, %f2000;
	fma.rn.f32 	%f1647, %f2051, %f1997, %f1646;
	mul.f32 	%f1648, %f2050, %f2001;
	fma.rn.f32 	%f1649, %f2051, %f1998, %f1648;
	fma.rn.f32 	%f1650, %f2052, %f1993, %f1645;
	fma.rn.f32 	%f1651, %f2052, %f1994, %f1647;
	fma.rn.f32 	%f1652, %f2052, %f1995, %f1649;
	mul.f32 	%f1653, %f1650, %f1650;
	fma.rn.f32 	%f1654, %f1651, %f1651, %f1653;
	fma.rn.f32 	%f1655, %f1652, %f1652, %f1654;
	sqrt.rn.f32 	%f1656, %f1655;
	div.rn.f32 	%f2050, %f1650, %f1656;
	div.rn.f32 	%f2051, %f1651, %f1656;
	div.rn.f32 	%f2052, %f1652, %f1656;

$L__BB10_97:
	mov.f32 	%f2055, %f2052;
	mov.f32 	%f2054, %f2051;
	mov.f32 	%f2053, %f2050;
	ld.const.u64 	%rd545, [params+184];
	setp.eq.s64 	%p51, %rd545, 0;
	mov.f32 	%f2039, 0f00000000;
	mov.f32 	%f2040, 0f3F800000;
	mov.f32 	%f2044, %f2032;
	mov.f32 	%f2045, %f2039;
	mov.f32 	%f2046, %f2040;
	mov.f32 	%f2047, %f2035;
	mov.f32 	%f2048, %f2040;
	mov.f32 	%f2049, %f2039;
	@%p51 bra 	$L__BB10_99;

	mul.f32 	%f1661, %f2035, %f1937;
	mov.f32 	%f1662, 0f3F800000;
	fma.rn.f32 	%f1663, %f1662, %f1938, %f1661;
	mul.f32 	%f1664, %f2035, %f1933;
	fma.rn.f32 	%f1665, %f1662, %f1934, %f1664;
	mul.f32 	%f1666, %f2035, %f1929;
	fma.rn.f32 	%f1667, %f1662, %f1930, %f1666;
	mov.f32 	%f1668, 0f00000000;
	fma.rn.f32 	%f2047, %f1668, %f1939, %f1663;
	fma.rn.f32 	%f2048, %f1668, %f1935, %f1665;
	fma.rn.f32 	%f2049, %f1668, %f1931, %f1667;
	mul.f32 	%f1669, %f2032, %f1937;
	fma.rn.f32 	%f1670, %f1668, %f1938, %f1669;
	mul.f32 	%f1671, %f2032, %f1933;
	fma.rn.f32 	%f1672, %f1668, %f1934, %f1671;
	mul.f32 	%f1673, %f2032, %f1929;
	fma.rn.f32 	%f1674, %f1668, %f1930, %f1673;
	fma.rn.f32 	%f2044, %f1662, %f1939, %f1670;
	fma.rn.f32 	%f2045, %f1662, %f1935, %f1672;
	fma.rn.f32 	%f2046, %f1662, %f1931, %f1674;

$L__BB10_99:
	ld.const.u64 	%rd546, [params+232];
	ld.const.u64 	%rd547, [params+280];
	or.b64  	%rd548, %rd546, %rd547;
	setp.eq.s64 	%p52, %rd548, 0;
	mov.f32 	%f2042, %f2040;
	mov.f32 	%f2043, %f2039;
	@%p52 bra 	$L__BB10_101;

	mul.f32 	%f1679, %f2053, %f1937;
	fma.rn.f32 	%f1680, %f2054, %f1933, %f1679;
	mul.f32 	%f1681, %f2053, %f1938;
	fma.rn.f32 	%f1682, %f2054, %f1934, %f1681;
	mul.f32 	%f1683, %f2053, %f1939;
	fma.rn.f32 	%f1684, %f2054, %f1935, %f1683;
	fma.rn.f32 	%f1685, %f2055, %f1929, %f1680;
	fma.rn.f32 	%f1686, %f2055, %f1930, %f1682;
	fma.rn.f32 	%f1687, %f2055, %f1931, %f1684;
	mul.f32 	%f1688, %f1685, %f1685;
	fma.rn.f32 	%f1689, %f1686, %f1686, %f1688;
	fma.rn.f32 	%f1690, %f1687, %f1687, %f1689;
	sqrt.rn.f32 	%f1691, %f1690;
	div.rn.f32 	%f1692, %f1685, %f1691;
	div.rn.f32 	%f1693, %f1686, %f1691;
	div.rn.f32 	%f1694, %f1687, %f1691;
	mul.f32 	%f1695, %f1692, %f1999;
	mul.f32 	%f1696, %f1692, %f2000;
	mul.f32 	%f1697, %f1692, %f2001;
	fma.rn.f32 	%f1698, %f1693, %f1996, %f1695;
	fma.rn.f32 	%f1699, %f1693, %f1997, %f1696;
	fma.rn.f32 	%f1700, %f1693, %f1998, %f1697;
	fma.rn.f32 	%f1701, %f1694, %f1993, %f1698;
	fma.rn.f32 	%f1702, %f1694, %f1994, %f1699;
	fma.rn.f32 	%f1703, %f1694, %f1995, %f1700;
	mul.f32 	%f1704, %f1701, %f1701;
	fma.rn.f32 	%f1705, %f1702, %f1702, %f1704;
	fma.rn.f32 	%f1706, %f1703, %f1703, %f1705;
	sqrt.rn.f32 	%f1707, %f1706;
	rcp.rn.f32 	%f1708, %f1707;
	mov.f32 	%f1709, 0f3F800000;
	mul.f32 	%f1710, %f1708, %f1701;
	mul.f32 	%f1711, %f1708, %f1702;
	mul.f32 	%f1712, %f1708, %f1703;
	mul.f32 	%f1713, %f2035, %f1999;
	fma.rn.f32 	%f1714, %f1709, %f1996, %f1713;
	mul.f32 	%f1715, %f2035, %f2000;
	fma.rn.f32 	%f1716, %f1709, %f1997, %f1715;
	mul.f32 	%f1717, %f2035, %f2001;
	fma.rn.f32 	%f1718, %f1709, %f1998, %f1717;
	mov.f32 	%f1719, 0f00000000;
	fma.rn.f32 	%f1720, %f1719, %f1993, %f1714;
	fma.rn.f32 	%f1721, %f1719, %f1994, %f1716;
	fma.rn.f32 	%f1722, %f1719, %f1995, %f1718;
	mul.f32 	%f1723, %f1720, %f1708;
	mul.f32 	%f1724, %f1721, %f1708;
	mul.f32 	%f1725, %f1722, %f1708;
	mul.f32 	%f1726, %f2032, %f1999;
	fma.rn.f32 	%f1727, %f1719, %f1996, %f1726;
	mul.f32 	%f1728, %f2032, %f2000;
	fma.rn.f32 	%f1729, %f1719, %f1997, %f1728;
	mul.f32 	%f1730, %f2032, %f2001;
	fma.rn.f32 	%f1731, %f1719, %f1998, %f1730;
	fma.rn.f32 	%f1732, %f1709, %f1993, %f1727;
	fma.rn.f32 	%f1733, %f1709, %f1994, %f1729;
	fma.rn.f32 	%f1734, %f1709, %f1995, %f1731;
	mul.f32 	%f1735, %f1732, %f1708;
	mul.f32 	%f1736, %f1733, %f1708;
	mul.f32 	%f1737, %f1734, %f1708;
	mul.f32 	%f1738, %f1710, %f1723;
	fma.rn.f32 	%f1739, %f1711, %f1724, %f1738;
	fma.rn.f32 	%f1740, %f1712, %f1725, %f1739;
	mul.f32 	%f1741, %f1710, %f1740;
	mul.f32 	%f1742, %f1711, %f1740;
	mul.f32 	%f1743, %f1712, %f1740;
	sub.f32 	%f2035, %f1723, %f1741;
	sub.f32 	%f2042, %f1724, %f1742;
	sub.f32 	%f2043, %f1725, %f1743;
	mul.f32 	%f1744, %f1710, %f1735;
	fma.rn.f32 	%f1745, %f1711, %f1736, %f1744;
	fma.rn.f32 	%f1746, %f1712, %f1737, %f1745;
	mul.f32 	%f1747, %f1710, %f1746;
	mul.f32 	%f1748, %f1711, %f1746;
	mul.f32 	%f1749, %f1712, %f1746;
	sub.f32 	%f2032, %f1735, %f1747;
	sub.f32 	%f2039, %f1736, %f1748;
	sub.f32 	%f2040, %f1737, %f1749;

$L__BB10_101:
	st.global.u32 	[%rd24], %r338;
	mov.f32 	%f2050, %f2020;
	mov.f32 	%f2051, %f2021;
	mov.f32 	%f2052, %f2022;

$L__BB10_102:
	ld.const.u64 	%rd549, [params+328];
	cvta.to.global.u64 	%rd550, %rd549;
	shl.b64 	%rd551, %rd23, 3;
	add.s64 	%rd552, %rd550, %rd551;
	st.global.u64 	[%rd552], %rd22;
	ld.const.u64 	%rd553, [params+336];
	cvta.to.global.u64 	%rd554, %rd553;
	shl.b64 	%rd555, %rd23, 2;
	add.s64 	%rd556, %rd554, %rd555;
	mov.u32 	%r643, 0;
	st.global.u32 	[%rd556], %r643;
	ld.const.u64 	%rd557, [params+160];
	cvta.to.global.u64 	%rd558, %rd557;
	add.s64 	%rd559, %rd558, %rd555;
	st.global.f32 	[%rd559], %f2056;
	ld.const.u64 	%rd560, [params+168];
	cvta.to.global.u64 	%rd561, %rd560;
	add.s64 	%rd562, %rd561, %rd555;
	st.global.f32 	[%rd562], %f2057;
	ld.const.u64 	%rd563, [params+176];
	cvta.to.global.u64 	%rd564, %rd563;
	add.s64 	%rd565, %rd564, %rd555;
	st.global.f32 	[%rd565], %f2058;
	ld.const.u64 	%rd566, [params+72];
	cvta.to.global.u64 	%rd567, %rd566;
	add.s64 	%rd568, %rd567, %rd555;
	st.global.f32 	[%rd568], %f1159;
	@%p26 bra 	$L__BB10_104;

	cvta.to.global.u64 	%rd569, %rd21;
	add.s64 	%rd571, %rd569, %rd555;
	st.global.f32 	[%rd571], %f1900;
	ld.const.u64 	%rd572, [params+104];
	cvta.to.global.u64 	%rd573, %rd572;
	add.s64 	%rd574, %rd573, %rd555;
	st.global.f32 	[%rd574], %f1899;

$L__BB10_104:
	ld.const.u64 	%rd39, [params+112];
	setp.eq.s64 	%p54, %rd39, 0;
	@%p54 bra 	$L__BB10_106;

	cvta.to.global.u64 	%rd575, %rd39;
	add.s64 	%rd577, %rd575, %rd555;
	st.global.f32 	[%rd577], %f2050;
	ld.const.u64 	%rd578, [params+120];
	cvta.to.global.u64 	%rd579, %rd578;
	add.s64 	%rd580, %rd579, %rd555;
	st.global.f32 	[%rd580], %f2051;
	ld.const.u64 	%rd581, [params+128];
	cvta.to.global.u64 	%rd582, %rd581;
	add.s64 	%rd583, %rd582, %rd555;
	st.global.f32 	[%rd583], %f2052;

$L__BB10_106:
	ld.const.u64 	%rd40, [params+136];
	setp.eq.s64 	%p55, %rd40, 0;
	@%p55 bra 	$L__BB10_108;

	cvta.to.global.u64 	%rd584, %rd40;
	add.s64 	%rd586, %rd584, %rd555;
	st.global.f32 	[%rd586], %f2053;
	ld.const.u64 	%rd587, [params+144];
	cvta.to.global.u64 	%rd588, %rd587;
	add.s64 	%rd589, %rd588, %rd555;
	st.global.f32 	[%rd589], %f2054;
	ld.const.u64 	%rd590, [params+152];
	cvta.to.global.u64 	%rd591, %rd590;
	add.s64 	%rd592, %rd591, %rd555;
	st.global.f32 	[%rd592], %f2055;

$L__BB10_108:
	ld.const.u64 	%rd41, [params+184];
	setp.eq.s64 	%p56, %rd41, 0;
	@%p56 bra 	$L__BB10_110;

	cvta.to.global.u64 	%rd593, %rd41;
	add.s64 	%rd595, %rd593, %rd555;
	st.global.f32 	[%rd595], %f2047;
	ld.const.u64 	%rd596, [params+192];
	cvta.to.global.u64 	%rd597, %rd596;
	add.s64 	%rd598, %rd597, %rd555;
	st.global.f32 	[%rd598], %f2048;
	ld.const.u64 	%rd599, [params+200];
	cvta.to.global.u64 	%rd600, %rd599;
	add.s64 	%rd601, %rd600, %rd555;
	st.global.f32 	[%rd601], %f2049;
	ld.const.u64 	%rd602, [params+208];
	cvta.to.global.u64 	%rd603, %rd602;
	add.s64 	%rd604, %rd603, %rd555;
	st.global.f32 	[%rd604], %f2044;
	ld.const.u64 	%rd605, [params+216];
	cvta.to.global.u64 	%rd606, %rd605;
	add.s64 	%rd607, %rd606, %rd555;
	st.global.f32 	[%rd607], %f2045;
	ld.const.u64 	%rd608, [params+224];
	cvta.to.global.u64 	%rd609, %rd608;
	add.s64 	%rd610, %rd609, %rd555;
	st.global.f32 	[%rd610], %f2046;

$L__BB10_110:
	ld.const.u64 	%rd42, [params+232];
	setp.eq.s64 	%p57, %rd42, 0;
	@%p57 bra 	$L__BB10_112;

	cvta.to.global.u64 	%rd611, %rd42;
	add.s64 	%rd613, %rd611, %rd555;
	st.global.f32 	[%rd613], %f2035;
	ld.const.u64 	%rd614, [params+240];
	cvta.to.global.u64 	%rd615, %rd614;
	add.s64 	%rd616, %rd615, %rd555;
	st.global.f32 	[%rd616], %f2042;
	ld.const.u64 	%rd617, [params+248];
	cvta.to.global.u64 	%rd618, %rd617;
	add.s64 	%rd619, %rd618, %rd555;
	st.global.f32 	[%rd619], %f2043;
	ld.const.u64 	%rd620, [params+256];
	cvta.to.global.u64 	%rd621, %rd620;
	add.s64 	%rd622, %rd621, %rd555;
	st.global.f32 	[%rd622], %f2032;
	ld.const.u64 	%rd623, [params+264];
	cvta.to.global.u64 	%rd624, %rd623;
	add.s64 	%rd625, %rd624, %rd555;
	st.global.f32 	[%rd625], %f2039;
	ld.const.u64 	%rd626, [params+272];
	cvta.to.global.u64 	%rd627, %rd626;
	add.s64 	%rd628, %rd627, %rd555;
	st.global.f32 	[%rd628], %f2040;

$L__BB10_112:
	ld.const.u64 	%rd43, [params+280];
	setp.eq.s64 	%p58, %rd43, 0;
	@%p58 bra 	$L__BB10_114;

	cvta.to.global.u64 	%rd629, %rd43;
	add.s64 	%rd631, %rd629, %rd555;
	st.global.f32 	[%rd631], %f2035;
	ld.const.u64 	%rd632, [params+288];
	cvta.to.global.u64 	%rd633, %rd632;
	add.s64 	%rd634, %rd633, %rd555;
	st.global.f32 	[%rd634], %f2042;
	ld.const.u64 	%rd635, [params+296];
	cvta.to.global.u64 	%rd636, %rd635;
	add.s64 	%rd637, %rd636, %rd555;
	st.global.f32 	[%rd637], %f2043;
	ld.const.u64 	%rd638, [params+304];
	cvta.to.global.u64 	%rd639, %rd638;
	add.s64 	%rd640, %rd639, %rd555;
	st.global.f32 	[%rd640], %f2032;
	ld.const.u64 	%rd641, [params+312];
	cvta.to.global.u64 	%rd642, %rd641;
	add.s64 	%rd643, %rd642, %rd555;
	st.global.f32 	[%rd643], %f2039;
	ld.const.u64 	%rd644, [params+320];
	cvta.to.global.u64 	%rd645, %rd644;
	add.s64 	%rd646, %rd645, %rd555;
	st.global.f32 	[%rd646], %f2040;

$L__BB10_114:
	ret;

}
	// .globl	__intersection__polyasphsurf
.visible .entry __intersection__polyasphsurf()
{
	.reg .pred 	%p<70>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<1374>;
	.reg .b32 	%r<327>;
	.reg .b64 	%rd<274>;


	// begin inline asm
	call (%rd17), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd1, [%rd17+8];
	// begin inline asm
	call (%f1270), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1271), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1272), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r11), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p4, %r11, 0;
	@%p4 bra 	$L__BB11_20;

	// begin inline asm
	call (%r12), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f481), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p5, %r12, 0;
	@%p5 bra 	$L__BB11_19;

	mov.u32 	%r324, 0;

$L__BB11_3:
	.pragma "nounroll";
	// begin inline asm
	call (%rd18), _optix_get_transform_list_handle, (%r324);
	// end inline asm
	// begin inline asm
	call (%r15), _optix_get_transform_type_from_handle, (%rd18);
	// end inline asm
	or.b32  	%r16, %r15, 1;
	setp.eq.s32 	%p6, %r16, 3;
	@%p6 bra 	$L__BB11_9;
	bra.uni 	$L__BB11_4;

$L__BB11_9:
	setp.eq.s32 	%p9, %r15, 2;
	@%p9 bra 	$L__BB11_13;
	bra.uni 	$L__BB11_10;

$L__BB11_13:
	// begin inline asm
	call (%rd90), _optix_get_matrix_motion_transform_from_handle, (%rd18);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd92];
	// end inline asm
	add.s64 	%rd96, %rd90, 16;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r108,%r109,%r110,%r111}, [%rd95];
	// end inline asm
	add.s64 	%rd99, %rd90, 32;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r112,%r113,%r114,%r115}, [%rd98];
	// end inline asm
	add.s64 	%rd102, %rd90, 48;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r116,%r117,%r118,%r119}, [%rd101];
	// end inline asm
	add.s64 	%rd105, %rd90, 64;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r120,%r121,%r122,%r123}, [%rd104];
	// end inline asm
	add.s64 	%rd108, %rd90, 80;
	// begin inline asm
	cvta.to.global.u64 %rd107, %rd108;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r124,%r125,%r126,%r127}, [%rd107];
	// end inline asm
	add.s64 	%rd111, %rd90, 96;
	// begin inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r128,%r129,%r130,%r131}, [%rd110];
	// end inline asm
	add.s64 	%rd114, %rd90, 112;
	// begin inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r132,%r133,%r134,%r135}, [%rd113];
	// end inline asm
	mov.b32 	%f609, %r107;
	mov.b32 	%f610, %r108;
	and.b32  	%r148, %r106, 65535;
	add.s32 	%r149, %r148, -1;
	cvt.rn.f32.s32 	%f611, %r149;
	sub.f32 	%f612, %f481, %f609;
	mul.f32 	%f613, %f612, %f611;
	sub.f32 	%f614, %f610, %f609;
	div.rn.f32 	%f615, %f613, %f614;
	min.f32 	%f616, %f611, %f615;
	mov.f32 	%f617, 0f00000000;
	max.f32 	%f618, %f617, %f616;
	cvt.rmi.f32.f32 	%f619, %f618;
	sub.f32 	%f90, %f618, %f619;
	cvt.rzi.s32.f32 	%r150, %f619;
	mul.wide.s32 	%rd125, %r150, 48;
	add.s64 	%rd117, %rd99, %rd125;
	// begin inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r136,%r137,%r138,%r139}, [%rd116];
	// end inline asm
	mov.b32 	%f1225, %r136;
	mov.b32 	%f1224, %r137;
	mov.b32 	%f1223, %r138;
	mov.b32 	%f1222, %r139;
	add.s64 	%rd120, %rd117, 16;
	// begin inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r140,%r141,%r142,%r143}, [%rd119];
	// end inline asm
	mov.b32 	%f1229, %r140;
	mov.b32 	%f1228, %r141;
	mov.b32 	%f1227, %r142;
	mov.b32 	%f1226, %r143;
	add.s64 	%rd123, %rd117, 32;
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r144,%r145,%r146,%r147}, [%rd122];
	// end inline asm
	mov.b32 	%f1233, %r144;
	mov.b32 	%f1232, %r145;
	mov.b32 	%f1231, %r146;
	mov.b32 	%f1230, %r147;
	setp.leu.f32 	%p11, %f90, 0f00000000;
	@%p11 bra 	$L__BB11_15;

	cvt.rmi.f32.f32 	%f1189, %f618;
	cvt.rzi.s32.f32 	%r323, %f1189;
	cvt.s64.s32 	%rd271, %r323;
	mov.f32 	%f620, 0f3F800000;
	sub.f32 	%f621, %f620, %f90;
	mul.lo.s64 	%rd135, %rd271, 48;
	add.s64 	%rd136, %rd90, %rd135;
	add.s64 	%rd127, %rd136, 80;
	// begin inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd126];
	// end inline asm
	mov.b32 	%f622, %r151;
	mov.b32 	%f623, %r152;
	mov.b32 	%f624, %r153;
	mov.b32 	%f625, %r154;
	mul.f32 	%f626, %f90, %f622;
	mul.f32 	%f627, %f90, %f623;
	mul.f32 	%f628, %f90, %f624;
	mul.f32 	%f629, %f90, %f625;
	fma.rn.f32 	%f1225, %f621, %f1225, %f626;
	fma.rn.f32 	%f1224, %f621, %f1224, %f627;
	fma.rn.f32 	%f1223, %f621, %f1223, %f628;
	fma.rn.f32 	%f1222, %f621, %f1222, %f629;
	add.s64 	%rd130, %rd136, 96;
	// begin inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd129];
	// end inline asm
	mov.b32 	%f630, %r155;
	mov.b32 	%f631, %r156;
	mov.b32 	%f632, %r157;
	mov.b32 	%f633, %r158;
	mul.f32 	%f634, %f90, %f630;
	mul.f32 	%f635, %f90, %f631;
	mul.f32 	%f636, %f90, %f632;
	mul.f32 	%f637, %f90, %f633;
	fma.rn.f32 	%f1229, %f621, %f1229, %f634;
	fma.rn.f32 	%f1228, %f621, %f1228, %f635;
	fma.rn.f32 	%f1227, %f621, %f1227, %f636;
	fma.rn.f32 	%f1226, %f621, %f1226, %f637;
	add.s64 	%rd133, %rd136, 112;
	// begin inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r159,%r160,%r161,%r162}, [%rd132];
	// end inline asm
	mov.b32 	%f638, %r159;
	mov.b32 	%f639, %r160;
	mov.b32 	%f640, %r161;
	mov.b32 	%f641, %r162;
	mul.f32 	%f642, %f90, %f638;
	mul.f32 	%f643, %f90, %f639;
	mul.f32 	%f644, %f90, %f640;
	mul.f32 	%f645, %f90, %f641;
	fma.rn.f32 	%f1233, %f621, %f1233, %f642;
	fma.rn.f32 	%f1232, %f621, %f1232, %f643;
	fma.rn.f32 	%f1231, %f621, %f1231, %f644;
	fma.rn.f32 	%f1230, %f621, %f1230, %f645;
	bra.uni 	$L__BB11_15;

$L__BB11_4:
	mov.f32 	%f1234, 0f00000000;
	mov.f32 	%f1237, 0f3F800000;
	setp.eq.s32 	%p7, %r15, 4;
	@%p7 bra 	$L__BB11_7;

	setp.ne.s32 	%p8, %r15, 1;
	mov.f32 	%f1235, %f1234;
	mov.f32 	%f1236, %f1234;
	mov.f32 	%f1238, %f1234;
	mov.f32 	%f1239, %f1234;
	mov.f32 	%f1240, %f1237;
	mov.f32 	%f1241, %f1234;
	mov.f32 	%f1242, %f1234;
	mov.f32 	%f1243, %f1237;
	mov.f32 	%f1244, %f1234;
	mov.f32 	%f1245, %f1234;
	@%p8 bra 	$L__BB11_16;

	// begin inline asm
	call (%rd20), _optix_get_static_transform_from_handle, (%rd18);
	// end inline asm
	add.s64 	%rd272, %rd20, 64;
	bra.uni 	$L__BB11_8;

$L__BB11_10:
	// begin inline asm
	call (%rd33), _optix_get_srt_motion_transform_from_handle, (%rd18);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd35, %rd33;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r29,%r30,%r31,%r32}, [%rd35];
	// end inline asm
	add.s64 	%rd39, %rd33, 16;
	// begin inline asm
	cvta.to.global.u64 %rd38, %rd39;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r33,%r34,%r35,%r36}, [%rd38];
	// end inline asm
	add.s64 	%rd42, %rd33, 32;
	// begin inline asm
	cvta.to.global.u64 %rd41, %rd42;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r37,%r38,%r39,%r40}, [%rd41];
	// end inline asm
	add.s64 	%rd45, %rd33, 48;
	// begin inline asm
	cvta.to.global.u64 %rd44, %rd45;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r41,%r42,%r43,%r44}, [%rd44];
	// end inline asm
	add.s64 	%rd48, %rd33, 64;
	// begin inline asm
	cvta.to.global.u64 %rd47, %rd48;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r45,%r46,%r47,%r48}, [%rd47];
	// end inline asm
	add.s64 	%rd51, %rd33, 80;
	// begin inline asm
	cvta.to.global.u64 %rd50, %rd51;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r49,%r50,%r51,%r52}, [%rd50];
	// end inline asm
	add.s64 	%rd54, %rd33, 96;
	// begin inline asm
	cvta.to.global.u64 %rd53, %rd54;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r53,%r54,%r55,%r56}, [%rd53];
	// end inline asm
	add.s64 	%rd57, %rd33, 112;
	// begin inline asm
	cvta.to.global.u64 %rd56, %rd57;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r57,%r58,%r59,%r60}, [%rd56];
	// end inline asm
	add.s64 	%rd60, %rd33, 128;
	// begin inline asm
	cvta.to.global.u64 %rd59, %rd60;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r61,%r62,%r63,%r64}, [%rd59];
	// end inline asm
	add.s64 	%rd63, %rd33, 144;
	// begin inline asm
	cvta.to.global.u64 %rd62, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r65,%r66,%r67,%r68}, [%rd62];
	// end inline asm
	mov.b32 	%f496, %r32;
	mov.b32 	%f497, %r33;
	and.b32  	%r85, %r31, 65535;
	add.s32 	%r86, %r85, -1;
	cvt.rn.f32.s32 	%f498, %r86;
	sub.f32 	%f499, %f481, %f496;
	mul.f32 	%f500, %f499, %f498;
	sub.f32 	%f501, %f497, %f496;
	div.rn.f32 	%f502, %f500, %f501;
	min.f32 	%f503, %f498, %f502;
	mov.f32 	%f504, 0f00000000;
	max.f32 	%f505, %f504, %f503;
	cvt.rmi.f32.f32 	%f506, %f505;
	sub.f32 	%f29, %f505, %f506;
	cvt.rzi.s32.f32 	%r87, %f506;
	mul.wide.s32 	%rd77, %r87, 64;
	add.s64 	%rd66, %rd42, %rd77;
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd66;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r69,%r70,%r71,%r72}, [%rd65];
	// end inline asm
	mov.b32 	%f1206, %r69;
	mov.b32 	%f1207, %r70;
	mov.b32 	%f1208, %r71;
	mov.b32 	%f1209, %r72;
	add.s64 	%rd69, %rd66, 16;
	// begin inline asm
	cvta.to.global.u64 %rd68, %rd69;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r73,%r74,%r75,%r76}, [%rd68];
	// end inline asm
	mov.b32 	%f1210, %r73;
	mov.b32 	%f1211, %r74;
	mov.b32 	%f1212, %r75;
	mov.b32 	%f1213, %r76;
	add.s64 	%rd72, %rd66, 32;
	// begin inline asm
	cvta.to.global.u64 %rd71, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r77,%r78,%r79,%r80}, [%rd71];
	// end inline asm
	mov.b32 	%f1214, %r77;
	mov.b32 	%f1215, %r78;
	mov.b32 	%f1216, %r79;
	mov.b32 	%f1217, %r80;
	add.s64 	%rd75, %rd66, 48;
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd75;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r81,%r82,%r83,%r84}, [%rd74];
	// end inline asm
	mov.b32 	%f1218, %r81;
	mov.b32 	%f1219, %r82;
	mov.b32 	%f1220, %r83;
	mov.b32 	%f1221, %r84;
	setp.leu.f32 	%p10, %f29, 0f00000000;
	@%p10 bra 	$L__BB11_12;

	mov.f32 	%f507, 0f3F800000;
	sub.f32 	%f508, %f507, %f29;
	add.s64 	%rd79, %rd66, 64;
	// begin inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd78];
	// end inline asm
	mov.b32 	%f509, %r88;
	mov.b32 	%f510, %r89;
	mov.b32 	%f511, %r90;
	mov.b32 	%f512, %r91;
	mul.f32 	%f513, %f29, %f509;
	mul.f32 	%f514, %f29, %f510;
	mul.f32 	%f515, %f29, %f511;
	mul.f32 	%f516, %f29, %f512;
	fma.rn.f32 	%f1206, %f508, %f1206, %f513;
	fma.rn.f32 	%f1207, %f508, %f1207, %f514;
	fma.rn.f32 	%f1208, %f508, %f1208, %f515;
	fma.rn.f32 	%f1209, %f508, %f1209, %f516;
	add.s64 	%rd82, %rd66, 80;
	// begin inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd81];
	// end inline asm
	mov.b32 	%f517, %r92;
	mov.b32 	%f518, %r93;
	mov.b32 	%f519, %r94;
	mov.b32 	%f520, %r95;
	mul.f32 	%f521, %f29, %f517;
	mul.f32 	%f522, %f29, %f518;
	mul.f32 	%f523, %f29, %f519;
	mul.f32 	%f524, %f29, %f520;
	fma.rn.f32 	%f1210, %f508, %f1210, %f521;
	fma.rn.f32 	%f1211, %f508, %f1211, %f522;
	fma.rn.f32 	%f1212, %f508, %f1212, %f523;
	fma.rn.f32 	%f1213, %f508, %f1213, %f524;
	add.s64 	%rd85, %rd66, 96;
	// begin inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd84];
	// end inline asm
	mov.b32 	%f525, %r96;
	mov.b32 	%f526, %r97;
	mov.b32 	%f527, %r98;
	mov.b32 	%f528, %r99;
	mul.f32 	%f529, %f29, %f525;
	mul.f32 	%f530, %f29, %f526;
	mul.f32 	%f531, %f29, %f527;
	mul.f32 	%f532, %f29, %f528;
	fma.rn.f32 	%f1214, %f508, %f1214, %f529;
	fma.rn.f32 	%f533, %f508, %f1215, %f530;
	fma.rn.f32 	%f534, %f508, %f1216, %f531;
	fma.rn.f32 	%f535, %f508, %f1217, %f532;
	add.s64 	%rd88, %rd66, 112;
	// begin inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd87];
	// end inline asm
	mov.b32 	%f536, %r100;
	mov.b32 	%f537, %r101;
	mov.b32 	%f538, %r102;
	mov.b32 	%f539, %r103;
	mul.f32 	%f540, %f29, %f536;
	mul.f32 	%f541, %f29, %f537;
	mul.f32 	%f542, %f29, %f538;
	mul.f32 	%f543, %f29, %f539;
	fma.rn.f32 	%f544, %f508, %f1218, %f540;
	fma.rn.f32 	%f1219, %f508, %f1219, %f541;
	fma.rn.f32 	%f1220, %f508, %f1220, %f542;
	fma.rn.f32 	%f1221, %f508, %f1221, %f543;
	mul.f32 	%f545, %f534, %f534;
	fma.rn.f32 	%f546, %f533, %f533, %f545;
	fma.rn.f32 	%f547, %f535, %f535, %f546;
	fma.rn.f32 	%f548, %f544, %f544, %f547;
	sqrt.rn.f32 	%f549, %f548;
	rcp.rn.f32 	%f550, %f549;
	mul.f32 	%f1215, %f533, %f550;
	mul.f32 	%f1216, %f534, %f550;
	mul.f32 	%f1217, %f535, %f550;
	mul.f32 	%f1218, %f550, %f544;

$L__BB11_12:
	mul.f32 	%f551, %f1216, %f1216;
	fma.rn.f32 	%f552, %f1215, %f1215, %f551;
	fma.rn.f32 	%f553, %f1217, %f1217, %f552;
	fma.rn.f32 	%f554, %f1218, %f1218, %f553;
	rcp.rn.f32 	%f555, %f554;
	mul.f32 	%f556, %f1215, %f555;
	mul.f32 	%f557, %f1216, %f555;
	mul.f32 	%f558, %f1217, %f555;
	mul.f32 	%f559, %f1218, %f555;
	mul.f32 	%f560, %f1215, %f556;
	mul.f32 	%f561, %f1216, %f557;
	mul.f32 	%f562, %f1217, %f558;
	mul.f32 	%f563, %f1215, %f557;
	mul.f32 	%f564, %f1217, %f559;
	mul.f32 	%f565, %f1215, %f558;
	mul.f32 	%f566, %f1216, %f559;
	mul.f32 	%f567, %f1216, %f558;
	mul.f32 	%f568, %f1215, %f559;
	sub.f32 	%f569, %f560, %f561;
	sub.f32 	%f570, %f569, %f562;
	fma.rn.f32 	%f571, %f1218, %f559, %f570;
	sub.f32 	%f572, %f563, %f564;
	add.f32 	%f573, %f572, %f572;
	add.f32 	%f574, %f565, %f566;
	add.f32 	%f575, %f574, %f574;
	add.f32 	%f576, %f563, %f564;
	add.f32 	%f577, %f576, %f576;
	sub.f32 	%f578, %f561, %f560;
	sub.f32 	%f579, %f578, %f562;
	fma.rn.f32 	%f580, %f1218, %f559, %f579;
	sub.f32 	%f581, %f567, %f568;
	add.f32 	%f582, %f581, %f581;
	sub.f32 	%f583, %f565, %f566;
	add.f32 	%f584, %f583, %f583;
	add.f32 	%f585, %f567, %f568;
	add.f32 	%f586, %f585, %f585;
	neg.f32 	%f587, %f560;
	sub.f32 	%f588, %f587, %f561;
	add.f32 	%f589, %f562, %f588;
	fma.rn.f32 	%f590, %f1218, %f559, %f589;
	mul.f32 	%f591, %f1209, %f571;
	fma.rn.f32 	%f592, %f1212, %f573, %f591;
	fma.rn.f32 	%f593, %f1214, %f575, %f592;
	sub.f32 	%f1222, %f1219, %f593;
	mul.f32 	%f594, %f1212, %f580;
	fma.rn.f32 	%f595, %f1209, %f577, %f594;
	fma.rn.f32 	%f596, %f1214, %f582, %f595;
	sub.f32 	%f1226, %f1220, %f596;
	mul.f32 	%f597, %f1212, %f586;
	fma.rn.f32 	%f598, %f1209, %f584, %f597;
	fma.rn.f32 	%f599, %f1214, %f590, %f598;
	sub.f32 	%f1230, %f1221, %f599;
	mul.f32 	%f600, %f1208, %f571;
	fma.rn.f32 	%f601, %f1211, %f573, %f600;
	fma.rn.f32 	%f1223, %f1213, %f575, %f601;
	mul.f32 	%f602, %f1211, %f580;
	fma.rn.f32 	%f603, %f1208, %f577, %f602;
	fma.rn.f32 	%f1227, %f1213, %f582, %f603;
	mul.f32 	%f604, %f1211, %f586;
	fma.rn.f32 	%f605, %f1208, %f584, %f604;
	fma.rn.f32 	%f1231, %f1213, %f590, %f605;
	mul.f32 	%f606, %f1207, %f571;
	fma.rn.f32 	%f1224, %f1210, %f573, %f606;
	mul.f32 	%f607, %f1210, %f580;
	fma.rn.f32 	%f1228, %f1207, %f577, %f607;
	mul.f32 	%f608, %f1210, %f586;
	fma.rn.f32 	%f1232, %f1207, %f584, %f608;
	mul.f32 	%f1225, %f1206, %f571;
	mul.f32 	%f1229, %f1206, %f577;
	mul.f32 	%f1233, %f1206, %f584;

$L__BB11_15:
	mul.f32 	%f646, %f1227, %f1232;
	mul.f32 	%f647, %f1228, %f1231;
	sub.f32 	%f648, %f647, %f646;
	mul.f32 	%f649, %f1225, %f648;
	mul.f32 	%f650, %f1227, %f1233;
	mul.f32 	%f651, %f1229, %f1231;
	sub.f32 	%f652, %f651, %f650;
	mul.f32 	%f653, %f1224, %f652;
	sub.f32 	%f654, %f649, %f653;
	mul.f32 	%f655, %f1228, %f1233;
	mul.f32 	%f656, %f1229, %f1232;
	sub.f32 	%f657, %f656, %f655;
	fma.rn.f32 	%f658, %f1223, %f657, %f654;
	rcp.rn.f32 	%f659, %f658;
	mul.f32 	%f1237, %f648, %f659;
	mul.f32 	%f660, %f1224, %f1231;
	mul.f32 	%f661, %f1223, %f1232;
	sub.f32 	%f662, %f661, %f660;
	mul.f32 	%f1236, %f662, %f659;
	mul.f32 	%f663, %f1223, %f1228;
	mul.f32 	%f664, %f1224, %f1227;
	sub.f32 	%f665, %f664, %f663;
	mul.f32 	%f1235, %f665, %f659;
	sub.f32 	%f666, %f650, %f651;
	mul.f32 	%f1241, %f666, %f659;
	mul.f32 	%f667, %f1223, %f1233;
	mul.f32 	%f668, %f1225, %f1231;
	sub.f32 	%f669, %f668, %f667;
	mul.f32 	%f1240, %f669, %f659;
	mul.f32 	%f670, %f1225, %f1227;
	mul.f32 	%f671, %f1223, %f1229;
	sub.f32 	%f672, %f671, %f670;
	mul.f32 	%f1239, %f672, %f659;
	mul.f32 	%f1245, %f657, %f659;
	mul.f32 	%f673, %f1225, %f1232;
	mul.f32 	%f674, %f1224, %f1233;
	sub.f32 	%f675, %f674, %f673;
	mul.f32 	%f1244, %f675, %f659;
	mul.f32 	%f676, %f1224, %f1229;
	mul.f32 	%f677, %f1225, %f1228;
	sub.f32 	%f678, %f677, %f676;
	mul.f32 	%f1243, %f678, %f659;
	mul.f32 	%f679, %f1222, %f1237;
	neg.f32 	%f680, %f679;
	mul.f32 	%f681, %f1226, %f1236;
	sub.f32 	%f682, %f680, %f681;
	mul.f32 	%f683, %f1230, %f1235;
	sub.f32 	%f1234, %f682, %f683;
	mul.f32 	%f684, %f1222, %f1241;
	neg.f32 	%f685, %f684;
	mul.f32 	%f686, %f1226, %f1240;
	sub.f32 	%f687, %f685, %f686;
	mul.f32 	%f688, %f1230, %f1239;
	sub.f32 	%f1238, %f687, %f688;
	mul.f32 	%f689, %f1222, %f1245;
	neg.f32 	%f690, %f689;
	mul.f32 	%f691, %f1226, %f1244;
	sub.f32 	%f692, %f690, %f691;
	mul.f32 	%f693, %f1230, %f1243;
	sub.f32 	%f1242, %f692, %f693;
	bra.uni 	$L__BB11_16;

$L__BB11_7:
	// begin inline asm
	call (%rd272), _optix_get_instance_inverse_transform_from_handle, (%rd18);
	// end inline asm

$L__BB11_8:
	// begin inline asm
	cvta.to.global.u64 %rd24, %rd272;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r17,%r18,%r19,%r20}, [%rd24];
	// end inline asm
	mov.b32 	%f1237, %r17;
	mov.b32 	%f1236, %r18;
	mov.b32 	%f1235, %r19;
	mov.b32 	%f1234, %r20;
	add.s64 	%rd28, %rd272, 16;
	// begin inline asm
	cvta.to.global.u64 %rd27, %rd28;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r21,%r22,%r23,%r24}, [%rd27];
	// end inline asm
	mov.b32 	%f1241, %r21;
	mov.b32 	%f1240, %r22;
	mov.b32 	%f1239, %r23;
	mov.b32 	%f1238, %r24;
	add.s64 	%rd31, %rd272, 32;
	// begin inline asm
	cvta.to.global.u64 %rd30, %rd31;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r25,%r26,%r27,%r28}, [%rd30];
	// end inline asm
	mov.b32 	%f1245, %r25;
	mov.b32 	%f1244, %r26;
	mov.b32 	%f1243, %r27;
	mov.b32 	%f1242, %r28;

$L__BB11_16:
	setp.eq.s32 	%p12, %r324, 0;
	@%p12 bra 	$L__BB11_18;

	mul.f32 	%f694, %f1202, %f1237;
	fma.rn.f32 	%f695, %f1198, %f1236, %f694;
	fma.rn.f32 	%f151, %f1194, %f1235, %f695;
	mul.f32 	%f696, %f1203, %f1237;
	fma.rn.f32 	%f697, %f1199, %f1236, %f696;
	fma.rn.f32 	%f152, %f1195, %f1235, %f697;
	mul.f32 	%f698, %f1204, %f1237;
	fma.rn.f32 	%f699, %f1200, %f1236, %f698;
	fma.rn.f32 	%f153, %f1196, %f1235, %f699;
	mul.f32 	%f700, %f1205, %f1237;
	fma.rn.f32 	%f701, %f1201, %f1236, %f700;
	fma.rn.f32 	%f702, %f1197, %f1235, %f701;
	add.f32 	%f1234, %f1234, %f702;
	mul.f32 	%f703, %f1202, %f1241;
	fma.rn.f32 	%f704, %f1198, %f1240, %f703;
	fma.rn.f32 	%f155, %f1194, %f1239, %f704;
	mul.f32 	%f705, %f1203, %f1241;
	fma.rn.f32 	%f706, %f1199, %f1240, %f705;
	fma.rn.f32 	%f156, %f1195, %f1239, %f706;
	mul.f32 	%f707, %f1204, %f1241;
	fma.rn.f32 	%f708, %f1200, %f1240, %f707;
	fma.rn.f32 	%f157, %f1196, %f1239, %f708;
	mul.f32 	%f709, %f1205, %f1241;
	fma.rn.f32 	%f710, %f1201, %f1240, %f709;
	fma.rn.f32 	%f711, %f1197, %f1239, %f710;
	add.f32 	%f1238, %f1238, %f711;
	mul.f32 	%f712, %f1202, %f1245;
	fma.rn.f32 	%f713, %f1198, %f1244, %f712;
	fma.rn.f32 	%f159, %f1194, %f1243, %f713;
	mul.f32 	%f714, %f1203, %f1245;
	fma.rn.f32 	%f715, %f1199, %f1244, %f714;
	fma.rn.f32 	%f160, %f1195, %f1243, %f715;
	mul.f32 	%f716, %f1204, %f1245;
	fma.rn.f32 	%f717, %f1200, %f1244, %f716;
	fma.rn.f32 	%f161, %f1196, %f1243, %f717;
	mul.f32 	%f718, %f1205, %f1245;
	fma.rn.f32 	%f719, %f1201, %f1244, %f718;
	fma.rn.f32 	%f720, %f1197, %f1243, %f719;
	add.f32 	%f1242, %f1242, %f720;
	mov.f32 	%f1235, %f153;
	mov.f32 	%f1236, %f152;
	mov.f32 	%f1237, %f151;
	mov.f32 	%f1239, %f157;
	mov.f32 	%f1240, %f156;
	mov.f32 	%f1241, %f155;
	mov.f32 	%f1243, %f161;
	mov.f32 	%f1244, %f160;
	mov.f32 	%f1245, %f159;

$L__BB11_18:
	add.s32 	%r324, %r324, 1;
	setp.lt.u32 	%p13, %r324, %r12;
	mov.f32 	%f1194, %f1245;
	mov.f32 	%f1195, %f1244;
	mov.f32 	%f1196, %f1243;
	mov.f32 	%f1197, %f1242;
	mov.f32 	%f1198, %f1241;
	mov.f32 	%f1199, %f1240;
	mov.f32 	%f1200, %f1239;
	mov.f32 	%f1201, %f1238;
	mov.f32 	%f1202, %f1237;
	mov.f32 	%f1203, %f1236;
	mov.f32 	%f1204, %f1235;
	mov.f32 	%f1205, %f1234;
	@%p13 bra 	$L__BB11_3;

$L__BB11_19:
	mul.f32 	%f721, %f1270, %f1237;
	fma.rn.f32 	%f722, %f1271, %f1236, %f721;
	fma.rn.f32 	%f723, %f1272, %f1235, %f722;
	mul.f32 	%f724, %f1270, %f1241;
	fma.rn.f32 	%f725, %f1271, %f1240, %f724;
	fma.rn.f32 	%f726, %f1272, %f1239, %f725;
	mul.f32 	%f727, %f1270, %f1245;
	fma.rn.f32 	%f728, %f1271, %f1244, %f727;
	fma.rn.f32 	%f729, %f1272, %f1243, %f728;
	add.f32 	%f1272, %f1242, %f729;
	add.f32 	%f1271, %f1238, %f726;
	add.f32 	%f1270, %f1234, %f723;

$L__BB11_20:
	// begin inline asm
	call (%f1328), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1329), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f732), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r163), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p14, %r163, 0;
	@%p14 bra 	$L__BB11_40;

	// begin inline asm
	call (%r164), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f733), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p15, %r164, 0;
	@%p15 bra 	$L__BB11_39;

	mov.u32 	%r325, 0;

$L__BB11_23:
	.pragma "nounroll";
	// begin inline asm
	call (%rd137), _optix_get_transform_list_handle, (%r325);
	// end inline asm
	// begin inline asm
	call (%r167), _optix_get_transform_type_from_handle, (%rd137);
	// end inline asm
	or.b32  	%r168, %r167, 1;
	setp.eq.s32 	%p16, %r168, 3;
	@%p16 bra 	$L__BB11_29;
	bra.uni 	$L__BB11_24;

$L__BB11_29:
	setp.eq.s32 	%p19, %r167, 2;
	@%p19 bra 	$L__BB11_33;
	bra.uni 	$L__BB11_30;

$L__BB11_33:
	// begin inline asm
	call (%rd209), _optix_get_matrix_motion_transform_from_handle, (%rd137);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd211];
	// end inline asm
	add.s64 	%rd215, %rd209, 16;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r260,%r261,%r262,%r263}, [%rd214];
	// end inline asm
	add.s64 	%rd218, %rd209, 32;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r264,%r265,%r266,%r267}, [%rd217];
	// end inline asm
	add.s64 	%rd221, %rd209, 48;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r268,%r269,%r270,%r271}, [%rd220];
	// end inline asm
	add.s64 	%rd224, %rd209, 64;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r272,%r273,%r274,%r275}, [%rd223];
	// end inline asm
	add.s64 	%rd227, %rd209, 80;
	// begin inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r276,%r277,%r278,%r279}, [%rd226];
	// end inline asm
	add.s64 	%rd230, %rd209, 96;
	// begin inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r280,%r281,%r282,%r283}, [%rd229];
	// end inline asm
	add.s64 	%rd233, %rd209, 112;
	// begin inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r284,%r285,%r286,%r287}, [%rd232];
	// end inline asm
	mov.b32 	%f837, %r259;
	mov.b32 	%f838, %r260;
	and.b32  	%r300, %r258, 65535;
	add.s32 	%r301, %r300, -1;
	cvt.rn.f32.s32 	%f839, %r301;
	sub.f32 	%f840, %f733, %f837;
	mul.f32 	%f841, %f840, %f839;
	sub.f32 	%f842, %f838, %f837;
	div.rn.f32 	%f843, %f841, %f842;
	min.f32 	%f844, %f839, %f843;
	mov.f32 	%f845, 0f00000000;
	max.f32 	%f846, %f845, %f844;
	cvt.rmi.f32.f32 	%f847, %f846;
	sub.f32 	%f260, %f846, %f847;
	cvt.rzi.s32.f32 	%r302, %f847;
	cvt.s64.s32 	%rd15, %r302;
	mul.wide.s32 	%rd244, %r302, 48;
	add.s64 	%rd236, %rd218, %rd244;
	// begin inline asm
	cvta.to.global.u64 %rd235, %rd236;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r288,%r289,%r290,%r291}, [%rd235];
	// end inline asm
	mov.b32 	%f1298, %r288;
	mov.b32 	%f1299, %r289;
	mov.b32 	%f1300, %r290;
	add.s64 	%rd239, %rd236, 16;
	// begin inline asm
	cvta.to.global.u64 %rd238, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r292,%r293,%r294,%r295}, [%rd238];
	// end inline asm
	mov.b32 	%f1295, %r292;
	mov.b32 	%f1296, %r293;
	mov.b32 	%f1297, %r294;
	add.s64 	%rd242, %rd236, 32;
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd242;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r296,%r297,%r298,%r299}, [%rd241];
	// end inline asm
	mov.b32 	%f1292, %r296;
	mov.b32 	%f1293, %r297;
	mov.b32 	%f1294, %r298;
	setp.leu.f32 	%p21, %f260, 0f00000000;
	@%p21 bra 	$L__BB11_35;

	mov.f32 	%f848, 0f3F800000;
	sub.f32 	%f849, %f848, %f260;
	mul.lo.s64 	%rd254, %rd15, 48;
	add.s64 	%rd255, %rd209, %rd254;
	add.s64 	%rd246, %rd255, 80;
	// begin inline asm
	cvta.to.global.u64 %rd245, %rd246;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd245];
	// end inline asm
	mov.b32 	%f850, %r303;
	mov.b32 	%f851, %r304;
	mov.b32 	%f852, %r305;
	mul.f32 	%f853, %f260, %f850;
	mul.f32 	%f854, %f260, %f851;
	mul.f32 	%f855, %f260, %f852;
	fma.rn.f32 	%f1298, %f849, %f1298, %f853;
	fma.rn.f32 	%f1299, %f849, %f1299, %f854;
	fma.rn.f32 	%f1300, %f849, %f1300, %f855;
	add.s64 	%rd249, %rd255, 96;
	// begin inline asm
	cvta.to.global.u64 %rd248, %rd249;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd248];
	// end inline asm
	mov.b32 	%f856, %r307;
	mov.b32 	%f857, %r308;
	mov.b32 	%f858, %r309;
	mul.f32 	%f859, %f260, %f856;
	mul.f32 	%f860, %f260, %f857;
	mul.f32 	%f861, %f260, %f858;
	fma.rn.f32 	%f1295, %f849, %f1295, %f859;
	fma.rn.f32 	%f1296, %f849, %f1296, %f860;
	fma.rn.f32 	%f1297, %f849, %f1297, %f861;
	add.s64 	%rd252, %rd255, 112;
	// begin inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd251];
	// end inline asm
	mov.b32 	%f862, %r311;
	mov.b32 	%f863, %r312;
	mov.b32 	%f864, %r313;
	mul.f32 	%f865, %f260, %f862;
	mul.f32 	%f866, %f260, %f863;
	mul.f32 	%f867, %f260, %f864;
	fma.rn.f32 	%f1292, %f849, %f1292, %f865;
	fma.rn.f32 	%f1293, %f849, %f1293, %f866;
	fma.rn.f32 	%f1294, %f849, %f1294, %f867;
	bra.uni 	$L__BB11_35;

$L__BB11_24:
	mov.f32 	%f1301, 0f00000000;
	mov.f32 	%f1303, 0f3F800000;
	setp.eq.s32 	%p17, %r167, 4;
	@%p17 bra 	$L__BB11_27;

	setp.ne.s32 	%p18, %r167, 1;
	mov.f32 	%f1302, %f1301;
	mov.f32 	%f1304, %f1301;
	mov.f32 	%f1305, %f1303;
	mov.f32 	%f1306, %f1301;
	mov.f32 	%f1307, %f1303;
	mov.f32 	%f1308, %f1301;
	mov.f32 	%f1309, %f1301;
	@%p18 bra 	$L__BB11_36;

	// begin inline asm
	call (%rd139), _optix_get_static_transform_from_handle, (%rd137);
	// end inline asm
	add.s64 	%rd273, %rd139, 64;
	bra.uni 	$L__BB11_28;

$L__BB11_30:
	// begin inline asm
	call (%rd152), _optix_get_srt_motion_transform_from_handle, (%rd137);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd154, %rd152;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r181,%r182,%r183,%r184}, [%rd154];
	// end inline asm
	add.s64 	%rd158, %rd152, 16;
	// begin inline asm
	cvta.to.global.u64 %rd157, %rd158;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r185,%r186,%r187,%r188}, [%rd157];
	// end inline asm
	add.s64 	%rd161, %rd152, 32;
	// begin inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r189,%r190,%r191,%r192}, [%rd160];
	// end inline asm
	add.s64 	%rd164, %rd152, 48;
	// begin inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r193,%r194,%r195,%r196}, [%rd163];
	// end inline asm
	add.s64 	%rd167, %rd152, 64;
	// begin inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r197,%r198,%r199,%r200}, [%rd166];
	// end inline asm
	add.s64 	%rd170, %rd152, 80;
	// begin inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r201,%r202,%r203,%r204}, [%rd169];
	// end inline asm
	add.s64 	%rd173, %rd152, 96;
	// begin inline asm
	cvta.to.global.u64 %rd172, %rd173;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r205,%r206,%r207,%r208}, [%rd172];
	// end inline asm
	add.s64 	%rd176, %rd152, 112;
	// begin inline asm
	cvta.to.global.u64 %rd175, %rd176;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r209,%r210,%r211,%r212}, [%rd175];
	// end inline asm
	add.s64 	%rd179, %rd152, 128;
	// begin inline asm
	cvta.to.global.u64 %rd178, %rd179;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r213,%r214,%r215,%r216}, [%rd178];
	// end inline asm
	add.s64 	%rd182, %rd152, 144;
	// begin inline asm
	cvta.to.global.u64 %rd181, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r217,%r218,%r219,%r220}, [%rd181];
	// end inline asm
	mov.b32 	%f745, %r184;
	mov.b32 	%f746, %r185;
	and.b32  	%r237, %r183, 65535;
	add.s32 	%r238, %r237, -1;
	cvt.rn.f32.s32 	%f747, %r238;
	sub.f32 	%f748, %f733, %f745;
	mul.f32 	%f749, %f748, %f747;
	sub.f32 	%f750, %f746, %f745;
	div.rn.f32 	%f751, %f749, %f750;
	min.f32 	%f752, %f747, %f751;
	mov.f32 	%f753, 0f00000000;
	max.f32 	%f754, %f753, %f752;
	cvt.rmi.f32.f32 	%f755, %f754;
	sub.f32 	%f220, %f754, %f755;
	cvt.rzi.s32.f32 	%r239, %f755;
	mul.wide.s32 	%rd196, %r239, 64;
	add.s64 	%rd185, %rd161, %rd196;
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd185;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r221,%r222,%r223,%r224}, [%rd184];
	// end inline asm
	mov.b32 	%f1282, %r221;
	mov.b32 	%f1283, %r222;
	mov.b32 	%f1284, %r223;
	add.s64 	%rd188, %rd185, 16;
	// begin inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r225,%r226,%r227,%r228}, [%rd187];
	// end inline asm
	mov.b32 	%f1285, %r225;
	mov.b32 	%f1286, %r226;
	mov.b32 	%f1287, %r228;
	add.s64 	%rd191, %rd185, 32;
	// begin inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r229,%r230,%r231,%r232}, [%rd190];
	// end inline asm
	mov.b32 	%f1288, %r230;
	mov.b32 	%f1289, %r231;
	mov.b32 	%f1290, %r232;
	add.s64 	%rd194, %rd185, 48;
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r233,%r234,%r235,%r236}, [%rd193];
	// end inline asm
	mov.b32 	%f1291, %r233;
	setp.leu.f32 	%p20, %f220, 0f00000000;
	@%p20 bra 	$L__BB11_32;

	mov.f32 	%f756, 0f3F800000;
	sub.f32 	%f757, %f756, %f220;
	add.s64 	%rd198, %rd185, 64;
	// begin inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd197];
	// end inline asm
	mov.b32 	%f758, %r240;
	mov.b32 	%f759, %r241;
	mov.b32 	%f760, %r242;
	mul.f32 	%f761, %f220, %f758;
	mul.f32 	%f762, %f220, %f759;
	mul.f32 	%f763, %f220, %f760;
	fma.rn.f32 	%f1282, %f757, %f1282, %f761;
	fma.rn.f32 	%f1283, %f757, %f1283, %f762;
	fma.rn.f32 	%f1284, %f757, %f1284, %f763;
	add.s64 	%rd201, %rd185, 80;
	// begin inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd200];
	// end inline asm
	mov.b32 	%f764, %r244;
	mov.b32 	%f765, %r245;
	mov.b32 	%f766, %r247;
	mul.f32 	%f767, %f220, %f764;
	mul.f32 	%f768, %f220, %f765;
	mul.f32 	%f769, %f220, %f766;
	fma.rn.f32 	%f1285, %f757, %f1285, %f767;
	fma.rn.f32 	%f1286, %f757, %f1286, %f768;
	fma.rn.f32 	%f1287, %f757, %f1287, %f769;
	add.s64 	%rd204, %rd185, 96;
	// begin inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd203];
	// end inline asm
	mov.b32 	%f770, %r249;
	mov.b32 	%f771, %r250;
	mov.b32 	%f772, %r251;
	mul.f32 	%f773, %f220, %f770;
	mul.f32 	%f774, %f220, %f771;
	mul.f32 	%f775, %f220, %f772;
	fma.rn.f32 	%f776, %f757, %f1288, %f773;
	fma.rn.f32 	%f777, %f757, %f1289, %f774;
	fma.rn.f32 	%f778, %f757, %f1290, %f775;
	add.s64 	%rd207, %rd185, 112;
	// begin inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd206];
	// end inline asm
	mov.b32 	%f779, %r252;
	mul.f32 	%f780, %f220, %f779;
	fma.rn.f32 	%f781, %f757, %f1291, %f780;
	mul.f32 	%f782, %f777, %f777;
	fma.rn.f32 	%f783, %f776, %f776, %f782;
	fma.rn.f32 	%f784, %f778, %f778, %f783;
	fma.rn.f32 	%f785, %f781, %f781, %f784;
	sqrt.rn.f32 	%f786, %f785;
	rcp.rn.f32 	%f787, %f786;
	mul.f32 	%f1288, %f776, %f787;
	mul.f32 	%f1289, %f777, %f787;
	mul.f32 	%f1290, %f778, %f787;
	mul.f32 	%f1291, %f787, %f781;

$L__BB11_32:
	mul.f32 	%f788, %f1289, %f1289;
	fma.rn.f32 	%f789, %f1288, %f1288, %f788;
	fma.rn.f32 	%f790, %f1290, %f1290, %f789;
	fma.rn.f32 	%f791, %f1291, %f1291, %f790;
	rcp.rn.f32 	%f792, %f791;
	mul.f32 	%f793, %f1288, %f792;
	mul.f32 	%f794, %f1289, %f792;
	mul.f32 	%f795, %f1290, %f792;
	mul.f32 	%f796, %f1291, %f792;
	mul.f32 	%f797, %f1288, %f793;
	mul.f32 	%f798, %f1289, %f794;
	mul.f32 	%f799, %f1290, %f795;
	mul.f32 	%f800, %f1288, %f794;
	mul.f32 	%f801, %f1290, %f796;
	mul.f32 	%f802, %f1288, %f795;
	mul.f32 	%f803, %f1289, %f796;
	mul.f32 	%f804, %f1289, %f795;
	mul.f32 	%f805, %f1288, %f796;
	sub.f32 	%f806, %f797, %f798;
	sub.f32 	%f807, %f806, %f799;
	fma.rn.f32 	%f808, %f1291, %f796, %f807;
	sub.f32 	%f809, %f800, %f801;
	add.f32 	%f810, %f809, %f809;
	add.f32 	%f811, %f802, %f803;
	add.f32 	%f812, %f811, %f811;
	add.f32 	%f813, %f800, %f801;
	add.f32 	%f814, %f813, %f813;
	sub.f32 	%f815, %f798, %f797;
	sub.f32 	%f816, %f815, %f799;
	fma.rn.f32 	%f817, %f1291, %f796, %f816;
	sub.f32 	%f818, %f804, %f805;
	add.f32 	%f819, %f818, %f818;
	sub.f32 	%f820, %f802, %f803;
	add.f32 	%f821, %f820, %f820;
	add.f32 	%f822, %f804, %f805;
	add.f32 	%f823, %f822, %f822;
	neg.f32 	%f824, %f797;
	sub.f32 	%f825, %f824, %f798;
	add.f32 	%f826, %f799, %f825;
	fma.rn.f32 	%f827, %f1291, %f796, %f826;
	mul.f32 	%f828, %f1284, %f808;
	fma.rn.f32 	%f829, %f1286, %f810, %f828;
	fma.rn.f32 	%f1300, %f1287, %f812, %f829;
	mul.f32 	%f830, %f1286, %f817;
	fma.rn.f32 	%f831, %f1284, %f814, %f830;
	fma.rn.f32 	%f1297, %f1287, %f819, %f831;
	mul.f32 	%f832, %f1286, %f823;
	fma.rn.f32 	%f833, %f1284, %f821, %f832;
	fma.rn.f32 	%f1294, %f1287, %f827, %f833;
	mul.f32 	%f834, %f1283, %f808;
	fma.rn.f32 	%f1299, %f1285, %f810, %f834;
	mul.f32 	%f835, %f1285, %f817;
	fma.rn.f32 	%f1296, %f1283, %f814, %f835;
	mul.f32 	%f836, %f1285, %f823;
	fma.rn.f32 	%f1293, %f1283, %f821, %f836;
	mul.f32 	%f1298, %f1282, %f808;
	mul.f32 	%f1295, %f1282, %f814;
	mul.f32 	%f1292, %f1282, %f821;

$L__BB11_35:
	mul.f32 	%f868, %f1293, %f1297;
	mul.f32 	%f869, %f1294, %f1296;
	sub.f32 	%f870, %f869, %f868;
	mul.f32 	%f871, %f1298, %f870;
	mul.f32 	%f872, %f1292, %f1297;
	mul.f32 	%f873, %f1294, %f1295;
	sub.f32 	%f874, %f873, %f872;
	mul.f32 	%f875, %f874, %f1299;
	sub.f32 	%f876, %f871, %f875;
	mul.f32 	%f877, %f1292, %f1296;
	mul.f32 	%f878, %f1293, %f1295;
	sub.f32 	%f879, %f878, %f877;
	fma.rn.f32 	%f880, %f879, %f1300, %f876;
	rcp.rn.f32 	%f881, %f880;
	mul.f32 	%f1307, %f870, %f881;
	mul.f32 	%f882, %f1294, %f1299;
	mul.f32 	%f883, %f1293, %f1300;
	sub.f32 	%f884, %f883, %f882;
	mul.f32 	%f1308, %f884, %f881;
	mul.f32 	%f885, %f1296, %f1300;
	mul.f32 	%f886, %f1297, %f1299;
	sub.f32 	%f887, %f886, %f885;
	mul.f32 	%f1309, %f887, %f881;
	sub.f32 	%f888, %f872, %f873;
	mul.f32 	%f1304, %f888, %f881;
	mul.f32 	%f889, %f1292, %f1300;
	mul.f32 	%f890, %f1294, %f1298;
	sub.f32 	%f891, %f890, %f889;
	mul.f32 	%f1305, %f891, %f881;
	mul.f32 	%f892, %f1297, %f1298;
	mul.f32 	%f893, %f1295, %f1300;
	sub.f32 	%f894, %f893, %f892;
	mul.f32 	%f1306, %f894, %f881;
	mul.f32 	%f1301, %f879, %f881;
	mul.f32 	%f895, %f1293, %f1298;
	mul.f32 	%f896, %f1292, %f1299;
	sub.f32 	%f897, %f896, %f895;
	mul.f32 	%f1302, %f897, %f881;
	mul.f32 	%f898, %f1295, %f1299;
	mul.f32 	%f899, %f1296, %f1298;
	sub.f32 	%f900, %f899, %f898;
	mul.f32 	%f1303, %f900, %f881;
	bra.uni 	$L__BB11_36;

$L__BB11_27:
	// begin inline asm
	call (%rd273), _optix_get_instance_inverse_transform_from_handle, (%rd137);
	// end inline asm

$L__BB11_28:
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd273;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r169,%r170,%r171,%r172}, [%rd143];
	// end inline asm
	mov.b32 	%f1307, %r169;
	mov.b32 	%f1308, %r170;
	mov.b32 	%f1309, %r171;
	add.s64 	%rd147, %rd273, 16;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r173,%r174,%r175,%r176}, [%rd146];
	// end inline asm
	mov.b32 	%f1304, %r173;
	mov.b32 	%f1305, %r174;
	mov.b32 	%f1306, %r175;
	add.s64 	%rd150, %rd273, 32;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r177,%r178,%r179,%r180}, [%rd149];
	// end inline asm
	mov.b32 	%f1301, %r177;
	mov.b32 	%f1302, %r178;
	mov.b32 	%f1303, %r179;

$L__BB11_36:
	setp.eq.s32 	%p22, %r325, 0;
	@%p22 bra 	$L__BB11_38;

	mul.f32 	%f901, %f1278, %f1308;
	fma.rn.f32 	%f902, %f1275, %f1307, %f901;
	fma.rn.f32 	%f306, %f1281, %f1309, %f902;
	mul.f32 	%f903, %f1277, %f1308;
	fma.rn.f32 	%f904, %f1274, %f1307, %f903;
	fma.rn.f32 	%f307, %f1280, %f1309, %f904;
	mul.f32 	%f905, %f1276, %f1308;
	fma.rn.f32 	%f906, %f1273, %f1307, %f905;
	fma.rn.f32 	%f1309, %f1279, %f1309, %f906;
	mul.f32 	%f907, %f1278, %f1305;
	fma.rn.f32 	%f908, %f1275, %f1304, %f907;
	fma.rn.f32 	%f309, %f1281, %f1306, %f908;
	mul.f32 	%f909, %f1277, %f1305;
	fma.rn.f32 	%f910, %f1274, %f1304, %f909;
	fma.rn.f32 	%f310, %f1280, %f1306, %f910;
	mul.f32 	%f911, %f1276, %f1305;
	fma.rn.f32 	%f912, %f1273, %f1304, %f911;
	fma.rn.f32 	%f1306, %f1279, %f1306, %f912;
	mul.f32 	%f913, %f1278, %f1302;
	fma.rn.f32 	%f914, %f1275, %f1301, %f913;
	fma.rn.f32 	%f312, %f1281, %f1303, %f914;
	mul.f32 	%f915, %f1277, %f1302;
	fma.rn.f32 	%f916, %f1274, %f1301, %f915;
	fma.rn.f32 	%f313, %f1280, %f1303, %f916;
	mul.f32 	%f917, %f1276, %f1302;
	fma.rn.f32 	%f918, %f1273, %f1301, %f917;
	fma.rn.f32 	%f1303, %f1279, %f1303, %f918;
	mov.f32 	%f1301, %f312;
	mov.f32 	%f1302, %f313;
	mov.f32 	%f1304, %f309;
	mov.f32 	%f1305, %f310;
	mov.f32 	%f1307, %f306;
	mov.f32 	%f1308, %f307;

$L__BB11_38:
	add.s32 	%r325, %r325, 1;
	setp.lt.u32 	%p23, %r325, %r164;
	mov.f32 	%f1273, %f1309;
	mov.f32 	%f1274, %f1308;
	mov.f32 	%f1275, %f1307;
	mov.f32 	%f1276, %f1306;
	mov.f32 	%f1277, %f1305;
	mov.f32 	%f1278, %f1304;
	mov.f32 	%f1279, %f1303;
	mov.f32 	%f1280, %f1302;
	mov.f32 	%f1281, %f1301;
	@%p23 bra 	$L__BB11_23;

$L__BB11_39:
	mul.f32 	%f919, %f1329, %f1308;
	fma.rn.f32 	%f920, %f1328, %f1307, %f919;
	mul.f32 	%f921, %f1329, %f1305;
	fma.rn.f32 	%f922, %f1328, %f1304, %f921;
	mul.f32 	%f923, %f1329, %f1302;
	fma.rn.f32 	%f924, %f1328, %f1301, %f923;
	fma.rn.f32 	%f1330, %f732, %f1303, %f924;
	fma.rn.f32 	%f1329, %f732, %f1306, %f922;
	fma.rn.f32 	%f1328, %f732, %f1309, %f920;
	bra.uni 	$L__BB11_41;

$L__BB11_40:
	mov.f32 	%f1330, %f732;

$L__BB11_41:
	// begin inline asm
	call (%f925), _optix_get_ray_tmin, ();
	// end inline asm
	// begin inline asm
	call (%f926), _optix_get_ray_tmax, ();
	// end inline asm
	add.s64 	%rd16, %rd1, 288;
	ld.v4.f32 	{%f929, %f930, %f931, %f932}, [%rd1+288];
	ld.v4.f32 	{%f933, %f934, %f935, %f936}, [%rd1+304];
	ld.f32 	%f353, [%rd1+372];
	ld.f32 	%f354, [%rd1+376];
	sub.f32 	%f938, %f1270, %f929;
	sub.f32 	%f939, %f1271, %f930;
	sub.f32 	%f940, %f1272, %f931;
	add.f32 	%f355, %f933, 0f3F800000;
	mul.f32 	%f941, %f1330, %f1330;
	mul.f32 	%f942, %f355, %f941;
	fma.rn.f32 	%f943, %f1328, %f1328, %f942;
	fma.rn.f32 	%f356, %f1329, %f1329, %f943;
	add.f32 	%f944, %f355, %f355;
	mul.f32 	%f945, %f944, %f940;
	add.f32 	%f946, %f938, %f938;
	mul.f32 	%f947, %f1328, %f946;
	fma.rn.f32 	%f948, %f1330, %f945, %f947;
	add.f32 	%f949, %f939, %f939;
	fma.rn.f32 	%f950, %f1329, %f949, %f948;
	add.f32 	%f951, %f1330, %f1330;
	div.rn.f32 	%f952, %f951, %f934;
	sub.f32 	%f357, %f950, %f952;
	mul.f32 	%f953, %f940, %f940;
	mul.f32 	%f954, %f355, %f953;
	fma.rn.f32 	%f955, %f938, %f938, %f954;
	fma.rn.f32 	%f956, %f939, %f939, %f955;
	add.f32 	%f957, %f940, %f940;
	div.rn.f32 	%f958, %f957, %f934;
	sub.f32 	%f358, %f956, %f958;
	setp.eq.f32 	%p25, %f356, 0f00000000;
	setp.eq.f32 	%p26, %f357, 0f00000000;
	and.pred  	%p27, %p25, %p26;
	mov.pred 	%p69, -1;
	mov.pred 	%p68, %p69;
	@%p27 bra 	$L__BB11_44;

	neg.f32 	%f959, %f358;
	div.rn.f32 	%f1331, %f959, %f357;
	mul.f32 	%f960, %f356, 0fC0800000;
	mul.f32 	%f961, %f960, %f358;
	fma.rn.f32 	%f360, %f357, %f357, %f961;
	setp.neu.f32 	%p29, %f356, 0f00000000;
	setp.lt.f32 	%p30, %f360, 0f00000000;
	and.pred  	%p31, %p30, %p29;
	mov.f32 	%f1332, %f1331;
	@%p31 bra 	$L__BB11_44;

	mov.b32 	%r315, %f357;
	and.b32  	%r316, %r315, -2147483648;
	sqrt.rn.f32 	%f962, %f360;
	mov.b32 	%r317, %f962;
	and.b32  	%r318, %r317, 2147483647;
	or.b32  	%r319, %r318, %r316;
	mov.b32 	%f963, %r319;
	add.f32 	%f964, %f357, %f963;
	mul.f32 	%f965, %f964, 0fBF000000;
	div.rn.f32 	%f966, %f965, %f356;
	div.rn.f32 	%f967, %f358, %f965;
	min.f32 	%f968, %f966, %f967;
	max.f32 	%f969, %f966, %f967;
	selp.f32 	%f1332, %f1331, %f968, %p25;
	selp.f32 	%f1331, %f1331, %f969, %p25;
	mov.pred 	%p68, 0;

$L__BB11_44:
	@%p68 bra 	$L__BB11_46;

	fma.rn.f32 	%f971, %f1332, %f1328, %f1270;
	sub.f32 	%f972, %f971, %f929;
	fma.rn.f32 	%f973, %f1332, %f1329, %f1271;
	sub.f32 	%f974, %f973, %f930;
	fma.rn.f32 	%f975, %f1332, %f1330, %f1272;
	sub.f32 	%f976, %f975, %f931;
	mul.f32 	%f977, %f974, %f974;
	fma.rn.f32 	%f978, %f972, %f972, %f977;
	sqrt.rn.f32 	%f979, %f978;
	setp.le.f32 	%p35, %f979, %f936;
	setp.ge.f32 	%p36, %f976, %f353;
	and.pred  	%p37, %p36, %p35;
	setp.le.f32 	%p38, %f976, %f354;
	and.pred  	%p39, %p38, %p37;
	setp.ge.f32 	%p40, %f1332, %f925;
	and.pred  	%p41, %p39, %p40;
	setp.lt.f32 	%p42, %f1332, %f926;
	and.pred  	%p43, %p42, %p41;
	fma.rn.f32 	%f980, %f1331, %f1328, %f1270;
	sub.f32 	%f981, %f980, %f929;
	fma.rn.f32 	%f982, %f1331, %f1329, %f1271;
	sub.f32 	%f983, %f982, %f930;
	fma.rn.f32 	%f984, %f1331, %f1330, %f1272;
	sub.f32 	%f985, %f984, %f931;
	mul.f32 	%f986, %f983, %f983;
	fma.rn.f32 	%f987, %f981, %f981, %f986;
	sqrt.rn.f32 	%f988, %f987;
	setp.le.f32 	%p44, %f988, %f936;
	setp.ge.f32 	%p45, %f985, %f353;
	and.pred  	%p46, %p45, %p44;
	setp.le.f32 	%p47, %f985, %f354;
	and.pred  	%p48, %p47, %p46;
	setp.ge.f32 	%p49, %f1331, %f925;
	and.pred  	%p50, %p48, %p49;
	setp.lt.f32 	%p51, %f1331, %f926;
	and.pred  	%p52, %p51, %p50;
	or.pred  	%p53, %p43, %p52;
	selp.f32 	%f1373, %f1332, %f1331, %p43;
	not.pred 	%p69, %p53;

$L__BB11_46:
	@%p69 bra 	$L__BB11_62;

	fma.rn.f32 	%f1355, %f1373, %f1329, %f1271;
	fma.rn.f32 	%f1354, %f1373, %f1328, %f1270;
	sub.f32 	%f991, %f1354, %f929;
	sub.f32 	%f992, %f1355, %f930;
	mul.f32 	%f993, %f992, %f992;
	fma.rn.f32 	%f994, %f991, %f991, %f993;
	sqrt.rn.f32 	%f371, %f994;
	mul.f32 	%f372, %f371, %f371;
	mul.f32 	%f373, %f934, %f934;
	mul.f32 	%f374, %f373, %f355;
	ld.u8 	%rs1, [%rd16+72];
	setp.eq.s16 	%p54, %rs1, 0;
	ld.f32 	%f375, [%rd16+32];
	@%p54 bra 	$L__BB11_49;

	fma.rn.f32 	%f995, %f372, %f375, 0f00000000;
	ld.f32 	%f1352, [%rd16+36];
	mul.f32 	%f996, %f372, %f372;
	fma.rn.f32 	%f997, %f996, %f1352, %f995;
	mul.f32 	%f998, %f372, %f996;
	ld.f32 	%f1351, [%rd16+40];
	fma.rn.f32 	%f999, %f998, %f1351, %f997;
	mul.f32 	%f1000, %f372, %f998;
	ld.f32 	%f1350, [%rd16+44];
	fma.rn.f32 	%f1001, %f1000, %f1350, %f999;
	mul.f32 	%f1002, %f372, %f1000;
	ld.f32 	%f1349, [%rd16+48];
	fma.rn.f32 	%f1003, %f1002, %f1349, %f1001;
	mul.f32 	%f1004, %f372, %f1002;
	ld.f32 	%f1348, [%rd16+52];
	fma.rn.f32 	%f1005, %f1004, %f1348, %f1003;
	mul.f32 	%f1006, %f372, %f1004;
	ld.f32 	%f1347, [%rd16+56];
	fma.rn.f32 	%f1007, %f1006, %f1347, %f1005;
	mul.f32 	%f1008, %f372, %f1006;
	ld.f32 	%f1346, [%rd16+60];
	fma.rn.f32 	%f1009, %f1008, %f1346, %f1007;
	mul.f32 	%f1010, %f372, %f1008;
	ld.f32 	%f1345, [%rd16+64];
	fma.rn.f32 	%f1011, %f1010, %f1345, %f1009;
	mul.f32 	%f1012, %f372, %f1010;
	ld.f32 	%f1344, [%rd16+68];
	fma.rn.f32 	%f1343, %f1012, %f1344, %f1011;
	bra.uni 	$L__BB11_50;

$L__BB11_49:
	fma.rn.f32 	%f1013, %f371, %f375, 0f00000000;
	ld.f32 	%f1352, [%rd16+36];
	fma.rn.f32 	%f1014, %f372, %f1352, %f1013;
	ld.f32 	%f1351, [%rd16+40];
	mul.f32 	%f1015, %f371, %f372;
	fma.rn.f32 	%f1016, %f1015, %f1351, %f1014;
	mul.f32 	%f1017, %f371, %f1015;
	ld.f32 	%f1350, [%rd16+44];
	fma.rn.f32 	%f1018, %f1017, %f1350, %f1016;
	mul.f32 	%f1019, %f371, %f1017;
	ld.f32 	%f1349, [%rd16+48];
	fma.rn.f32 	%f1020, %f1019, %f1349, %f1018;
	mul.f32 	%f1021, %f371, %f1019;
	ld.f32 	%f1348, [%rd16+52];
	fma.rn.f32 	%f1022, %f1021, %f1348, %f1020;
	mul.f32 	%f1023, %f371, %f1021;
	ld.f32 	%f1347, [%rd16+56];
	fma.rn.f32 	%f1024, %f1023, %f1347, %f1022;
	mul.f32 	%f1025, %f371, %f1023;
	ld.f32 	%f1346, [%rd16+60];
	fma.rn.f32 	%f1026, %f1025, %f1346, %f1024;
	mul.f32 	%f1027, %f371, %f1025;
	ld.f32 	%f1345, [%rd16+64];
	fma.rn.f32 	%f1028, %f1027, %f1345, %f1026;
	mul.f32 	%f1029, %f371, %f1027;
	ld.f32 	%f1344, [%rd16+68];
	fma.rn.f32 	%f1343, %f1029, %f1344, %f1028;

$L__BB11_50:
	mul.f32 	%f1030, %f374, %f372;
	mov.f32 	%f1031, 0f3F800000;
	sub.f32 	%f1032, %f1031, %f1030;
	sqrt.rn.f32 	%f1033, %f1032;
	add.f32 	%f1034, %f1033, 0f3F800000;
	mul.f32 	%f1035, %f934, %f372;
	div.rn.f32 	%f1036, %f1035, %f1034;
	add.f32 	%f1037, %f1036, %f1343;
	fma.rn.f32 	%f410, %f1373, %f1330, %f1272;
	sub.f32 	%f1038, %f410, %f931;
	sub.f32 	%f1356, %f1037, %f1038;
	abs.f32 	%f1372, %f1356;
	setp.leu.f32 	%p55, %f1372, 0f358637BD;
	@%p55 bra 	$L__BB11_59;

	mov.u64 	%rd256, 2;
	cvt.rn.f32.u64 	%f412, %rd256;
	mov.u64 	%rd257, 4;
	cvt.rn.f32.u64 	%f413, %rd257;
	mov.u64 	%rd258, 6;
	cvt.rn.f32.u64 	%f414, %rd258;
	mov.u64 	%rd259, 8;
	cvt.rn.f32.u64 	%f415, %rd259;
	mov.u64 	%rd260, 10;
	cvt.rn.f32.u64 	%f416, %rd260;
	fma.rn.f32 	%f417, %f412, %f375, 0f00000000;
	mov.u32 	%r326, 0;
	mov.u64 	%rd266, 1;
	mov.u64 	%rd267, 3;
	mov.u64 	%rd268, 5;
	mov.u64 	%rd269, 7;
	mov.f32 	%f1358, %f1373;

$L__BB11_52:
	sub.f32 	%f435, %f1354, %f929;
	sub.f32 	%f436, %f1355, %f930;
	mul.f32 	%f437, %f435, %f435;
	mul.f32 	%f438, %f436, %f436;
	add.f32 	%f1039, %f437, %f438;
	sqrt.rn.f32 	%f439, %f1039;
	mov.f32 	%f1361, 0f00000000;
	@%p54 bra 	$L__BB11_54;

	mul.f32 	%f1040, %f439, %f439;
	mul.f32 	%f1041, %f413, %f1352;
	fma.rn.f32 	%f1042, %f1040, %f1041, %f417;
	mul.f32 	%f1043, %f1040, %f1040;
	mul.f32 	%f1044, %f414, %f1351;
	fma.rn.f32 	%f1045, %f1043, %f1044, %f1042;
	mul.f32 	%f1046, %f1040, %f1043;
	mul.f32 	%f1047, %f415, %f1350;
	fma.rn.f32 	%f1048, %f1046, %f1047, %f1045;
	mul.f32 	%f1049, %f1040, %f1046;
	mul.f32 	%f1050, %f416, %f1349;
	fma.rn.f32 	%f1051, %f1049, %f1050, %f1048;
	mul.f32 	%f1052, %f1040, %f1049;
	mov.u64 	%rd261, 12;
	cvt.rn.f32.u64 	%f1053, %rd261;
	mul.f32 	%f1054, %f1053, %f1348;
	fma.rn.f32 	%f1055, %f1052, %f1054, %f1051;
	mul.f32 	%f1056, %f1040, %f1052;
	mov.u64 	%rd262, 14;
	cvt.rn.f32.u64 	%f1057, %rd262;
	mul.f32 	%f1058, %f1057, %f1347;
	fma.rn.f32 	%f1059, %f1056, %f1058, %f1055;
	mul.f32 	%f1060, %f1040, %f1056;
	mov.u64 	%rd263, 16;
	cvt.rn.f32.u64 	%f1061, %rd263;
	mul.f32 	%f1062, %f1061, %f1346;
	fma.rn.f32 	%f1063, %f1060, %f1062, %f1059;
	mul.f32 	%f1064, %f1040, %f1060;
	mov.u64 	%rd264, 18;
	cvt.rn.f32.u64 	%f1065, %rd264;
	mul.f32 	%f1066, %f1065, %f1345;
	fma.rn.f32 	%f1067, %f1064, %f1066, %f1063;
	mul.f32 	%f1068, %f1040, %f1064;
	mov.u64 	%rd265, 20;
	cvt.rn.f32.u64 	%f1069, %rd265;
	mul.f32 	%f1070, %f1069, %f1344;
	fma.rn.f32 	%f1071, %f1068, %f1070, %f1067;
	mul.f32 	%f1360, %f436, %f1071;
	mul.f32 	%f1359, %f435, %f1071;
	bra.uni 	$L__BB11_55;

$L__BB11_54:
	rcp.rn.f32 	%f1072, %f439;
	cvt.rn.f32.u64 	%f1073, %rd266;
	mul.f32 	%f1074, %f1073, %f375;
	fma.rn.f32 	%f1075, %f1072, %f1074, 0f00000000;
	mul.f32 	%f1076, %f439, %f1072;
	mul.f32 	%f1077, %f412, %f1352;
	fma.rn.f32 	%f1078, %f1076, %f1077, %f1075;
	mul.f32 	%f1079, %f439, %f1076;
	cvt.rn.f32.u64 	%f1080, %rd267;
	mul.f32 	%f1081, %f1080, %f1351;
	fma.rn.f32 	%f1082, %f1079, %f1081, %f1078;
	mul.f32 	%f1083, %f439, %f1079;
	mul.f32 	%f1084, %f413, %f1350;
	fma.rn.f32 	%f1085, %f1083, %f1084, %f1082;
	mul.f32 	%f1086, %f439, %f1083;
	cvt.rn.f32.u64 	%f1087, %rd268;
	mul.f32 	%f1088, %f1087, %f1349;
	fma.rn.f32 	%f1089, %f1086, %f1088, %f1085;
	mul.f32 	%f1090, %f439, %f1086;
	mul.f32 	%f1091, %f414, %f1348;
	fma.rn.f32 	%f1092, %f1090, %f1091, %f1089;
	mul.f32 	%f1093, %f439, %f1090;
	cvt.rn.f32.u64 	%f1094, %rd269;
	mul.f32 	%f1095, %f1094, %f1347;
	fma.rn.f32 	%f1096, %f1093, %f1095, %f1092;
	mul.f32 	%f1097, %f439, %f1093;
	mul.f32 	%f1098, %f415, %f1346;
	fma.rn.f32 	%f1099, %f1097, %f1098, %f1096;
	mul.f32 	%f1100, %f439, %f1097;
	mov.u64 	%rd270, 9;
	cvt.rn.f32.u64 	%f1101, %rd270;
	mul.f32 	%f1102, %f1101, %f1345;
	fma.rn.f32 	%f1103, %f1100, %f1102, %f1099;
	mul.f32 	%f1104, %f439, %f1100;
	mul.f32 	%f1105, %f416, %f1344;
	fma.rn.f32 	%f1106, %f1104, %f1105, %f1103;
	mul.f32 	%f1360, %f436, %f1106;
	mul.f32 	%f1359, %f435, %f1106;

$L__BB11_55:
	sub.f32 	%f1193, %f1354, %f929;
	sub.f32 	%f1192, %f1355, %f930;
	mul.f32 	%f1191, %f1192, %f1192;
	mul.f32 	%f1190, %f1193, %f1193;
	mul.f32 	%f1107, %f373, %f1190;
	mul.f32 	%f1108, %f355, %f1107;
	sub.f32 	%f1110, %f1031, %f1108;
	sqrt.rn.f32 	%f1111, %f1110;
	mul.f32 	%f1112, %f934, %f1193;
	div.rn.f32 	%f1113, %f1112, %f1111;
	add.f32 	%f1114, %f1113, %f1359;
	mul.f32 	%f1115, %f373, %f1191;
	mul.f32 	%f1116, %f355, %f1115;
	sub.f32 	%f1117, %f1031, %f1116;
	sqrt.rn.f32 	%f1118, %f1117;
	mul.f32 	%f1119, %f934, %f1192;
	div.rn.f32 	%f1120, %f1119, %f1118;
	add.f32 	%f1121, %f1120, %f1360;
	add.f32 	%f1122, %f1361, 0fBF800000;
	mul.f32 	%f1123, %f1328, %f1114;
	fma.rn.f32 	%f1124, %f1329, %f1121, %f1123;
	fma.rn.f32 	%f1125, %f1330, %f1122, %f1124;
	div.rn.f32 	%f1126, %f1356, %f1125;
	sub.f32 	%f1358, %f1358, %f1126;
	fma.rn.f32 	%f1354, %f1358, %f1328, %f1270;
	fma.rn.f32 	%f1355, %f1358, %f1329, %f1271;
	sub.f32 	%f1127, %f1354, %f929;
	sub.f32 	%f1128, %f1355, %f930;
	mul.f32 	%f1129, %f1128, %f1128;
	fma.rn.f32 	%f1130, %f1127, %f1127, %f1129;
	sqrt.rn.f32 	%f455, %f1130;
	mul.f32 	%f456, %f455, %f455;
	@%p54 bra 	$L__BB11_57;

	fma.rn.f32 	%f1131, %f456, %f375, 0f00000000;
	mul.f32 	%f1132, %f456, %f456;
	fma.rn.f32 	%f1133, %f1132, %f1352, %f1131;
	mul.f32 	%f1134, %f456, %f1132;
	fma.rn.f32 	%f1135, %f1134, %f1351, %f1133;
	mul.f32 	%f1136, %f456, %f1134;
	fma.rn.f32 	%f1137, %f1136, %f1350, %f1135;
	mul.f32 	%f1138, %f456, %f1136;
	fma.rn.f32 	%f1139, %f1138, %f1349, %f1137;
	mul.f32 	%f1140, %f456, %f1138;
	fma.rn.f32 	%f1141, %f1140, %f1348, %f1139;
	mul.f32 	%f1142, %f456, %f1140;
	fma.rn.f32 	%f1143, %f1142, %f1347, %f1141;
	mul.f32 	%f1144, %f456, %f1142;
	fma.rn.f32 	%f1145, %f1144, %f1346, %f1143;
	mul.f32 	%f1146, %f456, %f1144;
	fma.rn.f32 	%f1147, %f1146, %f1345, %f1145;
	mul.f32 	%f1148, %f456, %f1146;
	fma.rn.f32 	%f1371, %f1148, %f1344, %f1147;
	bra.uni 	$L__BB11_58;

$L__BB11_57:
	fma.rn.f32 	%f1149, %f455, %f375, 0f00000000;
	fma.rn.f32 	%f1150, %f456, %f1352, %f1149;
	mul.f32 	%f1151, %f455, %f456;
	fma.rn.f32 	%f1152, %f1151, %f1351, %f1150;
	mul.f32 	%f1153, %f455, %f1151;
	fma.rn.f32 	%f1154, %f1153, %f1350, %f1152;
	mul.f32 	%f1155, %f455, %f1153;
	fma.rn.f32 	%f1156, %f1155, %f1349, %f1154;
	mul.f32 	%f1157, %f455, %f1155;
	fma.rn.f32 	%f1158, %f1157, %f1348, %f1156;
	mul.f32 	%f1159, %f455, %f1157;
	fma.rn.f32 	%f1160, %f1159, %f1347, %f1158;
	mul.f32 	%f1161, %f455, %f1159;
	fma.rn.f32 	%f1162, %f1161, %f1346, %f1160;
	mul.f32 	%f1163, %f455, %f1161;
	fma.rn.f32 	%f1164, %f1163, %f1345, %f1162;
	mul.f32 	%f1165, %f455, %f1163;
	fma.rn.f32 	%f1371, %f1165, %f1344, %f1164;

$L__BB11_58:
	mul.f32 	%f1166, %f374, %f456;
	sub.f32 	%f1168, %f1031, %f1166;
	sqrt.rn.f32 	%f1169, %f1168;
	add.f32 	%f1170, %f1169, 0f3F800000;
	mul.f32 	%f1171, %f934, %f456;
	div.rn.f32 	%f1172, %f1171, %f1170;
	add.f32 	%f1173, %f1172, %f1371;
	fma.rn.f32 	%f474, %f1358, %f1330, %f1272;
	sub.f32 	%f1174, %f474, %f931;
	sub.f32 	%f1356, %f1173, %f1174;
	abs.f32 	%f1175, %f1356;
	setp.lt.f32 	%p58, %f1175, %f1372;
	selp.f32 	%f1372, %f1175, %f1372, %p58;
	selp.f32 	%f1373, %f1358, %f1373, %p58;
	setp.gt.f32 	%p59, %f1175, 0f358637BD;
	add.s32 	%r326, %r326, 1;
	setp.lt.u32 	%p60, %r326, 8;
	and.pred  	%p61, %p60, %p59;
	@%p61 bra 	$L__BB11_52;

$L__BB11_59:
	setp.le.f32 	%p62, %f1372, 0f3727C5AC;
	@%p62 bra 	$L__BB11_62;

	fma.rn.f32 	%f1176, %f1373, %f1328, %f1270;
	sub.f32 	%f1177, %f1176, %f929;
	fma.rn.f32 	%f1178, %f1373, %f1329, %f1271;
	sub.f32 	%f1179, %f1178, %f930;
	fma.rn.f32 	%f1180, %f1373, %f1330, %f1272;
	sub.f32 	%f1181, %f1180, %f931;
	mul.f32 	%f1182, %f1179, %f1179;
	fma.rn.f32 	%f1183, %f1177, %f1177, %f1182;
	sqrt.rn.f32 	%f1184, %f1183;
	setp.gtu.f32 	%p63, %f1184, %f936;
	ld.f32 	%f1185, [%rd16+76];
	setp.ltu.f32 	%p64, %f1181, %f1185;
	or.pred  	%p65, %p64, %p63;
	ld.f32 	%f1186, [%rd16+80];
	setp.gtu.f32 	%p66, %f1181, %f1186;
	or.pred  	%p67, %p66, %p65;
	@%p67 bra 	$L__BB11_62;

	mov.u32 	%r322, 254;
	// begin inline asm
	call (%r321), _optix_report_intersection_0, (%f1373, %r322);
	// end inline asm

$L__BB11_62:
	ret;

}
	// .globl	__closesthit__polyasphsurf
.visible .entry __closesthit__polyasphsurf()
{
	.reg .pred 	%p<60>;
	.reg .b16 	%rs<4>;
	.reg .f32 	%f<2180>;
	.reg .b32 	%r<650>;
	.reg .b64 	%rd<667>;


	// begin inline asm
	call (%r25), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r26), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r28), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r29), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r30), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r31, %r30, %r26, %r29;
	mad.lo.s32 	%r1, %r31, %r25, %r28;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64 	%p1, %rd1, 0;
	@%p1 bra 	$L__BB12_2;

	cvta.to.global.u64 	%rd44, %rd1;
	cvt.u64.u32 	%rd45, %r1;
	add.s64 	%rd46, %rd44, %rd45;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd46], %rs1;
	bra.uni 	$L__BB12_117;

$L__BB12_2:
	// begin inline asm
	call (%rd47), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd3, [%rd47+8];
	// begin inline asm
	call (%f1953), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1954), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1955), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r32), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p2, %r32, 0;
	@%p2 bra 	$L__BB12_23;

	// begin inline asm
	call (%r33), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f737), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p3, %r33, 0;
	@%p3 bra 	$L__BB12_21;

	mov.u32 	%r645, 0;

$L__BB12_5:
	.pragma "nounroll";
	// begin inline asm
	call (%rd48), _optix_get_transform_list_handle, (%r645);
	// end inline asm
	// begin inline asm
	call (%r36), _optix_get_transform_type_from_handle, (%rd48);
	// end inline asm
	or.b32  	%r37, %r36, 1;
	setp.eq.s32 	%p4, %r37, 3;
	@%p4 bra 	$L__BB12_11;
	bra.uni 	$L__BB12_6;

$L__BB12_11:
	setp.eq.s32 	%p7, %r36, 2;
	@%p7 bra 	$L__BB12_15;
	bra.uni 	$L__BB12_12;

$L__BB12_15:
	// begin inline asm
	call (%rd120), _optix_get_matrix_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r125,%r126,%r127,%r128}, [%rd122];
	// end inline asm
	add.s64 	%rd126, %rd120, 16;
	// begin inline asm
	cvta.to.global.u64 %rd125, %rd126;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r129,%r130,%r131,%r132}, [%rd125];
	// end inline asm
	add.s64 	%rd129, %rd120, 32;
	// begin inline asm
	cvta.to.global.u64 %rd128, %rd129;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r133,%r134,%r135,%r136}, [%rd128];
	// end inline asm
	add.s64 	%rd132, %rd120, 48;
	// begin inline asm
	cvta.to.global.u64 %rd131, %rd132;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r137,%r138,%r139,%r140}, [%rd131];
	// end inline asm
	add.s64 	%rd135, %rd120, 64;
	// begin inline asm
	cvta.to.global.u64 %rd134, %rd135;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r141,%r142,%r143,%r144}, [%rd134];
	// end inline asm
	add.s64 	%rd138, %rd120, 80;
	// begin inline asm
	cvta.to.global.u64 %rd137, %rd138;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r145,%r146,%r147,%r148}, [%rd137];
	// end inline asm
	add.s64 	%rd141, %rd120, 96;
	// begin inline asm
	cvta.to.global.u64 %rd140, %rd141;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r149,%r150,%r151,%r152}, [%rd140];
	// end inline asm
	add.s64 	%rd144, %rd120, 112;
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd144;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r153,%r154,%r155,%r156}, [%rd143];
	// end inline asm
	mov.b32 	%f865, %r128;
	mov.b32 	%f866, %r129;
	and.b32  	%r169, %r127, 65535;
	add.s32 	%r170, %r169, -1;
	cvt.rn.f32.s32 	%f867, %r170;
	sub.f32 	%f868, %f737, %f865;
	mul.f32 	%f869, %f868, %f867;
	sub.f32 	%f870, %f866, %f865;
	div.rn.f32 	%f871, %f869, %f870;
	min.f32 	%f872, %f867, %f871;
	mov.f32 	%f873, 0f00000000;
	max.f32 	%f874, %f873, %f872;
	cvt.rmi.f32.f32 	%f875, %f874;
	sub.f32 	%f90, %f874, %f875;
	cvt.rzi.s32.f32 	%r171, %f875;
	mul.wide.s32 	%rd155, %r171, 48;
	add.s64 	%rd147, %rd129, %rd155;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r157,%r158,%r159,%r160}, [%rd146];
	// end inline asm
	mov.b32 	%f1908, %r157;
	mov.b32 	%f1907, %r158;
	mov.b32 	%f1906, %r159;
	mov.b32 	%f1905, %r160;
	add.s64 	%rd150, %rd147, 16;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r161,%r162,%r163,%r164}, [%rd149];
	// end inline asm
	mov.b32 	%f1912, %r161;
	mov.b32 	%f1911, %r162;
	mov.b32 	%f1910, %r163;
	mov.b32 	%f1909, %r164;
	add.s64 	%rd153, %rd147, 32;
	// begin inline asm
	cvta.to.global.u64 %rd152, %rd153;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r165,%r166,%r167,%r168}, [%rd152];
	// end inline asm
	mov.b32 	%f1916, %r165;
	mov.b32 	%f1915, %r166;
	mov.b32 	%f1914, %r167;
	mov.b32 	%f1913, %r168;
	setp.leu.f32 	%p9, %f90, 0f00000000;
	@%p9 bra 	$L__BB12_17;

	cvt.rmi.f32.f32 	%f1876, %f874;
	cvt.rzi.s32.f32 	%r644, %f1876;
	cvt.s64.s32 	%rd662, %r644;
	mov.f32 	%f876, 0f3F800000;
	sub.f32 	%f877, %f876, %f90;
	mul.lo.s64 	%rd165, %rd662, 48;
	add.s64 	%rd166, %rd120, %rd165;
	add.s64 	%rd157, %rd166, 80;
	// begin inline asm
	cvta.to.global.u64 %rd156, %rd157;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r172,%r173,%r174,%r175}, [%rd156];
	// end inline asm
	mov.b32 	%f878, %r172;
	mov.b32 	%f879, %r173;
	mov.b32 	%f880, %r174;
	mov.b32 	%f881, %r175;
	mul.f32 	%f882, %f90, %f878;
	mul.f32 	%f883, %f90, %f879;
	mul.f32 	%f884, %f90, %f880;
	mul.f32 	%f885, %f90, %f881;
	fma.rn.f32 	%f1908, %f877, %f1908, %f882;
	fma.rn.f32 	%f1907, %f877, %f1907, %f883;
	fma.rn.f32 	%f1906, %f877, %f1906, %f884;
	fma.rn.f32 	%f1905, %f877, %f1905, %f885;
	add.s64 	%rd160, %rd166, 96;
	// begin inline asm
	cvta.to.global.u64 %rd159, %rd160;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r176,%r177,%r178,%r179}, [%rd159];
	// end inline asm
	mov.b32 	%f886, %r176;
	mov.b32 	%f887, %r177;
	mov.b32 	%f888, %r178;
	mov.b32 	%f889, %r179;
	mul.f32 	%f890, %f90, %f886;
	mul.f32 	%f891, %f90, %f887;
	mul.f32 	%f892, %f90, %f888;
	mul.f32 	%f893, %f90, %f889;
	fma.rn.f32 	%f1912, %f877, %f1912, %f890;
	fma.rn.f32 	%f1911, %f877, %f1911, %f891;
	fma.rn.f32 	%f1910, %f877, %f1910, %f892;
	fma.rn.f32 	%f1909, %f877, %f1909, %f893;
	add.s64 	%rd163, %rd166, 112;
	// begin inline asm
	cvta.to.global.u64 %rd162, %rd163;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r180,%r181,%r182,%r183}, [%rd162];
	// end inline asm
	mov.b32 	%f894, %r180;
	mov.b32 	%f895, %r181;
	mov.b32 	%f896, %r182;
	mov.b32 	%f897, %r183;
	mul.f32 	%f898, %f90, %f894;
	mul.f32 	%f899, %f90, %f895;
	mul.f32 	%f900, %f90, %f896;
	mul.f32 	%f901, %f90, %f897;
	fma.rn.f32 	%f1916, %f877, %f1916, %f898;
	fma.rn.f32 	%f1915, %f877, %f1915, %f899;
	fma.rn.f32 	%f1914, %f877, %f1914, %f900;
	fma.rn.f32 	%f1913, %f877, %f1913, %f901;
	bra.uni 	$L__BB12_17;

$L__BB12_6:
	mov.f32 	%f1917, 0f00000000;
	mov.f32 	%f1920, 0f3F800000;
	setp.eq.s32 	%p5, %r36, 4;
	@%p5 bra 	$L__BB12_9;

	setp.ne.s32 	%p6, %r36, 1;
	mov.f32 	%f1918, %f1917;
	mov.f32 	%f1919, %f1917;
	mov.f32 	%f1921, %f1917;
	mov.f32 	%f1922, %f1917;
	mov.f32 	%f1923, %f1920;
	mov.f32 	%f1924, %f1917;
	mov.f32 	%f1925, %f1917;
	mov.f32 	%f1926, %f1920;
	mov.f32 	%f1927, %f1917;
	mov.f32 	%f1928, %f1917;
	@%p6 bra 	$L__BB12_18;

	// begin inline asm
	call (%rd50), _optix_get_static_transform_from_handle, (%rd48);
	// end inline asm
	add.s64 	%rd663, %rd50, 64;
	bra.uni 	$L__BB12_10;

$L__BB12_12:
	// begin inline asm
	call (%rd63), _optix_get_srt_motion_transform_from_handle, (%rd48);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r50,%r51,%r52,%r53}, [%rd65];
	// end inline asm
	add.s64 	%rd69, %rd63, 16;
	// begin inline asm
	cvta.to.global.u64 %rd68, %rd69;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r54,%r55,%r56,%r57}, [%rd68];
	// end inline asm
	add.s64 	%rd72, %rd63, 32;
	// begin inline asm
	cvta.to.global.u64 %rd71, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r58,%r59,%r60,%r61}, [%rd71];
	// end inline asm
	add.s64 	%rd75, %rd63, 48;
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd75;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r62,%r63,%r64,%r65}, [%rd74];
	// end inline asm
	add.s64 	%rd78, %rd63, 64;
	// begin inline asm
	cvta.to.global.u64 %rd77, %rd78;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r66,%r67,%r68,%r69}, [%rd77];
	// end inline asm
	add.s64 	%rd81, %rd63, 80;
	// begin inline asm
	cvta.to.global.u64 %rd80, %rd81;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r70,%r71,%r72,%r73}, [%rd80];
	// end inline asm
	add.s64 	%rd84, %rd63, 96;
	// begin inline asm
	cvta.to.global.u64 %rd83, %rd84;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r74,%r75,%r76,%r77}, [%rd83];
	// end inline asm
	add.s64 	%rd87, %rd63, 112;
	// begin inline asm
	cvta.to.global.u64 %rd86, %rd87;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r78,%r79,%r80,%r81}, [%rd86];
	// end inline asm
	add.s64 	%rd90, %rd63, 128;
	// begin inline asm
	cvta.to.global.u64 %rd89, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r82,%r83,%r84,%r85}, [%rd89];
	// end inline asm
	add.s64 	%rd93, %rd63, 144;
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd93;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r86,%r87,%r88,%r89}, [%rd92];
	// end inline asm
	mov.b32 	%f752, %r53;
	mov.b32 	%f753, %r54;
	and.b32  	%r106, %r52, 65535;
	add.s32 	%r107, %r106, -1;
	cvt.rn.f32.s32 	%f754, %r107;
	sub.f32 	%f755, %f737, %f752;
	mul.f32 	%f756, %f755, %f754;
	sub.f32 	%f757, %f753, %f752;
	div.rn.f32 	%f758, %f756, %f757;
	min.f32 	%f759, %f754, %f758;
	mov.f32 	%f760, 0f00000000;
	max.f32 	%f761, %f760, %f759;
	cvt.rmi.f32.f32 	%f762, %f761;
	sub.f32 	%f29, %f761, %f762;
	cvt.rzi.s32.f32 	%r108, %f762;
	mul.wide.s32 	%rd107, %r108, 64;
	add.s64 	%rd96, %rd72, %rd107;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r90,%r91,%r92,%r93}, [%rd95];
	// end inline asm
	mov.b32 	%f1889, %r90;
	mov.b32 	%f1890, %r91;
	mov.b32 	%f1891, %r92;
	mov.b32 	%f1892, %r93;
	add.s64 	%rd99, %rd96, 16;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r94,%r95,%r96,%r97}, [%rd98];
	// end inline asm
	mov.b32 	%f1893, %r94;
	mov.b32 	%f1894, %r95;
	mov.b32 	%f1895, %r96;
	mov.b32 	%f1896, %r97;
	add.s64 	%rd102, %rd96, 32;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r98,%r99,%r100,%r101}, [%rd101];
	// end inline asm
	mov.b32 	%f1897, %r98;
	mov.b32 	%f1898, %r99;
	mov.b32 	%f1899, %r100;
	mov.b32 	%f1900, %r101;
	add.s64 	%rd105, %rd96, 48;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r102,%r103,%r104,%r105}, [%rd104];
	// end inline asm
	mov.b32 	%f1901, %r102;
	mov.b32 	%f1902, %r103;
	mov.b32 	%f1903, %r104;
	mov.b32 	%f1904, %r105;
	setp.leu.f32 	%p8, %f29, 0f00000000;
	@%p8 bra 	$L__BB12_14;

	mov.f32 	%f763, 0f3F800000;
	sub.f32 	%f764, %f763, %f29;
	add.s64 	%rd109, %rd96, 64;
	// begin inline asm
	cvta.to.global.u64 %rd108, %rd109;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r109,%r110,%r111,%r112}, [%rd108];
	// end inline asm
	mov.b32 	%f765, %r109;
	mov.b32 	%f766, %r110;
	mov.b32 	%f767, %r111;
	mov.b32 	%f768, %r112;
	mul.f32 	%f769, %f29, %f765;
	mul.f32 	%f770, %f29, %f766;
	mul.f32 	%f771, %f29, %f767;
	mul.f32 	%f772, %f29, %f768;
	fma.rn.f32 	%f1889, %f764, %f1889, %f769;
	fma.rn.f32 	%f1890, %f764, %f1890, %f770;
	fma.rn.f32 	%f1891, %f764, %f1891, %f771;
	fma.rn.f32 	%f1892, %f764, %f1892, %f772;
	add.s64 	%rd112, %rd96, 80;
	// begin inline asm
	cvta.to.global.u64 %rd111, %rd112;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r113,%r114,%r115,%r116}, [%rd111];
	// end inline asm
	mov.b32 	%f773, %r113;
	mov.b32 	%f774, %r114;
	mov.b32 	%f775, %r115;
	mov.b32 	%f776, %r116;
	mul.f32 	%f777, %f29, %f773;
	mul.f32 	%f778, %f29, %f774;
	mul.f32 	%f779, %f29, %f775;
	mul.f32 	%f780, %f29, %f776;
	fma.rn.f32 	%f1893, %f764, %f1893, %f777;
	fma.rn.f32 	%f1894, %f764, %f1894, %f778;
	fma.rn.f32 	%f1895, %f764, %f1895, %f779;
	fma.rn.f32 	%f1896, %f764, %f1896, %f780;
	add.s64 	%rd115, %rd96, 96;
	// begin inline asm
	cvta.to.global.u64 %rd114, %rd115;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r117,%r118,%r119,%r120}, [%rd114];
	// end inline asm
	mov.b32 	%f781, %r117;
	mov.b32 	%f782, %r118;
	mov.b32 	%f783, %r119;
	mov.b32 	%f784, %r120;
	mul.f32 	%f785, %f29, %f781;
	mul.f32 	%f786, %f29, %f782;
	mul.f32 	%f787, %f29, %f783;
	mul.f32 	%f788, %f29, %f784;
	fma.rn.f32 	%f1897, %f764, %f1897, %f785;
	fma.rn.f32 	%f789, %f764, %f1898, %f786;
	fma.rn.f32 	%f790, %f764, %f1899, %f787;
	fma.rn.f32 	%f791, %f764, %f1900, %f788;
	add.s64 	%rd118, %rd96, 112;
	// begin inline asm
	cvta.to.global.u64 %rd117, %rd118;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r121,%r122,%r123,%r124}, [%rd117];
	// end inline asm
	mov.b32 	%f792, %r121;
	mov.b32 	%f793, %r122;
	mov.b32 	%f794, %r123;
	mov.b32 	%f795, %r124;
	mul.f32 	%f796, %f29, %f792;
	mul.f32 	%f797, %f29, %f793;
	mul.f32 	%f798, %f29, %f794;
	mul.f32 	%f799, %f29, %f795;
	fma.rn.f32 	%f800, %f764, %f1901, %f796;
	fma.rn.f32 	%f1902, %f764, %f1902, %f797;
	fma.rn.f32 	%f1903, %f764, %f1903, %f798;
	fma.rn.f32 	%f1904, %f764, %f1904, %f799;
	mul.f32 	%f801, %f790, %f790;
	fma.rn.f32 	%f802, %f789, %f789, %f801;
	fma.rn.f32 	%f803, %f791, %f791, %f802;
	fma.rn.f32 	%f804, %f800, %f800, %f803;
	sqrt.rn.f32 	%f805, %f804;
	rcp.rn.f32 	%f806, %f805;
	mul.f32 	%f1898, %f789, %f806;
	mul.f32 	%f1899, %f790, %f806;
	mul.f32 	%f1900, %f791, %f806;
	mul.f32 	%f1901, %f806, %f800;

$L__BB12_14:
	mul.f32 	%f807, %f1899, %f1899;
	fma.rn.f32 	%f808, %f1898, %f1898, %f807;
	fma.rn.f32 	%f809, %f1900, %f1900, %f808;
	fma.rn.f32 	%f810, %f1901, %f1901, %f809;
	rcp.rn.f32 	%f811, %f810;
	mul.f32 	%f812, %f1898, %f811;
	mul.f32 	%f813, %f1899, %f811;
	mul.f32 	%f814, %f1900, %f811;
	mul.f32 	%f815, %f1901, %f811;
	mul.f32 	%f816, %f1898, %f812;
	mul.f32 	%f817, %f1899, %f813;
	mul.f32 	%f818, %f1900, %f814;
	mul.f32 	%f819, %f1898, %f813;
	mul.f32 	%f820, %f1900, %f815;
	mul.f32 	%f821, %f1898, %f814;
	mul.f32 	%f822, %f1899, %f815;
	mul.f32 	%f823, %f1899, %f814;
	mul.f32 	%f824, %f1898, %f815;
	sub.f32 	%f825, %f816, %f817;
	sub.f32 	%f826, %f825, %f818;
	fma.rn.f32 	%f827, %f1901, %f815, %f826;
	sub.f32 	%f828, %f819, %f820;
	add.f32 	%f829, %f828, %f828;
	add.f32 	%f830, %f821, %f822;
	add.f32 	%f831, %f830, %f830;
	add.f32 	%f832, %f819, %f820;
	add.f32 	%f833, %f832, %f832;
	sub.f32 	%f834, %f817, %f816;
	sub.f32 	%f835, %f834, %f818;
	fma.rn.f32 	%f836, %f1901, %f815, %f835;
	sub.f32 	%f837, %f823, %f824;
	add.f32 	%f838, %f837, %f837;
	sub.f32 	%f839, %f821, %f822;
	add.f32 	%f840, %f839, %f839;
	add.f32 	%f841, %f823, %f824;
	add.f32 	%f842, %f841, %f841;
	neg.f32 	%f843, %f816;
	sub.f32 	%f844, %f843, %f817;
	add.f32 	%f845, %f818, %f844;
	fma.rn.f32 	%f846, %f1901, %f815, %f845;
	mul.f32 	%f847, %f1892, %f827;
	fma.rn.f32 	%f848, %f1895, %f829, %f847;
	fma.rn.f32 	%f849, %f1897, %f831, %f848;
	sub.f32 	%f1905, %f1902, %f849;
	mul.f32 	%f850, %f1895, %f836;
	fma.rn.f32 	%f851, %f1892, %f833, %f850;
	fma.rn.f32 	%f852, %f1897, %f838, %f851;
	sub.f32 	%f1909, %f1903, %f852;
	mul.f32 	%f853, %f1895, %f842;
	fma.rn.f32 	%f854, %f1892, %f840, %f853;
	fma.rn.f32 	%f855, %f1897, %f846, %f854;
	sub.f32 	%f1913, %f1904, %f855;
	mul.f32 	%f856, %f1891, %f827;
	fma.rn.f32 	%f857, %f1894, %f829, %f856;
	fma.rn.f32 	%f1906, %f1896, %f831, %f857;
	mul.f32 	%f858, %f1894, %f836;
	fma.rn.f32 	%f859, %f1891, %f833, %f858;
	fma.rn.f32 	%f1910, %f1896, %f838, %f859;
	mul.f32 	%f860, %f1894, %f842;
	fma.rn.f32 	%f861, %f1891, %f840, %f860;
	fma.rn.f32 	%f1914, %f1896, %f846, %f861;
	mul.f32 	%f862, %f1890, %f827;
	fma.rn.f32 	%f1907, %f1893, %f829, %f862;
	mul.f32 	%f863, %f1893, %f836;
	fma.rn.f32 	%f1911, %f1890, %f833, %f863;
	mul.f32 	%f864, %f1893, %f842;
	fma.rn.f32 	%f1915, %f1890, %f840, %f864;
	mul.f32 	%f1908, %f1889, %f827;
	mul.f32 	%f1912, %f1889, %f833;
	mul.f32 	%f1916, %f1889, %f840;

$L__BB12_17:
	mul.f32 	%f902, %f1910, %f1915;
	mul.f32 	%f903, %f1911, %f1914;
	sub.f32 	%f904, %f903, %f902;
	mul.f32 	%f905, %f1908, %f904;
	mul.f32 	%f906, %f1910, %f1916;
	mul.f32 	%f907, %f1912, %f1914;
	sub.f32 	%f908, %f907, %f906;
	mul.f32 	%f909, %f1907, %f908;
	sub.f32 	%f910, %f905, %f909;
	mul.f32 	%f911, %f1911, %f1916;
	mul.f32 	%f912, %f1912, %f1915;
	sub.f32 	%f913, %f912, %f911;
	fma.rn.f32 	%f914, %f1906, %f913, %f910;
	rcp.rn.f32 	%f915, %f914;
	mul.f32 	%f1920, %f904, %f915;
	mul.f32 	%f916, %f1907, %f1914;
	mul.f32 	%f917, %f1906, %f1915;
	sub.f32 	%f918, %f917, %f916;
	mul.f32 	%f1919, %f918, %f915;
	mul.f32 	%f919, %f1906, %f1911;
	mul.f32 	%f920, %f1907, %f1910;
	sub.f32 	%f921, %f920, %f919;
	mul.f32 	%f1918, %f921, %f915;
	sub.f32 	%f922, %f906, %f907;
	mul.f32 	%f1924, %f922, %f915;
	mul.f32 	%f923, %f1906, %f1916;
	mul.f32 	%f924, %f1908, %f1914;
	sub.f32 	%f925, %f924, %f923;
	mul.f32 	%f1923, %f925, %f915;
	mul.f32 	%f926, %f1908, %f1910;
	mul.f32 	%f927, %f1906, %f1912;
	sub.f32 	%f928, %f927, %f926;
	mul.f32 	%f1922, %f928, %f915;
	mul.f32 	%f1928, %f913, %f915;
	mul.f32 	%f929, %f1908, %f1915;
	mul.f32 	%f930, %f1907, %f1916;
	sub.f32 	%f931, %f930, %f929;
	mul.f32 	%f1927, %f931, %f915;
	mul.f32 	%f932, %f1907, %f1912;
	mul.f32 	%f933, %f1908, %f1911;
	sub.f32 	%f934, %f933, %f932;
	mul.f32 	%f1926, %f934, %f915;
	mul.f32 	%f935, %f1905, %f1920;
	neg.f32 	%f936, %f935;
	mul.f32 	%f937, %f1909, %f1919;
	sub.f32 	%f938, %f936, %f937;
	mul.f32 	%f939, %f1913, %f1918;
	sub.f32 	%f1917, %f938, %f939;
	mul.f32 	%f940, %f1905, %f1924;
	neg.f32 	%f941, %f940;
	mul.f32 	%f942, %f1909, %f1923;
	sub.f32 	%f943, %f941, %f942;
	mul.f32 	%f944, %f1913, %f1922;
	sub.f32 	%f1921, %f943, %f944;
	mul.f32 	%f945, %f1905, %f1928;
	neg.f32 	%f946, %f945;
	mul.f32 	%f947, %f1909, %f1927;
	sub.f32 	%f948, %f946, %f947;
	mul.f32 	%f949, %f1913, %f1926;
	sub.f32 	%f1925, %f948, %f949;
	bra.uni 	$L__BB12_18;

$L__BB12_9:
	// begin inline asm
	call (%rd663), _optix_get_instance_inverse_transform_from_handle, (%rd48);
	// end inline asm

$L__BB12_10:
	// begin inline asm
	cvta.to.global.u64 %rd54, %rd663;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r38,%r39,%r40,%r41}, [%rd54];
	// end inline asm
	mov.b32 	%f1920, %r38;
	mov.b32 	%f1919, %r39;
	mov.b32 	%f1918, %r40;
	mov.b32 	%f1917, %r41;
	add.s64 	%rd58, %rd663, 16;
	// begin inline asm
	cvta.to.global.u64 %rd57, %rd58;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r42,%r43,%r44,%r45}, [%rd57];
	// end inline asm
	mov.b32 	%f1924, %r42;
	mov.b32 	%f1923, %r43;
	mov.b32 	%f1922, %r44;
	mov.b32 	%f1921, %r45;
	add.s64 	%rd61, %rd663, 32;
	// begin inline asm
	cvta.to.global.u64 %rd60, %rd61;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r46,%r47,%r48,%r49}, [%rd60];
	// end inline asm
	mov.b32 	%f1928, %r46;
	mov.b32 	%f1927, %r47;
	mov.b32 	%f1926, %r48;
	mov.b32 	%f1925, %r49;

$L__BB12_18:
	setp.eq.s32 	%p10, %r645, 0;
	@%p10 bra 	$L__BB12_20;

	mul.f32 	%f950, %f1885, %f1920;
	fma.rn.f32 	%f951, %f1881, %f1919, %f950;
	fma.rn.f32 	%f151, %f1877, %f1918, %f951;
	mul.f32 	%f952, %f1886, %f1920;
	fma.rn.f32 	%f953, %f1882, %f1919, %f952;
	fma.rn.f32 	%f152, %f1878, %f1918, %f953;
	mul.f32 	%f954, %f1887, %f1920;
	fma.rn.f32 	%f955, %f1883, %f1919, %f954;
	fma.rn.f32 	%f153, %f1879, %f1918, %f955;
	mul.f32 	%f956, %f1888, %f1920;
	fma.rn.f32 	%f957, %f1884, %f1919, %f956;
	fma.rn.f32 	%f958, %f1880, %f1918, %f957;
	add.f32 	%f1917, %f1917, %f958;
	mul.f32 	%f959, %f1885, %f1924;
	fma.rn.f32 	%f960, %f1881, %f1923, %f959;
	fma.rn.f32 	%f155, %f1877, %f1922, %f960;
	mul.f32 	%f961, %f1886, %f1924;
	fma.rn.f32 	%f962, %f1882, %f1923, %f961;
	fma.rn.f32 	%f156, %f1878, %f1922, %f962;
	mul.f32 	%f963, %f1887, %f1924;
	fma.rn.f32 	%f964, %f1883, %f1923, %f963;
	fma.rn.f32 	%f157, %f1879, %f1922, %f964;
	mul.f32 	%f965, %f1888, %f1924;
	fma.rn.f32 	%f966, %f1884, %f1923, %f965;
	fma.rn.f32 	%f967, %f1880, %f1922, %f966;
	add.f32 	%f1921, %f1921, %f967;
	mul.f32 	%f968, %f1885, %f1928;
	fma.rn.f32 	%f969, %f1881, %f1927, %f968;
	fma.rn.f32 	%f159, %f1877, %f1926, %f969;
	mul.f32 	%f970, %f1886, %f1928;
	fma.rn.f32 	%f971, %f1882, %f1927, %f970;
	fma.rn.f32 	%f160, %f1878, %f1926, %f971;
	mul.f32 	%f972, %f1887, %f1928;
	fma.rn.f32 	%f973, %f1883, %f1927, %f972;
	fma.rn.f32 	%f161, %f1879, %f1926, %f973;
	mul.f32 	%f974, %f1888, %f1928;
	fma.rn.f32 	%f975, %f1884, %f1927, %f974;
	fma.rn.f32 	%f976, %f1880, %f1926, %f975;
	add.f32 	%f1925, %f1925, %f976;
	mov.f32 	%f1918, %f153;
	mov.f32 	%f1919, %f152;
	mov.f32 	%f1920, %f151;
	mov.f32 	%f1922, %f157;
	mov.f32 	%f1923, %f156;
	mov.f32 	%f1924, %f155;
	mov.f32 	%f1926, %f161;
	mov.f32 	%f1927, %f160;
	mov.f32 	%f1928, %f159;

$L__BB12_20:
	add.s32 	%r645, %r645, 1;
	setp.lt.u32 	%p11, %r645, %r33;
	mov.f32 	%f1877, %f1928;
	mov.f32 	%f1878, %f1927;
	mov.f32 	%f1879, %f1926;
	mov.f32 	%f1880, %f1925;
	mov.f32 	%f1881, %f1924;
	mov.f32 	%f1882, %f1923;
	mov.f32 	%f1883, %f1922;
	mov.f32 	%f1884, %f1921;
	mov.f32 	%f1885, %f1920;
	mov.f32 	%f1886, %f1919;
	mov.f32 	%f1887, %f1918;
	mov.f32 	%f1888, %f1917;
	@%p11 bra 	$L__BB12_5;

$L__BB12_21:
	mul.f32 	%f977, %f1953, %f1920;
	fma.rn.f32 	%f978, %f1954, %f1919, %f977;
	fma.rn.f32 	%f979, %f1955, %f1918, %f978;
	mul.f32 	%f980, %f1953, %f1924;
	fma.rn.f32 	%f981, %f1954, %f1923, %f980;
	fma.rn.f32 	%f982, %f1955, %f1922, %f981;
	mul.f32 	%f983, %f1953, %f1928;
	fma.rn.f32 	%f984, %f1954, %f1927, %f983;
	fma.rn.f32 	%f985, %f1955, %f1926, %f984;
	add.f32 	%f1955, %f1925, %f985;
	add.f32 	%f1954, %f1921, %f982;
	add.f32 	%f1953, %f1917, %f979;

$L__BB12_23:
	// begin inline asm
	call (%f2011), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f2012), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f988), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r184), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p12, %r184, 0;
	@%p12 bra 	$L__BB12_43;

	// begin inline asm
	call (%r185), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f989), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p13, %r185, 0;
	@%p13 bra 	$L__BB12_42;

	mov.u32 	%r646, 0;

$L__BB12_26:
	.pragma "nounroll";
	// begin inline asm
	call (%rd167), _optix_get_transform_list_handle, (%r646);
	// end inline asm
	// begin inline asm
	call (%r188), _optix_get_transform_type_from_handle, (%rd167);
	// end inline asm
	or.b32  	%r189, %r188, 1;
	setp.eq.s32 	%p14, %r189, 3;
	@%p14 bra 	$L__BB12_32;
	bra.uni 	$L__BB12_27;

$L__BB12_32:
	setp.eq.s32 	%p17, %r188, 2;
	@%p17 bra 	$L__BB12_36;
	bra.uni 	$L__BB12_33;

$L__BB12_36:
	// begin inline asm
	call (%rd239), _optix_get_matrix_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r277,%r278,%r279,%r280}, [%rd241];
	// end inline asm
	add.s64 	%rd245, %rd239, 16;
	// begin inline asm
	cvta.to.global.u64 %rd244, %rd245;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r281,%r282,%r283,%r284}, [%rd244];
	// end inline asm
	add.s64 	%rd248, %rd239, 32;
	// begin inline asm
	cvta.to.global.u64 %rd247, %rd248;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r285,%r286,%r287,%r288}, [%rd247];
	// end inline asm
	add.s64 	%rd251, %rd239, 48;
	// begin inline asm
	cvta.to.global.u64 %rd250, %rd251;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r289,%r290,%r291,%r292}, [%rd250];
	// end inline asm
	add.s64 	%rd254, %rd239, 64;
	// begin inline asm
	cvta.to.global.u64 %rd253, %rd254;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r293,%r294,%r295,%r296}, [%rd253];
	// end inline asm
	add.s64 	%rd257, %rd239, 80;
	// begin inline asm
	cvta.to.global.u64 %rd256, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r297,%r298,%r299,%r300}, [%rd256];
	// end inline asm
	add.s64 	%rd260, %rd239, 96;
	// begin inline asm
	cvta.to.global.u64 %rd259, %rd260;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r301,%r302,%r303,%r304}, [%rd259];
	// end inline asm
	add.s64 	%rd263, %rd239, 112;
	// begin inline asm
	cvta.to.global.u64 %rd262, %rd263;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r305,%r306,%r307,%r308}, [%rd262];
	// end inline asm
	mov.b32 	%f1093, %r280;
	mov.b32 	%f1094, %r281;
	and.b32  	%r321, %r279, 65535;
	add.s32 	%r322, %r321, -1;
	cvt.rn.f32.s32 	%f1095, %r322;
	sub.f32 	%f1096, %f989, %f1093;
	mul.f32 	%f1097, %f1096, %f1095;
	sub.f32 	%f1098, %f1094, %f1093;
	div.rn.f32 	%f1099, %f1097, %f1098;
	min.f32 	%f1100, %f1095, %f1099;
	mov.f32 	%f1101, 0f00000000;
	max.f32 	%f1102, %f1101, %f1100;
	cvt.rmi.f32.f32 	%f1103, %f1102;
	sub.f32 	%f258, %f1102, %f1103;
	cvt.rzi.s32.f32 	%r323, %f1103;
	cvt.s64.s32 	%rd17, %r323;
	mul.wide.s32 	%rd274, %r323, 48;
	add.s64 	%rd266, %rd248, %rd274;
	// begin inline asm
	cvta.to.global.u64 %rd265, %rd266;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r309,%r310,%r311,%r312}, [%rd265];
	// end inline asm
	mov.b32 	%f1981, %r309;
	mov.b32 	%f1982, %r310;
	mov.b32 	%f1983, %r311;
	add.s64 	%rd269, %rd266, 16;
	// begin inline asm
	cvta.to.global.u64 %rd268, %rd269;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r313,%r314,%r315,%r316}, [%rd268];
	// end inline asm
	mov.b32 	%f1978, %r313;
	mov.b32 	%f1979, %r314;
	mov.b32 	%f1980, %r315;
	add.s64 	%rd272, %rd266, 32;
	// begin inline asm
	cvta.to.global.u64 %rd271, %rd272;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r317,%r318,%r319,%r320}, [%rd271];
	// end inline asm
	mov.b32 	%f1975, %r317;
	mov.b32 	%f1976, %r318;
	mov.b32 	%f1977, %r319;
	setp.leu.f32 	%p19, %f258, 0f00000000;
	@%p19 bra 	$L__BB12_38;

	mov.f32 	%f1104, 0f3F800000;
	sub.f32 	%f1105, %f1104, %f258;
	mul.lo.s64 	%rd284, %rd17, 48;
	add.s64 	%rd285, %rd239, %rd284;
	add.s64 	%rd276, %rd285, 80;
	// begin inline asm
	cvta.to.global.u64 %rd275, %rd276;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r324,%r325,%r326,%r327}, [%rd275];
	// end inline asm
	mov.b32 	%f1106, %r324;
	mov.b32 	%f1107, %r325;
	mov.b32 	%f1108, %r326;
	mul.f32 	%f1109, %f258, %f1106;
	mul.f32 	%f1110, %f258, %f1107;
	mul.f32 	%f1111, %f258, %f1108;
	fma.rn.f32 	%f1981, %f1105, %f1981, %f1109;
	fma.rn.f32 	%f1982, %f1105, %f1982, %f1110;
	fma.rn.f32 	%f1983, %f1105, %f1983, %f1111;
	add.s64 	%rd279, %rd285, 96;
	// begin inline asm
	cvta.to.global.u64 %rd278, %rd279;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r328,%r329,%r330,%r331}, [%rd278];
	// end inline asm
	mov.b32 	%f1112, %r328;
	mov.b32 	%f1113, %r329;
	mov.b32 	%f1114, %r330;
	mul.f32 	%f1115, %f258, %f1112;
	mul.f32 	%f1116, %f258, %f1113;
	mul.f32 	%f1117, %f258, %f1114;
	fma.rn.f32 	%f1978, %f1105, %f1978, %f1115;
	fma.rn.f32 	%f1979, %f1105, %f1979, %f1116;
	fma.rn.f32 	%f1980, %f1105, %f1980, %f1117;
	add.s64 	%rd282, %rd285, 112;
	// begin inline asm
	cvta.to.global.u64 %rd281, %rd282;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r332,%r333,%r334,%r335}, [%rd281];
	// end inline asm
	mov.b32 	%f1118, %r332;
	mov.b32 	%f1119, %r333;
	mov.b32 	%f1120, %r334;
	mul.f32 	%f1121, %f258, %f1118;
	mul.f32 	%f1122, %f258, %f1119;
	mul.f32 	%f1123, %f258, %f1120;
	fma.rn.f32 	%f1975, %f1105, %f1975, %f1121;
	fma.rn.f32 	%f1976, %f1105, %f1976, %f1122;
	fma.rn.f32 	%f1977, %f1105, %f1977, %f1123;
	bra.uni 	$L__BB12_38;

$L__BB12_27:
	mov.f32 	%f1984, 0f00000000;
	mov.f32 	%f1986, 0f3F800000;
	setp.eq.s32 	%p15, %r188, 4;
	@%p15 bra 	$L__BB12_30;

	setp.ne.s32 	%p16, %r188, 1;
	mov.f32 	%f1985, %f1984;
	mov.f32 	%f1987, %f1984;
	mov.f32 	%f1988, %f1986;
	mov.f32 	%f1989, %f1984;
	mov.f32 	%f1990, %f1986;
	mov.f32 	%f1991, %f1984;
	mov.f32 	%f1992, %f1984;
	@%p16 bra 	$L__BB12_39;

	// begin inline asm
	call (%rd169), _optix_get_static_transform_from_handle, (%rd167);
	// end inline asm
	add.s64 	%rd664, %rd169, 64;
	bra.uni 	$L__BB12_31;

$L__BB12_33:
	// begin inline asm
	call (%rd182), _optix_get_srt_motion_transform_from_handle, (%rd167);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r202,%r203,%r204,%r205}, [%rd184];
	// end inline asm
	add.s64 	%rd188, %rd182, 16;
	// begin inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r206,%r207,%r208,%r209}, [%rd187];
	// end inline asm
	add.s64 	%rd191, %rd182, 32;
	// begin inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r210,%r211,%r212,%r213}, [%rd190];
	// end inline asm
	add.s64 	%rd194, %rd182, 48;
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r214,%r215,%r216,%r217}, [%rd193];
	// end inline asm
	add.s64 	%rd197, %rd182, 64;
	// begin inline asm
	cvta.to.global.u64 %rd196, %rd197;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r218,%r219,%r220,%r221}, [%rd196];
	// end inline asm
	add.s64 	%rd200, %rd182, 80;
	// begin inline asm
	cvta.to.global.u64 %rd199, %rd200;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r222,%r223,%r224,%r225}, [%rd199];
	// end inline asm
	add.s64 	%rd203, %rd182, 96;
	// begin inline asm
	cvta.to.global.u64 %rd202, %rd203;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r226,%r227,%r228,%r229}, [%rd202];
	// end inline asm
	add.s64 	%rd206, %rd182, 112;
	// begin inline asm
	cvta.to.global.u64 %rd205, %rd206;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r230,%r231,%r232,%r233}, [%rd205];
	// end inline asm
	add.s64 	%rd209, %rd182, 128;
	// begin inline asm
	cvta.to.global.u64 %rd208, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r234,%r235,%r236,%r237}, [%rd208];
	// end inline asm
	add.s64 	%rd212, %rd182, 144;
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd212;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r238,%r239,%r240,%r241}, [%rd211];
	// end inline asm
	mov.b32 	%f1001, %r205;
	mov.b32 	%f1002, %r206;
	and.b32  	%r258, %r204, 65535;
	add.s32 	%r259, %r258, -1;
	cvt.rn.f32.s32 	%f1003, %r259;
	sub.f32 	%f1004, %f989, %f1001;
	mul.f32 	%f1005, %f1004, %f1003;
	sub.f32 	%f1006, %f1002, %f1001;
	div.rn.f32 	%f1007, %f1005, %f1006;
	min.f32 	%f1008, %f1003, %f1007;
	mov.f32 	%f1009, 0f00000000;
	max.f32 	%f1010, %f1009, %f1008;
	cvt.rmi.f32.f32 	%f1011, %f1010;
	sub.f32 	%f218, %f1010, %f1011;
	cvt.rzi.s32.f32 	%r260, %f1011;
	mul.wide.s32 	%rd226, %r260, 64;
	add.s64 	%rd215, %rd191, %rd226;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r242,%r243,%r244,%r245}, [%rd214];
	// end inline asm
	mov.b32 	%f1965, %r242;
	mov.b32 	%f1966, %r243;
	mov.b32 	%f1967, %r244;
	add.s64 	%rd218, %rd215, 16;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r246,%r247,%r248,%r249}, [%rd217];
	// end inline asm
	mov.b32 	%f1968, %r246;
	mov.b32 	%f1969, %r247;
	mov.b32 	%f1970, %r249;
	add.s64 	%rd221, %rd215, 32;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r250,%r251,%r252,%r253}, [%rd220];
	// end inline asm
	mov.b32 	%f1971, %r251;
	mov.b32 	%f1972, %r252;
	mov.b32 	%f1973, %r253;
	add.s64 	%rd224, %rd215, 48;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r254,%r255,%r256,%r257}, [%rd223];
	// end inline asm
	mov.b32 	%f1974, %r254;
	setp.leu.f32 	%p18, %f218, 0f00000000;
	@%p18 bra 	$L__BB12_35;

	mov.f32 	%f1012, 0f3F800000;
	sub.f32 	%f1013, %f1012, %f218;
	add.s64 	%rd228, %rd215, 64;
	// begin inline asm
	cvta.to.global.u64 %rd227, %rd228;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r261,%r262,%r263,%r264}, [%rd227];
	// end inline asm
	mov.b32 	%f1014, %r261;
	mov.b32 	%f1015, %r262;
	mov.b32 	%f1016, %r263;
	mul.f32 	%f1017, %f218, %f1014;
	mul.f32 	%f1018, %f218, %f1015;
	mul.f32 	%f1019, %f218, %f1016;
	fma.rn.f32 	%f1965, %f1013, %f1965, %f1017;
	fma.rn.f32 	%f1966, %f1013, %f1966, %f1018;
	fma.rn.f32 	%f1967, %f1013, %f1967, %f1019;
	add.s64 	%rd231, %rd215, 80;
	// begin inline asm
	cvta.to.global.u64 %rd230, %rd231;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r265,%r266,%r267,%r268}, [%rd230];
	// end inline asm
	mov.b32 	%f1020, %r265;
	mov.b32 	%f1021, %r266;
	mov.b32 	%f1022, %r268;
	mul.f32 	%f1023, %f218, %f1020;
	mul.f32 	%f1024, %f218, %f1021;
	mul.f32 	%f1025, %f218, %f1022;
	fma.rn.f32 	%f1968, %f1013, %f1968, %f1023;
	fma.rn.f32 	%f1969, %f1013, %f1969, %f1024;
	fma.rn.f32 	%f1970, %f1013, %f1970, %f1025;
	add.s64 	%rd234, %rd215, 96;
	// begin inline asm
	cvta.to.global.u64 %rd233, %rd234;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r269,%r270,%r271,%r272}, [%rd233];
	// end inline asm
	mov.b32 	%f1026, %r270;
	mov.b32 	%f1027, %r271;
	mov.b32 	%f1028, %r272;
	mul.f32 	%f1029, %f218, %f1026;
	mul.f32 	%f1030, %f218, %f1027;
	mul.f32 	%f1031, %f218, %f1028;
	fma.rn.f32 	%f1032, %f1013, %f1971, %f1029;
	fma.rn.f32 	%f1033, %f1013, %f1972, %f1030;
	fma.rn.f32 	%f1034, %f1013, %f1973, %f1031;
	add.s64 	%rd237, %rd215, 112;
	// begin inline asm
	cvta.to.global.u64 %rd236, %rd237;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r273,%r274,%r275,%r276}, [%rd236];
	// end inline asm
	mov.b32 	%f1035, %r273;
	mul.f32 	%f1036, %f218, %f1035;
	fma.rn.f32 	%f1037, %f1013, %f1974, %f1036;
	mul.f32 	%f1038, %f1033, %f1033;
	fma.rn.f32 	%f1039, %f1032, %f1032, %f1038;
	fma.rn.f32 	%f1040, %f1034, %f1034, %f1039;
	fma.rn.f32 	%f1041, %f1037, %f1037, %f1040;
	sqrt.rn.f32 	%f1042, %f1041;
	rcp.rn.f32 	%f1043, %f1042;
	mul.f32 	%f1971, %f1032, %f1043;
	mul.f32 	%f1972, %f1033, %f1043;
	mul.f32 	%f1973, %f1034, %f1043;
	mul.f32 	%f1974, %f1043, %f1037;

$L__BB12_35:
	mul.f32 	%f1044, %f1972, %f1972;
	fma.rn.f32 	%f1045, %f1971, %f1971, %f1044;
	fma.rn.f32 	%f1046, %f1973, %f1973, %f1045;
	fma.rn.f32 	%f1047, %f1974, %f1974, %f1046;
	rcp.rn.f32 	%f1048, %f1047;
	mul.f32 	%f1049, %f1971, %f1048;
	mul.f32 	%f1050, %f1972, %f1048;
	mul.f32 	%f1051, %f1973, %f1048;
	mul.f32 	%f1052, %f1974, %f1048;
	mul.f32 	%f1053, %f1971, %f1049;
	mul.f32 	%f1054, %f1972, %f1050;
	mul.f32 	%f1055, %f1973, %f1051;
	mul.f32 	%f1056, %f1971, %f1050;
	mul.f32 	%f1057, %f1973, %f1052;
	mul.f32 	%f1058, %f1971, %f1051;
	mul.f32 	%f1059, %f1972, %f1052;
	mul.f32 	%f1060, %f1972, %f1051;
	mul.f32 	%f1061, %f1971, %f1052;
	sub.f32 	%f1062, %f1053, %f1054;
	sub.f32 	%f1063, %f1062, %f1055;
	fma.rn.f32 	%f1064, %f1974, %f1052, %f1063;
	sub.f32 	%f1065, %f1056, %f1057;
	add.f32 	%f1066, %f1065, %f1065;
	add.f32 	%f1067, %f1058, %f1059;
	add.f32 	%f1068, %f1067, %f1067;
	add.f32 	%f1069, %f1056, %f1057;
	add.f32 	%f1070, %f1069, %f1069;
	sub.f32 	%f1071, %f1054, %f1053;
	sub.f32 	%f1072, %f1071, %f1055;
	fma.rn.f32 	%f1073, %f1974, %f1052, %f1072;
	sub.f32 	%f1074, %f1060, %f1061;
	add.f32 	%f1075, %f1074, %f1074;
	sub.f32 	%f1076, %f1058, %f1059;
	add.f32 	%f1077, %f1076, %f1076;
	add.f32 	%f1078, %f1060, %f1061;
	add.f32 	%f1079, %f1078, %f1078;
	neg.f32 	%f1080, %f1053;
	sub.f32 	%f1081, %f1080, %f1054;
	add.f32 	%f1082, %f1055, %f1081;
	fma.rn.f32 	%f1083, %f1974, %f1052, %f1082;
	mul.f32 	%f1084, %f1967, %f1064;
	fma.rn.f32 	%f1085, %f1969, %f1066, %f1084;
	fma.rn.f32 	%f1983, %f1970, %f1068, %f1085;
	mul.f32 	%f1086, %f1969, %f1073;
	fma.rn.f32 	%f1087, %f1967, %f1070, %f1086;
	fma.rn.f32 	%f1980, %f1970, %f1075, %f1087;
	mul.f32 	%f1088, %f1969, %f1079;
	fma.rn.f32 	%f1089, %f1967, %f1077, %f1088;
	fma.rn.f32 	%f1977, %f1970, %f1083, %f1089;
	mul.f32 	%f1090, %f1966, %f1064;
	fma.rn.f32 	%f1982, %f1968, %f1066, %f1090;
	mul.f32 	%f1091, %f1968, %f1073;
	fma.rn.f32 	%f1979, %f1966, %f1070, %f1091;
	mul.f32 	%f1092, %f1968, %f1079;
	fma.rn.f32 	%f1976, %f1966, %f1077, %f1092;
	mul.f32 	%f1981, %f1965, %f1064;
	mul.f32 	%f1978, %f1965, %f1070;
	mul.f32 	%f1975, %f1965, %f1077;

$L__BB12_38:
	mul.f32 	%f1124, %f1976, %f1980;
	mul.f32 	%f1125, %f1977, %f1979;
	sub.f32 	%f1126, %f1125, %f1124;
	mul.f32 	%f1127, %f1981, %f1126;
	mul.f32 	%f1128, %f1975, %f1980;
	mul.f32 	%f1129, %f1977, %f1978;
	sub.f32 	%f1130, %f1129, %f1128;
	mul.f32 	%f1131, %f1130, %f1982;
	sub.f32 	%f1132, %f1127, %f1131;
	mul.f32 	%f1133, %f1975, %f1979;
	mul.f32 	%f1134, %f1976, %f1978;
	sub.f32 	%f1135, %f1134, %f1133;
	fma.rn.f32 	%f1136, %f1135, %f1983, %f1132;
	rcp.rn.f32 	%f1137, %f1136;
	mul.f32 	%f1990, %f1126, %f1137;
	mul.f32 	%f1138, %f1977, %f1982;
	mul.f32 	%f1139, %f1976, %f1983;
	sub.f32 	%f1140, %f1139, %f1138;
	mul.f32 	%f1991, %f1140, %f1137;
	mul.f32 	%f1141, %f1979, %f1983;
	mul.f32 	%f1142, %f1980, %f1982;
	sub.f32 	%f1143, %f1142, %f1141;
	mul.f32 	%f1992, %f1143, %f1137;
	sub.f32 	%f1144, %f1128, %f1129;
	mul.f32 	%f1987, %f1144, %f1137;
	mul.f32 	%f1145, %f1975, %f1983;
	mul.f32 	%f1146, %f1977, %f1981;
	sub.f32 	%f1147, %f1146, %f1145;
	mul.f32 	%f1988, %f1147, %f1137;
	mul.f32 	%f1148, %f1980, %f1981;
	mul.f32 	%f1149, %f1978, %f1983;
	sub.f32 	%f1150, %f1149, %f1148;
	mul.f32 	%f1989, %f1150, %f1137;
	mul.f32 	%f1984, %f1135, %f1137;
	mul.f32 	%f1151, %f1976, %f1981;
	mul.f32 	%f1152, %f1975, %f1982;
	sub.f32 	%f1153, %f1152, %f1151;
	mul.f32 	%f1985, %f1153, %f1137;
	mul.f32 	%f1154, %f1978, %f1982;
	mul.f32 	%f1155, %f1979, %f1981;
	sub.f32 	%f1156, %f1155, %f1154;
	mul.f32 	%f1986, %f1156, %f1137;
	bra.uni 	$L__BB12_39;

$L__BB12_30:
	// begin inline asm
	call (%rd664), _optix_get_instance_inverse_transform_from_handle, (%rd167);
	// end inline asm

$L__BB12_31:
	// begin inline asm
	cvta.to.global.u64 %rd173, %rd664;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r190,%r191,%r192,%r193}, [%rd173];
	// end inline asm
	mov.b32 	%f1990, %r190;
	mov.b32 	%f1991, %r191;
	mov.b32 	%f1992, %r192;
	add.s64 	%rd177, %rd664, 16;
	// begin inline asm
	cvta.to.global.u64 %rd176, %rd177;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r194,%r195,%r196,%r197}, [%rd176];
	// end inline asm
	mov.b32 	%f1987, %r194;
	mov.b32 	%f1988, %r195;
	mov.b32 	%f1989, %r196;
	add.s64 	%rd180, %rd664, 32;
	// begin inline asm
	cvta.to.global.u64 %rd179, %rd180;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r198,%r199,%r200,%r201}, [%rd179];
	// end inline asm
	mov.b32 	%f1984, %r198;
	mov.b32 	%f1985, %r199;
	mov.b32 	%f1986, %r200;

$L__BB12_39:
	setp.eq.s32 	%p20, %r646, 0;
	@%p20 bra 	$L__BB12_41;

	mul.f32 	%f1157, %f1961, %f1991;
	fma.rn.f32 	%f1158, %f1958, %f1990, %f1157;
	fma.rn.f32 	%f304, %f1964, %f1992, %f1158;
	mul.f32 	%f1159, %f1960, %f1991;
	fma.rn.f32 	%f1160, %f1957, %f1990, %f1159;
	fma.rn.f32 	%f305, %f1963, %f1992, %f1160;
	mul.f32 	%f1161, %f1959, %f1991;
	fma.rn.f32 	%f1162, %f1956, %f1990, %f1161;
	fma.rn.f32 	%f1992, %f1962, %f1992, %f1162;
	mul.f32 	%f1163, %f1961, %f1988;
	fma.rn.f32 	%f1164, %f1958, %f1987, %f1163;
	fma.rn.f32 	%f307, %f1964, %f1989, %f1164;
	mul.f32 	%f1165, %f1960, %f1988;
	fma.rn.f32 	%f1166, %f1957, %f1987, %f1165;
	fma.rn.f32 	%f308, %f1963, %f1989, %f1166;
	mul.f32 	%f1167, %f1959, %f1988;
	fma.rn.f32 	%f1168, %f1956, %f1987, %f1167;
	fma.rn.f32 	%f1989, %f1962, %f1989, %f1168;
	mul.f32 	%f1169, %f1961, %f1985;
	fma.rn.f32 	%f1170, %f1958, %f1984, %f1169;
	fma.rn.f32 	%f310, %f1964, %f1986, %f1170;
	mul.f32 	%f1171, %f1960, %f1985;
	fma.rn.f32 	%f1172, %f1957, %f1984, %f1171;
	fma.rn.f32 	%f311, %f1963, %f1986, %f1172;
	mul.f32 	%f1173, %f1959, %f1985;
	fma.rn.f32 	%f1174, %f1956, %f1984, %f1173;
	fma.rn.f32 	%f1986, %f1962, %f1986, %f1174;
	mov.f32 	%f1984, %f310;
	mov.f32 	%f1985, %f311;
	mov.f32 	%f1987, %f307;
	mov.f32 	%f1988, %f308;
	mov.f32 	%f1990, %f304;
	mov.f32 	%f1991, %f305;

$L__BB12_41:
	add.s32 	%r646, %r646, 1;
	setp.lt.u32 	%p21, %r646, %r185;
	mov.f32 	%f1956, %f1992;
	mov.f32 	%f1957, %f1991;
	mov.f32 	%f1958, %f1990;
	mov.f32 	%f1959, %f1989;
	mov.f32 	%f1960, %f1988;
	mov.f32 	%f1961, %f1987;
	mov.f32 	%f1962, %f1986;
	mov.f32 	%f1963, %f1985;
	mov.f32 	%f1964, %f1984;
	@%p21 bra 	$L__BB12_26;

$L__BB12_42:
	mul.f32 	%f1175, %f2012, %f1991;
	fma.rn.f32 	%f1176, %f2011, %f1990, %f1175;
	mul.f32 	%f1177, %f2012, %f1988;
	fma.rn.f32 	%f1178, %f2011, %f1987, %f1177;
	mul.f32 	%f1179, %f2012, %f1985;
	fma.rn.f32 	%f1180, %f2011, %f1984, %f1179;
	fma.rn.f32 	%f2013, %f988, %f1986, %f1180;
	fma.rn.f32 	%f2012, %f988, %f1989, %f1178;
	fma.rn.f32 	%f2011, %f988, %f1992, %f1176;
	bra.uni 	$L__BB12_44;

$L__BB12_43:
	mov.f32 	%f2013, %f988;

$L__BB12_44:
	// begin inline asm
	call (%f1182), _optix_get_ray_tmax, ();
	// end inline asm
	ld.const.u64 	%rd286, [params+80];
	setp.eq.s64 	%p22, %rd286, 0;
	@%p22 bra 	$L__BB12_49;

	ld.u64 	%rd287, [%rd47];
	ld.const.u64 	%rd288, [params+328];
	cvta.to.global.u64 	%rd289, %rd288;
	cvt.u64.u32 	%rd18, %r1;
	mul.wide.u32 	%rd290, %r1, 8;
	add.s64 	%rd291, %rd289, %rd290;
	st.global.u64 	[%rd291], %rd287;
	ld.const.u64 	%rd292, [params+336];
	cvta.to.global.u64 	%rd293, %rd292;
	mul.wide.u32 	%rd294, %r1, 4;
	add.s64 	%rd295, %rd293, %rd294;
	mov.u32 	%r336, 0;
	st.global.u32 	[%rd295], %r336;
	ld.const.u64 	%rd296, [params+344];
	cvta.to.global.u64 	%rd297, %rd296;
	add.s64 	%rd19, %rd297, %rd294;
	ld.global.u32 	%r10, [%rd19];
	setp.eq.s32 	%p23, %r10, 0;
	@%p23 bra 	$L__BB12_48;

	// begin inline asm
	call (%r337), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p24, %r337, %r10;
	@%p24 bra 	$L__BB12_48;

	st.global.u32 	[%rd19], %r337;

$L__BB12_48:
	ld.const.u64 	%rd298, [params+72];
	cvta.to.global.u64 	%rd299, %rd298;
	shl.b64 	%rd300, %rd18, 2;
	add.s64 	%rd301, %rd299, %rd300;
	st.global.f32 	[%rd301], %f1182;
	bra.uni 	$L__BB12_117;

$L__BB12_49:
	fma.rn.f32 	%f2177, %f1182, %f2011, %f1953;
	fma.rn.f32 	%f2178, %f1182, %f2012, %f1954;
	fma.rn.f32 	%f2179, %f1182, %f2013, %f1955;
	add.s64 	%rd20, %rd3, 288;
	ld.v4.f32 	{%f1184, %f1185, %f1186, %f1187}, [%rd3+288];
	ld.v2.f32 	{%f1190, %f1191}, [%rd3+304];
	mov.u64 	%rd302, 8;
	sub.f32 	%f344, %f2177, %f1184;
	sub.f32 	%f345, %f2178, %f1185;
	mul.f32 	%f1194, %f1191, %f344;
	add.f32 	%f1195, %f1190, 0f3F800000;
	mov.f32 	%f2161, 0f3F800000;
	mul.f32 	%f1197, %f344, %f344;
	mul.f32 	%f1198, %f1191, %f1191;
	mul.f32 	%f1199, %f1198, %f1197;
	mul.f32 	%f1200, %f1195, %f1199;
	sub.f32 	%f1201, %f2161, %f1200;
	sqrt.rn.f32 	%f1202, %f1201;
	div.rn.f32 	%f346, %f1194, %f1202;
	mul.f32 	%f1203, %f1191, %f345;
	mul.f32 	%f1204, %f345, %f345;
	mul.f32 	%f1205, %f1198, %f1204;
	mul.f32 	%f1206, %f1195, %f1205;
	sub.f32 	%f1207, %f2161, %f1206;
	sqrt.rn.f32 	%f1208, %f1207;
	div.rn.f32 	%f347, %f1203, %f1208;
	ld.u8 	%rs2, [%rd3+360];
	setp.eq.s16 	%p25, %rs2, 0;
	add.f32 	%f1209, %f1197, %f1204;
	sqrt.rn.f32 	%f348, %f1209;
	mov.u64 	%rd303, 2;
	cvt.rn.f32.u64 	%f349, %rd303;
	mov.u64 	%rd304, 4;
	cvt.rn.f32.u64 	%f350, %rd304;
	mov.u64 	%rd305, 6;
	cvt.rn.f32.u64 	%f351, %rd305;
	cvt.rn.f32.u64 	%f352, %rd302;
	mov.u64 	%rd306, 10;
	cvt.rn.f32.u64 	%f353, %rd306;
	mov.f32 	%f2016, 0f00000000;
	@%p25 bra 	$L__BB12_51;

	mul.f32 	%f1210, %f348, %f348;
	ld.f32 	%f1211, [%rd20+32];
	fma.rn.f32 	%f1212, %f349, %f1211, 0f00000000;
	ld.f32 	%f1213, [%rd20+36];
	mul.f32 	%f1214, %f350, %f1213;
	fma.rn.f32 	%f1215, %f1210, %f1214, %f1212;
	mul.f32 	%f1216, %f1210, %f1210;
	ld.f32 	%f1217, [%rd20+40];
	mul.f32 	%f1218, %f351, %f1217;
	fma.rn.f32 	%f1219, %f1216, %f1218, %f1215;
	mul.f32 	%f1220, %f1210, %f1216;
	mov.u64 	%rd307, 12;
	ld.f32 	%f1221, [%rd20+44];
	mul.f32 	%f1222, %f352, %f1221;
	fma.rn.f32 	%f1223, %f1220, %f1222, %f1219;
	mul.f32 	%f1224, %f1210, %f1220;
	mov.u64 	%rd308, 16;
	ld.f32 	%f1225, [%rd20+48];
	mul.f32 	%f1226, %f353, %f1225;
	fma.rn.f32 	%f1227, %f1224, %f1226, %f1223;
	mul.f32 	%f1228, %f1210, %f1224;
	mov.u64 	%rd309, 20;
	ld.f32 	%f1229, [%rd20+52];
	cvt.rn.f32.u64 	%f1230, %rd307;
	mul.f32 	%f1231, %f1230, %f1229;
	fma.rn.f32 	%f1232, %f1228, %f1231, %f1227;
	mul.f32 	%f1233, %f1210, %f1228;
	ld.f32 	%f1234, [%rd20+56];
	mov.u64 	%rd310, 14;
	cvt.rn.f32.u64 	%f1235, %rd310;
	mul.f32 	%f1236, %f1235, %f1234;
	fma.rn.f32 	%f1237, %f1233, %f1236, %f1232;
	mul.f32 	%f1238, %f1210, %f1233;
	ld.f32 	%f1239, [%rd20+60];
	cvt.rn.f32.u64 	%f1240, %rd308;
	mul.f32 	%f1241, %f1240, %f1239;
	fma.rn.f32 	%f1242, %f1238, %f1241, %f1237;
	mul.f32 	%f1243, %f1210, %f1238;
	ld.f32 	%f1244, [%rd20+64];
	mov.u64 	%rd311, 18;
	cvt.rn.f32.u64 	%f1245, %rd311;
	mul.f32 	%f1246, %f1245, %f1244;
	fma.rn.f32 	%f1247, %f1243, %f1246, %f1242;
	mul.f32 	%f1248, %f1210, %f1243;
	ld.f32 	%f1249, [%rd20+68];
	cvt.rn.f32.u64 	%f1250, %rd309;
	mul.f32 	%f1251, %f1250, %f1249;
	fma.rn.f32 	%f1252, %f1248, %f1251, %f1247;
	mul.f32 	%f2015, %f345, %f1252;
	mul.f32 	%f2014, %f344, %f1252;
	bra.uni 	$L__BB12_52;

$L__BB12_51:
	rcp.rn.f32 	%f1253, %f348;
	ld.f32 	%f1254, [%rd20+32];
	mov.u64 	%rd312, 1;
	cvt.rn.f32.u64 	%f1255, %rd312;
	mul.f32 	%f1256, %f1255, %f1254;
	fma.rn.f32 	%f1257, %f1253, %f1256, 0f00000000;
	mul.f32 	%f1258, %f348, %f1253;
	ld.f32 	%f1259, [%rd20+36];
	mul.f32 	%f1260, %f349, %f1259;
	fma.rn.f32 	%f1261, %f1258, %f1260, %f1257;
	mul.f32 	%f1262, %f348, %f1258;
	ld.f32 	%f1263, [%rd20+40];
	mov.u64 	%rd313, 3;
	cvt.rn.f32.u64 	%f1264, %rd313;
	mul.f32 	%f1265, %f1264, %f1263;
	fma.rn.f32 	%f1266, %f1262, %f1265, %f1261;
	mul.f32 	%f1267, %f348, %f1262;
	ld.f32 	%f1268, [%rd20+44];
	mul.f32 	%f1269, %f350, %f1268;
	fma.rn.f32 	%f1270, %f1267, %f1269, %f1266;
	mul.f32 	%f1271, %f348, %f1267;
	ld.f32 	%f1272, [%rd20+48];
	mov.u64 	%rd314, 5;
	cvt.rn.f32.u64 	%f1273, %rd314;
	mul.f32 	%f1274, %f1273, %f1272;
	fma.rn.f32 	%f1275, %f1271, %f1274, %f1270;
	mul.f32 	%f1276, %f348, %f1271;
	ld.f32 	%f1277, [%rd20+52];
	mul.f32 	%f1278, %f351, %f1277;
	fma.rn.f32 	%f1279, %f1276, %f1278, %f1275;
	mul.f32 	%f1280, %f348, %f1276;
	ld.f32 	%f1281, [%rd20+56];
	mov.u64 	%rd315, 7;
	cvt.rn.f32.u64 	%f1282, %rd315;
	mul.f32 	%f1283, %f1282, %f1281;
	fma.rn.f32 	%f1284, %f1280, %f1283, %f1279;
	mul.f32 	%f1285, %f348, %f1280;
	ld.f32 	%f1286, [%rd20+60];
	mul.f32 	%f1287, %f352, %f1286;
	fma.rn.f32 	%f1288, %f1285, %f1287, %f1284;
	mul.f32 	%f1289, %f348, %f1285;
	ld.f32 	%f1290, [%rd20+64];
	mov.u64 	%rd316, 9;
	cvt.rn.f32.u64 	%f1291, %rd316;
	mul.f32 	%f1292, %f1291, %f1290;
	fma.rn.f32 	%f1293, %f1289, %f1292, %f1288;
	mul.f32 	%f1294, %f348, %f1289;
	ld.f32 	%f1295, [%rd20+68];
	mul.f32 	%f1296, %f353, %f1295;
	fma.rn.f32 	%f1297, %f1294, %f1296, %f1293;
	mul.f32 	%f2015, %f345, %f1297;
	mul.f32 	%f2014, %f344, %f1297;

$L__BB12_52:
	add.f32 	%f366, %f346, %f2014;
	add.f32 	%f367, %f347, %f2015;
	add.f32 	%f368, %f2016, 0fBF800000;
	ld.u8 	%rs3, [%rd20+92];
	setp.eq.s16 	%p26, %rs3, 0;
	mul.f32 	%f369, %f366, %f366;
	@%p26 bra 	$L__BB12_54;

	neg.f32 	%f1298, %f366;
	neg.f32 	%f1299, %f367;
	fma.rn.f32 	%f1300, %f1299, %f1299, %f369;
	neg.f32 	%f1301, %f368;
	fma.rn.f32 	%f1302, %f1301, %f1301, %f1300;
	sqrt.rn.f32 	%f1303, %f1302;
	div.rn.f32 	%f2162, %f1298, %f1303;
	div.rn.f32 	%f2159, %f1299, %f1303;
	div.rn.f32 	%f2173, %f1301, %f1303;
	bra.uni 	$L__BB12_55;

$L__BB12_54:
	fma.rn.f32 	%f1304, %f367, %f367, %f369;
	fma.rn.f32 	%f1305, %f368, %f368, %f1304;
	sqrt.rn.f32 	%f1306, %f1305;
	div.rn.f32 	%f2162, %f366, %f1306;
	div.rn.f32 	%f2159, %f367, %f1306;
	div.rn.f32 	%f2173, %f368, %f1306;

$L__BB12_55:
	ld.const.u64 	%rd21, [params+96];
	setp.eq.s64 	%p27, %rd21, 0;
	@%p27 bra 	$L__BB12_57;

	ld.v4.f32 	{%f1308, %f1309, %f1310, %f1311}, [%rd20+-80];
	ld.f32 	%f1314, [%rd20+-128];
	fma.rn.f32 	%f1315, %f2177, %f1314, %f1308;
	ld.f32 	%f1316, [%rd20+-124];
	fma.rn.f32 	%f1317, %f2177, %f1316, %f1309;
	ld.f32 	%f1318, [%rd20+-112];
	fma.rn.f32 	%f1319, %f2178, %f1318, %f1315;
	ld.f32 	%f1320, [%rd20+-108];
	fma.rn.f32 	%f1321, %f2178, %f1320, %f1317;
	ld.f32 	%f1322, [%rd20+-96];
	fma.rn.f32 	%f1323, %f2179, %f1322, %f1319;
	ld.f32 	%f1324, [%rd20+-92];
	fma.rn.f32 	%f1325, %f2179, %f1324, %f1321;
	ld.f32 	%f1326, [%rd20+24];
	div.rn.f32 	%f2021, %f1323, %f1326;
	div.rn.f32 	%f2020, %f1325, %f1326;

$L__BB12_57:
	ld.u64 	%rd22, [%rd47];
	ld.const.u64 	%rd317, [params+344];
	cvta.to.global.u64 	%rd318, %rd317;
	cvt.u64.u32 	%rd23, %r1;
	mul.wide.u32 	%rd319, %r1, 4;
	add.s64 	%rd24, %rd318, %rd319;
	ld.global.u32 	%r12, [%rd24];
	setp.eq.s32 	%p28, %r12, 0;
	mov.f32 	%f2160, 0f00000000;
	mov.f32 	%f2163, 0f3F800000;
	mov.f32 	%f2164, 0f00000000;
	mov.f32 	%f2166, 0f00000000;
	mov.f32 	%f2167, 0f3F800000;
	mov.f32 	%f2169, 0f3F800000;
	mov.f32 	%f2170, 0f00000000;
	mov.f32 	%f2165, %f2159;
	mov.f32 	%f2168, %f2162;
	mov.f32 	%f2171, %f2162;
	mov.f32 	%f2172, %f2159;
	mov.f32 	%f2174, %f2162;
	mov.f32 	%f2175, %f2159;
	mov.f32 	%f2176, %f2173;
	@%p28 bra 	$L__BB12_105;

	// begin inline asm
	call (%r338), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p29, %r338, %r12;
	mov.f32 	%f2165, %f2159;
	mov.f32 	%f2168, %f2162;
	mov.f32 	%f2171, %f2162;
	mov.f32 	%f2172, %f2159;
	mov.f32 	%f2174, %f2162;
	mov.f32 	%f2175, %f2159;
	mov.f32 	%f2176, %f2173;
	@%p29 bra 	$L__BB12_105;

	// begin inline asm
	call (%r339), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p30, %r339, 0;
	mov.f32 	%f2121, 0f00000000;
	mov.f32 	%f2120, 0f3F800000;
	mov.f32 	%f2058, %f2120;
	mov.f32 	%f2059, %f2121;
	mov.f32 	%f2060, %f2121;
	mov.f32 	%f2061, %f2121;
	mov.f32 	%f2054, %f2121;
	mov.f32 	%f2055, %f2120;
	mov.f32 	%f2056, %f2121;
	mov.f32 	%f2057, %f2121;
	mov.f32 	%f2050, %f2121;
	mov.f32 	%f2051, %f2121;
	mov.f32 	%f2052, %f2120;
	mov.f32 	%f2053, %f2121;
	@%p30 bra 	$L__BB12_77;

	// begin inline asm
	call (%r340), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1355), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p31, %r340, 1;
	@%p31 bra 	$L__BB12_77;

	add.s32 	%r647, %r340, 1;
	mov.u32 	%r648, 1;

$L__BB12_62:
	.pragma "nounroll";
	add.s32 	%r342, %r647, -2;
	// begin inline asm
	call (%rd320), _optix_get_transform_list_handle, (%r342);
	// end inline asm
	// begin inline asm
	call (%r343), _optix_get_transform_type_from_handle, (%rd320);
	// end inline asm
	or.b32  	%r344, %r343, 1;
	setp.eq.s32 	%p32, %r344, 3;
	@%p32 bra 	$L__BB12_68;
	bra.uni 	$L__BB12_63;

$L__BB12_68:
	setp.eq.s32 	%p35, %r343, 2;
	@%p35 bra 	$L__BB12_72;
	bra.uni 	$L__BB12_69;

$L__BB12_72:
	// begin inline asm
	call (%rd392), _optix_get_matrix_motion_transform_from_handle, (%rd320);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd394, %rd392;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r432,%r433,%r434,%r435}, [%rd394];
	// end inline asm
	add.s64 	%rd398, %rd392, 16;
	// begin inline asm
	cvta.to.global.u64 %rd397, %rd398;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r436,%r437,%r438,%r439}, [%rd397];
	// end inline asm
	add.s64 	%rd401, %rd392, 32;
	// begin inline asm
	cvta.to.global.u64 %rd400, %rd401;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r440,%r441,%r442,%r443}, [%rd400];
	// end inline asm
	add.s64 	%rd404, %rd392, 48;
	// begin inline asm
	cvta.to.global.u64 %rd403, %rd404;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r444,%r445,%r446,%r447}, [%rd403];
	// end inline asm
	add.s64 	%rd407, %rd392, 64;
	// begin inline asm
	cvta.to.global.u64 %rd406, %rd407;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r448,%r449,%r450,%r451}, [%rd406];
	// end inline asm
	add.s64 	%rd410, %rd392, 80;
	// begin inline asm
	cvta.to.global.u64 %rd409, %rd410;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r452,%r453,%r454,%r455}, [%rd409];
	// end inline asm
	add.s64 	%rd413, %rd392, 96;
	// begin inline asm
	cvta.to.global.u64 %rd412, %rd413;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r456,%r457,%r458,%r459}, [%rd412];
	// end inline asm
	add.s64 	%rd416, %rd392, 112;
	// begin inline asm
	cvta.to.global.u64 %rd415, %rd416;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r460,%r461,%r462,%r463}, [%rd415];
	// end inline asm
	mov.b32 	%f1483, %r435;
	mov.b32 	%f1484, %r436;
	and.b32  	%r476, %r434, 65535;
	add.s32 	%r477, %r476, -1;
	cvt.rn.f32.s32 	%f1485, %r477;
	sub.f32 	%f1486, %f1355, %f1483;
	mul.f32 	%f1487, %f1486, %f1485;
	sub.f32 	%f1488, %f1484, %f1483;
	div.rn.f32 	%f1489, %f1487, %f1488;
	min.f32 	%f1490, %f1485, %f1489;
	mov.f32 	%f1491, 0f00000000;
	max.f32 	%f1492, %f1491, %f1490;
	cvt.rmi.f32.f32 	%f1493, %f1492;
	sub.f32 	%f469, %f1492, %f1493;
	cvt.rzi.s32.f32 	%r478, %f1493;
	cvt.s64.s32 	%rd31, %r478;
	mul.wide.s32 	%rd427, %r478, 48;
	add.s64 	%rd419, %rd401, %rd427;
	// begin inline asm
	cvta.to.global.u64 %rd418, %rd419;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r464,%r465,%r466,%r467}, [%rd418];
	// end inline asm
	mov.b32 	%f2058, %r464;
	mov.b32 	%f2059, %r465;
	mov.b32 	%f2060, %r466;
	mov.b32 	%f2061, %r467;
	add.s64 	%rd422, %rd419, 16;
	// begin inline asm
	cvta.to.global.u64 %rd421, %rd422;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r468,%r469,%r470,%r471}, [%rd421];
	// end inline asm
	mov.b32 	%f2054, %r468;
	mov.b32 	%f2055, %r469;
	mov.b32 	%f2056, %r470;
	mov.b32 	%f2057, %r471;
	add.s64 	%rd425, %rd419, 32;
	// begin inline asm
	cvta.to.global.u64 %rd424, %rd425;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r472,%r473,%r474,%r475}, [%rd424];
	// end inline asm
	mov.b32 	%f2050, %r472;
	mov.b32 	%f2051, %r473;
	mov.b32 	%f2052, %r474;
	mov.b32 	%f2053, %r475;
	setp.leu.f32 	%p37, %f469, 0f00000000;
	@%p37 bra 	$L__BB12_74;

	mov.f32 	%f1494, 0f3F800000;
	sub.f32 	%f1495, %f1494, %f469;
	mul.lo.s64 	%rd437, %rd31, 48;
	add.s64 	%rd438, %rd392, %rd437;
	add.s64 	%rd429, %rd438, 80;
	// begin inline asm
	cvta.to.global.u64 %rd428, %rd429;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r479,%r480,%r481,%r482}, [%rd428];
	// end inline asm
	mov.b32 	%f1496, %r479;
	mov.b32 	%f1497, %r480;
	mov.b32 	%f1498, %r481;
	mov.b32 	%f1499, %r482;
	mul.f32 	%f1500, %f469, %f1496;
	mul.f32 	%f1501, %f469, %f1497;
	mul.f32 	%f1502, %f469, %f1498;
	mul.f32 	%f1503, %f469, %f1499;
	fma.rn.f32 	%f2058, %f1495, %f2058, %f1500;
	fma.rn.f32 	%f2059, %f1495, %f2059, %f1501;
	fma.rn.f32 	%f2060, %f1495, %f2060, %f1502;
	fma.rn.f32 	%f2061, %f1495, %f2061, %f1503;
	add.s64 	%rd432, %rd438, 96;
	// begin inline asm
	cvta.to.global.u64 %rd431, %rd432;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r483,%r484,%r485,%r486}, [%rd431];
	// end inline asm
	mov.b32 	%f1504, %r483;
	mov.b32 	%f1505, %r484;
	mov.b32 	%f1506, %r485;
	mov.b32 	%f1507, %r486;
	mul.f32 	%f1508, %f469, %f1504;
	mul.f32 	%f1509, %f469, %f1505;
	mul.f32 	%f1510, %f469, %f1506;
	mul.f32 	%f1511, %f469, %f1507;
	fma.rn.f32 	%f2054, %f1495, %f2054, %f1508;
	fma.rn.f32 	%f2055, %f1495, %f2055, %f1509;
	fma.rn.f32 	%f2056, %f1495, %f2056, %f1510;
	fma.rn.f32 	%f2057, %f1495, %f2057, %f1511;
	add.s64 	%rd435, %rd438, 112;
	// begin inline asm
	cvta.to.global.u64 %rd434, %rd435;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r487,%r488,%r489,%r490}, [%rd434];
	// end inline asm
	mov.b32 	%f1512, %r487;
	mov.b32 	%f1513, %r488;
	mov.b32 	%f1514, %r489;
	mov.b32 	%f1515, %r490;
	mul.f32 	%f1516, %f469, %f1512;
	mul.f32 	%f1517, %f469, %f1513;
	mul.f32 	%f1518, %f469, %f1514;
	mul.f32 	%f1519, %f469, %f1515;
	fma.rn.f32 	%f2050, %f1495, %f2050, %f1516;
	fma.rn.f32 	%f2051, %f1495, %f2051, %f1517;
	fma.rn.f32 	%f2052, %f1495, %f2052, %f1518;
	fma.rn.f32 	%f2053, %f1495, %f2053, %f1519;
	bra.uni 	$L__BB12_74;

$L__BB12_63:
	mov.f32 	%f2050, 0f00000000;
	mov.f32 	%f2052, 0f3F800000;
	setp.eq.s32 	%p33, %r343, 4;
	@%p33 bra 	$L__BB12_66;

	setp.ne.s32 	%p34, %r343, 1;
	mov.f32 	%f2051, %f2050;
	mov.f32 	%f2053, %f2050;
	mov.f32 	%f2054, %f2050;
	mov.f32 	%f2055, %f2052;
	mov.f32 	%f2056, %f2050;
	mov.f32 	%f2057, %f2050;
	mov.f32 	%f2058, %f2052;
	mov.f32 	%f2059, %f2050;
	mov.f32 	%f2060, %f2050;
	mov.f32 	%f2061, %f2050;
	@%p34 bra 	$L__BB12_74;

	// begin inline asm
	call (%rd322), _optix_get_static_transform_from_handle, (%rd320);
	// end inline asm
	add.s64 	%rd665, %rd322, 16;
	bra.uni 	$L__BB12_67;

$L__BB12_69:
	// begin inline asm
	call (%rd335), _optix_get_srt_motion_transform_from_handle, (%rd320);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd337, %rd335;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r357,%r358,%r359,%r360}, [%rd337];
	// end inline asm
	add.s64 	%rd341, %rd335, 16;
	// begin inline asm
	cvta.to.global.u64 %rd340, %rd341;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r361,%r362,%r363,%r364}, [%rd340];
	// end inline asm
	add.s64 	%rd344, %rd335, 32;
	// begin inline asm
	cvta.to.global.u64 %rd343, %rd344;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r365,%r366,%r367,%r368}, [%rd343];
	// end inline asm
	add.s64 	%rd347, %rd335, 48;
	// begin inline asm
	cvta.to.global.u64 %rd346, %rd347;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r369,%r370,%r371,%r372}, [%rd346];
	// end inline asm
	add.s64 	%rd350, %rd335, 64;
	// begin inline asm
	cvta.to.global.u64 %rd349, %rd350;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r373,%r374,%r375,%r376}, [%rd349];
	// end inline asm
	add.s64 	%rd353, %rd335, 80;
	// begin inline asm
	cvta.to.global.u64 %rd352, %rd353;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r377,%r378,%r379,%r380}, [%rd352];
	// end inline asm
	add.s64 	%rd356, %rd335, 96;
	// begin inline asm
	cvta.to.global.u64 %rd355, %rd356;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r381,%r382,%r383,%r384}, [%rd355];
	// end inline asm
	add.s64 	%rd359, %rd335, 112;
	// begin inline asm
	cvta.to.global.u64 %rd358, %rd359;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r385,%r386,%r387,%r388}, [%rd358];
	// end inline asm
	add.s64 	%rd362, %rd335, 128;
	// begin inline asm
	cvta.to.global.u64 %rd361, %rd362;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r389,%r390,%r391,%r392}, [%rd361];
	// end inline asm
	add.s64 	%rd365, %rd335, 144;
	// begin inline asm
	cvta.to.global.u64 %rd364, %rd365;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r393,%r394,%r395,%r396}, [%rd364];
	// end inline asm
	mov.b32 	%f1370, %r360;
	mov.b32 	%f1371, %r361;
	and.b32  	%r413, %r359, 65535;
	add.s32 	%r414, %r413, -1;
	cvt.rn.f32.s32 	%f1372, %r414;
	sub.f32 	%f1373, %f1355, %f1370;
	mul.f32 	%f1374, %f1373, %f1372;
	sub.f32 	%f1375, %f1371, %f1370;
	div.rn.f32 	%f1376, %f1374, %f1375;
	min.f32 	%f1377, %f1372, %f1376;
	mov.f32 	%f1378, 0f00000000;
	max.f32 	%f1379, %f1378, %f1377;
	cvt.rmi.f32.f32 	%f1380, %f1379;
	sub.f32 	%f408, %f1379, %f1380;
	cvt.rzi.s32.f32 	%r415, %f1380;
	mul.wide.s32 	%rd379, %r415, 64;
	add.s64 	%rd368, %rd344, %rd379;
	// begin inline asm
	cvta.to.global.u64 %rd367, %rd368;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r397,%r398,%r399,%r400}, [%rd367];
	// end inline asm
	mov.b32 	%f2034, %r397;
	mov.b32 	%f2035, %r398;
	mov.b32 	%f2036, %r399;
	mov.b32 	%f2037, %r400;
	add.s64 	%rd371, %rd368, 16;
	// begin inline asm
	cvta.to.global.u64 %rd370, %rd371;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r401,%r402,%r403,%r404}, [%rd370];
	// end inline asm
	mov.b32 	%f2038, %r401;
	mov.b32 	%f2039, %r402;
	mov.b32 	%f2040, %r403;
	mov.b32 	%f2041, %r404;
	add.s64 	%rd374, %rd368, 32;
	// begin inline asm
	cvta.to.global.u64 %rd373, %rd374;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r405,%r406,%r407,%r408}, [%rd373];
	// end inline asm
	mov.b32 	%f2042, %r405;
	mov.b32 	%f2043, %r406;
	mov.b32 	%f2044, %r407;
	mov.b32 	%f2045, %r408;
	add.s64 	%rd377, %rd368, 48;
	// begin inline asm
	cvta.to.global.u64 %rd376, %rd377;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r409,%r410,%r411,%r412}, [%rd376];
	// end inline asm
	mov.b32 	%f2046, %r409;
	mov.b32 	%f2047, %r410;
	mov.b32 	%f2048, %r411;
	mov.b32 	%f2049, %r412;
	setp.leu.f32 	%p36, %f408, 0f00000000;
	@%p36 bra 	$L__BB12_71;

	mov.f32 	%f1381, 0f3F800000;
	sub.f32 	%f1382, %f1381, %f408;
	add.s64 	%rd381, %rd368, 64;
	// begin inline asm
	cvta.to.global.u64 %rd380, %rd381;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r416,%r417,%r418,%r419}, [%rd380];
	// end inline asm
	mov.b32 	%f1383, %r416;
	mov.b32 	%f1384, %r417;
	mov.b32 	%f1385, %r418;
	mov.b32 	%f1386, %r419;
	mul.f32 	%f1387, %f408, %f1383;
	mul.f32 	%f1388, %f408, %f1384;
	mul.f32 	%f1389, %f408, %f1385;
	mul.f32 	%f1390, %f408, %f1386;
	fma.rn.f32 	%f2034, %f1382, %f2034, %f1387;
	fma.rn.f32 	%f2035, %f1382, %f2035, %f1388;
	fma.rn.f32 	%f2036, %f1382, %f2036, %f1389;
	fma.rn.f32 	%f2037, %f1382, %f2037, %f1390;
	add.s64 	%rd384, %rd368, 80;
	// begin inline asm
	cvta.to.global.u64 %rd383, %rd384;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r420,%r421,%r422,%r423}, [%rd383];
	// end inline asm
	mov.b32 	%f1391, %r420;
	mov.b32 	%f1392, %r421;
	mov.b32 	%f1393, %r422;
	mov.b32 	%f1394, %r423;
	mul.f32 	%f1395, %f408, %f1391;
	mul.f32 	%f1396, %f408, %f1392;
	mul.f32 	%f1397, %f408, %f1393;
	mul.f32 	%f1398, %f408, %f1394;
	fma.rn.f32 	%f2038, %f1382, %f2038, %f1395;
	fma.rn.f32 	%f2039, %f1382, %f2039, %f1396;
	fma.rn.f32 	%f2040, %f1382, %f2040, %f1397;
	fma.rn.f32 	%f2041, %f1382, %f2041, %f1398;
	add.s64 	%rd387, %rd368, 96;
	// begin inline asm
	cvta.to.global.u64 %rd386, %rd387;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r424,%r425,%r426,%r427}, [%rd386];
	// end inline asm
	mov.b32 	%f1399, %r424;
	mov.b32 	%f1400, %r425;
	mov.b32 	%f1401, %r426;
	mov.b32 	%f1402, %r427;
	mul.f32 	%f1403, %f408, %f1399;
	mul.f32 	%f1404, %f408, %f1400;
	mul.f32 	%f1405, %f408, %f1401;
	mul.f32 	%f1406, %f408, %f1402;
	fma.rn.f32 	%f2042, %f1382, %f2042, %f1403;
	fma.rn.f32 	%f1407, %f1382, %f2043, %f1404;
	fma.rn.f32 	%f1408, %f1382, %f2044, %f1405;
	fma.rn.f32 	%f1409, %f1382, %f2045, %f1406;
	add.s64 	%rd390, %rd368, 112;
	// begin inline asm
	cvta.to.global.u64 %rd389, %rd390;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r428,%r429,%r430,%r431}, [%rd389];
	// end inline asm
	mov.b32 	%f1410, %r428;
	mov.b32 	%f1411, %r429;
	mov.b32 	%f1412, %r430;
	mov.b32 	%f1413, %r431;
	mul.f32 	%f1414, %f408, %f1410;
	mul.f32 	%f1415, %f408, %f1411;
	mul.f32 	%f1416, %f408, %f1412;
	mul.f32 	%f1417, %f408, %f1413;
	fma.rn.f32 	%f1418, %f1382, %f2046, %f1414;
	fma.rn.f32 	%f2047, %f1382, %f2047, %f1415;
	fma.rn.f32 	%f2048, %f1382, %f2048, %f1416;
	fma.rn.f32 	%f2049, %f1382, %f2049, %f1417;
	mul.f32 	%f1419, %f1408, %f1408;
	fma.rn.f32 	%f1420, %f1407, %f1407, %f1419;
	fma.rn.f32 	%f1421, %f1409, %f1409, %f1420;
	fma.rn.f32 	%f1422, %f1418, %f1418, %f1421;
	sqrt.rn.f32 	%f1423, %f1422;
	rcp.rn.f32 	%f1424, %f1423;
	mul.f32 	%f2043, %f1407, %f1424;
	mul.f32 	%f2044, %f1408, %f1424;
	mul.f32 	%f2045, %f1409, %f1424;
	mul.f32 	%f2046, %f1424, %f1418;

$L__BB12_71:
	mul.f32 	%f1425, %f2044, %f2044;
	fma.rn.f32 	%f1426, %f2043, %f2043, %f1425;
	fma.rn.f32 	%f1427, %f2045, %f2045, %f1426;
	fma.rn.f32 	%f1428, %f2046, %f2046, %f1427;
	rcp.rn.f32 	%f1429, %f1428;
	mul.f32 	%f1430, %f2043, %f1429;
	mul.f32 	%f1431, %f2044, %f1429;
	mul.f32 	%f1432, %f2045, %f1429;
	mul.f32 	%f1433, %f2046, %f1429;
	mul.f32 	%f1434, %f2043, %f1430;
	mul.f32 	%f1435, %f2044, %f1431;
	mul.f32 	%f1436, %f2045, %f1432;
	mul.f32 	%f1437, %f2043, %f1431;
	mul.f32 	%f1438, %f2045, %f1433;
	mul.f32 	%f1439, %f2043, %f1432;
	mul.f32 	%f1440, %f2044, %f1433;
	mul.f32 	%f1441, %f2044, %f1432;
	mul.f32 	%f1442, %f2043, %f1433;
	sub.f32 	%f1443, %f1434, %f1435;
	sub.f32 	%f1444, %f1443, %f1436;
	fma.rn.f32 	%f1445, %f2046, %f1433, %f1444;
	sub.f32 	%f1446, %f1437, %f1438;
	add.f32 	%f1447, %f1446, %f1446;
	add.f32 	%f1448, %f1439, %f1440;
	add.f32 	%f1449, %f1448, %f1448;
	add.f32 	%f1450, %f1437, %f1438;
	add.f32 	%f1451, %f1450, %f1450;
	sub.f32 	%f1452, %f1435, %f1434;
	sub.f32 	%f1453, %f1452, %f1436;
	fma.rn.f32 	%f1454, %f2046, %f1433, %f1453;
	sub.f32 	%f1455, %f1441, %f1442;
	add.f32 	%f1456, %f1455, %f1455;
	sub.f32 	%f1457, %f1439, %f1440;
	add.f32 	%f1458, %f1457, %f1457;
	add.f32 	%f1459, %f1441, %f1442;
	add.f32 	%f1460, %f1459, %f1459;
	neg.f32 	%f1461, %f1434;
	sub.f32 	%f1462, %f1461, %f1435;
	add.f32 	%f1463, %f1436, %f1462;
	fma.rn.f32 	%f1464, %f2046, %f1433, %f1463;
	mul.f32 	%f1465, %f2037, %f1445;
	fma.rn.f32 	%f1466, %f2040, %f1447, %f1465;
	fma.rn.f32 	%f1467, %f2042, %f1449, %f1466;
	sub.f32 	%f2061, %f2047, %f1467;
	mul.f32 	%f1468, %f2040, %f1454;
	fma.rn.f32 	%f1469, %f2037, %f1451, %f1468;
	fma.rn.f32 	%f1470, %f2042, %f1456, %f1469;
	sub.f32 	%f2057, %f2048, %f1470;
	mul.f32 	%f1471, %f2040, %f1460;
	fma.rn.f32 	%f1472, %f2037, %f1458, %f1471;
	fma.rn.f32 	%f1473, %f2042, %f1464, %f1472;
	sub.f32 	%f2053, %f2049, %f1473;
	mul.f32 	%f1474, %f2036, %f1445;
	fma.rn.f32 	%f1475, %f2039, %f1447, %f1474;
	fma.rn.f32 	%f2060, %f2041, %f1449, %f1475;
	mul.f32 	%f1476, %f2039, %f1454;
	fma.rn.f32 	%f1477, %f2036, %f1451, %f1476;
	fma.rn.f32 	%f2056, %f2041, %f1456, %f1477;
	mul.f32 	%f1478, %f2039, %f1460;
	fma.rn.f32 	%f1479, %f2036, %f1458, %f1478;
	fma.rn.f32 	%f2052, %f2041, %f1464, %f1479;
	mul.f32 	%f1480, %f2035, %f1445;
	fma.rn.f32 	%f2059, %f2038, %f1447, %f1480;
	mul.f32 	%f1481, %f2038, %f1454;
	fma.rn.f32 	%f2055, %f2035, %f1451, %f1481;
	mul.f32 	%f1482, %f2038, %f1460;
	fma.rn.f32 	%f2051, %f2035, %f1458, %f1482;
	mul.f32 	%f2058, %f2034, %f1445;
	mul.f32 	%f2054, %f2034, %f1451;
	mul.f32 	%f2050, %f2034, %f1458;
	bra.uni 	$L__BB12_74;

$L__BB12_66:
	// begin inline asm
	call (%rd665), _optix_get_instance_transform_from_handle, (%rd320);
	// end inline asm

$L__BB12_67:
	// begin inline asm
	cvta.to.global.u64 %rd326, %rd665;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r345,%r346,%r347,%r348}, [%rd326];
	// end inline asm
	mov.b32 	%f2058, %r345;
	mov.b32 	%f2059, %r346;
	mov.b32 	%f2060, %r347;
	mov.b32 	%f2061, %r348;
	add.s64 	%rd330, %rd665, 16;
	// begin inline asm
	cvta.to.global.u64 %rd329, %rd330;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r349,%r350,%r351,%r352}, [%rd329];
	// end inline asm
	mov.b32 	%f2054, %r349;
	mov.b32 	%f2055, %r350;
	mov.b32 	%f2056, %r351;
	mov.b32 	%f2057, %r352;
	add.s64 	%rd333, %rd665, 32;
	// begin inline asm
	cvta.to.global.u64 %rd332, %rd333;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r353,%r354,%r355,%r356}, [%rd332];
	// end inline asm
	mov.b32 	%f2050, %r353;
	mov.b32 	%f2051, %r354;
	mov.b32 	%f2052, %r355;
	mov.b32 	%f2053, %r356;

$L__BB12_74:
	setp.eq.s32 	%p38, %r648, 1;
	@%p38 bra 	$L__BB12_76;

	mul.f32 	%f1520, %f2029, %f2059;
	fma.rn.f32 	%f1521, %f2025, %f2058, %f1520;
	fma.rn.f32 	%f506, %f2033, %f2060, %f1521;
	mul.f32 	%f1522, %f2028, %f2059;
	fma.rn.f32 	%f1523, %f2024, %f2058, %f1522;
	fma.rn.f32 	%f507, %f2032, %f2060, %f1523;
	mul.f32 	%f1524, %f2027, %f2059;
	fma.rn.f32 	%f1525, %f2023, %f2058, %f1524;
	fma.rn.f32 	%f508, %f2031, %f2060, %f1525;
	mul.f32 	%f1526, %f2026, %f2059;
	fma.rn.f32 	%f1527, %f2022, %f2058, %f1526;
	fma.rn.f32 	%f1528, %f2030, %f2060, %f1527;
	add.f32 	%f2061, %f2061, %f1528;
	mul.f32 	%f1529, %f2029, %f2055;
	fma.rn.f32 	%f1530, %f2025, %f2054, %f1529;
	fma.rn.f32 	%f510, %f2033, %f2056, %f1530;
	mul.f32 	%f1531, %f2028, %f2055;
	fma.rn.f32 	%f1532, %f2024, %f2054, %f1531;
	fma.rn.f32 	%f511, %f2032, %f2056, %f1532;
	mul.f32 	%f1533, %f2027, %f2055;
	fma.rn.f32 	%f1534, %f2023, %f2054, %f1533;
	fma.rn.f32 	%f512, %f2031, %f2056, %f1534;
	mul.f32 	%f1535, %f2026, %f2055;
	fma.rn.f32 	%f1536, %f2022, %f2054, %f1535;
	fma.rn.f32 	%f1537, %f2030, %f2056, %f1536;
	add.f32 	%f2057, %f2057, %f1537;
	mul.f32 	%f1538, %f2029, %f2051;
	fma.rn.f32 	%f1539, %f2025, %f2050, %f1538;
	fma.rn.f32 	%f514, %f2033, %f2052, %f1539;
	mul.f32 	%f1540, %f2028, %f2051;
	fma.rn.f32 	%f1541, %f2024, %f2050, %f1540;
	fma.rn.f32 	%f515, %f2032, %f2052, %f1541;
	mul.f32 	%f1542, %f2027, %f2051;
	fma.rn.f32 	%f1543, %f2023, %f2050, %f1542;
	fma.rn.f32 	%f516, %f2031, %f2052, %f1543;
	mul.f32 	%f1544, %f2026, %f2051;
	fma.rn.f32 	%f1545, %f2022, %f2050, %f1544;
	fma.rn.f32 	%f1546, %f2030, %f2052, %f1545;
	add.f32 	%f2053, %f2053, %f1546;
	mov.f32 	%f2050, %f514;
	mov.f32 	%f2051, %f515;
	mov.f32 	%f2052, %f516;
	mov.f32 	%f2054, %f510;
	mov.f32 	%f2055, %f511;
	mov.f32 	%f2056, %f512;
	mov.f32 	%f2058, %f506;
	mov.f32 	%f2059, %f507;
	mov.f32 	%f2060, %f508;

$L__BB12_76:
	add.s32 	%r648, %r648, -1;
	add.s32 	%r647, %r647, -1;
	setp.gt.s32 	%p39, %r647, 1;
	mov.f32 	%f2022, %f2061;
	mov.f32 	%f2023, %f2060;
	mov.f32 	%f2024, %f2059;
	mov.f32 	%f2025, %f2058;
	mov.f32 	%f2026, %f2057;
	mov.f32 	%f2027, %f2056;
	mov.f32 	%f2028, %f2055;
	mov.f32 	%f2029, %f2054;
	mov.f32 	%f2030, %f2053;
	mov.f32 	%f2031, %f2052;
	mov.f32 	%f2032, %f2051;
	mov.f32 	%f2033, %f2050;
	@%p39 bra 	$L__BB12_62;

$L__BB12_77:
	// begin inline asm
	call (%r491), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p40, %r491, 0;
	mov.f32 	%f2122, %f2121;
	mov.f32 	%f2117, %f2121;
	mov.f32 	%f2118, %f2120;
	mov.f32 	%f2119, %f2121;
	mov.f32 	%f2114, %f2121;
	mov.f32 	%f2115, %f2121;
	mov.f32 	%f2116, %f2120;
	@%p40 bra 	$L__BB12_96;

	// begin inline asm
	call (%r492), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1556), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p41, %r492, 0;
	@%p41 bra 	$L__BB12_96;

	mov.u32 	%r649, 0;

$L__BB12_80:
	.pragma "nounroll";
	// begin inline asm
	call (%rd439), _optix_get_transform_list_handle, (%r649);
	// end inline asm
	// begin inline asm
	call (%r495), _optix_get_transform_type_from_handle, (%rd439);
	// end inline asm
	or.b32  	%r496, %r495, 1;
	setp.eq.s32 	%p42, %r496, 3;
	@%p42 bra 	$L__BB12_86;
	bra.uni 	$L__BB12_81;

$L__BB12_86:
	setp.eq.s32 	%p45, %r495, 2;
	@%p45 bra 	$L__BB12_90;
	bra.uni 	$L__BB12_87;

$L__BB12_90:
	// begin inline asm
	call (%rd511), _optix_get_matrix_motion_transform_from_handle, (%rd439);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd513, %rd511;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd513];
	// end inline asm
	add.s64 	%rd517, %rd511, 16;
	// begin inline asm
	cvta.to.global.u64 %rd516, %rd517;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r588,%r589,%r590,%r591}, [%rd516];
	// end inline asm
	add.s64 	%rd520, %rd511, 32;
	// begin inline asm
	cvta.to.global.u64 %rd519, %rd520;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd519];
	// end inline asm
	add.s64 	%rd523, %rd511, 48;
	// begin inline asm
	cvta.to.global.u64 %rd522, %rd523;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd522];
	// end inline asm
	add.s64 	%rd526, %rd511, 64;
	// begin inline asm
	cvta.to.global.u64 %rd525, %rd526;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd525];
	// end inline asm
	add.s64 	%rd529, %rd511, 80;
	// begin inline asm
	cvta.to.global.u64 %rd528, %rd529;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd528];
	// end inline asm
	add.s64 	%rd532, %rd511, 96;
	// begin inline asm
	cvta.to.global.u64 %rd531, %rd532;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd531];
	// end inline asm
	add.s64 	%rd535, %rd511, 112;
	// begin inline asm
	cvta.to.global.u64 %rd534, %rd535;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r612,%r613,%r614,%r615}, [%rd534];
	// end inline asm
	mov.b32 	%f1660, %r587;
	mov.b32 	%f1661, %r588;
	and.b32  	%r628, %r586, 65535;
	add.s32 	%r629, %r628, -1;
	cvt.rn.f32.s32 	%f1662, %r629;
	sub.f32 	%f1663, %f1556, %f1660;
	mul.f32 	%f1664, %f1663, %f1662;
	sub.f32 	%f1665, %f1661, %f1660;
	div.rn.f32 	%f1666, %f1664, %f1665;
	min.f32 	%f1667, %f1662, %f1666;
	mov.f32 	%f1668, 0f00000000;
	max.f32 	%f1669, %f1668, %f1667;
	cvt.rmi.f32.f32 	%f1670, %f1669;
	sub.f32 	%f601, %f1669, %f1670;
	cvt.rzi.s32.f32 	%r630, %f1670;
	cvt.s64.s32 	%rd38, %r630;
	mul.wide.s32 	%rd546, %r630, 48;
	add.s64 	%rd538, %rd520, %rd546;
	// begin inline asm
	cvta.to.global.u64 %rd537, %rd538;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r616,%r617,%r618,%r619}, [%rd537];
	// end inline asm
	mov.b32 	%f2111, %r616;
	mov.b32 	%f2112, %r617;
	mov.b32 	%f2113, %r618;
	add.s64 	%rd541, %rd538, 16;
	// begin inline asm
	cvta.to.global.u64 %rd540, %rd541;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r620,%r621,%r622,%r623}, [%rd540];
	// end inline asm
	mov.b32 	%f2108, %r620;
	mov.b32 	%f2109, %r621;
	mov.b32 	%f2110, %r622;
	add.s64 	%rd544, %rd538, 32;
	// begin inline asm
	cvta.to.global.u64 %rd543, %rd544;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r624,%r625,%r626,%r627}, [%rd543];
	// end inline asm
	mov.b32 	%f2105, %r624;
	mov.b32 	%f2106, %r625;
	mov.b32 	%f2107, %r626;
	setp.leu.f32 	%p47, %f601, 0f00000000;
	@%p47 bra 	$L__BB12_92;

	mov.f32 	%f1671, 0f3F800000;
	sub.f32 	%f1672, %f1671, %f601;
	mul.lo.s64 	%rd556, %rd38, 48;
	add.s64 	%rd557, %rd511, %rd556;
	add.s64 	%rd548, %rd557, 80;
	// begin inline asm
	cvta.to.global.u64 %rd547, %rd548;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r631,%r632,%r633,%r634}, [%rd547];
	// end inline asm
	mov.b32 	%f1673, %r631;
	mov.b32 	%f1674, %r632;
	mov.b32 	%f1675, %r633;
	mul.f32 	%f1676, %f601, %f1673;
	mul.f32 	%f1677, %f601, %f1674;
	mul.f32 	%f1678, %f601, %f1675;
	fma.rn.f32 	%f2111, %f1672, %f2111, %f1676;
	fma.rn.f32 	%f2112, %f1672, %f2112, %f1677;
	fma.rn.f32 	%f2113, %f1672, %f2113, %f1678;
	add.s64 	%rd551, %rd557, 96;
	// begin inline asm
	cvta.to.global.u64 %rd550, %rd551;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r635,%r636,%r637,%r638}, [%rd550];
	// end inline asm
	mov.b32 	%f1679, %r635;
	mov.b32 	%f1680, %r636;
	mov.b32 	%f1681, %r637;
	mul.f32 	%f1682, %f601, %f1679;
	mul.f32 	%f1683, %f601, %f1680;
	mul.f32 	%f1684, %f601, %f1681;
	fma.rn.f32 	%f2108, %f1672, %f2108, %f1682;
	fma.rn.f32 	%f2109, %f1672, %f2109, %f1683;
	fma.rn.f32 	%f2110, %f1672, %f2110, %f1684;
	add.s64 	%rd554, %rd557, 112;
	// begin inline asm
	cvta.to.global.u64 %rd553, %rd554;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r639,%r640,%r641,%r642}, [%rd553];
	// end inline asm
	mov.b32 	%f1685, %r639;
	mov.b32 	%f1686, %r640;
	mov.b32 	%f1687, %r641;
	mul.f32 	%f1688, %f601, %f1685;
	mul.f32 	%f1689, %f601, %f1686;
	mul.f32 	%f1690, %f601, %f1687;
	fma.rn.f32 	%f2105, %f1672, %f2105, %f1688;
	fma.rn.f32 	%f2106, %f1672, %f2106, %f1689;
	fma.rn.f32 	%f2107, %f1672, %f2107, %f1690;
	bra.uni 	$L__BB12_92;

$L__BB12_81:
	mov.f32 	%f2114, 0f00000000;
	mov.f32 	%f2116, 0f3F800000;
	setp.eq.s32 	%p43, %r495, 4;
	@%p43 bra 	$L__BB12_84;

	setp.ne.s32 	%p44, %r495, 1;
	mov.f32 	%f2115, %f2114;
	mov.f32 	%f2117, %f2114;
	mov.f32 	%f2118, %f2116;
	mov.f32 	%f2119, %f2114;
	mov.f32 	%f2120, %f2116;
	mov.f32 	%f2121, %f2114;
	mov.f32 	%f2122, %f2114;
	@%p44 bra 	$L__BB12_93;

	// begin inline asm
	call (%rd441), _optix_get_static_transform_from_handle, (%rd439);
	// end inline asm
	add.s64 	%rd666, %rd441, 64;
	bra.uni 	$L__BB12_85;

$L__BB12_87:
	// begin inline asm
	call (%rd454), _optix_get_srt_motion_transform_from_handle, (%rd439);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd456, %rd454;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd456];
	// end inline asm
	add.s64 	%rd460, %rd454, 16;
	// begin inline asm
	cvta.to.global.u64 %rd459, %rd460;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r513,%r514,%r515,%r516}, [%rd459];
	// end inline asm
	add.s64 	%rd463, %rd454, 32;
	// begin inline asm
	cvta.to.global.u64 %rd462, %rd463;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r517,%r518,%r519,%r520}, [%rd462];
	// end inline asm
	add.s64 	%rd466, %rd454, 48;
	// begin inline asm
	cvta.to.global.u64 %rd465, %rd466;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r521,%r522,%r523,%r524}, [%rd465];
	// end inline asm
	add.s64 	%rd469, %rd454, 64;
	// begin inline asm
	cvta.to.global.u64 %rd468, %rd469;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r525,%r526,%r527,%r528}, [%rd468];
	// end inline asm
	add.s64 	%rd472, %rd454, 80;
	// begin inline asm
	cvta.to.global.u64 %rd471, %rd472;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r529,%r530,%r531,%r532}, [%rd471];
	// end inline asm
	add.s64 	%rd475, %rd454, 96;
	// begin inline asm
	cvta.to.global.u64 %rd474, %rd475;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r533,%r534,%r535,%r536}, [%rd474];
	// end inline asm
	add.s64 	%rd478, %rd454, 112;
	// begin inline asm
	cvta.to.global.u64 %rd477, %rd478;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r537,%r538,%r539,%r540}, [%rd477];
	// end inline asm
	add.s64 	%rd481, %rd454, 128;
	// begin inline asm
	cvta.to.global.u64 %rd480, %rd481;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r541,%r542,%r543,%r544}, [%rd480];
	// end inline asm
	add.s64 	%rd484, %rd454, 144;
	// begin inline asm
	cvta.to.global.u64 %rd483, %rd484;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r545,%r546,%r547,%r548}, [%rd483];
	// end inline asm
	mov.b32 	%f1568, %r512;
	mov.b32 	%f1569, %r513;
	and.b32  	%r565, %r511, 65535;
	add.s32 	%r566, %r565, -1;
	cvt.rn.f32.s32 	%f1570, %r566;
	sub.f32 	%f1571, %f1556, %f1568;
	mul.f32 	%f1572, %f1571, %f1570;
	sub.f32 	%f1573, %f1569, %f1568;
	div.rn.f32 	%f1574, %f1572, %f1573;
	min.f32 	%f1575, %f1570, %f1574;
	mov.f32 	%f1576, 0f00000000;
	max.f32 	%f1577, %f1576, %f1575;
	cvt.rmi.f32.f32 	%f1578, %f1577;
	sub.f32 	%f561, %f1577, %f1578;
	cvt.rzi.s32.f32 	%r567, %f1578;
	mul.wide.s32 	%rd498, %r567, 64;
	add.s64 	%rd487, %rd463, %rd498;
	// begin inline asm
	cvta.to.global.u64 %rd486, %rd487;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r549,%r550,%r551,%r552}, [%rd486];
	// end inline asm
	mov.b32 	%f2095, %r549;
	mov.b32 	%f2096, %r550;
	mov.b32 	%f2097, %r551;
	add.s64 	%rd490, %rd487, 16;
	// begin inline asm
	cvta.to.global.u64 %rd489, %rd490;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r553,%r554,%r555,%r556}, [%rd489];
	// end inline asm
	mov.b32 	%f2098, %r553;
	mov.b32 	%f2099, %r554;
	mov.b32 	%f2100, %r556;
	add.s64 	%rd493, %rd487, 32;
	// begin inline asm
	cvta.to.global.u64 %rd492, %rd493;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r557,%r558,%r559,%r560}, [%rd492];
	// end inline asm
	mov.b32 	%f2101, %r558;
	mov.b32 	%f2102, %r559;
	mov.b32 	%f2103, %r560;
	add.s64 	%rd496, %rd487, 48;
	// begin inline asm
	cvta.to.global.u64 %rd495, %rd496;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r561,%r562,%r563,%r564}, [%rd495];
	// end inline asm
	mov.b32 	%f2104, %r561;
	setp.leu.f32 	%p46, %f561, 0f00000000;
	@%p46 bra 	$L__BB12_89;

	mov.f32 	%f1579, 0f3F800000;
	sub.f32 	%f1580, %f1579, %f561;
	add.s64 	%rd500, %rd487, 64;
	// begin inline asm
	cvta.to.global.u64 %rd499, %rd500;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd499];
	// end inline asm
	mov.b32 	%f1581, %r568;
	mov.b32 	%f1582, %r569;
	mov.b32 	%f1583, %r570;
	mul.f32 	%f1584, %f561, %f1581;
	mul.f32 	%f1585, %f561, %f1582;
	mul.f32 	%f1586, %f561, %f1583;
	fma.rn.f32 	%f2095, %f1580, %f2095, %f1584;
	fma.rn.f32 	%f2096, %f1580, %f2096, %f1585;
	fma.rn.f32 	%f2097, %f1580, %f2097, %f1586;
	add.s64 	%rd503, %rd487, 80;
	// begin inline asm
	cvta.to.global.u64 %rd502, %rd503;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd502];
	// end inline asm
	mov.b32 	%f1587, %r572;
	mov.b32 	%f1588, %r573;
	mov.b32 	%f1589, %r575;
	mul.f32 	%f1590, %f561, %f1587;
	mul.f32 	%f1591, %f561, %f1588;
	mul.f32 	%f1592, %f561, %f1589;
	fma.rn.f32 	%f2098, %f1580, %f2098, %f1590;
	fma.rn.f32 	%f2099, %f1580, %f2099, %f1591;
	fma.rn.f32 	%f2100, %f1580, %f2100, %f1592;
	add.s64 	%rd506, %rd487, 96;
	// begin inline asm
	cvta.to.global.u64 %rd505, %rd506;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd505];
	// end inline asm
	mov.b32 	%f1593, %r577;
	mov.b32 	%f1594, %r578;
	mov.b32 	%f1595, %r579;
	mul.f32 	%f1596, %f561, %f1593;
	mul.f32 	%f1597, %f561, %f1594;
	mul.f32 	%f1598, %f561, %f1595;
	fma.rn.f32 	%f1599, %f1580, %f2101, %f1596;
	fma.rn.f32 	%f1600, %f1580, %f2102, %f1597;
	fma.rn.f32 	%f1601, %f1580, %f2103, %f1598;
	add.s64 	%rd509, %rd487, 112;
	// begin inline asm
	cvta.to.global.u64 %rd508, %rd509;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd508];
	// end inline asm
	mov.b32 	%f1602, %r580;
	mul.f32 	%f1603, %f561, %f1602;
	fma.rn.f32 	%f1604, %f1580, %f2104, %f1603;
	mul.f32 	%f1605, %f1600, %f1600;
	fma.rn.f32 	%f1606, %f1599, %f1599, %f1605;
	fma.rn.f32 	%f1607, %f1601, %f1601, %f1606;
	fma.rn.f32 	%f1608, %f1604, %f1604, %f1607;
	sqrt.rn.f32 	%f1609, %f1608;
	rcp.rn.f32 	%f1610, %f1609;
	mul.f32 	%f2101, %f1599, %f1610;
	mul.f32 	%f2102, %f1600, %f1610;
	mul.f32 	%f2103, %f1601, %f1610;
	mul.f32 	%f2104, %f1610, %f1604;

$L__BB12_89:
	mul.f32 	%f1611, %f2102, %f2102;
	fma.rn.f32 	%f1612, %f2101, %f2101, %f1611;
	fma.rn.f32 	%f1613, %f2103, %f2103, %f1612;
	fma.rn.f32 	%f1614, %f2104, %f2104, %f1613;
	rcp.rn.f32 	%f1615, %f1614;
	mul.f32 	%f1616, %f2101, %f1615;
	mul.f32 	%f1617, %f2102, %f1615;
	mul.f32 	%f1618, %f2103, %f1615;
	mul.f32 	%f1619, %f2104, %f1615;
	mul.f32 	%f1620, %f2101, %f1616;
	mul.f32 	%f1621, %f2102, %f1617;
	mul.f32 	%f1622, %f2103, %f1618;
	mul.f32 	%f1623, %f2101, %f1617;
	mul.f32 	%f1624, %f2103, %f1619;
	mul.f32 	%f1625, %f2101, %f1618;
	mul.f32 	%f1626, %f2102, %f1619;
	mul.f32 	%f1627, %f2102, %f1618;
	mul.f32 	%f1628, %f2101, %f1619;
	sub.f32 	%f1629, %f1620, %f1621;
	sub.f32 	%f1630, %f1629, %f1622;
	fma.rn.f32 	%f1631, %f2104, %f1619, %f1630;
	sub.f32 	%f1632, %f1623, %f1624;
	add.f32 	%f1633, %f1632, %f1632;
	add.f32 	%f1634, %f1625, %f1626;
	add.f32 	%f1635, %f1634, %f1634;
	add.f32 	%f1636, %f1623, %f1624;
	add.f32 	%f1637, %f1636, %f1636;
	sub.f32 	%f1638, %f1621, %f1620;
	sub.f32 	%f1639, %f1638, %f1622;
	fma.rn.f32 	%f1640, %f2104, %f1619, %f1639;
	sub.f32 	%f1641, %f1627, %f1628;
	add.f32 	%f1642, %f1641, %f1641;
	sub.f32 	%f1643, %f1625, %f1626;
	add.f32 	%f1644, %f1643, %f1643;
	add.f32 	%f1645, %f1627, %f1628;
	add.f32 	%f1646, %f1645, %f1645;
	neg.f32 	%f1647, %f1620;
	sub.f32 	%f1648, %f1647, %f1621;
	add.f32 	%f1649, %f1622, %f1648;
	fma.rn.f32 	%f1650, %f2104, %f1619, %f1649;
	mul.f32 	%f1651, %f2097, %f1631;
	fma.rn.f32 	%f1652, %f2099, %f1633, %f1651;
	fma.rn.f32 	%f2113, %f2100, %f1635, %f1652;
	mul.f32 	%f1653, %f2099, %f1640;
	fma.rn.f32 	%f1654, %f2097, %f1637, %f1653;
	fma.rn.f32 	%f2110, %f2100, %f1642, %f1654;
	mul.f32 	%f1655, %f2099, %f1646;
	fma.rn.f32 	%f1656, %f2097, %f1644, %f1655;
	fma.rn.f32 	%f2107, %f2100, %f1650, %f1656;
	mul.f32 	%f1657, %f2096, %f1631;
	fma.rn.f32 	%f2112, %f2098, %f1633, %f1657;
	mul.f32 	%f1658, %f2098, %f1640;
	fma.rn.f32 	%f2109, %f2096, %f1637, %f1658;
	mul.f32 	%f1659, %f2098, %f1646;
	fma.rn.f32 	%f2106, %f2096, %f1644, %f1659;
	mul.f32 	%f2111, %f2095, %f1631;
	mul.f32 	%f2108, %f2095, %f1637;
	mul.f32 	%f2105, %f2095, %f1644;

$L__BB12_92:
	mul.f32 	%f1691, %f2106, %f2110;
	mul.f32 	%f1692, %f2107, %f2109;
	sub.f32 	%f1693, %f1692, %f1691;
	mul.f32 	%f1694, %f2111, %f1693;
	mul.f32 	%f1695, %f2105, %f2110;
	mul.f32 	%f1696, %f2107, %f2108;
	sub.f32 	%f1697, %f1696, %f1695;
	mul.f32 	%f1698, %f1697, %f2112;
	sub.f32 	%f1699, %f1694, %f1698;
	mul.f32 	%f1700, %f2105, %f2109;
	mul.f32 	%f1701, %f2106, %f2108;
	sub.f32 	%f1702, %f1701, %f1700;
	fma.rn.f32 	%f1703, %f1702, %f2113, %f1699;
	rcp.rn.f32 	%f1704, %f1703;
	mul.f32 	%f2120, %f1693, %f1704;
	mul.f32 	%f1705, %f2107, %f2112;
	mul.f32 	%f1706, %f2106, %f2113;
	sub.f32 	%f1707, %f1706, %f1705;
	mul.f32 	%f2121, %f1707, %f1704;
	mul.f32 	%f1708, %f2109, %f2113;
	mul.f32 	%f1709, %f2110, %f2112;
	sub.f32 	%f1710, %f1709, %f1708;
	mul.f32 	%f2122, %f1710, %f1704;
	sub.f32 	%f1711, %f1695, %f1696;
	mul.f32 	%f2117, %f1711, %f1704;
	mul.f32 	%f1712, %f2105, %f2113;
	mul.f32 	%f1713, %f2107, %f2111;
	sub.f32 	%f1714, %f1713, %f1712;
	mul.f32 	%f2118, %f1714, %f1704;
	mul.f32 	%f1715, %f2110, %f2111;
	mul.f32 	%f1716, %f2108, %f2113;
	sub.f32 	%f1717, %f1716, %f1715;
	mul.f32 	%f2119, %f1717, %f1704;
	mul.f32 	%f2114, %f1702, %f1704;
	mul.f32 	%f1718, %f2106, %f2111;
	mul.f32 	%f1719, %f2105, %f2112;
	sub.f32 	%f1720, %f1719, %f1718;
	mul.f32 	%f2115, %f1720, %f1704;
	mul.f32 	%f1721, %f2108, %f2112;
	mul.f32 	%f1722, %f2109, %f2111;
	sub.f32 	%f1723, %f1722, %f1721;
	mul.f32 	%f2116, %f1723, %f1704;
	bra.uni 	$L__BB12_93;

$L__BB12_84:
	// begin inline asm
	call (%rd666), _optix_get_instance_inverse_transform_from_handle, (%rd439);
	// end inline asm

$L__BB12_85:
	// begin inline asm
	cvta.to.global.u64 %rd445, %rd666;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd445];
	// end inline asm
	mov.b32 	%f2120, %r497;
	mov.b32 	%f2121, %r498;
	mov.b32 	%f2122, %r499;
	add.s64 	%rd449, %rd666, 16;
	// begin inline asm
	cvta.to.global.u64 %rd448, %rd449;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd448];
	// end inline asm
	mov.b32 	%f2117, %r501;
	mov.b32 	%f2118, %r502;
	mov.b32 	%f2119, %r503;
	add.s64 	%rd452, %rd666, 32;
	// begin inline asm
	cvta.to.global.u64 %rd451, %rd452;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd451];
	// end inline asm
	mov.b32 	%f2114, %r505;
	mov.b32 	%f2115, %r506;
	mov.b32 	%f2116, %r507;

$L__BB12_93:
	setp.eq.s32 	%p48, %r649, 0;
	@%p48 bra 	$L__BB12_95;

	mul.f32 	%f1724, %f2091, %f2121;
	fma.rn.f32 	%f1725, %f2088, %f2120, %f1724;
	fma.rn.f32 	%f647, %f2094, %f2122, %f1725;
	mul.f32 	%f1726, %f2090, %f2121;
	fma.rn.f32 	%f1727, %f2087, %f2120, %f1726;
	fma.rn.f32 	%f648, %f2093, %f2122, %f1727;
	mul.f32 	%f1728, %f2089, %f2121;
	fma.rn.f32 	%f1729, %f2086, %f2120, %f1728;
	fma.rn.f32 	%f2122, %f2092, %f2122, %f1729;
	mul.f32 	%f1730, %f2091, %f2118;
	fma.rn.f32 	%f1731, %f2088, %f2117, %f1730;
	fma.rn.f32 	%f650, %f2094, %f2119, %f1731;
	mul.f32 	%f1732, %f2090, %f2118;
	fma.rn.f32 	%f1733, %f2087, %f2117, %f1732;
	fma.rn.f32 	%f651, %f2093, %f2119, %f1733;
	mul.f32 	%f1734, %f2089, %f2118;
	fma.rn.f32 	%f1735, %f2086, %f2117, %f1734;
	fma.rn.f32 	%f2119, %f2092, %f2119, %f1735;
	mul.f32 	%f1736, %f2091, %f2115;
	fma.rn.f32 	%f1737, %f2088, %f2114, %f1736;
	fma.rn.f32 	%f653, %f2094, %f2116, %f1737;
	mul.f32 	%f1738, %f2090, %f2115;
	fma.rn.f32 	%f1739, %f2087, %f2114, %f1738;
	fma.rn.f32 	%f654, %f2093, %f2116, %f1739;
	mul.f32 	%f1740, %f2089, %f2115;
	fma.rn.f32 	%f1741, %f2086, %f2114, %f1740;
	fma.rn.f32 	%f2116, %f2092, %f2116, %f1741;
	mov.f32 	%f2114, %f653;
	mov.f32 	%f2115, %f654;
	mov.f32 	%f2117, %f650;
	mov.f32 	%f2118, %f651;
	mov.f32 	%f2120, %f647;
	mov.f32 	%f2121, %f648;

$L__BB12_95:
	add.s32 	%r649, %r649, 1;
	setp.lt.u32 	%p49, %r649, %r492;
	mov.f32 	%f2086, %f2122;
	mov.f32 	%f2087, %f2121;
	mov.f32 	%f2088, %f2120;
	mov.f32 	%f2089, %f2119;
	mov.f32 	%f2090, %f2118;
	mov.f32 	%f2091, %f2117;
	mov.f32 	%f2092, %f2116;
	mov.f32 	%f2093, %f2115;
	mov.f32 	%f2094, %f2114;
	@%p49 bra 	$L__BB12_80;

$L__BB12_96:
	fma.rn.f32 	%f1742, %f2177, %f2058, %f2061;
	fma.rn.f32 	%f1743, %f2178, %f2059, %f1742;
	fma.rn.f32 	%f1744, %f2177, %f2054, %f2057;
	fma.rn.f32 	%f1745, %f2178, %f2055, %f1744;
	fma.rn.f32 	%f1746, %f2177, %f2050, %f2053;
	fma.rn.f32 	%f1747, %f2178, %f2051, %f1746;
	fma.rn.f32 	%f2177, %f2179, %f2060, %f1743;
	fma.rn.f32 	%f2178, %f2179, %f2056, %f1745;
	fma.rn.f32 	%f2179, %f2179, %f2052, %f1747;
	ld.const.u64 	%rd558, [params+112];
	setp.eq.s64 	%p50, %rd558, 0;
	mov.f32 	%f2171, %f2162;
	mov.f32 	%f2172, %f2159;
	mov.f32 	%f2143, %f2173;
	@%p50 bra 	$L__BB12_98;

	mul.f32 	%f1748, %f2162, %f2120;
	fma.rn.f32 	%f1749, %f2159, %f2117, %f1748;
	mul.f32 	%f1750, %f2162, %f2121;
	fma.rn.f32 	%f1751, %f2159, %f2118, %f1750;
	mul.f32 	%f1752, %f2162, %f2122;
	fma.rn.f32 	%f1753, %f2159, %f2119, %f1752;
	fma.rn.f32 	%f1754, %f2173, %f2114, %f1749;
	fma.rn.f32 	%f1755, %f2173, %f2115, %f1751;
	fma.rn.f32 	%f1756, %f2173, %f2116, %f1753;
	mul.f32 	%f1757, %f1754, %f1754;
	fma.rn.f32 	%f1758, %f1755, %f1755, %f1757;
	fma.rn.f32 	%f1759, %f1756, %f1756, %f1758;
	sqrt.rn.f32 	%f1760, %f1759;
	div.rn.f32 	%f2171, %f1754, %f1760;
	div.rn.f32 	%f2172, %f1755, %f1760;
	div.rn.f32 	%f2143, %f1756, %f1760;

$L__BB12_98:
	ld.const.u64 	%rd559, [params+136];
	setp.eq.s64 	%p51, %rd559, 0;
	mov.f32 	%f2174, %f2162;
	mov.f32 	%f2175, %f2159;
	@%p51 bra 	$L__BB12_100;

	mul.f32 	%f1761, %f2162, %f2120;
	fma.rn.f32 	%f1762, %f2159, %f2117, %f1761;
	mul.f32 	%f1763, %f2162, %f2121;
	fma.rn.f32 	%f1764, %f2159, %f2118, %f1763;
	mul.f32 	%f1765, %f2162, %f2122;
	fma.rn.f32 	%f1766, %f2159, %f2119, %f1765;
	fma.rn.f32 	%f1767, %f2173, %f2114, %f1762;
	fma.rn.f32 	%f1768, %f2173, %f2115, %f1764;
	fma.rn.f32 	%f1769, %f2173, %f2116, %f1766;
	mul.f32 	%f1770, %f1767, %f1767;
	fma.rn.f32 	%f1771, %f1768, %f1768, %f1770;
	fma.rn.f32 	%f1772, %f1769, %f1769, %f1771;
	sqrt.rn.f32 	%f1773, %f1772;
	div.rn.f32 	%f2174, %f1767, %f1773;
	div.rn.f32 	%f2175, %f1768, %f1773;
	div.rn.f32 	%f2173, %f1769, %f1773;

$L__BB12_100:
	mov.f32 	%f2176, %f2173;
	ld.const.u64 	%rd560, [params+184];
	setp.eq.s64 	%p52, %rd560, 0;
	mov.f32 	%f2160, 0f00000000;
	mov.f32 	%f2161, 0f3F800000;
	mov.f32 	%f2165, %f2159;
	mov.f32 	%f2166, %f2160;
	mov.f32 	%f2167, %f2161;
	mov.f32 	%f2168, %f2162;
	mov.f32 	%f2169, %f2161;
	mov.f32 	%f2170, %f2160;
	@%p52 bra 	$L__BB12_102;

	mul.f32 	%f1778, %f2162, %f2058;
	mov.f32 	%f1779, 0f3F800000;
	fma.rn.f32 	%f1780, %f1779, %f2059, %f1778;
	mul.f32 	%f1781, %f2162, %f2054;
	fma.rn.f32 	%f1782, %f1779, %f2055, %f1781;
	mul.f32 	%f1783, %f2162, %f2050;
	fma.rn.f32 	%f1784, %f1779, %f2051, %f1783;
	mov.f32 	%f1785, 0f00000000;
	fma.rn.f32 	%f2168, %f1785, %f2060, %f1780;
	fma.rn.f32 	%f2169, %f1785, %f2056, %f1782;
	fma.rn.f32 	%f2170, %f1785, %f2052, %f1784;
	mul.f32 	%f1786, %f2159, %f2058;
	fma.rn.f32 	%f1787, %f1785, %f2059, %f1786;
	mul.f32 	%f1788, %f2159, %f2054;
	fma.rn.f32 	%f1789, %f1785, %f2055, %f1788;
	mul.f32 	%f1790, %f2159, %f2050;
	fma.rn.f32 	%f1791, %f1785, %f2051, %f1790;
	fma.rn.f32 	%f2165, %f1779, %f2060, %f1787;
	fma.rn.f32 	%f2166, %f1779, %f2056, %f1789;
	fma.rn.f32 	%f2167, %f1779, %f2052, %f1791;

$L__BB12_102:
	ld.const.u64 	%rd561, [params+232];
	ld.const.u64 	%rd562, [params+280];
	or.b64  	%rd563, %rd561, %rd562;
	setp.eq.s64 	%p53, %rd563, 0;
	mov.f32 	%f2163, %f2161;
	mov.f32 	%f2164, %f2160;
	@%p53 bra 	$L__BB12_104;

	mul.f32 	%f1796, %f2174, %f2058;
	fma.rn.f32 	%f1797, %f2175, %f2054, %f1796;
	mul.f32 	%f1798, %f2174, %f2059;
	fma.rn.f32 	%f1799, %f2175, %f2055, %f1798;
	mul.f32 	%f1800, %f2174, %f2060;
	fma.rn.f32 	%f1801, %f2175, %f2056, %f1800;
	fma.rn.f32 	%f1802, %f2176, %f2050, %f1797;
	fma.rn.f32 	%f1803, %f2176, %f2051, %f1799;
	fma.rn.f32 	%f1804, %f2176, %f2052, %f1801;
	mul.f32 	%f1805, %f1802, %f1802;
	fma.rn.f32 	%f1806, %f1803, %f1803, %f1805;
	fma.rn.f32 	%f1807, %f1804, %f1804, %f1806;
	sqrt.rn.f32 	%f1808, %f1807;
	div.rn.f32 	%f1809, %f1802, %f1808;
	div.rn.f32 	%f1810, %f1803, %f1808;
	div.rn.f32 	%f1811, %f1804, %f1808;
	mul.f32 	%f1812, %f1809, %f2120;
	mul.f32 	%f1813, %f1809, %f2121;
	mul.f32 	%f1814, %f1809, %f2122;
	fma.rn.f32 	%f1815, %f1810, %f2117, %f1812;
	fma.rn.f32 	%f1816, %f1810, %f2118, %f1813;
	fma.rn.f32 	%f1817, %f1810, %f2119, %f1814;
	fma.rn.f32 	%f1818, %f1811, %f2114, %f1815;
	fma.rn.f32 	%f1819, %f1811, %f2115, %f1816;
	fma.rn.f32 	%f1820, %f1811, %f2116, %f1817;
	mul.f32 	%f1821, %f1818, %f1818;
	fma.rn.f32 	%f1822, %f1819, %f1819, %f1821;
	fma.rn.f32 	%f1823, %f1820, %f1820, %f1822;
	sqrt.rn.f32 	%f1824, %f1823;
	rcp.rn.f32 	%f1825, %f1824;
	mov.f32 	%f1826, 0f3F800000;
	mul.f32 	%f1827, %f1825, %f1818;
	mul.f32 	%f1828, %f1825, %f1819;
	mul.f32 	%f1829, %f1825, %f1820;
	mul.f32 	%f1830, %f2162, %f2120;
	fma.rn.f32 	%f1831, %f1826, %f2117, %f1830;
	mul.f32 	%f1832, %f2162, %f2121;
	fma.rn.f32 	%f1833, %f1826, %f2118, %f1832;
	mul.f32 	%f1834, %f2162, %f2122;
	fma.rn.f32 	%f1835, %f1826, %f2119, %f1834;
	mov.f32 	%f1836, 0f00000000;
	fma.rn.f32 	%f1837, %f1836, %f2114, %f1831;
	fma.rn.f32 	%f1838, %f1836, %f2115, %f1833;
	fma.rn.f32 	%f1839, %f1836, %f2116, %f1835;
	mul.f32 	%f1840, %f1837, %f1825;
	mul.f32 	%f1841, %f1838, %f1825;
	mul.f32 	%f1842, %f1839, %f1825;
	mul.f32 	%f1843, %f2159, %f2120;
	fma.rn.f32 	%f1844, %f1836, %f2117, %f1843;
	mul.f32 	%f1845, %f2159, %f2121;
	fma.rn.f32 	%f1846, %f1836, %f2118, %f1845;
	mul.f32 	%f1847, %f2159, %f2122;
	fma.rn.f32 	%f1848, %f1836, %f2119, %f1847;
	fma.rn.f32 	%f1849, %f1826, %f2114, %f1844;
	fma.rn.f32 	%f1850, %f1826, %f2115, %f1846;
	fma.rn.f32 	%f1851, %f1826, %f2116, %f1848;
	mul.f32 	%f1852, %f1849, %f1825;
	mul.f32 	%f1853, %f1850, %f1825;
	mul.f32 	%f1854, %f1851, %f1825;
	mul.f32 	%f1855, %f1827, %f1840;
	fma.rn.f32 	%f1856, %f1828, %f1841, %f1855;
	fma.rn.f32 	%f1857, %f1829, %f1842, %f1856;
	mul.f32 	%f1858, %f1827, %f1857;
	mul.f32 	%f1859, %f1828, %f1857;
	mul.f32 	%f1860, %f1829, %f1857;
	sub.f32 	%f2162, %f1840, %f1858;
	sub.f32 	%f2163, %f1841, %f1859;
	sub.f32 	%f2164, %f1842, %f1860;
	mul.f32 	%f1861, %f1827, %f1852;
	fma.rn.f32 	%f1862, %f1828, %f1853, %f1861;
	fma.rn.f32 	%f1863, %f1829, %f1854, %f1862;
	mul.f32 	%f1864, %f1827, %f1863;
	mul.f32 	%f1865, %f1828, %f1863;
	mul.f32 	%f1866, %f1829, %f1863;
	sub.f32 	%f2159, %f1852, %f1864;
	sub.f32 	%f2160, %f1853, %f1865;
	sub.f32 	%f2161, %f1854, %f1866;

$L__BB12_104:
	st.global.u32 	[%rd24], %r338;
	mov.f32 	%f2173, %f2143;

$L__BB12_105:
	ld.const.u64 	%rd564, [params+328];
	cvta.to.global.u64 	%rd565, %rd564;
	shl.b64 	%rd566, %rd23, 3;
	add.s64 	%rd567, %rd565, %rd566;
	st.global.u64 	[%rd567], %rd22;
	ld.const.u64 	%rd568, [params+336];
	cvta.to.global.u64 	%rd569, %rd568;
	shl.b64 	%rd570, %rd23, 2;
	add.s64 	%rd571, %rd569, %rd570;
	mov.u32 	%r643, 0;
	st.global.u32 	[%rd571], %r643;
	ld.const.u64 	%rd572, [params+160];
	cvta.to.global.u64 	%rd573, %rd572;
	add.s64 	%rd574, %rd573, %rd570;
	st.global.f32 	[%rd574], %f2177;
	ld.const.u64 	%rd575, [params+168];
	cvta.to.global.u64 	%rd576, %rd575;
	add.s64 	%rd577, %rd576, %rd570;
	st.global.f32 	[%rd577], %f2178;
	ld.const.u64 	%rd578, [params+176];
	cvta.to.global.u64 	%rd579, %rd578;
	add.s64 	%rd580, %rd579, %rd570;
	st.global.f32 	[%rd580], %f2179;
	ld.const.u64 	%rd581, [params+72];
	cvta.to.global.u64 	%rd582, %rd581;
	add.s64 	%rd583, %rd582, %rd570;
	st.global.f32 	[%rd583], %f1182;
	@%p27 bra 	$L__BB12_107;

	cvta.to.global.u64 	%rd584, %rd21;
	add.s64 	%rd586, %rd584, %rd570;
	st.global.f32 	[%rd586], %f2021;
	ld.const.u64 	%rd587, [params+104];
	cvta.to.global.u64 	%rd588, %rd587;
	add.s64 	%rd589, %rd588, %rd570;
	st.global.f32 	[%rd589], %f2020;

$L__BB12_107:
	ld.const.u64 	%rd39, [params+112];
	setp.eq.s64 	%p55, %rd39, 0;
	@%p55 bra 	$L__BB12_109;

	cvta.to.global.u64 	%rd590, %rd39;
	add.s64 	%rd592, %rd590, %rd570;
	st.global.f32 	[%rd592], %f2171;
	ld.const.u64 	%rd593, [params+120];
	cvta.to.global.u64 	%rd594, %rd593;
	add.s64 	%rd595, %rd594, %rd570;
	st.global.f32 	[%rd595], %f2172;
	ld.const.u64 	%rd596, [params+128];
	cvta.to.global.u64 	%rd597, %rd596;
	add.s64 	%rd598, %rd597, %rd570;
	st.global.f32 	[%rd598], %f2173;

$L__BB12_109:
	ld.const.u64 	%rd40, [params+136];
	setp.eq.s64 	%p56, %rd40, 0;
	@%p56 bra 	$L__BB12_111;

	cvta.to.global.u64 	%rd599, %rd40;
	add.s64 	%rd601, %rd599, %rd570;
	st.global.f32 	[%rd601], %f2174;
	ld.const.u64 	%rd602, [params+144];
	cvta.to.global.u64 	%rd603, %rd602;
	add.s64 	%rd604, %rd603, %rd570;
	st.global.f32 	[%rd604], %f2175;
	ld.const.u64 	%rd605, [params+152];
	cvta.to.global.u64 	%rd606, %rd605;
	add.s64 	%rd607, %rd606, %rd570;
	st.global.f32 	[%rd607], %f2176;

$L__BB12_111:
	ld.const.u64 	%rd41, [params+184];
	setp.eq.s64 	%p57, %rd41, 0;
	@%p57 bra 	$L__BB12_113;

	cvta.to.global.u64 	%rd608, %rd41;
	add.s64 	%rd610, %rd608, %rd570;
	st.global.f32 	[%rd610], %f2168;
	ld.const.u64 	%rd611, [params+192];
	cvta.to.global.u64 	%rd612, %rd611;
	add.s64 	%rd613, %rd612, %rd570;
	st.global.f32 	[%rd613], %f2169;
	ld.const.u64 	%rd614, [params+200];
	cvta.to.global.u64 	%rd615, %rd614;
	add.s64 	%rd616, %rd615, %rd570;
	st.global.f32 	[%rd616], %f2170;
	ld.const.u64 	%rd617, [params+208];
	cvta.to.global.u64 	%rd618, %rd617;
	add.s64 	%rd619, %rd618, %rd570;
	st.global.f32 	[%rd619], %f2165;
	ld.const.u64 	%rd620, [params+216];
	cvta.to.global.u64 	%rd621, %rd620;
	add.s64 	%rd622, %rd621, %rd570;
	st.global.f32 	[%rd622], %f2166;
	ld.const.u64 	%rd623, [params+224];
	cvta.to.global.u64 	%rd624, %rd623;
	add.s64 	%rd625, %rd624, %rd570;
	st.global.f32 	[%rd625], %f2167;

$L__BB12_113:
	ld.const.u64 	%rd42, [params+232];
	setp.eq.s64 	%p58, %rd42, 0;
	@%p58 bra 	$L__BB12_115;

	cvta.to.global.u64 	%rd626, %rd42;
	add.s64 	%rd628, %rd626, %rd570;
	st.global.f32 	[%rd628], %f2162;
	ld.const.u64 	%rd629, [params+240];
	cvta.to.global.u64 	%rd630, %rd629;
	add.s64 	%rd631, %rd630, %rd570;
	st.global.f32 	[%rd631], %f2163;
	ld.const.u64 	%rd632, [params+248];
	cvta.to.global.u64 	%rd633, %rd632;
	add.s64 	%rd634, %rd633, %rd570;
	st.global.f32 	[%rd634], %f2164;
	ld.const.u64 	%rd635, [params+256];
	cvta.to.global.u64 	%rd636, %rd635;
	add.s64 	%rd637, %rd636, %rd570;
	st.global.f32 	[%rd637], %f2159;
	ld.const.u64 	%rd638, [params+264];
	cvta.to.global.u64 	%rd639, %rd638;
	add.s64 	%rd640, %rd639, %rd570;
	st.global.f32 	[%rd640], %f2160;
	ld.const.u64 	%rd641, [params+272];
	cvta.to.global.u64 	%rd642, %rd641;
	add.s64 	%rd643, %rd642, %rd570;
	st.global.f32 	[%rd643], %f2161;

$L__BB12_115:
	ld.const.u64 	%rd43, [params+280];
	setp.eq.s64 	%p59, %rd43, 0;
	@%p59 bra 	$L__BB12_117;

	cvta.to.global.u64 	%rd644, %rd43;
	add.s64 	%rd646, %rd644, %rd570;
	st.global.f32 	[%rd646], %f2162;
	ld.const.u64 	%rd647, [params+288];
	cvta.to.global.u64 	%rd648, %rd647;
	add.s64 	%rd649, %rd648, %rd570;
	st.global.f32 	[%rd649], %f2163;
	ld.const.u64 	%rd650, [params+296];
	cvta.to.global.u64 	%rd651, %rd650;
	add.s64 	%rd652, %rd651, %rd570;
	st.global.f32 	[%rd652], %f2164;
	ld.const.u64 	%rd653, [params+304];
	cvta.to.global.u64 	%rd654, %rd653;
	add.s64 	%rd655, %rd654, %rd570;
	st.global.f32 	[%rd655], %f2159;
	ld.const.u64 	%rd656, [params+312];
	cvta.to.global.u64 	%rd657, %rd656;
	add.s64 	%rd658, %rd657, %rd570;
	st.global.f32 	[%rd658], %f2160;
	ld.const.u64 	%rd659, [params+320];
	cvta.to.global.u64 	%rd660, %rd659;
	add.s64 	%rd661, %rd660, %rd570;
	st.global.f32 	[%rd661], %f2161;

$L__BB12_117:
	ret;

}
	// .globl	__intersection__cylhollow
.visible .entry __intersection__cylhollow()
{
	.reg .pred 	%p<319>;
	.reg .b16 	%rs<11>;
	.reg .f32 	%f<2109>;
	.reg .b32 	%r<458>;
	.reg .b64 	%rd<259>;


	// begin inline asm
	call (%rd17), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd1, [%rd17+8];
	// begin inline asm
	call (%f1999), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f2000), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f2001), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r15), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p13, %r15, 0;
	@%p13 bra 	$L__BB13_20;

	// begin inline asm
	call (%r16), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f541), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p14, %r16, 0;
	@%p14 bra 	$L__BB13_19;

	mov.u32 	%r456, 0;

$L__BB13_3:
	.pragma "nounroll";
	// begin inline asm
	call (%rd18), _optix_get_transform_list_handle, (%r456);
	// end inline asm
	// begin inline asm
	call (%r19), _optix_get_transform_type_from_handle, (%rd18);
	// end inline asm
	or.b32  	%r20, %r19, 1;
	setp.eq.s32 	%p15, %r20, 3;
	@%p15 bra 	$L__BB13_9;
	bra.uni 	$L__BB13_4;

$L__BB13_9:
	setp.eq.s32 	%p18, %r19, 2;
	@%p18 bra 	$L__BB13_13;
	bra.uni 	$L__BB13_10;

$L__BB13_13:
	// begin inline asm
	call (%rd90), _optix_get_matrix_motion_transform_from_handle, (%rd18);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd92, %rd90;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r108,%r109,%r110,%r111}, [%rd92];
	// end inline asm
	add.s64 	%rd96, %rd90, 16;
	// begin inline asm
	cvta.to.global.u64 %rd95, %rd96;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r112,%r113,%r114,%r115}, [%rd95];
	// end inline asm
	add.s64 	%rd99, %rd90, 32;
	// begin inline asm
	cvta.to.global.u64 %rd98, %rd99;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r116,%r117,%r118,%r119}, [%rd98];
	// end inline asm
	add.s64 	%rd102, %rd90, 48;
	// begin inline asm
	cvta.to.global.u64 %rd101, %rd102;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r120,%r121,%r122,%r123}, [%rd101];
	// end inline asm
	add.s64 	%rd105, %rd90, 64;
	// begin inline asm
	cvta.to.global.u64 %rd104, %rd105;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r124,%r125,%r126,%r127}, [%rd104];
	// end inline asm
	add.s64 	%rd108, %rd90, 80;
	// begin inline asm
	cvta.to.global.u64 %rd107, %rd108;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r128,%r129,%r130,%r131}, [%rd107];
	// end inline asm
	add.s64 	%rd111, %rd90, 96;
	// begin inline asm
	cvta.to.global.u64 %rd110, %rd111;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r132,%r133,%r134,%r135}, [%rd110];
	// end inline asm
	add.s64 	%rd114, %rd90, 112;
	// begin inline asm
	cvta.to.global.u64 %rd113, %rd114;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r136,%r137,%r138,%r139}, [%rd113];
	// end inline asm
	mov.b32 	%f669, %r111;
	mov.b32 	%f670, %r112;
	and.b32  	%r152, %r110, 65535;
	add.s32 	%r153, %r152, -1;
	cvt.rn.f32.s32 	%f671, %r153;
	sub.f32 	%f672, %f541, %f669;
	mul.f32 	%f673, %f672, %f671;
	sub.f32 	%f674, %f670, %f669;
	div.rn.f32 	%f675, %f673, %f674;
	min.f32 	%f676, %f671, %f675;
	mov.f32 	%f677, 0f00000000;
	max.f32 	%f678, %f677, %f676;
	cvt.rmi.f32.f32 	%f679, %f678;
	sub.f32 	%f90, %f678, %f679;
	cvt.rzi.s32.f32 	%r154, %f679;
	mul.wide.s32 	%rd125, %r154, 48;
	add.s64 	%rd117, %rd99, %rd125;
	// begin inline asm
	cvta.to.global.u64 %rd116, %rd117;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r140,%r141,%r142,%r143}, [%rd116];
	// end inline asm
	mov.b32 	%f1954, %r140;
	mov.b32 	%f1953, %r141;
	mov.b32 	%f1952, %r142;
	mov.b32 	%f1951, %r143;
	add.s64 	%rd120, %rd117, 16;
	// begin inline asm
	cvta.to.global.u64 %rd119, %rd120;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r144,%r145,%r146,%r147}, [%rd119];
	// end inline asm
	mov.b32 	%f1958, %r144;
	mov.b32 	%f1957, %r145;
	mov.b32 	%f1956, %r146;
	mov.b32 	%f1955, %r147;
	add.s64 	%rd123, %rd117, 32;
	// begin inline asm
	cvta.to.global.u64 %rd122, %rd123;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r148,%r149,%r150,%r151}, [%rd122];
	// end inline asm
	mov.b32 	%f1962, %r148;
	mov.b32 	%f1961, %r149;
	mov.b32 	%f1960, %r150;
	mov.b32 	%f1959, %r151;
	setp.leu.f32 	%p20, %f90, 0f00000000;
	@%p20 bra 	$L__BB13_15;

	cvt.rmi.f32.f32 	%f1902, %f678;
	cvt.rzi.s32.f32 	%r455, %f1902;
	cvt.s64.s32 	%rd256, %r455;
	mov.f32 	%f680, 0f3F800000;
	sub.f32 	%f681, %f680, %f90;
	mul.lo.s64 	%rd135, %rd256, 48;
	add.s64 	%rd136, %rd90, %rd135;
	add.s64 	%rd127, %rd136, 80;
	// begin inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd126];
	// end inline asm
	mov.b32 	%f682, %r155;
	mov.b32 	%f683, %r156;
	mov.b32 	%f684, %r157;
	mov.b32 	%f685, %r158;
	mul.f32 	%f686, %f90, %f682;
	mul.f32 	%f687, %f90, %f683;
	mul.f32 	%f688, %f90, %f684;
	mul.f32 	%f689, %f90, %f685;
	fma.rn.f32 	%f1954, %f681, %f1954, %f686;
	fma.rn.f32 	%f1953, %f681, %f1953, %f687;
	fma.rn.f32 	%f1952, %f681, %f1952, %f688;
	fma.rn.f32 	%f1951, %f681, %f1951, %f689;
	add.s64 	%rd130, %rd136, 96;
	// begin inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r159,%r160,%r161,%r162}, [%rd129];
	// end inline asm
	mov.b32 	%f690, %r159;
	mov.b32 	%f691, %r160;
	mov.b32 	%f692, %r161;
	mov.b32 	%f693, %r162;
	mul.f32 	%f694, %f90, %f690;
	mul.f32 	%f695, %f90, %f691;
	mul.f32 	%f696, %f90, %f692;
	mul.f32 	%f697, %f90, %f693;
	fma.rn.f32 	%f1958, %f681, %f1958, %f694;
	fma.rn.f32 	%f1957, %f681, %f1957, %f695;
	fma.rn.f32 	%f1956, %f681, %f1956, %f696;
	fma.rn.f32 	%f1955, %f681, %f1955, %f697;
	add.s64 	%rd133, %rd136, 112;
	// begin inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd132];
	// end inline asm
	mov.b32 	%f698, %r163;
	mov.b32 	%f699, %r164;
	mov.b32 	%f700, %r165;
	mov.b32 	%f701, %r166;
	mul.f32 	%f702, %f90, %f698;
	mul.f32 	%f703, %f90, %f699;
	mul.f32 	%f704, %f90, %f700;
	mul.f32 	%f705, %f90, %f701;
	fma.rn.f32 	%f1962, %f681, %f1962, %f702;
	fma.rn.f32 	%f1961, %f681, %f1961, %f703;
	fma.rn.f32 	%f1960, %f681, %f1960, %f704;
	fma.rn.f32 	%f1959, %f681, %f1959, %f705;
	bra.uni 	$L__BB13_15;

$L__BB13_4:
	mov.f32 	%f1963, 0f00000000;
	mov.f32 	%f1966, 0f3F800000;
	setp.eq.s32 	%p16, %r19, 4;
	@%p16 bra 	$L__BB13_7;

	setp.ne.s32 	%p17, %r19, 1;
	mov.f32 	%f1964, %f1963;
	mov.f32 	%f1965, %f1963;
	mov.f32 	%f1967, %f1963;
	mov.f32 	%f1968, %f1963;
	mov.f32 	%f1969, %f1966;
	mov.f32 	%f1970, %f1963;
	mov.f32 	%f1971, %f1963;
	mov.f32 	%f1972, %f1966;
	mov.f32 	%f1973, %f1963;
	mov.f32 	%f1974, %f1963;
	@%p17 bra 	$L__BB13_16;

	// begin inline asm
	call (%rd20), _optix_get_static_transform_from_handle, (%rd18);
	// end inline asm
	add.s64 	%rd257, %rd20, 64;
	bra.uni 	$L__BB13_8;

$L__BB13_10:
	// begin inline asm
	call (%rd33), _optix_get_srt_motion_transform_from_handle, (%rd18);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd35, %rd33;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r33,%r34,%r35,%r36}, [%rd35];
	// end inline asm
	add.s64 	%rd39, %rd33, 16;
	// begin inline asm
	cvta.to.global.u64 %rd38, %rd39;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r37,%r38,%r39,%r40}, [%rd38];
	// end inline asm
	add.s64 	%rd42, %rd33, 32;
	// begin inline asm
	cvta.to.global.u64 %rd41, %rd42;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r41,%r42,%r43,%r44}, [%rd41];
	// end inline asm
	add.s64 	%rd45, %rd33, 48;
	// begin inline asm
	cvta.to.global.u64 %rd44, %rd45;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r45,%r46,%r47,%r48}, [%rd44];
	// end inline asm
	add.s64 	%rd48, %rd33, 64;
	// begin inline asm
	cvta.to.global.u64 %rd47, %rd48;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r49,%r50,%r51,%r52}, [%rd47];
	// end inline asm
	add.s64 	%rd51, %rd33, 80;
	// begin inline asm
	cvta.to.global.u64 %rd50, %rd51;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r53,%r54,%r55,%r56}, [%rd50];
	// end inline asm
	add.s64 	%rd54, %rd33, 96;
	// begin inline asm
	cvta.to.global.u64 %rd53, %rd54;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r57,%r58,%r59,%r60}, [%rd53];
	// end inline asm
	add.s64 	%rd57, %rd33, 112;
	// begin inline asm
	cvta.to.global.u64 %rd56, %rd57;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r61,%r62,%r63,%r64}, [%rd56];
	// end inline asm
	add.s64 	%rd60, %rd33, 128;
	// begin inline asm
	cvta.to.global.u64 %rd59, %rd60;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r65,%r66,%r67,%r68}, [%rd59];
	// end inline asm
	add.s64 	%rd63, %rd33, 144;
	// begin inline asm
	cvta.to.global.u64 %rd62, %rd63;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r69,%r70,%r71,%r72}, [%rd62];
	// end inline asm
	mov.b32 	%f556, %r36;
	mov.b32 	%f557, %r37;
	and.b32  	%r89, %r35, 65535;
	add.s32 	%r90, %r89, -1;
	cvt.rn.f32.s32 	%f558, %r90;
	sub.f32 	%f559, %f541, %f556;
	mul.f32 	%f560, %f559, %f558;
	sub.f32 	%f561, %f557, %f556;
	div.rn.f32 	%f562, %f560, %f561;
	min.f32 	%f563, %f558, %f562;
	mov.f32 	%f564, 0f00000000;
	max.f32 	%f565, %f564, %f563;
	cvt.rmi.f32.f32 	%f566, %f565;
	sub.f32 	%f29, %f565, %f566;
	cvt.rzi.s32.f32 	%r91, %f566;
	mul.wide.s32 	%rd77, %r91, 64;
	add.s64 	%rd66, %rd42, %rd77;
	// begin inline asm
	cvta.to.global.u64 %rd65, %rd66;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r73,%r74,%r75,%r76}, [%rd65];
	// end inline asm
	mov.b32 	%f1935, %r73;
	mov.b32 	%f1936, %r74;
	mov.b32 	%f1937, %r75;
	mov.b32 	%f1938, %r76;
	add.s64 	%rd69, %rd66, 16;
	// begin inline asm
	cvta.to.global.u64 %rd68, %rd69;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r77,%r78,%r79,%r80}, [%rd68];
	// end inline asm
	mov.b32 	%f1939, %r77;
	mov.b32 	%f1940, %r78;
	mov.b32 	%f1941, %r79;
	mov.b32 	%f1942, %r80;
	add.s64 	%rd72, %rd66, 32;
	// begin inline asm
	cvta.to.global.u64 %rd71, %rd72;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r81,%r82,%r83,%r84}, [%rd71];
	// end inline asm
	mov.b32 	%f1943, %r81;
	mov.b32 	%f1944, %r82;
	mov.b32 	%f1945, %r83;
	mov.b32 	%f1946, %r84;
	add.s64 	%rd75, %rd66, 48;
	// begin inline asm
	cvta.to.global.u64 %rd74, %rd75;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r85,%r86,%r87,%r88}, [%rd74];
	// end inline asm
	mov.b32 	%f1947, %r85;
	mov.b32 	%f1948, %r86;
	mov.b32 	%f1949, %r87;
	mov.b32 	%f1950, %r88;
	setp.leu.f32 	%p19, %f29, 0f00000000;
	@%p19 bra 	$L__BB13_12;

	mov.f32 	%f567, 0f3F800000;
	sub.f32 	%f568, %f567, %f29;
	add.s64 	%rd79, %rd66, 64;
	// begin inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd78];
	// end inline asm
	mov.b32 	%f569, %r92;
	mov.b32 	%f570, %r93;
	mov.b32 	%f571, %r94;
	mov.b32 	%f572, %r95;
	mul.f32 	%f573, %f29, %f569;
	mul.f32 	%f574, %f29, %f570;
	mul.f32 	%f575, %f29, %f571;
	mul.f32 	%f576, %f29, %f572;
	fma.rn.f32 	%f1935, %f568, %f1935, %f573;
	fma.rn.f32 	%f1936, %f568, %f1936, %f574;
	fma.rn.f32 	%f1937, %f568, %f1937, %f575;
	fma.rn.f32 	%f1938, %f568, %f1938, %f576;
	add.s64 	%rd82, %rd66, 80;
	// begin inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd81];
	// end inline asm
	mov.b32 	%f577, %r96;
	mov.b32 	%f578, %r97;
	mov.b32 	%f579, %r98;
	mov.b32 	%f580, %r99;
	mul.f32 	%f581, %f29, %f577;
	mul.f32 	%f582, %f29, %f578;
	mul.f32 	%f583, %f29, %f579;
	mul.f32 	%f584, %f29, %f580;
	fma.rn.f32 	%f1939, %f568, %f1939, %f581;
	fma.rn.f32 	%f1940, %f568, %f1940, %f582;
	fma.rn.f32 	%f1941, %f568, %f1941, %f583;
	fma.rn.f32 	%f1942, %f568, %f1942, %f584;
	add.s64 	%rd85, %rd66, 96;
	// begin inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd84];
	// end inline asm
	mov.b32 	%f585, %r100;
	mov.b32 	%f586, %r101;
	mov.b32 	%f587, %r102;
	mov.b32 	%f588, %r103;
	mul.f32 	%f589, %f29, %f585;
	mul.f32 	%f590, %f29, %f586;
	mul.f32 	%f591, %f29, %f587;
	mul.f32 	%f592, %f29, %f588;
	fma.rn.f32 	%f1943, %f568, %f1943, %f589;
	fma.rn.f32 	%f593, %f568, %f1944, %f590;
	fma.rn.f32 	%f594, %f568, %f1945, %f591;
	fma.rn.f32 	%f595, %f568, %f1946, %f592;
	add.s64 	%rd88, %rd66, 112;
	// begin inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r104,%r105,%r106,%r107}, [%rd87];
	// end inline asm
	mov.b32 	%f596, %r104;
	mov.b32 	%f597, %r105;
	mov.b32 	%f598, %r106;
	mov.b32 	%f599, %r107;
	mul.f32 	%f600, %f29, %f596;
	mul.f32 	%f601, %f29, %f597;
	mul.f32 	%f602, %f29, %f598;
	mul.f32 	%f603, %f29, %f599;
	fma.rn.f32 	%f604, %f568, %f1947, %f600;
	fma.rn.f32 	%f1948, %f568, %f1948, %f601;
	fma.rn.f32 	%f1949, %f568, %f1949, %f602;
	fma.rn.f32 	%f1950, %f568, %f1950, %f603;
	mul.f32 	%f605, %f594, %f594;
	fma.rn.f32 	%f606, %f593, %f593, %f605;
	fma.rn.f32 	%f607, %f595, %f595, %f606;
	fma.rn.f32 	%f608, %f604, %f604, %f607;
	sqrt.rn.f32 	%f609, %f608;
	rcp.rn.f32 	%f610, %f609;
	mul.f32 	%f1944, %f593, %f610;
	mul.f32 	%f1945, %f594, %f610;
	mul.f32 	%f1946, %f595, %f610;
	mul.f32 	%f1947, %f610, %f604;

$L__BB13_12:
	mul.f32 	%f611, %f1945, %f1945;
	fma.rn.f32 	%f612, %f1944, %f1944, %f611;
	fma.rn.f32 	%f613, %f1946, %f1946, %f612;
	fma.rn.f32 	%f614, %f1947, %f1947, %f613;
	rcp.rn.f32 	%f615, %f614;
	mul.f32 	%f616, %f1944, %f615;
	mul.f32 	%f617, %f1945, %f615;
	mul.f32 	%f618, %f1946, %f615;
	mul.f32 	%f619, %f1947, %f615;
	mul.f32 	%f620, %f1944, %f616;
	mul.f32 	%f621, %f1945, %f617;
	mul.f32 	%f622, %f1946, %f618;
	mul.f32 	%f623, %f1944, %f617;
	mul.f32 	%f624, %f1946, %f619;
	mul.f32 	%f625, %f1944, %f618;
	mul.f32 	%f626, %f1945, %f619;
	mul.f32 	%f627, %f1945, %f618;
	mul.f32 	%f628, %f1944, %f619;
	sub.f32 	%f629, %f620, %f621;
	sub.f32 	%f630, %f629, %f622;
	fma.rn.f32 	%f631, %f1947, %f619, %f630;
	sub.f32 	%f632, %f623, %f624;
	add.f32 	%f633, %f632, %f632;
	add.f32 	%f634, %f625, %f626;
	add.f32 	%f635, %f634, %f634;
	add.f32 	%f636, %f623, %f624;
	add.f32 	%f637, %f636, %f636;
	sub.f32 	%f638, %f621, %f620;
	sub.f32 	%f639, %f638, %f622;
	fma.rn.f32 	%f640, %f1947, %f619, %f639;
	sub.f32 	%f641, %f627, %f628;
	add.f32 	%f642, %f641, %f641;
	sub.f32 	%f643, %f625, %f626;
	add.f32 	%f644, %f643, %f643;
	add.f32 	%f645, %f627, %f628;
	add.f32 	%f646, %f645, %f645;
	neg.f32 	%f647, %f620;
	sub.f32 	%f648, %f647, %f621;
	add.f32 	%f649, %f622, %f648;
	fma.rn.f32 	%f650, %f1947, %f619, %f649;
	mul.f32 	%f651, %f1938, %f631;
	fma.rn.f32 	%f652, %f1941, %f633, %f651;
	fma.rn.f32 	%f653, %f1943, %f635, %f652;
	sub.f32 	%f1951, %f1948, %f653;
	mul.f32 	%f654, %f1941, %f640;
	fma.rn.f32 	%f655, %f1938, %f637, %f654;
	fma.rn.f32 	%f656, %f1943, %f642, %f655;
	sub.f32 	%f1955, %f1949, %f656;
	mul.f32 	%f657, %f1941, %f646;
	fma.rn.f32 	%f658, %f1938, %f644, %f657;
	fma.rn.f32 	%f659, %f1943, %f650, %f658;
	sub.f32 	%f1959, %f1950, %f659;
	mul.f32 	%f660, %f1937, %f631;
	fma.rn.f32 	%f661, %f1940, %f633, %f660;
	fma.rn.f32 	%f1952, %f1942, %f635, %f661;
	mul.f32 	%f662, %f1940, %f640;
	fma.rn.f32 	%f663, %f1937, %f637, %f662;
	fma.rn.f32 	%f1956, %f1942, %f642, %f663;
	mul.f32 	%f664, %f1940, %f646;
	fma.rn.f32 	%f665, %f1937, %f644, %f664;
	fma.rn.f32 	%f1960, %f1942, %f650, %f665;
	mul.f32 	%f666, %f1936, %f631;
	fma.rn.f32 	%f1953, %f1939, %f633, %f666;
	mul.f32 	%f667, %f1939, %f640;
	fma.rn.f32 	%f1957, %f1936, %f637, %f667;
	mul.f32 	%f668, %f1939, %f646;
	fma.rn.f32 	%f1961, %f1936, %f644, %f668;
	mul.f32 	%f1954, %f1935, %f631;
	mul.f32 	%f1958, %f1935, %f637;
	mul.f32 	%f1962, %f1935, %f644;

$L__BB13_15:
	mul.f32 	%f706, %f1956, %f1961;
	mul.f32 	%f707, %f1957, %f1960;
	sub.f32 	%f708, %f707, %f706;
	mul.f32 	%f709, %f1954, %f708;
	mul.f32 	%f710, %f1956, %f1962;
	mul.f32 	%f711, %f1958, %f1960;
	sub.f32 	%f712, %f711, %f710;
	mul.f32 	%f713, %f1953, %f712;
	sub.f32 	%f714, %f709, %f713;
	mul.f32 	%f715, %f1957, %f1962;
	mul.f32 	%f716, %f1958, %f1961;
	sub.f32 	%f717, %f716, %f715;
	fma.rn.f32 	%f718, %f1952, %f717, %f714;
	rcp.rn.f32 	%f719, %f718;
	mul.f32 	%f1966, %f708, %f719;
	mul.f32 	%f720, %f1953, %f1960;
	mul.f32 	%f721, %f1952, %f1961;
	sub.f32 	%f722, %f721, %f720;
	mul.f32 	%f1965, %f722, %f719;
	mul.f32 	%f723, %f1952, %f1957;
	mul.f32 	%f724, %f1953, %f1956;
	sub.f32 	%f725, %f724, %f723;
	mul.f32 	%f1964, %f725, %f719;
	sub.f32 	%f726, %f710, %f711;
	mul.f32 	%f1970, %f726, %f719;
	mul.f32 	%f727, %f1952, %f1962;
	mul.f32 	%f728, %f1954, %f1960;
	sub.f32 	%f729, %f728, %f727;
	mul.f32 	%f1969, %f729, %f719;
	mul.f32 	%f730, %f1954, %f1956;
	mul.f32 	%f731, %f1952, %f1958;
	sub.f32 	%f732, %f731, %f730;
	mul.f32 	%f1968, %f732, %f719;
	mul.f32 	%f1974, %f717, %f719;
	mul.f32 	%f733, %f1954, %f1961;
	mul.f32 	%f734, %f1953, %f1962;
	sub.f32 	%f735, %f734, %f733;
	mul.f32 	%f1973, %f735, %f719;
	mul.f32 	%f736, %f1953, %f1958;
	mul.f32 	%f737, %f1954, %f1957;
	sub.f32 	%f738, %f737, %f736;
	mul.f32 	%f1972, %f738, %f719;
	mul.f32 	%f739, %f1951, %f1966;
	neg.f32 	%f740, %f739;
	mul.f32 	%f741, %f1955, %f1965;
	sub.f32 	%f742, %f740, %f741;
	mul.f32 	%f743, %f1959, %f1964;
	sub.f32 	%f1963, %f742, %f743;
	mul.f32 	%f744, %f1951, %f1970;
	neg.f32 	%f745, %f744;
	mul.f32 	%f746, %f1955, %f1969;
	sub.f32 	%f747, %f745, %f746;
	mul.f32 	%f748, %f1959, %f1968;
	sub.f32 	%f1967, %f747, %f748;
	mul.f32 	%f749, %f1951, %f1974;
	neg.f32 	%f750, %f749;
	mul.f32 	%f751, %f1955, %f1973;
	sub.f32 	%f752, %f750, %f751;
	mul.f32 	%f753, %f1959, %f1972;
	sub.f32 	%f1971, %f752, %f753;
	bra.uni 	$L__BB13_16;

$L__BB13_7:
	// begin inline asm
	call (%rd257), _optix_get_instance_inverse_transform_from_handle, (%rd18);
	// end inline asm

$L__BB13_8:
	// begin inline asm
	cvta.to.global.u64 %rd24, %rd257;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r21,%r22,%r23,%r24}, [%rd24];
	// end inline asm
	mov.b32 	%f1966, %r21;
	mov.b32 	%f1965, %r22;
	mov.b32 	%f1964, %r23;
	mov.b32 	%f1963, %r24;
	add.s64 	%rd28, %rd257, 16;
	// begin inline asm
	cvta.to.global.u64 %rd27, %rd28;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r25,%r26,%r27,%r28}, [%rd27];
	// end inline asm
	mov.b32 	%f1970, %r25;
	mov.b32 	%f1969, %r26;
	mov.b32 	%f1968, %r27;
	mov.b32 	%f1967, %r28;
	add.s64 	%rd31, %rd257, 32;
	// begin inline asm
	cvta.to.global.u64 %rd30, %rd31;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r29,%r30,%r31,%r32}, [%rd30];
	// end inline asm
	mov.b32 	%f1974, %r29;
	mov.b32 	%f1973, %r30;
	mov.b32 	%f1972, %r31;
	mov.b32 	%f1971, %r32;

$L__BB13_16:
	setp.eq.s32 	%p21, %r456, 0;
	@%p21 bra 	$L__BB13_18;

	mul.f32 	%f754, %f1931, %f1966;
	fma.rn.f32 	%f755, %f1927, %f1965, %f754;
	fma.rn.f32 	%f151, %f1923, %f1964, %f755;
	mul.f32 	%f756, %f1932, %f1966;
	fma.rn.f32 	%f757, %f1928, %f1965, %f756;
	fma.rn.f32 	%f152, %f1924, %f1964, %f757;
	mul.f32 	%f758, %f1933, %f1966;
	fma.rn.f32 	%f759, %f1929, %f1965, %f758;
	fma.rn.f32 	%f153, %f1925, %f1964, %f759;
	mul.f32 	%f760, %f1934, %f1966;
	fma.rn.f32 	%f761, %f1930, %f1965, %f760;
	fma.rn.f32 	%f762, %f1926, %f1964, %f761;
	add.f32 	%f1963, %f1963, %f762;
	mul.f32 	%f763, %f1931, %f1970;
	fma.rn.f32 	%f764, %f1927, %f1969, %f763;
	fma.rn.f32 	%f155, %f1923, %f1968, %f764;
	mul.f32 	%f765, %f1932, %f1970;
	fma.rn.f32 	%f766, %f1928, %f1969, %f765;
	fma.rn.f32 	%f156, %f1924, %f1968, %f766;
	mul.f32 	%f767, %f1933, %f1970;
	fma.rn.f32 	%f768, %f1929, %f1969, %f767;
	fma.rn.f32 	%f157, %f1925, %f1968, %f768;
	mul.f32 	%f769, %f1934, %f1970;
	fma.rn.f32 	%f770, %f1930, %f1969, %f769;
	fma.rn.f32 	%f771, %f1926, %f1968, %f770;
	add.f32 	%f1967, %f1967, %f771;
	mul.f32 	%f772, %f1931, %f1974;
	fma.rn.f32 	%f773, %f1927, %f1973, %f772;
	fma.rn.f32 	%f159, %f1923, %f1972, %f773;
	mul.f32 	%f774, %f1932, %f1974;
	fma.rn.f32 	%f775, %f1928, %f1973, %f774;
	fma.rn.f32 	%f160, %f1924, %f1972, %f775;
	mul.f32 	%f776, %f1933, %f1974;
	fma.rn.f32 	%f777, %f1929, %f1973, %f776;
	fma.rn.f32 	%f161, %f1925, %f1972, %f777;
	mul.f32 	%f778, %f1934, %f1974;
	fma.rn.f32 	%f779, %f1930, %f1973, %f778;
	fma.rn.f32 	%f780, %f1926, %f1972, %f779;
	add.f32 	%f1971, %f1971, %f780;
	mov.f32 	%f1964, %f153;
	mov.f32 	%f1965, %f152;
	mov.f32 	%f1966, %f151;
	mov.f32 	%f1968, %f157;
	mov.f32 	%f1969, %f156;
	mov.f32 	%f1970, %f155;
	mov.f32 	%f1972, %f161;
	mov.f32 	%f1973, %f160;
	mov.f32 	%f1974, %f159;

$L__BB13_18:
	add.s32 	%r456, %r456, 1;
	setp.lt.u32 	%p22, %r456, %r16;
	mov.f32 	%f1923, %f1974;
	mov.f32 	%f1924, %f1973;
	mov.f32 	%f1925, %f1972;
	mov.f32 	%f1926, %f1971;
	mov.f32 	%f1927, %f1970;
	mov.f32 	%f1928, %f1969;
	mov.f32 	%f1929, %f1968;
	mov.f32 	%f1930, %f1967;
	mov.f32 	%f1931, %f1966;
	mov.f32 	%f1932, %f1965;
	mov.f32 	%f1933, %f1964;
	mov.f32 	%f1934, %f1963;
	@%p22 bra 	$L__BB13_3;

$L__BB13_19:
	mul.f32 	%f781, %f1999, %f1966;
	fma.rn.f32 	%f782, %f2000, %f1965, %f781;
	fma.rn.f32 	%f783, %f2001, %f1964, %f782;
	mul.f32 	%f784, %f1999, %f1970;
	fma.rn.f32 	%f785, %f2000, %f1969, %f784;
	fma.rn.f32 	%f786, %f2001, %f1968, %f785;
	mul.f32 	%f787, %f1999, %f1974;
	fma.rn.f32 	%f788, %f2000, %f1973, %f787;
	fma.rn.f32 	%f789, %f2001, %f1972, %f788;
	add.f32 	%f2001, %f1971, %f789;
	add.f32 	%f2000, %f1967, %f786;
	add.f32 	%f1999, %f1963, %f783;

$L__BB13_20:
	// begin inline asm
	call (%f2057), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f2058), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f792), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r167), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p23, %r167, 0;
	@%p23 bra 	$L__BB13_40;

	// begin inline asm
	call (%r168), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f793), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p24, %r168, 0;
	@%p24 bra 	$L__BB13_39;

	mov.u32 	%r457, 0;

$L__BB13_23:
	.pragma "nounroll";
	// begin inline asm
	call (%rd137), _optix_get_transform_list_handle, (%r457);
	// end inline asm
	// begin inline asm
	call (%r171), _optix_get_transform_type_from_handle, (%rd137);
	// end inline asm
	or.b32  	%r172, %r171, 1;
	setp.eq.s32 	%p25, %r172, 3;
	@%p25 bra 	$L__BB13_29;
	bra.uni 	$L__BB13_24;

$L__BB13_29:
	setp.eq.s32 	%p28, %r171, 2;
	@%p28 bra 	$L__BB13_33;
	bra.uni 	$L__BB13_30;

$L__BB13_33:
	// begin inline asm
	call (%rd209), _optix_get_matrix_motion_transform_from_handle, (%rd137);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd211, %rd209;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r260,%r261,%r262,%r263}, [%rd211];
	// end inline asm
	add.s64 	%rd215, %rd209, 16;
	// begin inline asm
	cvta.to.global.u64 %rd214, %rd215;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r264,%r265,%r266,%r267}, [%rd214];
	// end inline asm
	add.s64 	%rd218, %rd209, 32;
	// begin inline asm
	cvta.to.global.u64 %rd217, %rd218;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r268,%r269,%r270,%r271}, [%rd217];
	// end inline asm
	add.s64 	%rd221, %rd209, 48;
	// begin inline asm
	cvta.to.global.u64 %rd220, %rd221;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r272,%r273,%r274,%r275}, [%rd220];
	// end inline asm
	add.s64 	%rd224, %rd209, 64;
	// begin inline asm
	cvta.to.global.u64 %rd223, %rd224;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r276,%r277,%r278,%r279}, [%rd223];
	// end inline asm
	add.s64 	%rd227, %rd209, 80;
	// begin inline asm
	cvta.to.global.u64 %rd226, %rd227;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r280,%r281,%r282,%r283}, [%rd226];
	// end inline asm
	add.s64 	%rd230, %rd209, 96;
	// begin inline asm
	cvta.to.global.u64 %rd229, %rd230;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r284,%r285,%r286,%r287}, [%rd229];
	// end inline asm
	add.s64 	%rd233, %rd209, 112;
	// begin inline asm
	cvta.to.global.u64 %rd232, %rd233;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r288,%r289,%r290,%r291}, [%rd232];
	// end inline asm
	mov.b32 	%f897, %r263;
	mov.b32 	%f898, %r264;
	and.b32  	%r304, %r262, 65535;
	add.s32 	%r305, %r304, -1;
	cvt.rn.f32.s32 	%f899, %r305;
	sub.f32 	%f900, %f793, %f897;
	mul.f32 	%f901, %f900, %f899;
	sub.f32 	%f902, %f898, %f897;
	div.rn.f32 	%f903, %f901, %f902;
	min.f32 	%f904, %f899, %f903;
	mov.f32 	%f905, 0f00000000;
	max.f32 	%f906, %f905, %f904;
	cvt.rmi.f32.f32 	%f907, %f906;
	sub.f32 	%f260, %f906, %f907;
	cvt.rzi.s32.f32 	%r306, %f907;
	cvt.s64.s32 	%rd15, %r306;
	mul.wide.s32 	%rd244, %r306, 48;
	add.s64 	%rd236, %rd218, %rd244;
	// begin inline asm
	cvta.to.global.u64 %rd235, %rd236;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r292,%r293,%r294,%r295}, [%rd235];
	// end inline asm
	mov.b32 	%f2027, %r292;
	mov.b32 	%f2028, %r293;
	mov.b32 	%f2029, %r294;
	add.s64 	%rd239, %rd236, 16;
	// begin inline asm
	cvta.to.global.u64 %rd238, %rd239;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r296,%r297,%r298,%r299}, [%rd238];
	// end inline asm
	mov.b32 	%f2024, %r296;
	mov.b32 	%f2025, %r297;
	mov.b32 	%f2026, %r298;
	add.s64 	%rd242, %rd236, 32;
	// begin inline asm
	cvta.to.global.u64 %rd241, %rd242;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r300,%r301,%r302,%r303}, [%rd241];
	// end inline asm
	mov.b32 	%f2021, %r300;
	mov.b32 	%f2022, %r301;
	mov.b32 	%f2023, %r302;
	setp.leu.f32 	%p30, %f260, 0f00000000;
	@%p30 bra 	$L__BB13_35;

	mov.f32 	%f908, 0f3F800000;
	sub.f32 	%f909, %f908, %f260;
	mul.lo.s64 	%rd254, %rd15, 48;
	add.s64 	%rd255, %rd209, %rd254;
	add.s64 	%rd246, %rd255, 80;
	// begin inline asm
	cvta.to.global.u64 %rd245, %rd246;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd245];
	// end inline asm
	mov.b32 	%f910, %r307;
	mov.b32 	%f911, %r308;
	mov.b32 	%f912, %r309;
	mul.f32 	%f913, %f260, %f910;
	mul.f32 	%f914, %f260, %f911;
	mul.f32 	%f915, %f260, %f912;
	fma.rn.f32 	%f2027, %f909, %f2027, %f913;
	fma.rn.f32 	%f2028, %f909, %f2028, %f914;
	fma.rn.f32 	%f2029, %f909, %f2029, %f915;
	add.s64 	%rd249, %rd255, 96;
	// begin inline asm
	cvta.to.global.u64 %rd248, %rd249;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd248];
	// end inline asm
	mov.b32 	%f916, %r311;
	mov.b32 	%f917, %r312;
	mov.b32 	%f918, %r313;
	mul.f32 	%f919, %f260, %f916;
	mul.f32 	%f920, %f260, %f917;
	mul.f32 	%f921, %f260, %f918;
	fma.rn.f32 	%f2024, %f909, %f2024, %f919;
	fma.rn.f32 	%f2025, %f909, %f2025, %f920;
	fma.rn.f32 	%f2026, %f909, %f2026, %f921;
	add.s64 	%rd252, %rd255, 112;
	// begin inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r315,%r316,%r317,%r318}, [%rd251];
	// end inline asm
	mov.b32 	%f922, %r315;
	mov.b32 	%f923, %r316;
	mov.b32 	%f924, %r317;
	mul.f32 	%f925, %f260, %f922;
	mul.f32 	%f926, %f260, %f923;
	mul.f32 	%f927, %f260, %f924;
	fma.rn.f32 	%f2021, %f909, %f2021, %f925;
	fma.rn.f32 	%f2022, %f909, %f2022, %f926;
	fma.rn.f32 	%f2023, %f909, %f2023, %f927;
	bra.uni 	$L__BB13_35;

$L__BB13_24:
	mov.f32 	%f2030, 0f00000000;
	mov.f32 	%f2032, 0f3F800000;
	setp.eq.s32 	%p26, %r171, 4;
	@%p26 bra 	$L__BB13_27;

	setp.ne.s32 	%p27, %r171, 1;
	mov.f32 	%f2031, %f2030;
	mov.f32 	%f2033, %f2030;
	mov.f32 	%f2034, %f2032;
	mov.f32 	%f2035, %f2030;
	mov.f32 	%f2036, %f2032;
	mov.f32 	%f2037, %f2030;
	mov.f32 	%f2038, %f2030;
	@%p27 bra 	$L__BB13_36;

	// begin inline asm
	call (%rd139), _optix_get_static_transform_from_handle, (%rd137);
	// end inline asm
	add.s64 	%rd258, %rd139, 64;
	bra.uni 	$L__BB13_28;

$L__BB13_30:
	// begin inline asm
	call (%rd152), _optix_get_srt_motion_transform_from_handle, (%rd137);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd154, %rd152;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r185,%r186,%r187,%r188}, [%rd154];
	// end inline asm
	add.s64 	%rd158, %rd152, 16;
	// begin inline asm
	cvta.to.global.u64 %rd157, %rd158;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r189,%r190,%r191,%r192}, [%rd157];
	// end inline asm
	add.s64 	%rd161, %rd152, 32;
	// begin inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r193,%r194,%r195,%r196}, [%rd160];
	// end inline asm
	add.s64 	%rd164, %rd152, 48;
	// begin inline asm
	cvta.to.global.u64 %rd163, %rd164;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r197,%r198,%r199,%r200}, [%rd163];
	// end inline asm
	add.s64 	%rd167, %rd152, 64;
	// begin inline asm
	cvta.to.global.u64 %rd166, %rd167;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r201,%r202,%r203,%r204}, [%rd166];
	// end inline asm
	add.s64 	%rd170, %rd152, 80;
	// begin inline asm
	cvta.to.global.u64 %rd169, %rd170;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r205,%r206,%r207,%r208}, [%rd169];
	// end inline asm
	add.s64 	%rd173, %rd152, 96;
	// begin inline asm
	cvta.to.global.u64 %rd172, %rd173;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r209,%r210,%r211,%r212}, [%rd172];
	// end inline asm
	add.s64 	%rd176, %rd152, 112;
	// begin inline asm
	cvta.to.global.u64 %rd175, %rd176;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r213,%r214,%r215,%r216}, [%rd175];
	// end inline asm
	add.s64 	%rd179, %rd152, 128;
	// begin inline asm
	cvta.to.global.u64 %rd178, %rd179;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r217,%r218,%r219,%r220}, [%rd178];
	// end inline asm
	add.s64 	%rd182, %rd152, 144;
	// begin inline asm
	cvta.to.global.u64 %rd181, %rd182;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r221,%r222,%r223,%r224}, [%rd181];
	// end inline asm
	mov.b32 	%f805, %r188;
	mov.b32 	%f806, %r189;
	and.b32  	%r241, %r187, 65535;
	add.s32 	%r242, %r241, -1;
	cvt.rn.f32.s32 	%f807, %r242;
	sub.f32 	%f808, %f793, %f805;
	mul.f32 	%f809, %f808, %f807;
	sub.f32 	%f810, %f806, %f805;
	div.rn.f32 	%f811, %f809, %f810;
	min.f32 	%f812, %f807, %f811;
	mov.f32 	%f813, 0f00000000;
	max.f32 	%f814, %f813, %f812;
	cvt.rmi.f32.f32 	%f815, %f814;
	sub.f32 	%f220, %f814, %f815;
	cvt.rzi.s32.f32 	%r243, %f815;
	mul.wide.s32 	%rd196, %r243, 64;
	add.s64 	%rd185, %rd161, %rd196;
	// begin inline asm
	cvta.to.global.u64 %rd184, %rd185;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r225,%r226,%r227,%r228}, [%rd184];
	// end inline asm
	mov.b32 	%f2011, %r225;
	mov.b32 	%f2012, %r226;
	mov.b32 	%f2013, %r227;
	add.s64 	%rd188, %rd185, 16;
	// begin inline asm
	cvta.to.global.u64 %rd187, %rd188;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r229,%r230,%r231,%r232}, [%rd187];
	// end inline asm
	mov.b32 	%f2014, %r229;
	mov.b32 	%f2015, %r230;
	mov.b32 	%f2016, %r232;
	add.s64 	%rd191, %rd185, 32;
	// begin inline asm
	cvta.to.global.u64 %rd190, %rd191;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r233,%r234,%r235,%r236}, [%rd190];
	// end inline asm
	mov.b32 	%f2017, %r234;
	mov.b32 	%f2018, %r235;
	mov.b32 	%f2019, %r236;
	add.s64 	%rd194, %rd185, 48;
	// begin inline asm
	cvta.to.global.u64 %rd193, %rd194;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r237,%r238,%r239,%r240}, [%rd193];
	// end inline asm
	mov.b32 	%f2020, %r237;
	setp.leu.f32 	%p29, %f220, 0f00000000;
	@%p29 bra 	$L__BB13_32;

	mov.f32 	%f816, 0f3F800000;
	sub.f32 	%f817, %f816, %f220;
	add.s64 	%rd198, %rd185, 64;
	// begin inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd197];
	// end inline asm
	mov.b32 	%f818, %r244;
	mov.b32 	%f819, %r245;
	mov.b32 	%f820, %r246;
	mul.f32 	%f821, %f220, %f818;
	mul.f32 	%f822, %f220, %f819;
	mul.f32 	%f823, %f220, %f820;
	fma.rn.f32 	%f2011, %f817, %f2011, %f821;
	fma.rn.f32 	%f2012, %f817, %f2012, %f822;
	fma.rn.f32 	%f2013, %f817, %f2013, %f823;
	add.s64 	%rd201, %rd185, 80;
	// begin inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd200];
	// end inline asm
	mov.b32 	%f824, %r248;
	mov.b32 	%f825, %r249;
	mov.b32 	%f826, %r251;
	mul.f32 	%f827, %f220, %f824;
	mul.f32 	%f828, %f220, %f825;
	mul.f32 	%f829, %f220, %f826;
	fma.rn.f32 	%f2014, %f817, %f2014, %f827;
	fma.rn.f32 	%f2015, %f817, %f2015, %f828;
	fma.rn.f32 	%f2016, %f817, %f2016, %f829;
	add.s64 	%rd204, %rd185, 96;
	// begin inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd203];
	// end inline asm
	mov.b32 	%f830, %r253;
	mov.b32 	%f831, %r254;
	mov.b32 	%f832, %r255;
	mul.f32 	%f833, %f220, %f830;
	mul.f32 	%f834, %f220, %f831;
	mul.f32 	%f835, %f220, %f832;
	fma.rn.f32 	%f836, %f817, %f2017, %f833;
	fma.rn.f32 	%f837, %f817, %f2018, %f834;
	fma.rn.f32 	%f838, %f817, %f2019, %f835;
	add.s64 	%rd207, %rd185, 112;
	// begin inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r256,%r257,%r258,%r259}, [%rd206];
	// end inline asm
	mov.b32 	%f839, %r256;
	mul.f32 	%f840, %f220, %f839;
	fma.rn.f32 	%f841, %f817, %f2020, %f840;
	mul.f32 	%f842, %f837, %f837;
	fma.rn.f32 	%f843, %f836, %f836, %f842;
	fma.rn.f32 	%f844, %f838, %f838, %f843;
	fma.rn.f32 	%f845, %f841, %f841, %f844;
	sqrt.rn.f32 	%f846, %f845;
	rcp.rn.f32 	%f847, %f846;
	mul.f32 	%f2017, %f836, %f847;
	mul.f32 	%f2018, %f837, %f847;
	mul.f32 	%f2019, %f838, %f847;
	mul.f32 	%f2020, %f847, %f841;

$L__BB13_32:
	mul.f32 	%f848, %f2018, %f2018;
	fma.rn.f32 	%f849, %f2017, %f2017, %f848;
	fma.rn.f32 	%f850, %f2019, %f2019, %f849;
	fma.rn.f32 	%f851, %f2020, %f2020, %f850;
	rcp.rn.f32 	%f852, %f851;
	mul.f32 	%f853, %f2017, %f852;
	mul.f32 	%f854, %f2018, %f852;
	mul.f32 	%f855, %f2019, %f852;
	mul.f32 	%f856, %f2020, %f852;
	mul.f32 	%f857, %f2017, %f853;
	mul.f32 	%f858, %f2018, %f854;
	mul.f32 	%f859, %f2019, %f855;
	mul.f32 	%f860, %f2017, %f854;
	mul.f32 	%f861, %f2019, %f856;
	mul.f32 	%f862, %f2017, %f855;
	mul.f32 	%f863, %f2018, %f856;
	mul.f32 	%f864, %f2018, %f855;
	mul.f32 	%f865, %f2017, %f856;
	sub.f32 	%f866, %f857, %f858;
	sub.f32 	%f867, %f866, %f859;
	fma.rn.f32 	%f868, %f2020, %f856, %f867;
	sub.f32 	%f869, %f860, %f861;
	add.f32 	%f870, %f869, %f869;
	add.f32 	%f871, %f862, %f863;
	add.f32 	%f872, %f871, %f871;
	add.f32 	%f873, %f860, %f861;
	add.f32 	%f874, %f873, %f873;
	sub.f32 	%f875, %f858, %f857;
	sub.f32 	%f876, %f875, %f859;
	fma.rn.f32 	%f877, %f2020, %f856, %f876;
	sub.f32 	%f878, %f864, %f865;
	add.f32 	%f879, %f878, %f878;
	sub.f32 	%f880, %f862, %f863;
	add.f32 	%f881, %f880, %f880;
	add.f32 	%f882, %f864, %f865;
	add.f32 	%f883, %f882, %f882;
	neg.f32 	%f884, %f857;
	sub.f32 	%f885, %f884, %f858;
	add.f32 	%f886, %f859, %f885;
	fma.rn.f32 	%f887, %f2020, %f856, %f886;
	mul.f32 	%f888, %f2013, %f868;
	fma.rn.f32 	%f889, %f2015, %f870, %f888;
	fma.rn.f32 	%f2029, %f2016, %f872, %f889;
	mul.f32 	%f890, %f2015, %f877;
	fma.rn.f32 	%f891, %f2013, %f874, %f890;
	fma.rn.f32 	%f2026, %f2016, %f879, %f891;
	mul.f32 	%f892, %f2015, %f883;
	fma.rn.f32 	%f893, %f2013, %f881, %f892;
	fma.rn.f32 	%f2023, %f2016, %f887, %f893;
	mul.f32 	%f894, %f2012, %f868;
	fma.rn.f32 	%f2028, %f2014, %f870, %f894;
	mul.f32 	%f895, %f2014, %f877;
	fma.rn.f32 	%f2025, %f2012, %f874, %f895;
	mul.f32 	%f896, %f2014, %f883;
	fma.rn.f32 	%f2022, %f2012, %f881, %f896;
	mul.f32 	%f2027, %f2011, %f868;
	mul.f32 	%f2024, %f2011, %f874;
	mul.f32 	%f2021, %f2011, %f881;

$L__BB13_35:
	mul.f32 	%f928, %f2022, %f2026;
	mul.f32 	%f929, %f2023, %f2025;
	sub.f32 	%f930, %f929, %f928;
	mul.f32 	%f931, %f2027, %f930;
	mul.f32 	%f932, %f2021, %f2026;
	mul.f32 	%f933, %f2023, %f2024;
	sub.f32 	%f934, %f933, %f932;
	mul.f32 	%f935, %f934, %f2028;
	sub.f32 	%f936, %f931, %f935;
	mul.f32 	%f937, %f2021, %f2025;
	mul.f32 	%f938, %f2022, %f2024;
	sub.f32 	%f939, %f938, %f937;
	fma.rn.f32 	%f940, %f939, %f2029, %f936;
	rcp.rn.f32 	%f941, %f940;
	mul.f32 	%f2036, %f930, %f941;
	mul.f32 	%f942, %f2023, %f2028;
	mul.f32 	%f943, %f2022, %f2029;
	sub.f32 	%f944, %f943, %f942;
	mul.f32 	%f2037, %f944, %f941;
	mul.f32 	%f945, %f2025, %f2029;
	mul.f32 	%f946, %f2026, %f2028;
	sub.f32 	%f947, %f946, %f945;
	mul.f32 	%f2038, %f947, %f941;
	sub.f32 	%f948, %f932, %f933;
	mul.f32 	%f2033, %f948, %f941;
	mul.f32 	%f949, %f2021, %f2029;
	mul.f32 	%f950, %f2023, %f2027;
	sub.f32 	%f951, %f950, %f949;
	mul.f32 	%f2034, %f951, %f941;
	mul.f32 	%f952, %f2026, %f2027;
	mul.f32 	%f953, %f2024, %f2029;
	sub.f32 	%f954, %f953, %f952;
	mul.f32 	%f2035, %f954, %f941;
	mul.f32 	%f2030, %f939, %f941;
	mul.f32 	%f955, %f2022, %f2027;
	mul.f32 	%f956, %f2021, %f2028;
	sub.f32 	%f957, %f956, %f955;
	mul.f32 	%f2031, %f957, %f941;
	mul.f32 	%f958, %f2024, %f2028;
	mul.f32 	%f959, %f2025, %f2027;
	sub.f32 	%f960, %f959, %f958;
	mul.f32 	%f2032, %f960, %f941;
	bra.uni 	$L__BB13_36;

$L__BB13_27:
	// begin inline asm
	call (%rd258), _optix_get_instance_inverse_transform_from_handle, (%rd137);
	// end inline asm

$L__BB13_28:
	// begin inline asm
	cvta.to.global.u64 %rd143, %rd258;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r173,%r174,%r175,%r176}, [%rd143];
	// end inline asm
	mov.b32 	%f2036, %r173;
	mov.b32 	%f2037, %r174;
	mov.b32 	%f2038, %r175;
	add.s64 	%rd147, %rd258, 16;
	// begin inline asm
	cvta.to.global.u64 %rd146, %rd147;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r177,%r178,%r179,%r180}, [%rd146];
	// end inline asm
	mov.b32 	%f2033, %r177;
	mov.b32 	%f2034, %r178;
	mov.b32 	%f2035, %r179;
	add.s64 	%rd150, %rd258, 32;
	// begin inline asm
	cvta.to.global.u64 %rd149, %rd150;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r181,%r182,%r183,%r184}, [%rd149];
	// end inline asm
	mov.b32 	%f2030, %r181;
	mov.b32 	%f2031, %r182;
	mov.b32 	%f2032, %r183;

$L__BB13_36:
	setp.eq.s32 	%p31, %r457, 0;
	@%p31 bra 	$L__BB13_38;

	mul.f32 	%f961, %f2007, %f2037;
	fma.rn.f32 	%f962, %f2004, %f2036, %f961;
	fma.rn.f32 	%f306, %f2010, %f2038, %f962;
	mul.f32 	%f963, %f2006, %f2037;
	fma.rn.f32 	%f964, %f2003, %f2036, %f963;
	fma.rn.f32 	%f307, %f2009, %f2038, %f964;
	mul.f32 	%f965, %f2005, %f2037;
	fma.rn.f32 	%f966, %f2002, %f2036, %f965;
	fma.rn.f32 	%f2038, %f2008, %f2038, %f966;
	mul.f32 	%f967, %f2007, %f2034;
	fma.rn.f32 	%f968, %f2004, %f2033, %f967;
	fma.rn.f32 	%f309, %f2010, %f2035, %f968;
	mul.f32 	%f969, %f2006, %f2034;
	fma.rn.f32 	%f970, %f2003, %f2033, %f969;
	fma.rn.f32 	%f310, %f2009, %f2035, %f970;
	mul.f32 	%f971, %f2005, %f2034;
	fma.rn.f32 	%f972, %f2002, %f2033, %f971;
	fma.rn.f32 	%f2035, %f2008, %f2035, %f972;
	mul.f32 	%f973, %f2007, %f2031;
	fma.rn.f32 	%f974, %f2004, %f2030, %f973;
	fma.rn.f32 	%f312, %f2010, %f2032, %f974;
	mul.f32 	%f975, %f2006, %f2031;
	fma.rn.f32 	%f976, %f2003, %f2030, %f975;
	fma.rn.f32 	%f313, %f2009, %f2032, %f976;
	mul.f32 	%f977, %f2005, %f2031;
	fma.rn.f32 	%f978, %f2002, %f2030, %f977;
	fma.rn.f32 	%f2032, %f2008, %f2032, %f978;
	mov.f32 	%f2030, %f312;
	mov.f32 	%f2031, %f313;
	mov.f32 	%f2033, %f309;
	mov.f32 	%f2034, %f310;
	mov.f32 	%f2036, %f306;
	mov.f32 	%f2037, %f307;

$L__BB13_38:
	add.s32 	%r457, %r457, 1;
	setp.lt.u32 	%p32, %r457, %r168;
	mov.f32 	%f2002, %f2038;
	mov.f32 	%f2003, %f2037;
	mov.f32 	%f2004, %f2036;
	mov.f32 	%f2005, %f2035;
	mov.f32 	%f2006, %f2034;
	mov.f32 	%f2007, %f2033;
	mov.f32 	%f2008, %f2032;
	mov.f32 	%f2009, %f2031;
	mov.f32 	%f2010, %f2030;
	@%p32 bra 	$L__BB13_23;

$L__BB13_39:
	mul.f32 	%f979, %f2058, %f2037;
	fma.rn.f32 	%f980, %f2057, %f2036, %f979;
	mul.f32 	%f981, %f2058, %f2034;
	fma.rn.f32 	%f982, %f2057, %f2033, %f981;
	mul.f32 	%f983, %f2058, %f2031;
	fma.rn.f32 	%f984, %f2057, %f2030, %f983;
	fma.rn.f32 	%f2059, %f792, %f2032, %f984;
	fma.rn.f32 	%f2058, %f792, %f2035, %f982;
	fma.rn.f32 	%f2057, %f792, %f2038, %f980;
	bra.uni 	$L__BB13_41;

$L__BB13_40:
	mov.f32 	%f2059, %f792;

$L__BB13_41:
	// begin inline asm
	call (%f985), _optix_get_ray_tmin, ();
	// end inline asm
	// begin inline asm
	call (%f986), _optix_get_ray_tmax, ();
	// end inline asm
	add.s64 	%rd16, %rd1, 304;
	ld.f32 	%f346, [%rd1+304];
	ld.f32 	%f347, [%rd1+288];
	ld.f32 	%f348, [%rd1+292];
	mov.f32 	%f992, 0f40000000;
	abs.f32 	%f350, %f2057;
	setp.lt.f32 	%p33, %f350, 0f00800000;
	mul.f32 	%f994, %f350, 0f4B800000;
	selp.f32 	%f995, %f994, %f350, %p33;
	selp.f32 	%f996, 0fC3170000, 0fC2FE0000, %p33;
	mov.b32 	%r319, %f995;
	and.b32  	%r320, %r319, 8388607;
	or.b32  	%r321, %r320, 1065353216;
	mov.b32 	%f997, %r321;
	shr.u32 	%r322, %r319, 23;
	cvt.rn.f32.u32 	%f998, %r322;
	add.f32 	%f999, %f996, %f998;
	setp.gt.f32 	%p34, %f997, 0f3FB504F3;
	mul.f32 	%f1000, %f997, 0f3F000000;
	add.f32 	%f1001, %f999, 0f3F800000;
	selp.f32 	%f1002, %f1001, %f999, %p34;
	selp.f32 	%f1003, %f1000, %f997, %p34;
	add.f32 	%f1004, %f1003, 0fBF800000;
	add.f32 	%f1005, %f1003, 0f3F800000;
	rcp.approx.ftz.f32 	%f1006, %f1005;
	add.f32 	%f1007, %f1004, %f1004;
	mul.f32 	%f1008, %f1007, %f1006;
	mul.f32 	%f1009, %f1008, %f1008;
	mov.f32 	%f1010, 0f3C4CAF63;
	mov.f32 	%f1011, 0f3B18F0FE;
	fma.rn.f32 	%f1012, %f1011, %f1009, %f1010;
	mov.f32 	%f1013, 0f3DAAAABD;
	fma.rn.f32 	%f1014, %f1012, %f1009, %f1013;
	mul.rn.f32 	%f1015, %f1014, %f1009;
	mul.rn.f32 	%f1016, %f1015, %f1008;
	sub.f32 	%f1017, %f1004, %f1008;
	add.f32 	%f1018, %f1017, %f1017;
	neg.f32 	%f1019, %f1008;
	fma.rn.f32 	%f1020, %f1019, %f1004, %f1018;
	mul.rn.f32 	%f1021, %f1006, %f1020;
	add.f32 	%f1022, %f1016, %f1008;
	sub.f32 	%f1023, %f1008, %f1022;
	add.f32 	%f1024, %f1016, %f1023;
	add.f32 	%f1025, %f1021, %f1024;
	add.f32 	%f1026, %f1022, %f1025;
	sub.f32 	%f1027, %f1022, %f1026;
	add.f32 	%f1028, %f1025, %f1027;
	mov.f32 	%f1029, 0f3F317200;
	mul.rn.f32 	%f1030, %f1002, %f1029;
	mov.f32 	%f1031, 0f35BFBE8E;
	mul.rn.f32 	%f1032, %f1002, %f1031;
	add.f32 	%f1033, %f1030, %f1026;
	sub.f32 	%f1034, %f1030, %f1033;
	add.f32 	%f1035, %f1026, %f1034;
	add.f32 	%f1036, %f1028, %f1035;
	add.f32 	%f1037, %f1032, %f1036;
	add.f32 	%f1038, %f1033, %f1037;
	sub.f32 	%f1039, %f1033, %f1038;
	add.f32 	%f1040, %f1037, %f1039;
	mul.rn.f32 	%f1041, %f992, %f1038;
	neg.f32 	%f1042, %f1041;
	fma.rn.f32 	%f1043, %f992, %f1038, %f1042;
	fma.rn.f32 	%f1044, %f992, %f1040, %f1043;
	mov.f32 	%f1045, 0f00000000;
	fma.rn.f32 	%f1046, %f1045, %f1038, %f1044;
	add.rn.f32 	%f1047, %f1041, %f1046;
	neg.f32 	%f1048, %f1047;
	add.rn.f32 	%f1049, %f1041, %f1048;
	add.rn.f32 	%f1050, %f1049, %f1046;
	mov.b32 	%r323, %f1047;
	setp.eq.s32 	%p35, %r323, 1118925336;
	add.s32 	%r324, %r323, -1;
	mov.b32 	%f1051, %r324;
	add.f32 	%f1052, %f1050, 0f37000000;
	selp.f32 	%f351, %f1052, %f1050, %p35;
	selp.f32 	%f1053, %f1051, %f1047, %p35;
	mov.f32 	%f1054, 0f3FB8AA3B;
	mul.rn.f32 	%f1055, %f1053, %f1054;
	cvt.rzi.f32.f32 	%f1056, %f1055;
	abs.f32 	%f1057, %f1056;
	setp.gt.f32 	%p36, %f1057, 0f42FC0000;
	mov.b32 	%r325, %f1056;
	and.b32  	%r326, %r325, -2147483648;
	or.b32  	%r327, %r326, 1123811328;
	mov.b32 	%f1058, %r327;
	selp.f32 	%f1059, %f1058, %f1056, %p36;
	mov.f32 	%f1060, 0fBF317218;
	fma.rn.f32 	%f1061, %f1059, %f1060, %f1053;
	mov.f32 	%f1062, 0f3102E308;
	fma.rn.f32 	%f1063, %f1059, %f1062, %f1061;
	mul.f32 	%f1064, %f1063, 0f3FB8AA3B;
	add.f32 	%f1065, %f1059, 0f4B40007F;
	mov.b32 	%r328, %f1065;
	shl.b32 	%r329, %r328, 23;
	mov.b32 	%f1066, %r329;
	ex2.approx.ftz.f32 	%f1067, %f1064;
	mul.f32 	%f352, %f1067, %f1066;
	setp.eq.f32 	%p37, %f352, 0f7F800000;
	mov.f32 	%f2060, 0f7F800000;
	@%p37 bra 	$L__BB13_43;

	fma.rn.f32 	%f2060, %f352, %f351, %f352;

$L__BB13_43:
	mov.f32 	%f1908, 0f3F800000;
	cvt.rzi.f32.f32 	%f1907, %f1908;
	add.f32 	%f1906, %f1907, %f1907;
	mov.f32 	%f1905, 0f40000000;
	sub.f32 	%f1904, %f1905, %f1906;
	abs.f32 	%f1903, %f1904;
	setp.lt.f32 	%p38, %f2057, 0f00000000;
	setp.eq.f32 	%p39, %f1903, 0f3F800000;
	and.pred  	%p1, %p38, %p39;
	setp.eq.f32 	%p40, %f2057, 0f00000000;
	@%p40 bra 	$L__BB13_47;
	bra.uni 	$L__BB13_44;

$L__BB13_47:
	add.f32 	%f1072, %f2057, %f2057;
	selp.f32 	%f2062, %f1072, 0f00000000, %p39;
	bra.uni 	$L__BB13_48;

$L__BB13_44:
	mov.b32 	%r330, %f2060;
	xor.b32  	%r331, %r330, -2147483648;
	mov.b32 	%f1068, %r331;
	selp.f32 	%f2062, %f1068, %f2060, %p1;
	setp.geu.f32 	%p41, %f2057, 0f00000000;
	@%p41 bra 	$L__BB13_48;

	mov.f32 	%f1922, 0f40000000;
	cvt.rzi.f32.f32 	%f1070, %f1922;
	setp.eq.f32 	%p42, %f1070, 0f40000000;
	@%p42 bra 	$L__BB13_48;

	mov.f32 	%f2062, 0f7FFFFFFF;

$L__BB13_48:
	abs.f32 	%f1909, %f2057;
	add.f32 	%f1073, %f1909, 0f40000000;
	mov.b32 	%r9, %f1073;
	setp.lt.s32 	%p44, %r9, 2139095040;
	@%p44 bra 	$L__BB13_53;

	abs.f32 	%f1920, %f2057;
	setp.gtu.f32 	%p45, %f1920, 0f7F800000;
	@%p45 bra 	$L__BB13_52;
	bra.uni 	$L__BB13_50;

$L__BB13_52:
	add.f32 	%f2062, %f2057, 0f40000000;
	bra.uni 	$L__BB13_53;

$L__BB13_50:
	abs.f32 	%f1921, %f2057;
	setp.neu.f32 	%p46, %f1921, 0f7F800000;
	@%p46 bra 	$L__BB13_53;

	selp.f32 	%f2062, 0fFF800000, 0f7F800000, %p1;

$L__BB13_53:
	mov.f32 	%f1919, 0f3102E308;
	mov.f32 	%f1918, 0fBF317218;
	mov.f32 	%f1917, 0f3FB8AA3B;
	mov.f32 	%f1916, 0f00000000;
	mov.f32 	%f1915, 0f35BFBE8E;
	mov.f32 	%f1914, 0f3F317200;
	mov.f32 	%f1913, 0f3DAAAABD;
	mov.f32 	%f1912, 0f3C4CAF63;
	mov.f32 	%f1911, 0f3B18F0FE;
	mov.f32 	%f1910, 0f40000000;
	abs.f32 	%f361, %f2058;
	setp.lt.f32 	%p47, %f361, 0f00800000;
	mul.f32 	%f1075, %f361, 0f4B800000;
	selp.f32 	%f1076, %f1075, %f361, %p47;
	selp.f32 	%f1077, 0fC3170000, 0fC2FE0000, %p47;
	mov.b32 	%r332, %f1076;
	and.b32  	%r333, %r332, 8388607;
	or.b32  	%r334, %r333, 1065353216;
	mov.b32 	%f1078, %r334;
	shr.u32 	%r335, %r332, 23;
	cvt.rn.f32.u32 	%f1079, %r335;
	add.f32 	%f1080, %f1077, %f1079;
	setp.gt.f32 	%p48, %f1078, 0f3FB504F3;
	mul.f32 	%f1081, %f1078, 0f3F000000;
	add.f32 	%f1082, %f1080, 0f3F800000;
	selp.f32 	%f1083, %f1082, %f1080, %p48;
	selp.f32 	%f1084, %f1081, %f1078, %p48;
	add.f32 	%f1085, %f1084, 0fBF800000;
	add.f32 	%f1086, %f1084, 0f3F800000;
	rcp.approx.ftz.f32 	%f1087, %f1086;
	add.f32 	%f1088, %f1085, %f1085;
	mul.f32 	%f1090, %f1088, %f1087;
	mul.f32 	%f1091, %f1090, %f1090;
	fma.rn.f32 	%f1094, %f1911, %f1091, %f1912;
	fma.rn.f32 	%f1096, %f1094, %f1091, %f1913;
	mul.rn.f32 	%f1097, %f1096, %f1091;
	mul.rn.f32 	%f1098, %f1097, %f1090;
	sub.f32 	%f1099, %f1085, %f1090;
	add.f32 	%f1100, %f1099, %f1099;
	neg.f32 	%f1101, %f1090;
	fma.rn.f32 	%f1102, %f1101, %f1085, %f1100;
	mul.rn.f32 	%f1103, %f1087, %f1102;
	add.f32 	%f1104, %f1098, %f1090;
	sub.f32 	%f1105, %f1090, %f1104;
	add.f32 	%f1106, %f1098, %f1105;
	add.f32 	%f1107, %f1103, %f1106;
	add.f32 	%f1108, %f1104, %f1107;
	sub.f32 	%f1109, %f1104, %f1108;
	add.f32 	%f1110, %f1107, %f1109;
	mul.rn.f32 	%f1112, %f1083, %f1914;
	mul.rn.f32 	%f1114, %f1083, %f1915;
	add.f32 	%f1115, %f1112, %f1108;
	sub.f32 	%f1116, %f1112, %f1115;
	add.f32 	%f1117, %f1108, %f1116;
	add.f32 	%f1118, %f1110, %f1117;
	add.f32 	%f1119, %f1114, %f1118;
	add.f32 	%f1120, %f1115, %f1119;
	sub.f32 	%f1121, %f1115, %f1120;
	add.f32 	%f1122, %f1119, %f1121;
	mul.rn.f32 	%f1123, %f1910, %f1120;
	neg.f32 	%f1124, %f1123;
	fma.rn.f32 	%f1125, %f1910, %f1120, %f1124;
	fma.rn.f32 	%f1126, %f1910, %f1122, %f1125;
	fma.rn.f32 	%f1128, %f1916, %f1120, %f1126;
	add.rn.f32 	%f1129, %f1123, %f1128;
	neg.f32 	%f1130, %f1129;
	add.rn.f32 	%f1131, %f1123, %f1130;
	add.rn.f32 	%f1132, %f1131, %f1128;
	mov.b32 	%r336, %f1129;
	setp.eq.s32 	%p49, %r336, 1118925336;
	add.s32 	%r337, %r336, -1;
	mov.b32 	%f1133, %r337;
	add.f32 	%f1134, %f1132, 0f37000000;
	selp.f32 	%f362, %f1134, %f1132, %p49;
	selp.f32 	%f1135, %f1133, %f1129, %p49;
	mul.rn.f32 	%f1137, %f1135, %f1917;
	cvt.rzi.f32.f32 	%f1138, %f1137;
	abs.f32 	%f1139, %f1138;
	setp.gt.f32 	%p50, %f1139, 0f42FC0000;
	mov.b32 	%r338, %f1138;
	and.b32  	%r339, %r338, -2147483648;
	or.b32  	%r340, %r339, 1123811328;
	mov.b32 	%f1140, %r340;
	selp.f32 	%f1141, %f1140, %f1138, %p50;
	fma.rn.f32 	%f1143, %f1141, %f1918, %f1135;
	fma.rn.f32 	%f1145, %f1141, %f1919, %f1143;
	mul.f32 	%f1146, %f1145, 0f3FB8AA3B;
	add.f32 	%f1147, %f1141, 0f4B40007F;
	mov.b32 	%r341, %f1147;
	shl.b32 	%r342, %r341, 23;
	mov.b32 	%f1148, %r342;
	ex2.approx.ftz.f32 	%f1149, %f1146;
	mul.f32 	%f363, %f1149, %f1148;
	setp.eq.f32 	%p51, %f363, 0f7F800000;
	mov.f32 	%f2063, 0f7F800000;
	@%p51 bra 	$L__BB13_55;

	fma.rn.f32 	%f2063, %f363, %f362, %f363;

$L__BB13_55:
	setp.lt.f32 	%p52, %f2058, 0f00000000;
	and.pred  	%p2, %p52, %p39;
	setp.eq.f32 	%p54, %f2058, 0f00000000;
	@%p54 bra 	$L__BB13_59;
	bra.uni 	$L__BB13_56;

$L__BB13_59:
	add.f32 	%f1154, %f2058, %f2058;
	selp.f32 	%f2065, %f1154, 0f00000000, %p39;
	bra.uni 	$L__BB13_60;

$L__BB13_56:
	mov.b32 	%r343, %f2063;
	xor.b32  	%r344, %r343, -2147483648;
	mov.b32 	%f1150, %r344;
	selp.f32 	%f2065, %f1150, %f2063, %p2;
	setp.geu.f32 	%p55, %f2058, 0f00000000;
	@%p55 bra 	$L__BB13_60;

	mov.f32 	%f1901, 0f40000000;
	cvt.rzi.f32.f32 	%f1152, %f1901;
	setp.eq.f32 	%p56, %f1152, 0f40000000;
	@%p56 bra 	$L__BB13_60;

	mov.f32 	%f2065, 0f7FFFFFFF;

$L__BB13_60:
	abs.f32 	%f1888, %f2058;
	add.f32 	%f1155, %f1888, 0f40000000;
	mov.b32 	%r10, %f1155;
	setp.lt.s32 	%p58, %r10, 2139095040;
	@%p58 bra 	$L__BB13_65;

	abs.f32 	%f1899, %f2058;
	setp.gtu.f32 	%p59, %f1899, 0f7F800000;
	@%p59 bra 	$L__BB13_64;
	bra.uni 	$L__BB13_62;

$L__BB13_64:
	add.f32 	%f2065, %f2058, 0f40000000;
	bra.uni 	$L__BB13_65;

$L__BB13_62:
	abs.f32 	%f1900, %f2058;
	setp.neu.f32 	%p60, %f1900, 0f7F800000;
	@%p60 bra 	$L__BB13_65;

	selp.f32 	%f2065, 0fFF800000, 0f7F800000, %p2;

$L__BB13_65:
	mov.f32 	%f1898, 0f3102E308;
	mov.f32 	%f1897, 0fBF317218;
	mov.f32 	%f1896, 0f3FB8AA3B;
	mov.f32 	%f1895, 0f00000000;
	mov.f32 	%f1894, 0f35BFBE8E;
	mov.f32 	%f1893, 0f3F317200;
	mov.f32 	%f1892, 0f3DAAAABD;
	mov.f32 	%f1891, 0f3C4CAF63;
	mov.f32 	%f1890, 0f3B18F0FE;
	mov.f32 	%f1889, 0f40000000;
	setp.eq.f32 	%p61, %f2058, 0f3F800000;
	selp.f32 	%f1157, 0f3F800000, %f2065, %p61;
	setp.eq.f32 	%p62, %f2057, 0f3F800000;
	selp.f32 	%f1158, 0f3F800000, %f2062, %p62;
	add.f32 	%f372, %f1158, %f1157;
	add.f32 	%f373, %f1999, %f1999;
	mul.f32 	%f1160, %f373, %f2057;
	add.f32 	%f1161, %f347, %f347;
	mul.f32 	%f1162, %f1161, %f2057;
	sub.f32 	%f1163, %f1160, %f1162;
	add.f32 	%f374, %f2000, %f2000;
	fma.rn.f32 	%f1164, %f374, %f2058, %f1163;
	add.f32 	%f1165, %f348, %f348;
	mul.f32 	%f1166, %f1165, %f2058;
	sub.f32 	%f375, %f1164, %f1166;
	abs.f32 	%f376, %f1999;
	setp.lt.f32 	%p63, %f376, 0f00800000;
	mul.f32 	%f1167, %f376, 0f4B800000;
	selp.f32 	%f1168, %f1167, %f376, %p63;
	selp.f32 	%f1169, 0fC3170000, 0fC2FE0000, %p63;
	mov.b32 	%r345, %f1168;
	and.b32  	%r346, %r345, 8388607;
	or.b32  	%r347, %r346, 1065353216;
	mov.b32 	%f1170, %r347;
	shr.u32 	%r348, %r345, 23;
	cvt.rn.f32.u32 	%f1171, %r348;
	add.f32 	%f1172, %f1169, %f1171;
	setp.gt.f32 	%p64, %f1170, 0f3FB504F3;
	mul.f32 	%f1173, %f1170, 0f3F000000;
	add.f32 	%f1174, %f1172, 0f3F800000;
	selp.f32 	%f1175, %f1174, %f1172, %p64;
	selp.f32 	%f1176, %f1173, %f1170, %p64;
	add.f32 	%f1177, %f1176, 0fBF800000;
	add.f32 	%f1178, %f1176, 0f3F800000;
	rcp.approx.ftz.f32 	%f1179, %f1178;
	add.f32 	%f1180, %f1177, %f1177;
	mul.f32 	%f1181, %f1180, %f1179;
	mul.f32 	%f1182, %f1181, %f1181;
	fma.rn.f32 	%f1185, %f1890, %f1182, %f1891;
	fma.rn.f32 	%f1187, %f1185, %f1182, %f1892;
	mul.rn.f32 	%f1188, %f1187, %f1182;
	mul.rn.f32 	%f1189, %f1188, %f1181;
	sub.f32 	%f1190, %f1177, %f1181;
	add.f32 	%f1191, %f1190, %f1190;
	neg.f32 	%f1192, %f1181;
	fma.rn.f32 	%f1193, %f1192, %f1177, %f1191;
	mul.rn.f32 	%f1194, %f1179, %f1193;
	add.f32 	%f1195, %f1189, %f1181;
	sub.f32 	%f1196, %f1181, %f1195;
	add.f32 	%f1197, %f1189, %f1196;
	add.f32 	%f1198, %f1194, %f1197;
	add.f32 	%f1199, %f1195, %f1198;
	sub.f32 	%f1200, %f1195, %f1199;
	add.f32 	%f1201, %f1198, %f1200;
	mul.rn.f32 	%f1203, %f1175, %f1893;
	mul.rn.f32 	%f1205, %f1175, %f1894;
	add.f32 	%f1206, %f1203, %f1199;
	sub.f32 	%f1207, %f1203, %f1206;
	add.f32 	%f1208, %f1199, %f1207;
	add.f32 	%f1209, %f1201, %f1208;
	add.f32 	%f1210, %f1205, %f1209;
	add.f32 	%f1211, %f1206, %f1210;
	sub.f32 	%f1212, %f1206, %f1211;
	add.f32 	%f1213, %f1210, %f1212;
	mul.rn.f32 	%f1214, %f1889, %f1211;
	neg.f32 	%f1215, %f1214;
	fma.rn.f32 	%f1216, %f1889, %f1211, %f1215;
	fma.rn.f32 	%f1217, %f1889, %f1213, %f1216;
	fma.rn.f32 	%f1219, %f1895, %f1211, %f1217;
	add.rn.f32 	%f1220, %f1214, %f1219;
	neg.f32 	%f1221, %f1220;
	add.rn.f32 	%f1222, %f1214, %f1221;
	add.rn.f32 	%f1223, %f1222, %f1219;
	mov.b32 	%r349, %f1220;
	setp.eq.s32 	%p65, %r349, 1118925336;
	add.s32 	%r350, %r349, -1;
	mov.b32 	%f1224, %r350;
	add.f32 	%f1225, %f1223, 0f37000000;
	selp.f32 	%f377, %f1225, %f1223, %p65;
	selp.f32 	%f1226, %f1224, %f1220, %p65;
	mul.rn.f32 	%f1228, %f1226, %f1896;
	cvt.rzi.f32.f32 	%f1229, %f1228;
	abs.f32 	%f1230, %f1229;
	setp.gt.f32 	%p66, %f1230, 0f42FC0000;
	mov.b32 	%r351, %f1229;
	and.b32  	%r352, %r351, -2147483648;
	or.b32  	%r353, %r352, 1123811328;
	mov.b32 	%f1231, %r353;
	selp.f32 	%f1232, %f1231, %f1229, %p66;
	fma.rn.f32 	%f1234, %f1232, %f1897, %f1226;
	fma.rn.f32 	%f1236, %f1232, %f1898, %f1234;
	mul.f32 	%f1237, %f1236, 0f3FB8AA3B;
	add.f32 	%f1238, %f1232, 0f4B40007F;
	mov.b32 	%r354, %f1238;
	shl.b32 	%r355, %r354, 23;
	mov.b32 	%f1239, %r355;
	ex2.approx.ftz.f32 	%f1240, %f1237;
	mul.f32 	%f378, %f1240, %f1239;
	setp.eq.f32 	%p67, %f378, 0f7F800000;
	mov.f32 	%f2066, 0f7F800000;
	@%p67 bra 	$L__BB13_67;

	fma.rn.f32 	%f2066, %f378, %f377, %f378;

$L__BB13_67:
	setp.lt.f32 	%p68, %f1999, 0f00000000;
	and.pred  	%p3, %p68, %p39;
	setp.eq.f32 	%p70, %f1999, 0f00000000;
	@%p70 bra 	$L__BB13_71;
	bra.uni 	$L__BB13_68;

$L__BB13_71:
	add.f32 	%f1887, %f1999, %f1999;
	selp.f32 	%f2068, %f1887, 0f00000000, %p39;
	bra.uni 	$L__BB13_72;

$L__BB13_68:
	mov.b32 	%r356, %f2066;
	xor.b32  	%r357, %r356, -2147483648;
	mov.b32 	%f1241, %r357;
	selp.f32 	%f2068, %f1241, %f2066, %p3;
	setp.geu.f32 	%p71, %f1999, 0f00000000;
	@%p71 bra 	$L__BB13_72;

	mov.f32 	%f1886, 0f40000000;
	cvt.rzi.f32.f32 	%f1243, %f1886;
	setp.eq.f32 	%p72, %f1243, 0f40000000;
	@%p72 bra 	$L__BB13_72;

	mov.f32 	%f2068, 0f7FFFFFFF;

$L__BB13_72:
	abs.f32 	%f1872, %f1999;
	add.f32 	%f1246, %f1872, 0f40000000;
	mov.b32 	%r11, %f1246;
	setp.lt.s32 	%p74, %r11, 2139095040;
	@%p74 bra 	$L__BB13_77;

	abs.f32 	%f1884, %f1999;
	setp.gtu.f32 	%p75, %f1884, 0f7F800000;
	@%p75 bra 	$L__BB13_76;
	bra.uni 	$L__BB13_74;

$L__BB13_76:
	add.f32 	%f2068, %f1999, 0f40000000;
	bra.uni 	$L__BB13_77;

$L__BB13_74:
	abs.f32 	%f1885, %f1999;
	setp.neu.f32 	%p76, %f1885, 0f7F800000;
	@%p76 bra 	$L__BB13_77;

	selp.f32 	%f2068, 0fFF800000, 0f7F800000, %p3;

$L__BB13_77:
	mov.f32 	%f1882, 0f3102E308;
	mov.f32 	%f1881, 0fBF317218;
	mov.f32 	%f1880, 0f3FB8AA3B;
	mov.f32 	%f1879, 0f00000000;
	mov.f32 	%f1878, 0f35BFBE8E;
	mov.f32 	%f1877, 0f3F317200;
	mov.f32 	%f1876, 0f3DAAAABD;
	mov.f32 	%f1875, 0f3C4CAF63;
	mov.f32 	%f1874, 0f3B18F0FE;
	mov.f32 	%f1873, 0f40000000;
	abs.f32 	%f388, %f347;
	setp.lt.f32 	%p77, %f388, 0f00800000;
	mul.f32 	%f1248, %f388, 0f4B800000;
	selp.f32 	%f1249, %f1248, %f388, %p77;
	selp.f32 	%f1250, 0fC3170000, 0fC2FE0000, %p77;
	mov.b32 	%r358, %f1249;
	and.b32  	%r359, %r358, 8388607;
	or.b32  	%r360, %r359, 1065353216;
	mov.b32 	%f1251, %r360;
	shr.u32 	%r361, %r358, 23;
	cvt.rn.f32.u32 	%f1252, %r361;
	add.f32 	%f1253, %f1250, %f1252;
	setp.gt.f32 	%p78, %f1251, 0f3FB504F3;
	mul.f32 	%f1254, %f1251, 0f3F000000;
	add.f32 	%f1255, %f1253, 0f3F800000;
	selp.f32 	%f1256, %f1255, %f1253, %p78;
	selp.f32 	%f1257, %f1254, %f1251, %p78;
	add.f32 	%f1258, %f1257, 0fBF800000;
	add.f32 	%f1259, %f1257, 0f3F800000;
	rcp.approx.ftz.f32 	%f1260, %f1259;
	add.f32 	%f1261, %f1258, %f1258;
	mul.f32 	%f1263, %f1261, %f1260;
	mul.f32 	%f1264, %f1263, %f1263;
	fma.rn.f32 	%f1267, %f1874, %f1264, %f1875;
	fma.rn.f32 	%f1269, %f1267, %f1264, %f1876;
	mul.rn.f32 	%f1270, %f1269, %f1264;
	mul.rn.f32 	%f1271, %f1270, %f1263;
	sub.f32 	%f1272, %f1258, %f1263;
	add.f32 	%f1273, %f1272, %f1272;
	neg.f32 	%f1274, %f1263;
	fma.rn.f32 	%f1275, %f1274, %f1258, %f1273;
	mul.rn.f32 	%f1276, %f1260, %f1275;
	add.f32 	%f1277, %f1271, %f1263;
	sub.f32 	%f1278, %f1263, %f1277;
	add.f32 	%f1279, %f1271, %f1278;
	add.f32 	%f1280, %f1276, %f1279;
	add.f32 	%f1281, %f1277, %f1280;
	sub.f32 	%f1282, %f1277, %f1281;
	add.f32 	%f1283, %f1280, %f1282;
	mul.rn.f32 	%f1285, %f1256, %f1877;
	mul.rn.f32 	%f1287, %f1256, %f1878;
	add.f32 	%f1288, %f1285, %f1281;
	sub.f32 	%f1289, %f1285, %f1288;
	add.f32 	%f1290, %f1281, %f1289;
	add.f32 	%f1291, %f1283, %f1290;
	add.f32 	%f1292, %f1287, %f1291;
	add.f32 	%f1293, %f1288, %f1292;
	sub.f32 	%f1294, %f1288, %f1293;
	add.f32 	%f1295, %f1292, %f1294;
	mul.rn.f32 	%f1296, %f1873, %f1293;
	neg.f32 	%f1297, %f1296;
	fma.rn.f32 	%f1298, %f1873, %f1293, %f1297;
	fma.rn.f32 	%f1299, %f1873, %f1295, %f1298;
	fma.rn.f32 	%f1301, %f1879, %f1293, %f1299;
	add.rn.f32 	%f1302, %f1296, %f1301;
	neg.f32 	%f1303, %f1302;
	add.rn.f32 	%f1304, %f1296, %f1303;
	add.rn.f32 	%f1305, %f1304, %f1301;
	mov.b32 	%r362, %f1302;
	setp.eq.s32 	%p79, %r362, 1118925336;
	add.s32 	%r363, %r362, -1;
	mov.b32 	%f1306, %r363;
	add.f32 	%f1307, %f1305, 0f37000000;
	selp.f32 	%f389, %f1307, %f1305, %p79;
	selp.f32 	%f1308, %f1306, %f1302, %p79;
	mul.rn.f32 	%f1310, %f1308, %f1880;
	cvt.rzi.f32.f32 	%f1311, %f1310;
	abs.f32 	%f1312, %f1311;
	setp.gt.f32 	%p80, %f1312, 0f42FC0000;
	mov.b32 	%r364, %f1311;
	and.b32  	%r365, %r364, -2147483648;
	or.b32  	%r366, %r365, 1123811328;
	mov.b32 	%f1313, %r366;
	selp.f32 	%f1314, %f1313, %f1311, %p80;
	fma.rn.f32 	%f1316, %f1314, %f1881, %f1308;
	fma.rn.f32 	%f1318, %f1314, %f1882, %f1316;
	mul.f32 	%f1319, %f1318, 0f3FB8AA3B;
	add.f32 	%f1320, %f1314, 0f4B40007F;
	mov.b32 	%r367, %f1320;
	shl.b32 	%r368, %r367, 23;
	mov.b32 	%f1321, %r368;
	ex2.approx.ftz.f32 	%f1322, %f1319;
	mul.f32 	%f390, %f1322, %f1321;
	setp.eq.f32 	%p81, %f390, 0f7F800000;
	mov.f32 	%f2069, 0f7F800000;
	@%p81 bra 	$L__BB13_79;

	fma.rn.f32 	%f2069, %f390, %f389, %f390;

$L__BB13_79:
	setp.lt.f32 	%p82, %f347, 0f00000000;
	and.pred  	%p4, %p82, %p39;
	setp.eq.f32 	%p84, %f347, 0f00000000;
	@%p84 bra 	$L__BB13_83;
	bra.uni 	$L__BB13_80;

$L__BB13_83:
	add.f32 	%f1871, %f347, %f347;
	selp.f32 	%f2071, %f1871, 0f00000000, %p39;
	bra.uni 	$L__BB13_84;

$L__BB13_80:
	mov.b32 	%r369, %f2069;
	xor.b32  	%r370, %r369, -2147483648;
	mov.b32 	%f1323, %r370;
	selp.f32 	%f2071, %f1323, %f2069, %p4;
	setp.geu.f32 	%p85, %f347, 0f00000000;
	@%p85 bra 	$L__BB13_84;

	mov.f32 	%f1870, 0f40000000;
	cvt.rzi.f32.f32 	%f1325, %f1870;
	setp.eq.f32 	%p86, %f1325, 0f40000000;
	@%p86 bra 	$L__BB13_84;

	mov.f32 	%f2071, 0f7FFFFFFF;

$L__BB13_84:
	abs.f32 	%f1855, %f347;
	add.f32 	%f1328, %f1855, 0f40000000;
	mov.b32 	%r12, %f1328;
	setp.lt.s32 	%p88, %r12, 2139095040;
	@%p88 bra 	$L__BB13_89;

	abs.f32 	%f1868, %f347;
	setp.gtu.f32 	%p89, %f1868, 0f7F800000;
	@%p89 bra 	$L__BB13_88;
	bra.uni 	$L__BB13_86;

$L__BB13_88:
	add.f32 	%f2071, %f347, 0f40000000;
	bra.uni 	$L__BB13_89;

$L__BB13_86:
	abs.f32 	%f1869, %f347;
	setp.neu.f32 	%p90, %f1869, 0f7F800000;
	@%p90 bra 	$L__BB13_89;

	selp.f32 	%f2071, 0fFF800000, 0f7F800000, %p4;

$L__BB13_89:
	add.f32 	%f1867, %f1999, %f1999;
	mul.f32 	%f1866, %f347, %f1867;
	mov.f32 	%f1865, 0f3102E308;
	mov.f32 	%f1864, 0fBF317218;
	mov.f32 	%f1863, 0f3FB8AA3B;
	mov.f32 	%f1862, 0f00000000;
	mov.f32 	%f1861, 0f35BFBE8E;
	mov.f32 	%f1860, 0f3F317200;
	mov.f32 	%f1859, 0f3DAAAABD;
	mov.f32 	%f1858, 0f3C4CAF63;
	mov.f32 	%f1857, 0f3B18F0FE;
	mov.f32 	%f1856, 0f40000000;
	setp.eq.f32 	%p91, %f347, 0f3F800000;
	selp.f32 	%f1330, 0f3F800000, %f2071, %p91;
	setp.eq.f32 	%p92, %f1999, 0f3F800000;
	selp.f32 	%f1331, 0f3F800000, %f2068, %p92;
	sub.f32 	%f1332, %f1331, %f1866;
	add.f32 	%f401, %f1332, %f1330;
	abs.f32 	%f402, %f2000;
	setp.lt.f32 	%p93, %f402, 0f00800000;
	mul.f32 	%f1333, %f402, 0f4B800000;
	selp.f32 	%f1334, %f1333, %f402, %p93;
	selp.f32 	%f1335, 0fC3170000, 0fC2FE0000, %p93;
	mov.b32 	%r371, %f1334;
	and.b32  	%r372, %r371, 8388607;
	or.b32  	%r373, %r372, 1065353216;
	mov.b32 	%f1336, %r373;
	shr.u32 	%r374, %r371, 23;
	cvt.rn.f32.u32 	%f1337, %r374;
	add.f32 	%f1338, %f1335, %f1337;
	setp.gt.f32 	%p94, %f1336, 0f3FB504F3;
	mul.f32 	%f1339, %f1336, 0f3F000000;
	add.f32 	%f1340, %f1338, 0f3F800000;
	selp.f32 	%f1341, %f1340, %f1338, %p94;
	selp.f32 	%f1342, %f1339, %f1336, %p94;
	add.f32 	%f1343, %f1342, 0fBF800000;
	add.f32 	%f1344, %f1342, 0f3F800000;
	rcp.approx.ftz.f32 	%f1345, %f1344;
	add.f32 	%f1346, %f1343, %f1343;
	mul.f32 	%f1348, %f1346, %f1345;
	mul.f32 	%f1349, %f1348, %f1348;
	fma.rn.f32 	%f1352, %f1857, %f1349, %f1858;
	fma.rn.f32 	%f1354, %f1352, %f1349, %f1859;
	mul.rn.f32 	%f1355, %f1354, %f1349;
	mul.rn.f32 	%f1356, %f1355, %f1348;
	sub.f32 	%f1357, %f1343, %f1348;
	add.f32 	%f1358, %f1357, %f1357;
	neg.f32 	%f1359, %f1348;
	fma.rn.f32 	%f1360, %f1359, %f1343, %f1358;
	mul.rn.f32 	%f1361, %f1345, %f1360;
	add.f32 	%f1362, %f1356, %f1348;
	sub.f32 	%f1363, %f1348, %f1362;
	add.f32 	%f1364, %f1356, %f1363;
	add.f32 	%f1365, %f1361, %f1364;
	add.f32 	%f1366, %f1362, %f1365;
	sub.f32 	%f1367, %f1362, %f1366;
	add.f32 	%f1368, %f1365, %f1367;
	mul.rn.f32 	%f1370, %f1341, %f1860;
	mul.rn.f32 	%f1372, %f1341, %f1861;
	add.f32 	%f1373, %f1370, %f1366;
	sub.f32 	%f1374, %f1370, %f1373;
	add.f32 	%f1375, %f1366, %f1374;
	add.f32 	%f1376, %f1368, %f1375;
	add.f32 	%f1377, %f1372, %f1376;
	add.f32 	%f1378, %f1373, %f1377;
	sub.f32 	%f1379, %f1373, %f1378;
	add.f32 	%f1380, %f1377, %f1379;
	mul.rn.f32 	%f1381, %f1856, %f1378;
	neg.f32 	%f1382, %f1381;
	fma.rn.f32 	%f1383, %f1856, %f1378, %f1382;
	fma.rn.f32 	%f1384, %f1856, %f1380, %f1383;
	fma.rn.f32 	%f1386, %f1862, %f1378, %f1384;
	add.rn.f32 	%f1387, %f1381, %f1386;
	neg.f32 	%f1388, %f1387;
	add.rn.f32 	%f1389, %f1381, %f1388;
	add.rn.f32 	%f1390, %f1389, %f1386;
	mov.b32 	%r375, %f1387;
	setp.eq.s32 	%p95, %r375, 1118925336;
	add.s32 	%r376, %r375, -1;
	mov.b32 	%f1391, %r376;
	add.f32 	%f1392, %f1390, 0f37000000;
	selp.f32 	%f403, %f1392, %f1390, %p95;
	selp.f32 	%f1393, %f1391, %f1387, %p95;
	mul.rn.f32 	%f1395, %f1393, %f1863;
	cvt.rzi.f32.f32 	%f1396, %f1395;
	abs.f32 	%f1397, %f1396;
	setp.gt.f32 	%p96, %f1397, 0f42FC0000;
	mov.b32 	%r377, %f1396;
	and.b32  	%r378, %r377, -2147483648;
	or.b32  	%r379, %r378, 1123811328;
	mov.b32 	%f1398, %r379;
	selp.f32 	%f1399, %f1398, %f1396, %p96;
	fma.rn.f32 	%f1401, %f1399, %f1864, %f1393;
	fma.rn.f32 	%f1403, %f1399, %f1865, %f1401;
	mul.f32 	%f1404, %f1403, 0f3FB8AA3B;
	add.f32 	%f1405, %f1399, 0f4B40007F;
	mov.b32 	%r380, %f1405;
	shl.b32 	%r381, %r380, 23;
	mov.b32 	%f1406, %r381;
	ex2.approx.ftz.f32 	%f1407, %f1404;
	mul.f32 	%f404, %f1407, %f1406;
	setp.eq.f32 	%p97, %f404, 0f7F800000;
	mov.f32 	%f2072, 0f7F800000;
	@%p97 bra 	$L__BB13_91;

	fma.rn.f32 	%f2072, %f404, %f403, %f404;

$L__BB13_91:
	setp.lt.f32 	%p98, %f2000, 0f00000000;
	and.pred  	%p5, %p98, %p39;
	setp.eq.f32 	%p100, %f2000, 0f00000000;
	@%p100 bra 	$L__BB13_95;
	bra.uni 	$L__BB13_92;

$L__BB13_95:
	add.f32 	%f1849, %f2000, %f2000;
	selp.f32 	%f2074, %f1849, 0f00000000, %p39;
	bra.uni 	$L__BB13_96;

$L__BB13_92:
	mov.b32 	%r382, %f2072;
	xor.b32  	%r383, %r382, -2147483648;
	mov.b32 	%f1408, %r383;
	selp.f32 	%f2074, %f1408, %f2072, %p5;
	setp.geu.f32 	%p101, %f2000, 0f00000000;
	@%p101 bra 	$L__BB13_96;

	mov.f32 	%f1848, 0f40000000;
	cvt.rzi.f32.f32 	%f1410, %f1848;
	setp.eq.f32 	%p102, %f1410, 0f40000000;
	@%p102 bra 	$L__BB13_96;

	mov.f32 	%f2074, 0f7FFFFFFF;

$L__BB13_96:
	abs.f32 	%f1822, %f2000;
	add.f32 	%f1413, %f1822, 0f40000000;
	mov.b32 	%r13, %f1413;
	setp.lt.s32 	%p104, %r13, 2139095040;
	@%p104 bra 	$L__BB13_101;

	abs.f32 	%f1846, %f2000;
	setp.gtu.f32 	%p105, %f1846, 0f7F800000;
	@%p105 bra 	$L__BB13_100;
	bra.uni 	$L__BB13_98;

$L__BB13_100:
	add.f32 	%f2074, %f2000, 0f40000000;
	bra.uni 	$L__BB13_101;

$L__BB13_98:
	abs.f32 	%f1847, %f2000;
	setp.neu.f32 	%p106, %f1847, 0f7F800000;
	@%p106 bra 	$L__BB13_101;

	selp.f32 	%f2074, 0fFF800000, 0f7F800000, %p5;

$L__BB13_101:
	mov.f32 	%f1832, 0f3102E308;
	mov.f32 	%f1831, 0fBF317218;
	mov.f32 	%f1830, 0f3FB8AA3B;
	mov.f32 	%f1829, 0f00000000;
	mov.f32 	%f1828, 0f35BFBE8E;
	mov.f32 	%f1827, 0f3F317200;
	mov.f32 	%f1826, 0f3DAAAABD;
	mov.f32 	%f1825, 0f3C4CAF63;
	mov.f32 	%f1824, 0f3B18F0FE;
	mov.f32 	%f1823, 0f40000000;
	setp.eq.f32 	%p107, %f2000, 0f3F800000;
	selp.f32 	%f1415, 0f3F800000, %f2074, %p107;
	add.f32 	%f413, %f401, %f1415;
	abs.f32 	%f415, %f348;
	setp.lt.f32 	%p108, %f415, 0f00800000;
	mul.f32 	%f1416, %f415, 0f4B800000;
	selp.f32 	%f1417, %f1416, %f415, %p108;
	selp.f32 	%f1418, 0fC3170000, 0fC2FE0000, %p108;
	mov.b32 	%r384, %f1417;
	and.b32  	%r385, %r384, 8388607;
	or.b32  	%r386, %r385, 1065353216;
	mov.b32 	%f1419, %r386;
	shr.u32 	%r387, %r384, 23;
	cvt.rn.f32.u32 	%f1420, %r387;
	add.f32 	%f1421, %f1418, %f1420;
	setp.gt.f32 	%p109, %f1419, 0f3FB504F3;
	mul.f32 	%f1422, %f1419, 0f3F000000;
	add.f32 	%f1423, %f1421, 0f3F800000;
	selp.f32 	%f1424, %f1423, %f1421, %p109;
	selp.f32 	%f1425, %f1422, %f1419, %p109;
	add.f32 	%f1426, %f1425, 0fBF800000;
	add.f32 	%f1427, %f1425, 0f3F800000;
	rcp.approx.ftz.f32 	%f1428, %f1427;
	add.f32 	%f1429, %f1426, %f1426;
	mul.f32 	%f1431, %f1429, %f1428;
	mul.f32 	%f1432, %f1431, %f1431;
	fma.rn.f32 	%f1435, %f1824, %f1432, %f1825;
	fma.rn.f32 	%f1437, %f1435, %f1432, %f1826;
	mul.rn.f32 	%f1438, %f1437, %f1432;
	mul.rn.f32 	%f1439, %f1438, %f1431;
	sub.f32 	%f1440, %f1426, %f1431;
	add.f32 	%f1441, %f1440, %f1440;
	neg.f32 	%f1442, %f1431;
	fma.rn.f32 	%f1443, %f1442, %f1426, %f1441;
	mul.rn.f32 	%f1444, %f1428, %f1443;
	add.f32 	%f1445, %f1439, %f1431;
	sub.f32 	%f1446, %f1431, %f1445;
	add.f32 	%f1447, %f1439, %f1446;
	add.f32 	%f1448, %f1444, %f1447;
	add.f32 	%f1449, %f1445, %f1448;
	sub.f32 	%f1450, %f1445, %f1449;
	add.f32 	%f1451, %f1448, %f1450;
	mul.rn.f32 	%f1453, %f1424, %f1827;
	mul.rn.f32 	%f1455, %f1424, %f1828;
	add.f32 	%f1456, %f1453, %f1449;
	sub.f32 	%f1457, %f1453, %f1456;
	add.f32 	%f1458, %f1449, %f1457;
	add.f32 	%f1459, %f1451, %f1458;
	add.f32 	%f1460, %f1455, %f1459;
	add.f32 	%f1461, %f1456, %f1460;
	sub.f32 	%f1462, %f1456, %f1461;
	add.f32 	%f1463, %f1460, %f1462;
	mul.rn.f32 	%f1464, %f1823, %f1461;
	neg.f32 	%f1465, %f1464;
	fma.rn.f32 	%f1466, %f1823, %f1461, %f1465;
	fma.rn.f32 	%f1467, %f1823, %f1463, %f1466;
	fma.rn.f32 	%f1469, %f1829, %f1461, %f1467;
	add.rn.f32 	%f1470, %f1464, %f1469;
	neg.f32 	%f1471, %f1470;
	add.rn.f32 	%f1472, %f1464, %f1471;
	add.rn.f32 	%f1473, %f1472, %f1469;
	mov.b32 	%r388, %f1470;
	setp.eq.s32 	%p110, %r388, 1118925336;
	add.s32 	%r389, %r388, -1;
	mov.b32 	%f1474, %r389;
	add.f32 	%f1475, %f1473, 0f37000000;
	selp.f32 	%f416, %f1475, %f1473, %p110;
	selp.f32 	%f1476, %f1474, %f1470, %p110;
	mul.rn.f32 	%f1478, %f1476, %f1830;
	cvt.rzi.f32.f32 	%f1479, %f1478;
	abs.f32 	%f1480, %f1479;
	setp.gt.f32 	%p111, %f1480, 0f42FC0000;
	mov.b32 	%r390, %f1479;
	and.b32  	%r391, %r390, -2147483648;
	or.b32  	%r392, %r391, 1123811328;
	mov.b32 	%f1481, %r392;
	selp.f32 	%f1482, %f1481, %f1479, %p111;
	fma.rn.f32 	%f1484, %f1482, %f1831, %f1476;
	fma.rn.f32 	%f1486, %f1482, %f1832, %f1484;
	mul.f32 	%f1487, %f1486, 0f3FB8AA3B;
	add.f32 	%f1488, %f1482, 0f4B40007F;
	mov.b32 	%r393, %f1488;
	shl.b32 	%r394, %r393, 23;
	mov.b32 	%f1489, %r394;
	ex2.approx.ftz.f32 	%f1490, %f1487;
	mul.f32 	%f417, %f1490, %f1489;
	setp.eq.f32 	%p112, %f417, 0f7F800000;
	mov.f32 	%f2075, 0f7F800000;
	@%p112 bra 	$L__BB13_103;

	fma.rn.f32 	%f2075, %f417, %f416, %f417;

$L__BB13_103:
	setp.lt.f32 	%p113, %f348, 0f00000000;
	and.pred  	%p6, %p113, %p39;
	setp.eq.f32 	%p115, %f348, 0f00000000;
	@%p115 bra 	$L__BB13_107;
	bra.uni 	$L__BB13_104;

$L__BB13_107:
	add.f32 	%f1845, %f348, %f348;
	selp.f32 	%f2077, %f1845, 0f00000000, %p39;
	bra.uni 	$L__BB13_108;

$L__BB13_104:
	mov.b32 	%r395, %f2075;
	xor.b32  	%r396, %r395, -2147483648;
	mov.b32 	%f1491, %r396;
	selp.f32 	%f2077, %f1491, %f2075, %p6;
	setp.geu.f32 	%p116, %f348, 0f00000000;
	@%p116 bra 	$L__BB13_108;

	mov.f32 	%f1844, 0f40000000;
	cvt.rzi.f32.f32 	%f1493, %f1844;
	setp.eq.f32 	%p117, %f1493, 0f40000000;
	@%p117 bra 	$L__BB13_108;

	mov.f32 	%f2077, 0f7FFFFFFF;

$L__BB13_108:
	abs.f32 	%f1850, %f348;
	add.f32 	%f1496, %f1850, 0f40000000;
	mov.b32 	%r14, %f1496;
	setp.lt.s32 	%p119, %r14, 2139095040;
	@%p119 bra 	$L__BB13_113;

	abs.f32 	%f1853, %f348;
	setp.gtu.f32 	%p120, %f1853, 0f7F800000;
	@%p120 bra 	$L__BB13_112;
	bra.uni 	$L__BB13_110;

$L__BB13_112:
	add.f32 	%f2077, %f348, 0f40000000;
	bra.uni 	$L__BB13_113;

$L__BB13_110:
	abs.f32 	%f1854, %f348;
	setp.neu.f32 	%p121, %f1854, 0f7F800000;
	@%p121 bra 	$L__BB13_113;

	selp.f32 	%f2077, 0fFF800000, 0f7F800000, %p6;

$L__BB13_113:
	add.f32 	%f1852, %f2000, %f2000;
	mul.f32 	%f1851, %f348, %f1852;
	mov.f32 	%f1843, 0f3102E308;
	mov.f32 	%f1842, 0fBF317218;
	mov.f32 	%f1841, 0f3FB8AA3B;
	mov.f32 	%f1840, 0f00000000;
	mov.f32 	%f1839, 0f35BFBE8E;
	mov.f32 	%f1838, 0f3F317200;
	mov.f32 	%f1837, 0f3DAAAABD;
	mov.f32 	%f1836, 0f3C4CAF63;
	mov.f32 	%f1835, 0f3B18F0FE;
	mov.f32 	%f1834, 0f40000000;
	setp.eq.f32 	%p122, %f348, 0f3F800000;
	selp.f32 	%f1498, 0f3F800000, %f2077, %p122;
	sub.f32 	%f1499, %f413, %f1851;
	add.f32 	%f426, %f1499, %f1498;
	abs.f32 	%f427, %f346;
	setp.lt.f32 	%p123, %f427, 0f00800000;
	mul.f32 	%f1500, %f427, 0f4B800000;
	selp.f32 	%f1501, %f1500, %f427, %p123;
	selp.f32 	%f1502, 0fC3170000, 0fC2FE0000, %p123;
	mov.b32 	%r397, %f1501;
	and.b32  	%r398, %r397, 8388607;
	or.b32  	%r399, %r398, 1065353216;
	mov.b32 	%f1503, %r399;
	shr.u32 	%r400, %r397, 23;
	cvt.rn.f32.u32 	%f1504, %r400;
	add.f32 	%f1505, %f1502, %f1504;
	setp.gt.f32 	%p124, %f1503, 0f3FB504F3;
	mul.f32 	%f1506, %f1503, 0f3F000000;
	add.f32 	%f1507, %f1505, 0f3F800000;
	selp.f32 	%f1508, %f1507, %f1505, %p124;
	selp.f32 	%f1509, %f1506, %f1503, %p124;
	add.f32 	%f1510, %f1509, 0fBF800000;
	add.f32 	%f1511, %f1509, 0f3F800000;
	rcp.approx.ftz.f32 	%f1512, %f1511;
	add.f32 	%f1513, %f1510, %f1510;
	mul.f32 	%f1515, %f1513, %f1512;
	mul.f32 	%f1516, %f1515, %f1515;
	fma.rn.f32 	%f1519, %f1835, %f1516, %f1836;
	fma.rn.f32 	%f1521, %f1519, %f1516, %f1837;
	mul.rn.f32 	%f1522, %f1521, %f1516;
	mul.rn.f32 	%f1523, %f1522, %f1515;
	sub.f32 	%f1524, %f1510, %f1515;
	add.f32 	%f1525, %f1524, %f1524;
	neg.f32 	%f1526, %f1515;
	fma.rn.f32 	%f1527, %f1526, %f1510, %f1525;
	mul.rn.f32 	%f1528, %f1512, %f1527;
	add.f32 	%f1529, %f1523, %f1515;
	sub.f32 	%f1530, %f1515, %f1529;
	add.f32 	%f1531, %f1523, %f1530;
	add.f32 	%f1532, %f1528, %f1531;
	add.f32 	%f1533, %f1529, %f1532;
	sub.f32 	%f1534, %f1529, %f1533;
	add.f32 	%f1535, %f1532, %f1534;
	mul.rn.f32 	%f1537, %f1508, %f1838;
	mul.rn.f32 	%f1539, %f1508, %f1839;
	add.f32 	%f1540, %f1537, %f1533;
	sub.f32 	%f1541, %f1537, %f1540;
	add.f32 	%f1542, %f1533, %f1541;
	add.f32 	%f1543, %f1535, %f1542;
	add.f32 	%f1544, %f1539, %f1543;
	add.f32 	%f1545, %f1540, %f1544;
	sub.f32 	%f1546, %f1540, %f1545;
	add.f32 	%f1547, %f1544, %f1546;
	mul.rn.f32 	%f1548, %f1834, %f1545;
	neg.f32 	%f1549, %f1548;
	fma.rn.f32 	%f1550, %f1834, %f1545, %f1549;
	fma.rn.f32 	%f1551, %f1834, %f1547, %f1550;
	fma.rn.f32 	%f1553, %f1840, %f1545, %f1551;
	add.rn.f32 	%f1554, %f1548, %f1553;
	neg.f32 	%f1555, %f1554;
	add.rn.f32 	%f1556, %f1548, %f1555;
	add.rn.f32 	%f1557, %f1556, %f1553;
	mov.b32 	%r401, %f1554;
	setp.eq.s32 	%p125, %r401, 1118925336;
	add.s32 	%r402, %r401, -1;
	mov.b32 	%f1558, %r402;
	add.f32 	%f1559, %f1557, 0f37000000;
	selp.f32 	%f428, %f1559, %f1557, %p125;
	selp.f32 	%f1560, %f1558, %f1554, %p125;
	mul.rn.f32 	%f1562, %f1560, %f1841;
	cvt.rzi.f32.f32 	%f1563, %f1562;
	abs.f32 	%f1564, %f1563;
	setp.gt.f32 	%p126, %f1564, 0f42FC0000;
	mov.b32 	%r403, %f1563;
	and.b32  	%r404, %r403, -2147483648;
	or.b32  	%r405, %r404, 1123811328;
	mov.b32 	%f1565, %r405;
	selp.f32 	%f1566, %f1565, %f1563, %p126;
	fma.rn.f32 	%f1568, %f1566, %f1842, %f1560;
	fma.rn.f32 	%f1570, %f1566, %f1843, %f1568;
	mul.f32 	%f1571, %f1570, 0f3FB8AA3B;
	add.f32 	%f1572, %f1566, 0f4B40007F;
	mov.b32 	%r406, %f1572;
	shl.b32 	%r407, %r406, 23;
	mov.b32 	%f1573, %r407;
	ex2.approx.ftz.f32 	%f1574, %f1571;
	mul.f32 	%f429, %f1574, %f1573;
	setp.eq.f32 	%p127, %f429, 0f7F800000;
	mov.f32 	%f2078, 0f7F800000;
	@%p127 bra 	$L__BB13_115;

	fma.rn.f32 	%f2078, %f429, %f428, %f429;

$L__BB13_115:
	setp.lt.f32 	%p128, %f346, 0f00000000;
	and.pred  	%p7, %p128, %p39;
	setp.eq.f32 	%p130, %f346, 0f00000000;
	@%p130 bra 	$L__BB13_119;
	bra.uni 	$L__BB13_116;

$L__BB13_119:
	add.f32 	%f1579, %f346, %f346;
	selp.f32 	%f2080, %f1579, 0f00000000, %p39;
	bra.uni 	$L__BB13_120;

$L__BB13_116:
	mov.b32 	%r408, %f2078;
	xor.b32  	%r409, %r408, -2147483648;
	mov.b32 	%f1575, %r409;
	selp.f32 	%f2080, %f1575, %f2078, %p7;
	setp.geu.f32 	%p131, %f346, 0f00000000;
	@%p131 bra 	$L__BB13_120;

	mov.f32 	%f1821, 0f40000000;
	cvt.rzi.f32.f32 	%f1577, %f1821;
	setp.eq.f32 	%p132, %f1577, 0f40000000;
	@%p132 bra 	$L__BB13_120;

	mov.f32 	%f2080, 0f7FFFFFFF;

$L__BB13_120:
	abs.f32 	%f1769, %f346;
	add.f32 	%f1580, %f1769, 0f40000000;
	mov.b32 	%r410, %f1580;
	setp.lt.s32 	%p134, %r410, 2139095040;
	@%p134 bra 	$L__BB13_125;

	abs.f32 	%f1819, %f346;
	setp.gtu.f32 	%p135, %f1819, 0f7F800000;
	@%p135 bra 	$L__BB13_124;
	bra.uni 	$L__BB13_122;

$L__BB13_124:
	add.f32 	%f2080, %f346, 0f40000000;
	bra.uni 	$L__BB13_125;

$L__BB13_122:
	abs.f32 	%f1820, %f346;
	setp.neu.f32 	%p136, %f1820, 0f7F800000;
	@%p136 bra 	$L__BB13_125;

	selp.f32 	%f2080, 0fFF800000, 0f7F800000, %p7;

$L__BB13_125:
	setp.eq.f32 	%p138, %f346, 0f3F800000;
	selp.f32 	%f1582, 0f3F800000, %f2080, %p138;
	sub.f32 	%f438, %f426, %f1582;
	setp.eq.f32 	%p139, %f375, 0f00000000;
	setp.eq.f32 	%p140, %f372, 0f00000000;
	and.pred  	%p141, %p139, %p140;
	mov.pred 	%p316, 0;
	@%p141 bra 	$L__BB13_128;

	neg.f32 	%f1583, %f438;
	div.rn.f32 	%f2081, %f1583, %f375;
	mul.f32 	%f1584, %f372, 0fC0800000;
	mul.f32 	%f1585, %f1584, %f438;
	fma.rn.f32 	%f440, %f375, %f375, %f1585;
	setp.neu.f32 	%p143, %f372, 0f00000000;
	setp.lt.f32 	%p144, %f440, 0f00000000;
	and.pred  	%p145, %p144, %p143;
	mov.f32 	%f2082, %f2081;
	@%p145 bra 	$L__BB13_128;

	mov.b32 	%r411, %f375;
	and.b32  	%r412, %r411, -2147483648;
	sqrt.rn.f32 	%f1586, %f440;
	mov.b32 	%r413, %f1586;
	and.b32  	%r414, %r413, 2147483647;
	or.b32  	%r415, %r414, %r412;
	mov.b32 	%f1587, %r415;
	add.f32 	%f1588, %f375, %f1587;
	mul.f32 	%f1589, %f1588, 0fBF000000;
	div.rn.f32 	%f1590, %f1589, %f372;
	div.rn.f32 	%f1591, %f438, %f1589;
	min.f32 	%f1592, %f1590, %f1591;
	max.f32 	%f1593, %f1590, %f1591;
	selp.f32 	%f2082, %f2081, %f1592, %p140;
	selp.f32 	%f2081, %f2081, %f1593, %p140;
	mov.pred 	%p316, -1;

$L__BB13_128:
	ld.v2.f32 	{%f1594, %f1595}, [%rd16+16];
	setp.lt.f32 	%p148, %f2082, %f986;
	setp.gt.f32 	%p149, %f2082, %f985;
	and.pred  	%p150, %p149, %p148;
	and.pred  	%p151, %p316, %p150;
	mov.u16 	%rs9, 0;
	not.pred 	%p152, %p151;
	@%p152 bra 	$L__BB13_131;

	fma.rn.f32 	%f447, %f2082, %f2059, %f2001;
	setp.ltu.f32 	%p153, %f447, %f1594;
	@%p153 bra 	$L__BB13_131;

	setp.lt.f32 	%p154, %f447, %f1595;
	selp.u16 	%rs9, 1, 0, %p154;

$L__BB13_131:
	setp.lt.f32 	%p156, %f2081, %f986;
	setp.gt.f32 	%p157, %f2081, %f985;
	and.pred  	%p158, %p157, %p156;
	and.pred  	%p159, %p158, %p316;
	mov.pred 	%p317, 0;
	not.pred 	%p160, %p159;
	@%p160 bra 	$L__BB13_134;

	fma.rn.f32 	%f448, %f2081, %f2059, %f2001;
	setp.ltu.f32 	%p162, %f448, %f1594;
	@%p162 bra 	$L__BB13_134;

	setp.lt.f32 	%p317, %f448, %f1595;

$L__BB13_134:
	setp.eq.f32 	%p276, %f352, 0f7F800000;
	selp.f32 	%f1597, %f2081, 0f7F800000, %p317;
	mov.f32 	%f2083, 0f7F800000;
	setp.eq.s16 	%p163, %rs9, 0;
	selp.f32 	%f449, %f1597, %f2082, %p163;
	ld.f32 	%f450, [%rd16+4];
	@%p276 bra 	$L__BB13_136;

	fma.rn.f32 	%f2083, %f352, %f351, %f352;

$L__BB13_136:
	setp.eq.f32 	%p277, %f2057, 0f00000000;
	@%p277 bra 	$L__BB13_140;
	bra.uni 	$L__BB13_137;

$L__BB13_140:
	add.f32 	%f1602, %f2057, %f2057;
	selp.f32 	%f2085, %f1602, 0f00000000, %p39;
	bra.uni 	$L__BB13_141;

$L__BB13_137:
	mov.b32 	%r416, %f2083;
	xor.b32  	%r417, %r416, -2147483648;
	mov.b32 	%f1598, %r417;
	selp.f32 	%f2085, %f1598, %f2083, %p1;
	setp.geu.f32 	%p166, %f2057, 0f00000000;
	@%p166 bra 	$L__BB13_141;

	mov.f32 	%f1818, 0f40000000;
	cvt.rzi.f32.f32 	%f1600, %f1818;
	setp.eq.f32 	%p167, %f1600, 0f40000000;
	@%p167 bra 	$L__BB13_141;

	mov.f32 	%f2085, 0f7FFFFFFF;

$L__BB13_141:
	abs.f32 	%f1771, %f2057;
	add.f32 	%f1770, %f1771, 0f40000000;
	mov.b32 	%r449, %f1770;
	setp.lt.s32 	%p278, %r449, 2139095040;
	@%p278 bra 	$L__BB13_146;

	abs.f32 	%f1816, %f2057;
	setp.gtu.f32 	%p170, %f1816, 0f7F800000;
	@%p170 bra 	$L__BB13_145;
	bra.uni 	$L__BB13_143;

$L__BB13_145:
	add.f32 	%f2085, %f2057, 0f40000000;
	bra.uni 	$L__BB13_146;

$L__BB13_143:
	abs.f32 	%f1817, %f2057;
	setp.neu.f32 	%p171, %f1817, 0f7F800000;
	@%p171 bra 	$L__BB13_146;

	selp.f32 	%f2085, 0fFF800000, 0f7F800000, %p1;

$L__BB13_146:
	setp.eq.f32 	%p279, %f363, 0f7F800000;
	mov.f32 	%f2086, 0f7F800000;
	@%p279 bra 	$L__BB13_148;

	fma.rn.f32 	%f2086, %f363, %f362, %f363;

$L__BB13_148:
	setp.eq.f32 	%p280, %f2058, 0f00000000;
	@%p280 bra 	$L__BB13_152;
	bra.uni 	$L__BB13_149;

$L__BB13_152:
	add.f32 	%f1608, %f2058, %f2058;
	selp.f32 	%f2088, %f1608, 0f00000000, %p39;
	bra.uni 	$L__BB13_153;

$L__BB13_149:
	setp.lt.f32 	%p301, %f2058, 0f00000000;
	and.pred  	%p300, %p301, %p39;
	mov.b32 	%r418, %f2086;
	xor.b32  	%r419, %r418, -2147483648;
	mov.b32 	%f1604, %r419;
	selp.f32 	%f2088, %f1604, %f2086, %p300;
	setp.geu.f32 	%p174, %f2058, 0f00000000;
	@%p174 bra 	$L__BB13_153;

	mov.f32 	%f1815, 0f40000000;
	cvt.rzi.f32.f32 	%f1606, %f1815;
	setp.eq.f32 	%p175, %f1606, 0f40000000;
	@%p175 bra 	$L__BB13_153;

	mov.f32 	%f2088, 0f7FFFFFFF;

$L__BB13_153:
	abs.f32 	%f1773, %f2058;
	add.f32 	%f1772, %f1773, 0f40000000;
	mov.b32 	%r450, %f1772;
	setp.lt.s32 	%p281, %r450, 2139095040;
	@%p281 bra 	$L__BB13_158;

	abs.f32 	%f1813, %f2058;
	setp.gtu.f32 	%p178, %f1813, 0f7F800000;
	@%p178 bra 	$L__BB13_157;
	bra.uni 	$L__BB13_155;

$L__BB13_157:
	add.f32 	%f2088, %f2058, 0f40000000;
	bra.uni 	$L__BB13_158;

$L__BB13_155:
	abs.f32 	%f1814, %f2058;
	setp.neu.f32 	%p179, %f1814, 0f7F800000;
	@%p179 bra 	$L__BB13_158;

	setp.lt.f32 	%p311, %f2058, 0f00000000;
	and.pred  	%p310, %p311, %p39;
	selp.f32 	%f2088, 0fFF800000, 0f7F800000, %p310;

$L__BB13_158:
	setp.eq.f32 	%p284, %f378, 0f7F800000;
	setp.eq.f32 	%p283, %f2057, 0f3F800000;
	setp.eq.f32 	%p282, %f2058, 0f3F800000;
	selp.f32 	%f1610, 0f3F800000, %f2088, %p282;
	selp.f32 	%f1611, 0f3F800000, %f2085, %p283;
	add.f32 	%f467, %f1611, %f1610;
	mov.f32 	%f2089, 0f7F800000;
	@%p284 bra 	$L__BB13_160;

	fma.rn.f32 	%f2089, %f378, %f377, %f378;

$L__BB13_160:
	setp.eq.f32 	%p285, %f1999, 0f00000000;
	@%p285 bra 	$L__BB13_164;
	bra.uni 	$L__BB13_161;

$L__BB13_164:
	add.f32 	%f1812, %f1999, %f1999;
	selp.f32 	%f2091, %f1812, 0f00000000, %p39;
	bra.uni 	$L__BB13_165;

$L__BB13_161:
	setp.lt.f32 	%p303, %f1999, 0f00000000;
	and.pred  	%p302, %p303, %p39;
	mov.b32 	%r420, %f2089;
	xor.b32  	%r421, %r420, -2147483648;
	mov.b32 	%f1612, %r421;
	selp.f32 	%f2091, %f1612, %f2089, %p302;
	setp.geu.f32 	%p184, %f1999, 0f00000000;
	@%p184 bra 	$L__BB13_165;

	mov.f32 	%f1811, 0f40000000;
	cvt.rzi.f32.f32 	%f1614, %f1811;
	setp.eq.f32 	%p185, %f1614, 0f40000000;
	@%p185 bra 	$L__BB13_165;

	mov.f32 	%f2091, 0f7FFFFFFF;

$L__BB13_165:
	abs.f32 	%f1775, %f1999;
	add.f32 	%f1774, %f1775, 0f40000000;
	mov.b32 	%r451, %f1774;
	setp.lt.s32 	%p286, %r451, 2139095040;
	@%p286 bra 	$L__BB13_170;

	abs.f32 	%f1809, %f1999;
	setp.gtu.f32 	%p188, %f1809, 0f7F800000;
	@%p188 bra 	$L__BB13_169;
	bra.uni 	$L__BB13_167;

$L__BB13_169:
	add.f32 	%f2091, %f1999, 0f40000000;
	bra.uni 	$L__BB13_170;

$L__BB13_167:
	abs.f32 	%f1810, %f1999;
	setp.neu.f32 	%p189, %f1810, 0f7F800000;
	@%p189 bra 	$L__BB13_170;

	setp.lt.f32 	%p309, %f1999, 0f00000000;
	and.pred  	%p308, %p309, %p39;
	selp.f32 	%f2091, 0fFF800000, 0f7F800000, %p308;

$L__BB13_170:
	setp.eq.f32 	%p288, %f390, 0f7F800000;
	setp.eq.f32 	%p287, %f1999, 0f3F800000;
	add.f32 	%f1777, %f1999, %f1999;
	mul.f32 	%f1776, %f347, %f1777;
	selp.f32 	%f1618, 0f3F800000, %f2091, %p287;
	sub.f32 	%f476, %f1618, %f1776;
	mov.f32 	%f2092, 0f7F800000;
	@%p288 bra 	$L__BB13_172;

	fma.rn.f32 	%f2092, %f390, %f389, %f390;

$L__BB13_172:
	setp.eq.f32 	%p289, %f347, 0f00000000;
	@%p289 bra 	$L__BB13_176;
	bra.uni 	$L__BB13_173;

$L__BB13_176:
	add.f32 	%f1808, %f347, %f347;
	selp.f32 	%f2094, %f1808, 0f00000000, %p39;
	bra.uni 	$L__BB13_177;

$L__BB13_173:
	setp.lt.f32 	%p305, %f347, 0f00000000;
	and.pred  	%p304, %p305, %p39;
	mov.b32 	%r422, %f2092;
	xor.b32  	%r423, %r422, -2147483648;
	mov.b32 	%f1619, %r423;
	selp.f32 	%f2094, %f1619, %f2092, %p304;
	setp.geu.f32 	%p193, %f347, 0f00000000;
	@%p193 bra 	$L__BB13_177;

	mov.f32 	%f1807, 0f40000000;
	cvt.rzi.f32.f32 	%f1621, %f1807;
	setp.eq.f32 	%p194, %f1621, 0f40000000;
	@%p194 bra 	$L__BB13_177;

	mov.f32 	%f2094, 0f7FFFFFFF;

$L__BB13_177:
	abs.f32 	%f1779, %f347;
	add.f32 	%f1778, %f1779, 0f40000000;
	mov.b32 	%r452, %f1778;
	setp.lt.s32 	%p290, %r452, 2139095040;
	@%p290 bra 	$L__BB13_182;

	abs.f32 	%f1805, %f347;
	setp.gtu.f32 	%p197, %f1805, 0f7F800000;
	@%p197 bra 	$L__BB13_181;
	bra.uni 	$L__BB13_179;

$L__BB13_181:
	add.f32 	%f2094, %f347, 0f40000000;
	bra.uni 	$L__BB13_182;

$L__BB13_179:
	abs.f32 	%f1806, %f347;
	setp.neu.f32 	%p198, %f1806, 0f7F800000;
	@%p198 bra 	$L__BB13_182;

	setp.lt.f32 	%p307, %f347, 0f00000000;
	and.pred  	%p306, %p307, %p39;
	selp.f32 	%f2094, 0fFF800000, 0f7F800000, %p306;

$L__BB13_182:
	setp.eq.f32 	%p292, %f404, 0f7F800000;
	setp.eq.f32 	%p291, %f347, 0f3F800000;
	selp.f32 	%f1625, 0f3F800000, %f2094, %p291;
	add.f32 	%f485, %f476, %f1625;
	mov.f32 	%f2095, 0f7F800000;
	@%p292 bra 	$L__BB13_184;

	fma.rn.f32 	%f2095, %f404, %f403, %f404;

$L__BB13_184:
	setp.eq.f32 	%p293, %f2000, 0f00000000;
	@%p293 bra 	$L__BB13_188;
	bra.uni 	$L__BB13_185;

$L__BB13_188:
	add.f32 	%f1804, %f2000, %f2000;
	selp.f32 	%f2097, %f1804, 0f00000000, %p39;
	bra.uni 	$L__BB13_189;

$L__BB13_185:
	setp.lt.f32 	%p313, %f2000, 0f00000000;
	and.pred  	%p312, %p313, %p39;
	mov.b32 	%r424, %f2095;
	xor.b32  	%r425, %r424, -2147483648;
	mov.b32 	%f1626, %r425;
	selp.f32 	%f2097, %f1626, %f2095, %p312;
	setp.geu.f32 	%p202, %f2000, 0f00000000;
	@%p202 bra 	$L__BB13_189;

	mov.f32 	%f1803, 0f40000000;
	cvt.rzi.f32.f32 	%f1628, %f1803;
	setp.eq.f32 	%p203, %f1628, 0f40000000;
	@%p203 bra 	$L__BB13_189;

	mov.f32 	%f2097, 0f7FFFFFFF;

$L__BB13_189:
	abs.f32 	%f1781, %f2000;
	add.f32 	%f1780, %f1781, 0f40000000;
	mov.b32 	%r453, %f1780;
	setp.lt.s32 	%p294, %r453, 2139095040;
	@%p294 bra 	$L__BB13_194;

	abs.f32 	%f1801, %f2000;
	setp.gtu.f32 	%p206, %f1801, 0f7F800000;
	@%p206 bra 	$L__BB13_193;
	bra.uni 	$L__BB13_191;

$L__BB13_193:
	add.f32 	%f2097, %f2000, 0f40000000;
	bra.uni 	$L__BB13_194;

$L__BB13_191:
	abs.f32 	%f1802, %f2000;
	setp.neu.f32 	%p207, %f1802, 0f7F800000;
	@%p207 bra 	$L__BB13_194;

	setp.lt.f32 	%p315, %f2000, 0f00000000;
	and.pred  	%p314, %p315, %p39;
	selp.f32 	%f2097, 0fFF800000, 0f7F800000, %p314;

$L__BB13_194:
	setp.eq.f32 	%p296, %f417, 0f7F800000;
	setp.eq.f32 	%p295, %f2000, 0f3F800000;
	add.f32 	%f1783, %f2000, %f2000;
	mul.f32 	%f1782, %f348, %f1783;
	selp.f32 	%f1632, 0f3F800000, %f2097, %p295;
	add.f32 	%f1633, %f485, %f1632;
	sub.f32 	%f494, %f1633, %f1782;
	mov.f32 	%f2098, 0f7F800000;
	@%p296 bra 	$L__BB13_196;

	fma.rn.f32 	%f2098, %f417, %f416, %f417;

$L__BB13_196:
	setp.eq.f32 	%p297, %f348, 0f00000000;
	@%p297 bra 	$L__BB13_200;
	bra.uni 	$L__BB13_197;

$L__BB13_200:
	add.f32 	%f1800, %f348, %f348;
	selp.f32 	%f2100, %f1800, 0f00000000, %p39;
	bra.uni 	$L__BB13_201;

$L__BB13_197:
	mov.b32 	%r426, %f2098;
	xor.b32  	%r427, %r426, -2147483648;
	mov.b32 	%f1634, %r427;
	selp.f32 	%f2100, %f1634, %f2098, %p6;
	setp.geu.f32 	%p211, %f348, 0f00000000;
	@%p211 bra 	$L__BB13_201;

	mov.f32 	%f1799, 0f40000000;
	cvt.rzi.f32.f32 	%f1636, %f1799;
	setp.eq.f32 	%p212, %f1636, 0f40000000;
	@%p212 bra 	$L__BB13_201;

	mov.f32 	%f2100, 0f7FFFFFFF;

$L__BB13_201:
	abs.f32 	%f1785, %f348;
	add.f32 	%f1784, %f1785, 0f40000000;
	mov.b32 	%r454, %f1784;
	setp.lt.s32 	%p298, %r454, 2139095040;
	@%p298 bra 	$L__BB13_206;

	abs.f32 	%f1797, %f348;
	setp.gtu.f32 	%p215, %f1797, 0f7F800000;
	@%p215 bra 	$L__BB13_205;
	bra.uni 	$L__BB13_203;

$L__BB13_205:
	add.f32 	%f2100, %f348, 0f40000000;
	bra.uni 	$L__BB13_206;

$L__BB13_203:
	abs.f32 	%f1798, %f348;
	setp.neu.f32 	%p216, %f1798, 0f7F800000;
	@%p216 bra 	$L__BB13_206;

	selp.f32 	%f2100, 0fFF800000, 0f7F800000, %p6;

$L__BB13_206:
	setp.eq.f32 	%p299, %f348, 0f3F800000;
	mov.f32 	%f1795, 0f3102E308;
	mov.f32 	%f1794, 0fBF317218;
	mov.f32 	%f1793, 0f3FB8AA3B;
	mov.f32 	%f1792, 0f00000000;
	mov.f32 	%f1791, 0f35BFBE8E;
	mov.f32 	%f1790, 0f3F317200;
	mov.f32 	%f1789, 0f3DAAAABD;
	mov.f32 	%f1788, 0f3C4CAF63;
	mov.f32 	%f1787, 0f3B18F0FE;
	mov.f32 	%f1786, 0f40000000;
	selp.f32 	%f1640, 0f3F800000, %f2100, %p299;
	add.f32 	%f503, %f494, %f1640;
	abs.f32 	%f504, %f450;
	setp.lt.f32 	%p218, %f504, 0f00800000;
	mul.f32 	%f1641, %f504, 0f4B800000;
	selp.f32 	%f1642, %f1641, %f504, %p218;
	selp.f32 	%f1643, 0fC3170000, 0fC2FE0000, %p218;
	mov.b32 	%r428, %f1642;
	and.b32  	%r429, %r428, 8388607;
	or.b32  	%r430, %r429, 1065353216;
	mov.b32 	%f1644, %r430;
	shr.u32 	%r431, %r428, 23;
	cvt.rn.f32.u32 	%f1645, %r431;
	add.f32 	%f1646, %f1643, %f1645;
	setp.gt.f32 	%p219, %f1644, 0f3FB504F3;
	mul.f32 	%f1647, %f1644, 0f3F000000;
	add.f32 	%f1648, %f1646, 0f3F800000;
	selp.f32 	%f1649, %f1648, %f1646, %p219;
	selp.f32 	%f1650, %f1647, %f1644, %p219;
	add.f32 	%f1651, %f1650, 0fBF800000;
	add.f32 	%f1652, %f1650, 0f3F800000;
	rcp.approx.ftz.f32 	%f1653, %f1652;
	add.f32 	%f1654, %f1651, %f1651;
	mul.f32 	%f1656, %f1654, %f1653;
	mul.f32 	%f1657, %f1656, %f1656;
	fma.rn.f32 	%f1660, %f1787, %f1657, %f1788;
	fma.rn.f32 	%f1662, %f1660, %f1657, %f1789;
	mul.rn.f32 	%f1663, %f1662, %f1657;
	mul.rn.f32 	%f1664, %f1663, %f1656;
	sub.f32 	%f1665, %f1651, %f1656;
	add.f32 	%f1666, %f1665, %f1665;
	neg.f32 	%f1667, %f1656;
	fma.rn.f32 	%f1668, %f1667, %f1651, %f1666;
	mul.rn.f32 	%f1669, %f1653, %f1668;
	add.f32 	%f1670, %f1664, %f1656;
	sub.f32 	%f1671, %f1656, %f1670;
	add.f32 	%f1672, %f1664, %f1671;
	add.f32 	%f1673, %f1669, %f1672;
	add.f32 	%f1674, %f1670, %f1673;
	sub.f32 	%f1675, %f1670, %f1674;
	add.f32 	%f1676, %f1673, %f1675;
	mul.rn.f32 	%f1678, %f1649, %f1790;
	mul.rn.f32 	%f1680, %f1649, %f1791;
	add.f32 	%f1681, %f1678, %f1674;
	sub.f32 	%f1682, %f1678, %f1681;
	add.f32 	%f1683, %f1674, %f1682;
	add.f32 	%f1684, %f1676, %f1683;
	add.f32 	%f1685, %f1680, %f1684;
	add.f32 	%f1686, %f1681, %f1685;
	sub.f32 	%f1687, %f1681, %f1686;
	add.f32 	%f1688, %f1685, %f1687;
	mul.rn.f32 	%f1689, %f1786, %f1686;
	neg.f32 	%f1690, %f1689;
	fma.rn.f32 	%f1691, %f1786, %f1686, %f1690;
	fma.rn.f32 	%f1692, %f1786, %f1688, %f1691;
	fma.rn.f32 	%f1694, %f1792, %f1686, %f1692;
	add.rn.f32 	%f1695, %f1689, %f1694;
	neg.f32 	%f1696, %f1695;
	add.rn.f32 	%f1697, %f1689, %f1696;
	add.rn.f32 	%f1698, %f1697, %f1694;
	mov.b32 	%r432, %f1695;
	setp.eq.s32 	%p220, %r432, 1118925336;
	add.s32 	%r433, %r432, -1;
	mov.b32 	%f1699, %r433;
	add.f32 	%f1700, %f1698, 0f37000000;
	selp.f32 	%f505, %f1700, %f1698, %p220;
	selp.f32 	%f1701, %f1699, %f1695, %p220;
	mul.rn.f32 	%f1703, %f1701, %f1793;
	cvt.rzi.f32.f32 	%f1704, %f1703;
	abs.f32 	%f1705, %f1704;
	setp.gt.f32 	%p221, %f1705, 0f42FC0000;
	mov.b32 	%r434, %f1704;
	and.b32  	%r435, %r434, -2147483648;
	or.b32  	%r436, %r435, 1123811328;
	mov.b32 	%f1706, %r436;
	selp.f32 	%f1707, %f1706, %f1704, %p221;
	fma.rn.f32 	%f1709, %f1707, %f1794, %f1701;
	fma.rn.f32 	%f1711, %f1707, %f1795, %f1709;
	mul.f32 	%f1712, %f1711, 0f3FB8AA3B;
	add.f32 	%f1713, %f1707, 0f4B40007F;
	mov.b32 	%r437, %f1713;
	shl.b32 	%r438, %r437, 23;
	mov.b32 	%f1714, %r438;
	ex2.approx.ftz.f32 	%f1715, %f1712;
	mul.f32 	%f506, %f1715, %f1714;
	setp.eq.f32 	%p222, %f506, 0f7F800000;
	mov.f32 	%f2101, 0f7F800000;
	@%p222 bra 	$L__BB13_208;

	fma.rn.f32 	%f2101, %f506, %f505, %f506;

$L__BB13_208:
	setp.lt.f32 	%p223, %f450, 0f00000000;
	and.pred  	%p11, %p223, %p39;
	setp.eq.f32 	%p225, %f450, 0f00000000;
	@%p225 bra 	$L__BB13_212;
	bra.uni 	$L__BB13_209;

$L__BB13_212:
	add.f32 	%f1720, %f450, %f450;
	selp.f32 	%f2103, %f1720, 0f00000000, %p39;
	bra.uni 	$L__BB13_213;

$L__BB13_209:
	mov.b32 	%r439, %f2101;
	xor.b32  	%r440, %r439, -2147483648;
	mov.b32 	%f1716, %r440;
	selp.f32 	%f2103, %f1716, %f2101, %p11;
	setp.geu.f32 	%p226, %f450, 0f00000000;
	@%p226 bra 	$L__BB13_213;

	mov.f32 	%f1796, 0f40000000;
	cvt.rzi.f32.f32 	%f1718, %f1796;
	setp.eq.f32 	%p227, %f1718, 0f40000000;
	@%p227 bra 	$L__BB13_213;

	mov.f32 	%f2103, 0f7FFFFFFF;

$L__BB13_213:
	add.f32 	%f1721, %f504, 0f40000000;
	mov.b32 	%r441, %f1721;
	setp.lt.s32 	%p229, %r441, 2139095040;
	@%p229 bra 	$L__BB13_218;

	setp.gtu.f32 	%p230, %f504, 0f7F800000;
	@%p230 bra 	$L__BB13_217;
	bra.uni 	$L__BB13_215;

$L__BB13_217:
	add.f32 	%f2103, %f450, 0f40000000;
	bra.uni 	$L__BB13_218;

$L__BB13_215:
	setp.neu.f32 	%p231, %f504, 0f7F800000;
	@%p231 bra 	$L__BB13_218;

	selp.f32 	%f2103, 0fFF800000, 0f7F800000, %p11;

$L__BB13_218:
	setp.eq.f32 	%p233, %f450, 0f3F800000;
	selp.f32 	%f1723, 0f3F800000, %f2103, %p233;
	sub.f32 	%f515, %f503, %f1723;
	setp.eq.f32 	%p234, %f467, 0f00000000;
	and.pred  	%p236, %p139, %p234;
	mov.pred 	%p318, 0;
	@%p236 bra 	$L__BB13_221;

	neg.f32 	%f1724, %f515;
	div.rn.f32 	%f2104, %f1724, %f375;
	mul.f32 	%f1725, %f467, 0fC0800000;
	mul.f32 	%f1726, %f1725, %f515;
	fma.rn.f32 	%f517, %f375, %f375, %f1726;
	setp.neu.f32 	%p238, %f467, 0f00000000;
	setp.lt.f32 	%p239, %f517, 0f00000000;
	and.pred  	%p240, %p239, %p238;
	mov.f32 	%f2105, %f2104;
	@%p240 bra 	$L__BB13_221;

	mov.b32 	%r442, %f375;
	and.b32  	%r443, %r442, -2147483648;
	sqrt.rn.f32 	%f1727, %f517;
	mov.b32 	%r444, %f1727;
	and.b32  	%r445, %r444, 2147483647;
	or.b32  	%r446, %r445, %r443;
	mov.b32 	%f1728, %r446;
	add.f32 	%f1729, %f375, %f1728;
	mul.f32 	%f1730, %f1729, 0fBF000000;
	div.rn.f32 	%f1731, %f1730, %f467;
	div.rn.f32 	%f1732, %f515, %f1730;
	min.f32 	%f1733, %f1731, %f1732;
	max.f32 	%f1734, %f1731, %f1732;
	selp.f32 	%f2105, %f2104, %f1733, %p234;
	selp.f32 	%f2104, %f2104, %f1734, %p234;
	mov.pred 	%p318, -1;

$L__BB13_221:
	setp.lt.f32 	%p243, %f2105, %f986;
	setp.gt.f32 	%p244, %f2105, %f985;
	and.pred  	%p245, %p244, %p243;
	and.pred  	%p246, %p318, %p245;
	mov.u16 	%rs10, 0;
	not.pred 	%p247, %p246;
	@%p247 bra 	$L__BB13_224;

	fma.rn.f32 	%f522, %f2105, %f2059, %f2001;
	setp.ltu.f32 	%p248, %f522, %f1594;
	@%p248 bra 	$L__BB13_224;

	setp.lt.f32 	%p249, %f522, %f1595;
	selp.u16 	%rs10, 1, 0, %p249;

$L__BB13_224:
	setp.lt.f32 	%p250, %f2104, %f986;
	setp.gt.f32 	%p251, %f2104, %f985;
	and.pred  	%p252, %p251, %p250;
	and.pred  	%p253, %p252, %p318;
	not.pred 	%p254, %p253;
	mov.f32 	%f2108, 0f7F800000;
	mov.f32 	%f2106, %f2108;
	@%p254 bra 	$L__BB13_227;

	fma.rn.f32 	%f523, %f2104, %f2059, %f2001;
	setp.ltu.f32 	%p255, %f523, %f1594;
	@%p255 bra 	$L__BB13_227;

	setp.lt.f32 	%p256, %f523, %f1595;
	selp.f32 	%f2106, %f2104, 0f7F800000, %p256;

$L__BB13_227:
	add.f32 	%f526, %f347, 0f00000000;
	add.f32 	%f527, %f348, 0f00000000;
	ld.f32 	%f528, [%rd16+-8];
	add.f32 	%f529, %f528, 0f00000000;
	setp.eq.s16 	%p257, %rs10, 0;
	selp.f32 	%f530, %f2106, %f2105, %p257;
	setp.eq.f32 	%p258, %f2059, 0f00000000;
	mov.f32 	%f2107, %f2108;
	@%p258 bra 	$L__BB13_229;

	sub.f32 	%f1738, %f529, %f2001;
	div.rn.f32 	%f2107, %f1738, %f2059;

$L__BB13_229:
	setp.gtu.f32 	%p259, %f2107, %f986;
	setp.ltu.f32 	%p260, %f2107, %f985;
	or.pred  	%p261, %p259, %p260;
	selp.f32 	%f1740, 0f7F800000, %f2107, %p261;
	fma.rn.f32 	%f1741, %f1740, %f2057, %f1999;
	fma.rn.f32 	%f1742, %f1740, %f2058, %f2000;
	fma.rn.f32 	%f1743, %f1740, %f2059, %f2001;
	sub.f32 	%f1744, %f526, %f1741;
	sub.f32 	%f1745, %f527, %f1742;
	sub.f32 	%f1746, %f529, %f1743;
	mul.f32 	%f1747, %f1744, %f1744;
	fma.rn.f32 	%f1748, %f1745, %f1745, %f1747;
	fma.rn.f32 	%f1749, %f1746, %f1746, %f1748;
	sqrt.rn.f32 	%f1750, %f1749;
	setp.ge.f32 	%p262, %f1750, %f346;
	setp.le.f32 	%p263, %f1750, %f450;
	and.pred  	%p264, %p263, %p262;
	selp.f32 	%f533, %f1740, 0f7F800000, %p264;
	ld.f32 	%f1751, [%rd16+12];
	add.f32 	%f534, %f528, %f1751;
	@%p258 bra 	$L__BB13_231;

	sub.f32 	%f1752, %f534, %f2001;
	div.rn.f32 	%f2108, %f1752, %f2059;

$L__BB13_231:
	setp.gtu.f32 	%p266, %f2108, %f986;
	setp.ltu.f32 	%p267, %f2108, %f985;
	or.pred  	%p268, %p266, %p267;
	selp.f32 	%f1753, 0f7F800000, %f2108, %p268;
	fma.rn.f32 	%f1754, %f1753, %f2057, %f1999;
	fma.rn.f32 	%f1755, %f1753, %f2058, %f2000;
	fma.rn.f32 	%f1756, %f1753, %f2059, %f2001;
	sub.f32 	%f1757, %f526, %f1754;
	sub.f32 	%f1758, %f527, %f1755;
	sub.f32 	%f1759, %f534, %f1756;
	mul.f32 	%f1760, %f1757, %f1757;
	fma.rn.f32 	%f1761, %f1758, %f1758, %f1760;
	fma.rn.f32 	%f1762, %f1759, %f1759, %f1761;
	sqrt.rn.f32 	%f1763, %f1762;
	setp.ge.f32 	%p269, %f1763, %f346;
	setp.le.f32 	%p270, %f1763, %f450;
	and.pred  	%p271, %p270, %p269;
	selp.f32 	%f1764, %f1753, 0f7F800000, %p271;
	setp.lt.f32 	%p272, %f449, %f530;
	selp.f32 	%f1765, %f449, %f530, %p272;
	setp.lt.f32 	%p273, %f1765, %f533;
	selp.f32 	%f1766, %f1765, %f533, %p273;
	setp.lt.f32 	%p274, %f1766, %f1764;
	selp.f32 	%f537, %f1766, %f1764, %p274;
	setp.eq.f32 	%p275, %f537, 0f7F800000;
	@%p275 bra 	$L__BB13_233;

	mov.u32 	%r448, 254;
	// begin inline asm
	call (%r447), _optix_report_intersection_0, (%f537, %r448);
	// end inline asm

$L__BB13_233:
	ret;

}
	// .globl	__closesthit__cylhollow
.visible .entry __closesthit__cylhollow()
{
	.reg .pred 	%p<58>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<1985>;
	.reg .b32 	%r<647>;
	.reg .b64 	%rd<634>;


	// begin inline asm
	call (%r23), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r24), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r26), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r27), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r28), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r29, %r28, %r24, %r27;
	mad.lo.s32 	%r1, %r29, %r23, %r26;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64 	%p1, %rd1, 0;
	@%p1 bra 	$L__BB14_2;

	cvta.to.global.u64 	%rd42, %rd1;
	cvt.u64.u32 	%rd43, %r1;
	add.s64 	%rd44, %rd42, %rd43;
	mov.u16 	%rs1, 1;
	st.global.u8 	[%rd44], %rs1;
	bra.uni 	$L__BB14_112;

$L__BB14_2:
	// begin inline asm
	call (%rd45), _optix_get_sbt_data_ptr_64, ();
	// end inline asm
	ld.u64 	%rd3, [%rd45+8];
	// begin inline asm
	call (%f1775), _optix_get_world_ray_origin_x, ();
	// end inline asm
	// begin inline asm
	call (%f1776), _optix_get_world_ray_origin_y, ();
	// end inline asm
	// begin inline asm
	call (%f1777), _optix_get_world_ray_origin_z, ();
	// end inline asm
	// begin inline asm
	call (%r30), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p2, %r30, 0;
	@%p2 bra 	$L__BB14_23;

	// begin inline asm
	call (%r31), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f704), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p3, %r31, 0;
	@%p3 bra 	$L__BB14_21;

	mov.u32 	%r642, 0;

$L__BB14_5:
	.pragma "nounroll";
	// begin inline asm
	call (%rd46), _optix_get_transform_list_handle, (%r642);
	// end inline asm
	// begin inline asm
	call (%r34), _optix_get_transform_type_from_handle, (%rd46);
	// end inline asm
	or.b32  	%r35, %r34, 1;
	setp.eq.s32 	%p4, %r35, 3;
	@%p4 bra 	$L__BB14_11;
	bra.uni 	$L__BB14_6;

$L__BB14_11:
	setp.eq.s32 	%p7, %r34, 2;
	@%p7 bra 	$L__BB14_15;
	bra.uni 	$L__BB14_12;

$L__BB14_15:
	// begin inline asm
	call (%rd118), _optix_get_matrix_motion_transform_from_handle, (%rd46);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd120, %rd118;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r123,%r124,%r125,%r126}, [%rd120];
	// end inline asm
	add.s64 	%rd124, %rd118, 16;
	// begin inline asm
	cvta.to.global.u64 %rd123, %rd124;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r127,%r128,%r129,%r130}, [%rd123];
	// end inline asm
	add.s64 	%rd127, %rd118, 32;
	// begin inline asm
	cvta.to.global.u64 %rd126, %rd127;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r131,%r132,%r133,%r134}, [%rd126];
	// end inline asm
	add.s64 	%rd130, %rd118, 48;
	// begin inline asm
	cvta.to.global.u64 %rd129, %rd130;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r135,%r136,%r137,%r138}, [%rd129];
	// end inline asm
	add.s64 	%rd133, %rd118, 64;
	// begin inline asm
	cvta.to.global.u64 %rd132, %rd133;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r139,%r140,%r141,%r142}, [%rd132];
	// end inline asm
	add.s64 	%rd136, %rd118, 80;
	// begin inline asm
	cvta.to.global.u64 %rd135, %rd136;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r143,%r144,%r145,%r146}, [%rd135];
	// end inline asm
	add.s64 	%rd139, %rd118, 96;
	// begin inline asm
	cvta.to.global.u64 %rd138, %rd139;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r147,%r148,%r149,%r150}, [%rd138];
	// end inline asm
	add.s64 	%rd142, %rd118, 112;
	// begin inline asm
	cvta.to.global.u64 %rd141, %rd142;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r151,%r152,%r153,%r154}, [%rd141];
	// end inline asm
	mov.b32 	%f832, %r126;
	mov.b32 	%f833, %r127;
	and.b32  	%r167, %r125, 65535;
	add.s32 	%r168, %r167, -1;
	cvt.rn.f32.s32 	%f834, %r168;
	sub.f32 	%f835, %f704, %f832;
	mul.f32 	%f836, %f835, %f834;
	sub.f32 	%f837, %f833, %f832;
	div.rn.f32 	%f838, %f836, %f837;
	min.f32 	%f839, %f834, %f838;
	mov.f32 	%f840, 0f00000000;
	max.f32 	%f841, %f840, %f839;
	cvt.rmi.f32.f32 	%f842, %f841;
	sub.f32 	%f90, %f841, %f842;
	cvt.rzi.s32.f32 	%r169, %f842;
	mul.wide.s32 	%rd153, %r169, 48;
	add.s64 	%rd145, %rd127, %rd153;
	// begin inline asm
	cvta.to.global.u64 %rd144, %rd145;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r155,%r156,%r157,%r158}, [%rd144];
	// end inline asm
	mov.b32 	%f1730, %r155;
	mov.b32 	%f1729, %r156;
	mov.b32 	%f1728, %r157;
	mov.b32 	%f1727, %r158;
	add.s64 	%rd148, %rd145, 16;
	// begin inline asm
	cvta.to.global.u64 %rd147, %rd148;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r159,%r160,%r161,%r162}, [%rd147];
	// end inline asm
	mov.b32 	%f1734, %r159;
	mov.b32 	%f1733, %r160;
	mov.b32 	%f1732, %r161;
	mov.b32 	%f1731, %r162;
	add.s64 	%rd151, %rd145, 32;
	// begin inline asm
	cvta.to.global.u64 %rd150, %rd151;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r163,%r164,%r165,%r166}, [%rd150];
	// end inline asm
	mov.b32 	%f1738, %r163;
	mov.b32 	%f1737, %r164;
	mov.b32 	%f1736, %r165;
	mov.b32 	%f1735, %r166;
	setp.leu.f32 	%p9, %f90, 0f00000000;
	@%p9 bra 	$L__BB14_17;

	cvt.rmi.f32.f32 	%f1698, %f841;
	cvt.rzi.s32.f32 	%r641, %f1698;
	cvt.s64.s32 	%rd629, %r641;
	mov.f32 	%f843, 0f3F800000;
	sub.f32 	%f844, %f843, %f90;
	mul.lo.s64 	%rd163, %rd629, 48;
	add.s64 	%rd164, %rd118, %rd163;
	add.s64 	%rd155, %rd164, 80;
	// begin inline asm
	cvta.to.global.u64 %rd154, %rd155;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r170,%r171,%r172,%r173}, [%rd154];
	// end inline asm
	mov.b32 	%f845, %r170;
	mov.b32 	%f846, %r171;
	mov.b32 	%f847, %r172;
	mov.b32 	%f848, %r173;
	mul.f32 	%f849, %f90, %f845;
	mul.f32 	%f850, %f90, %f846;
	mul.f32 	%f851, %f90, %f847;
	mul.f32 	%f852, %f90, %f848;
	fma.rn.f32 	%f1730, %f844, %f1730, %f849;
	fma.rn.f32 	%f1729, %f844, %f1729, %f850;
	fma.rn.f32 	%f1728, %f844, %f1728, %f851;
	fma.rn.f32 	%f1727, %f844, %f1727, %f852;
	add.s64 	%rd158, %rd164, 96;
	// begin inline asm
	cvta.to.global.u64 %rd157, %rd158;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r174,%r175,%r176,%r177}, [%rd157];
	// end inline asm
	mov.b32 	%f853, %r174;
	mov.b32 	%f854, %r175;
	mov.b32 	%f855, %r176;
	mov.b32 	%f856, %r177;
	mul.f32 	%f857, %f90, %f853;
	mul.f32 	%f858, %f90, %f854;
	mul.f32 	%f859, %f90, %f855;
	mul.f32 	%f860, %f90, %f856;
	fma.rn.f32 	%f1734, %f844, %f1734, %f857;
	fma.rn.f32 	%f1733, %f844, %f1733, %f858;
	fma.rn.f32 	%f1732, %f844, %f1732, %f859;
	fma.rn.f32 	%f1731, %f844, %f1731, %f860;
	add.s64 	%rd161, %rd164, 112;
	// begin inline asm
	cvta.to.global.u64 %rd160, %rd161;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r178,%r179,%r180,%r181}, [%rd160];
	// end inline asm
	mov.b32 	%f861, %r178;
	mov.b32 	%f862, %r179;
	mov.b32 	%f863, %r180;
	mov.b32 	%f864, %r181;
	mul.f32 	%f865, %f90, %f861;
	mul.f32 	%f866, %f90, %f862;
	mul.f32 	%f867, %f90, %f863;
	mul.f32 	%f868, %f90, %f864;
	fma.rn.f32 	%f1738, %f844, %f1738, %f865;
	fma.rn.f32 	%f1737, %f844, %f1737, %f866;
	fma.rn.f32 	%f1736, %f844, %f1736, %f867;
	fma.rn.f32 	%f1735, %f844, %f1735, %f868;
	bra.uni 	$L__BB14_17;

$L__BB14_6:
	mov.f32 	%f1739, 0f00000000;
	mov.f32 	%f1742, 0f3F800000;
	setp.eq.s32 	%p5, %r34, 4;
	@%p5 bra 	$L__BB14_9;

	setp.ne.s32 	%p6, %r34, 1;
	mov.f32 	%f1740, %f1739;
	mov.f32 	%f1741, %f1739;
	mov.f32 	%f1743, %f1739;
	mov.f32 	%f1744, %f1739;
	mov.f32 	%f1745, %f1742;
	mov.f32 	%f1746, %f1739;
	mov.f32 	%f1747, %f1739;
	mov.f32 	%f1748, %f1742;
	mov.f32 	%f1749, %f1739;
	mov.f32 	%f1750, %f1739;
	@%p6 bra 	$L__BB14_18;

	// begin inline asm
	call (%rd48), _optix_get_static_transform_from_handle, (%rd46);
	// end inline asm
	add.s64 	%rd630, %rd48, 64;
	bra.uni 	$L__BB14_10;

$L__BB14_12:
	// begin inline asm
	call (%rd61), _optix_get_srt_motion_transform_from_handle, (%rd46);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd63, %rd61;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r48,%r49,%r50,%r51}, [%rd63];
	// end inline asm
	add.s64 	%rd67, %rd61, 16;
	// begin inline asm
	cvta.to.global.u64 %rd66, %rd67;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r52,%r53,%r54,%r55}, [%rd66];
	// end inline asm
	add.s64 	%rd70, %rd61, 32;
	// begin inline asm
	cvta.to.global.u64 %rd69, %rd70;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r56,%r57,%r58,%r59}, [%rd69];
	// end inline asm
	add.s64 	%rd73, %rd61, 48;
	// begin inline asm
	cvta.to.global.u64 %rd72, %rd73;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r60,%r61,%r62,%r63}, [%rd72];
	// end inline asm
	add.s64 	%rd76, %rd61, 64;
	// begin inline asm
	cvta.to.global.u64 %rd75, %rd76;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r64,%r65,%r66,%r67}, [%rd75];
	// end inline asm
	add.s64 	%rd79, %rd61, 80;
	// begin inline asm
	cvta.to.global.u64 %rd78, %rd79;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r68,%r69,%r70,%r71}, [%rd78];
	// end inline asm
	add.s64 	%rd82, %rd61, 96;
	// begin inline asm
	cvta.to.global.u64 %rd81, %rd82;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r72,%r73,%r74,%r75}, [%rd81];
	// end inline asm
	add.s64 	%rd85, %rd61, 112;
	// begin inline asm
	cvta.to.global.u64 %rd84, %rd85;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r76,%r77,%r78,%r79}, [%rd84];
	// end inline asm
	add.s64 	%rd88, %rd61, 128;
	// begin inline asm
	cvta.to.global.u64 %rd87, %rd88;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r80,%r81,%r82,%r83}, [%rd87];
	// end inline asm
	add.s64 	%rd91, %rd61, 144;
	// begin inline asm
	cvta.to.global.u64 %rd90, %rd91;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r84,%r85,%r86,%r87}, [%rd90];
	// end inline asm
	mov.b32 	%f719, %r51;
	mov.b32 	%f720, %r52;
	and.b32  	%r104, %r50, 65535;
	add.s32 	%r105, %r104, -1;
	cvt.rn.f32.s32 	%f721, %r105;
	sub.f32 	%f722, %f704, %f719;
	mul.f32 	%f723, %f722, %f721;
	sub.f32 	%f724, %f720, %f719;
	div.rn.f32 	%f725, %f723, %f724;
	min.f32 	%f726, %f721, %f725;
	mov.f32 	%f727, 0f00000000;
	max.f32 	%f728, %f727, %f726;
	cvt.rmi.f32.f32 	%f729, %f728;
	sub.f32 	%f29, %f728, %f729;
	cvt.rzi.s32.f32 	%r106, %f729;
	mul.wide.s32 	%rd105, %r106, 64;
	add.s64 	%rd94, %rd70, %rd105;
	// begin inline asm
	cvta.to.global.u64 %rd93, %rd94;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r88,%r89,%r90,%r91}, [%rd93];
	// end inline asm
	mov.b32 	%f1711, %r88;
	mov.b32 	%f1712, %r89;
	mov.b32 	%f1713, %r90;
	mov.b32 	%f1714, %r91;
	add.s64 	%rd97, %rd94, 16;
	// begin inline asm
	cvta.to.global.u64 %rd96, %rd97;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r92,%r93,%r94,%r95}, [%rd96];
	// end inline asm
	mov.b32 	%f1715, %r92;
	mov.b32 	%f1716, %r93;
	mov.b32 	%f1717, %r94;
	mov.b32 	%f1718, %r95;
	add.s64 	%rd100, %rd94, 32;
	// begin inline asm
	cvta.to.global.u64 %rd99, %rd100;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r96,%r97,%r98,%r99}, [%rd99];
	// end inline asm
	mov.b32 	%f1719, %r96;
	mov.b32 	%f1720, %r97;
	mov.b32 	%f1721, %r98;
	mov.b32 	%f1722, %r99;
	add.s64 	%rd103, %rd94, 48;
	// begin inline asm
	cvta.to.global.u64 %rd102, %rd103;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r100,%r101,%r102,%r103}, [%rd102];
	// end inline asm
	mov.b32 	%f1723, %r100;
	mov.b32 	%f1724, %r101;
	mov.b32 	%f1725, %r102;
	mov.b32 	%f1726, %r103;
	setp.leu.f32 	%p8, %f29, 0f00000000;
	@%p8 bra 	$L__BB14_14;

	mov.f32 	%f730, 0f3F800000;
	sub.f32 	%f731, %f730, %f29;
	add.s64 	%rd107, %rd94, 64;
	// begin inline asm
	cvta.to.global.u64 %rd106, %rd107;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r107,%r108,%r109,%r110}, [%rd106];
	// end inline asm
	mov.b32 	%f732, %r107;
	mov.b32 	%f733, %r108;
	mov.b32 	%f734, %r109;
	mov.b32 	%f735, %r110;
	mul.f32 	%f736, %f29, %f732;
	mul.f32 	%f737, %f29, %f733;
	mul.f32 	%f738, %f29, %f734;
	mul.f32 	%f739, %f29, %f735;
	fma.rn.f32 	%f1711, %f731, %f1711, %f736;
	fma.rn.f32 	%f1712, %f731, %f1712, %f737;
	fma.rn.f32 	%f1713, %f731, %f1713, %f738;
	fma.rn.f32 	%f1714, %f731, %f1714, %f739;
	add.s64 	%rd110, %rd94, 80;
	// begin inline asm
	cvta.to.global.u64 %rd109, %rd110;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r111,%r112,%r113,%r114}, [%rd109];
	// end inline asm
	mov.b32 	%f740, %r111;
	mov.b32 	%f741, %r112;
	mov.b32 	%f742, %r113;
	mov.b32 	%f743, %r114;
	mul.f32 	%f744, %f29, %f740;
	mul.f32 	%f745, %f29, %f741;
	mul.f32 	%f746, %f29, %f742;
	mul.f32 	%f747, %f29, %f743;
	fma.rn.f32 	%f1715, %f731, %f1715, %f744;
	fma.rn.f32 	%f1716, %f731, %f1716, %f745;
	fma.rn.f32 	%f1717, %f731, %f1717, %f746;
	fma.rn.f32 	%f1718, %f731, %f1718, %f747;
	add.s64 	%rd113, %rd94, 96;
	// begin inline asm
	cvta.to.global.u64 %rd112, %rd113;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r115,%r116,%r117,%r118}, [%rd112];
	// end inline asm
	mov.b32 	%f748, %r115;
	mov.b32 	%f749, %r116;
	mov.b32 	%f750, %r117;
	mov.b32 	%f751, %r118;
	mul.f32 	%f752, %f29, %f748;
	mul.f32 	%f753, %f29, %f749;
	mul.f32 	%f754, %f29, %f750;
	mul.f32 	%f755, %f29, %f751;
	fma.rn.f32 	%f1719, %f731, %f1719, %f752;
	fma.rn.f32 	%f756, %f731, %f1720, %f753;
	fma.rn.f32 	%f757, %f731, %f1721, %f754;
	fma.rn.f32 	%f758, %f731, %f1722, %f755;
	add.s64 	%rd116, %rd94, 112;
	// begin inline asm
	cvta.to.global.u64 %rd115, %rd116;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r119,%r120,%r121,%r122}, [%rd115];
	// end inline asm
	mov.b32 	%f759, %r119;
	mov.b32 	%f760, %r120;
	mov.b32 	%f761, %r121;
	mov.b32 	%f762, %r122;
	mul.f32 	%f763, %f29, %f759;
	mul.f32 	%f764, %f29, %f760;
	mul.f32 	%f765, %f29, %f761;
	mul.f32 	%f766, %f29, %f762;
	fma.rn.f32 	%f767, %f731, %f1723, %f763;
	fma.rn.f32 	%f1724, %f731, %f1724, %f764;
	fma.rn.f32 	%f1725, %f731, %f1725, %f765;
	fma.rn.f32 	%f1726, %f731, %f1726, %f766;
	mul.f32 	%f768, %f757, %f757;
	fma.rn.f32 	%f769, %f756, %f756, %f768;
	fma.rn.f32 	%f770, %f758, %f758, %f769;
	fma.rn.f32 	%f771, %f767, %f767, %f770;
	sqrt.rn.f32 	%f772, %f771;
	rcp.rn.f32 	%f773, %f772;
	mul.f32 	%f1720, %f756, %f773;
	mul.f32 	%f1721, %f757, %f773;
	mul.f32 	%f1722, %f758, %f773;
	mul.f32 	%f1723, %f773, %f767;

$L__BB14_14:
	mul.f32 	%f774, %f1721, %f1721;
	fma.rn.f32 	%f775, %f1720, %f1720, %f774;
	fma.rn.f32 	%f776, %f1722, %f1722, %f775;
	fma.rn.f32 	%f777, %f1723, %f1723, %f776;
	rcp.rn.f32 	%f778, %f777;
	mul.f32 	%f779, %f1720, %f778;
	mul.f32 	%f780, %f1721, %f778;
	mul.f32 	%f781, %f1722, %f778;
	mul.f32 	%f782, %f1723, %f778;
	mul.f32 	%f783, %f1720, %f779;
	mul.f32 	%f784, %f1721, %f780;
	mul.f32 	%f785, %f1722, %f781;
	mul.f32 	%f786, %f1720, %f780;
	mul.f32 	%f787, %f1722, %f782;
	mul.f32 	%f788, %f1720, %f781;
	mul.f32 	%f789, %f1721, %f782;
	mul.f32 	%f790, %f1721, %f781;
	mul.f32 	%f791, %f1720, %f782;
	sub.f32 	%f792, %f783, %f784;
	sub.f32 	%f793, %f792, %f785;
	fma.rn.f32 	%f794, %f1723, %f782, %f793;
	sub.f32 	%f795, %f786, %f787;
	add.f32 	%f796, %f795, %f795;
	add.f32 	%f797, %f788, %f789;
	add.f32 	%f798, %f797, %f797;
	add.f32 	%f799, %f786, %f787;
	add.f32 	%f800, %f799, %f799;
	sub.f32 	%f801, %f784, %f783;
	sub.f32 	%f802, %f801, %f785;
	fma.rn.f32 	%f803, %f1723, %f782, %f802;
	sub.f32 	%f804, %f790, %f791;
	add.f32 	%f805, %f804, %f804;
	sub.f32 	%f806, %f788, %f789;
	add.f32 	%f807, %f806, %f806;
	add.f32 	%f808, %f790, %f791;
	add.f32 	%f809, %f808, %f808;
	neg.f32 	%f810, %f783;
	sub.f32 	%f811, %f810, %f784;
	add.f32 	%f812, %f785, %f811;
	fma.rn.f32 	%f813, %f1723, %f782, %f812;
	mul.f32 	%f814, %f1714, %f794;
	fma.rn.f32 	%f815, %f1717, %f796, %f814;
	fma.rn.f32 	%f816, %f1719, %f798, %f815;
	sub.f32 	%f1727, %f1724, %f816;
	mul.f32 	%f817, %f1717, %f803;
	fma.rn.f32 	%f818, %f1714, %f800, %f817;
	fma.rn.f32 	%f819, %f1719, %f805, %f818;
	sub.f32 	%f1731, %f1725, %f819;
	mul.f32 	%f820, %f1717, %f809;
	fma.rn.f32 	%f821, %f1714, %f807, %f820;
	fma.rn.f32 	%f822, %f1719, %f813, %f821;
	sub.f32 	%f1735, %f1726, %f822;
	mul.f32 	%f823, %f1713, %f794;
	fma.rn.f32 	%f824, %f1716, %f796, %f823;
	fma.rn.f32 	%f1728, %f1718, %f798, %f824;
	mul.f32 	%f825, %f1716, %f803;
	fma.rn.f32 	%f826, %f1713, %f800, %f825;
	fma.rn.f32 	%f1732, %f1718, %f805, %f826;
	mul.f32 	%f827, %f1716, %f809;
	fma.rn.f32 	%f828, %f1713, %f807, %f827;
	fma.rn.f32 	%f1736, %f1718, %f813, %f828;
	mul.f32 	%f829, %f1712, %f794;
	fma.rn.f32 	%f1729, %f1715, %f796, %f829;
	mul.f32 	%f830, %f1715, %f803;
	fma.rn.f32 	%f1733, %f1712, %f800, %f830;
	mul.f32 	%f831, %f1715, %f809;
	fma.rn.f32 	%f1737, %f1712, %f807, %f831;
	mul.f32 	%f1730, %f1711, %f794;
	mul.f32 	%f1734, %f1711, %f800;
	mul.f32 	%f1738, %f1711, %f807;

$L__BB14_17:
	mul.f32 	%f869, %f1732, %f1737;
	mul.f32 	%f870, %f1733, %f1736;
	sub.f32 	%f871, %f870, %f869;
	mul.f32 	%f872, %f1730, %f871;
	mul.f32 	%f873, %f1732, %f1738;
	mul.f32 	%f874, %f1734, %f1736;
	sub.f32 	%f875, %f874, %f873;
	mul.f32 	%f876, %f1729, %f875;
	sub.f32 	%f877, %f872, %f876;
	mul.f32 	%f878, %f1733, %f1738;
	mul.f32 	%f879, %f1734, %f1737;
	sub.f32 	%f880, %f879, %f878;
	fma.rn.f32 	%f881, %f1728, %f880, %f877;
	rcp.rn.f32 	%f882, %f881;
	mul.f32 	%f1742, %f871, %f882;
	mul.f32 	%f883, %f1729, %f1736;
	mul.f32 	%f884, %f1728, %f1737;
	sub.f32 	%f885, %f884, %f883;
	mul.f32 	%f1741, %f885, %f882;
	mul.f32 	%f886, %f1728, %f1733;
	mul.f32 	%f887, %f1729, %f1732;
	sub.f32 	%f888, %f887, %f886;
	mul.f32 	%f1740, %f888, %f882;
	sub.f32 	%f889, %f873, %f874;
	mul.f32 	%f1746, %f889, %f882;
	mul.f32 	%f890, %f1728, %f1738;
	mul.f32 	%f891, %f1730, %f1736;
	sub.f32 	%f892, %f891, %f890;
	mul.f32 	%f1745, %f892, %f882;
	mul.f32 	%f893, %f1730, %f1732;
	mul.f32 	%f894, %f1728, %f1734;
	sub.f32 	%f895, %f894, %f893;
	mul.f32 	%f1744, %f895, %f882;
	mul.f32 	%f1750, %f880, %f882;
	mul.f32 	%f896, %f1730, %f1737;
	mul.f32 	%f897, %f1729, %f1738;
	sub.f32 	%f898, %f897, %f896;
	mul.f32 	%f1749, %f898, %f882;
	mul.f32 	%f899, %f1729, %f1734;
	mul.f32 	%f900, %f1730, %f1733;
	sub.f32 	%f901, %f900, %f899;
	mul.f32 	%f1748, %f901, %f882;
	mul.f32 	%f902, %f1727, %f1742;
	neg.f32 	%f903, %f902;
	mul.f32 	%f904, %f1731, %f1741;
	sub.f32 	%f905, %f903, %f904;
	mul.f32 	%f906, %f1735, %f1740;
	sub.f32 	%f1739, %f905, %f906;
	mul.f32 	%f907, %f1727, %f1746;
	neg.f32 	%f908, %f907;
	mul.f32 	%f909, %f1731, %f1745;
	sub.f32 	%f910, %f908, %f909;
	mul.f32 	%f911, %f1735, %f1744;
	sub.f32 	%f1743, %f910, %f911;
	mul.f32 	%f912, %f1727, %f1750;
	neg.f32 	%f913, %f912;
	mul.f32 	%f914, %f1731, %f1749;
	sub.f32 	%f915, %f913, %f914;
	mul.f32 	%f916, %f1735, %f1748;
	sub.f32 	%f1747, %f915, %f916;
	bra.uni 	$L__BB14_18;

$L__BB14_9:
	// begin inline asm
	call (%rd630), _optix_get_instance_inverse_transform_from_handle, (%rd46);
	// end inline asm

$L__BB14_10:
	// begin inline asm
	cvta.to.global.u64 %rd52, %rd630;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r36,%r37,%r38,%r39}, [%rd52];
	// end inline asm
	mov.b32 	%f1742, %r36;
	mov.b32 	%f1741, %r37;
	mov.b32 	%f1740, %r38;
	mov.b32 	%f1739, %r39;
	add.s64 	%rd56, %rd630, 16;
	// begin inline asm
	cvta.to.global.u64 %rd55, %rd56;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r40,%r41,%r42,%r43}, [%rd55];
	// end inline asm
	mov.b32 	%f1746, %r40;
	mov.b32 	%f1745, %r41;
	mov.b32 	%f1744, %r42;
	mov.b32 	%f1743, %r43;
	add.s64 	%rd59, %rd630, 32;
	// begin inline asm
	cvta.to.global.u64 %rd58, %rd59;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r44,%r45,%r46,%r47}, [%rd58];
	// end inline asm
	mov.b32 	%f1750, %r44;
	mov.b32 	%f1749, %r45;
	mov.b32 	%f1748, %r46;
	mov.b32 	%f1747, %r47;

$L__BB14_18:
	setp.eq.s32 	%p10, %r642, 0;
	@%p10 bra 	$L__BB14_20;

	mul.f32 	%f917, %f1707, %f1742;
	fma.rn.f32 	%f918, %f1703, %f1741, %f917;
	fma.rn.f32 	%f151, %f1699, %f1740, %f918;
	mul.f32 	%f919, %f1708, %f1742;
	fma.rn.f32 	%f920, %f1704, %f1741, %f919;
	fma.rn.f32 	%f152, %f1700, %f1740, %f920;
	mul.f32 	%f921, %f1709, %f1742;
	fma.rn.f32 	%f922, %f1705, %f1741, %f921;
	fma.rn.f32 	%f153, %f1701, %f1740, %f922;
	mul.f32 	%f923, %f1710, %f1742;
	fma.rn.f32 	%f924, %f1706, %f1741, %f923;
	fma.rn.f32 	%f925, %f1702, %f1740, %f924;
	add.f32 	%f1739, %f1739, %f925;
	mul.f32 	%f926, %f1707, %f1746;
	fma.rn.f32 	%f927, %f1703, %f1745, %f926;
	fma.rn.f32 	%f155, %f1699, %f1744, %f927;
	mul.f32 	%f928, %f1708, %f1746;
	fma.rn.f32 	%f929, %f1704, %f1745, %f928;
	fma.rn.f32 	%f156, %f1700, %f1744, %f929;
	mul.f32 	%f930, %f1709, %f1746;
	fma.rn.f32 	%f931, %f1705, %f1745, %f930;
	fma.rn.f32 	%f157, %f1701, %f1744, %f931;
	mul.f32 	%f932, %f1710, %f1746;
	fma.rn.f32 	%f933, %f1706, %f1745, %f932;
	fma.rn.f32 	%f934, %f1702, %f1744, %f933;
	add.f32 	%f1743, %f1743, %f934;
	mul.f32 	%f935, %f1707, %f1750;
	fma.rn.f32 	%f936, %f1703, %f1749, %f935;
	fma.rn.f32 	%f159, %f1699, %f1748, %f936;
	mul.f32 	%f937, %f1708, %f1750;
	fma.rn.f32 	%f938, %f1704, %f1749, %f937;
	fma.rn.f32 	%f160, %f1700, %f1748, %f938;
	mul.f32 	%f939, %f1709, %f1750;
	fma.rn.f32 	%f940, %f1705, %f1749, %f939;
	fma.rn.f32 	%f161, %f1701, %f1748, %f940;
	mul.f32 	%f941, %f1710, %f1750;
	fma.rn.f32 	%f942, %f1706, %f1749, %f941;
	fma.rn.f32 	%f943, %f1702, %f1748, %f942;
	add.f32 	%f1747, %f1747, %f943;
	mov.f32 	%f1740, %f153;
	mov.f32 	%f1741, %f152;
	mov.f32 	%f1742, %f151;
	mov.f32 	%f1744, %f157;
	mov.f32 	%f1745, %f156;
	mov.f32 	%f1746, %f155;
	mov.f32 	%f1748, %f161;
	mov.f32 	%f1749, %f160;
	mov.f32 	%f1750, %f159;

$L__BB14_20:
	add.s32 	%r642, %r642, 1;
	setp.lt.u32 	%p11, %r642, %r31;
	mov.f32 	%f1699, %f1750;
	mov.f32 	%f1700, %f1749;
	mov.f32 	%f1701, %f1748;
	mov.f32 	%f1702, %f1747;
	mov.f32 	%f1703, %f1746;
	mov.f32 	%f1704, %f1745;
	mov.f32 	%f1705, %f1744;
	mov.f32 	%f1706, %f1743;
	mov.f32 	%f1707, %f1742;
	mov.f32 	%f1708, %f1741;
	mov.f32 	%f1709, %f1740;
	mov.f32 	%f1710, %f1739;
	@%p11 bra 	$L__BB14_5;

$L__BB14_21:
	mul.f32 	%f944, %f1775, %f1742;
	fma.rn.f32 	%f945, %f1776, %f1741, %f944;
	fma.rn.f32 	%f946, %f1777, %f1740, %f945;
	mul.f32 	%f947, %f1775, %f1746;
	fma.rn.f32 	%f948, %f1776, %f1745, %f947;
	fma.rn.f32 	%f949, %f1777, %f1744, %f948;
	mul.f32 	%f950, %f1775, %f1750;
	fma.rn.f32 	%f951, %f1776, %f1749, %f950;
	fma.rn.f32 	%f952, %f1777, %f1748, %f951;
	add.f32 	%f1777, %f1747, %f952;
	add.f32 	%f1776, %f1743, %f949;
	add.f32 	%f1775, %f1739, %f946;

$L__BB14_23:
	// begin inline asm
	call (%f1833), _optix_get_world_ray_direction_x, ();
	// end inline asm
	// begin inline asm
	call (%f1834), _optix_get_world_ray_direction_y, ();
	// end inline asm
	// begin inline asm
	call (%f955), _optix_get_world_ray_direction_z, ();
	// end inline asm
	// begin inline asm
	call (%r182), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p12, %r182, 0;
	@%p12 bra 	$L__BB14_43;

	// begin inline asm
	call (%r183), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f956), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p13, %r183, 0;
	@%p13 bra 	$L__BB14_42;

	mov.u32 	%r643, 0;

$L__BB14_26:
	.pragma "nounroll";
	// begin inline asm
	call (%rd165), _optix_get_transform_list_handle, (%r643);
	// end inline asm
	// begin inline asm
	call (%r186), _optix_get_transform_type_from_handle, (%rd165);
	// end inline asm
	or.b32  	%r187, %r186, 1;
	setp.eq.s32 	%p14, %r187, 3;
	@%p14 bra 	$L__BB14_32;
	bra.uni 	$L__BB14_27;

$L__BB14_32:
	setp.eq.s32 	%p17, %r186, 2;
	@%p17 bra 	$L__BB14_36;
	bra.uni 	$L__BB14_33;

$L__BB14_36:
	// begin inline asm
	call (%rd237), _optix_get_matrix_motion_transform_from_handle, (%rd165);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd239, %rd237;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r275,%r276,%r277,%r278}, [%rd239];
	// end inline asm
	add.s64 	%rd243, %rd237, 16;
	// begin inline asm
	cvta.to.global.u64 %rd242, %rd243;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r279,%r280,%r281,%r282}, [%rd242];
	// end inline asm
	add.s64 	%rd246, %rd237, 32;
	// begin inline asm
	cvta.to.global.u64 %rd245, %rd246;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r283,%r284,%r285,%r286}, [%rd245];
	// end inline asm
	add.s64 	%rd249, %rd237, 48;
	// begin inline asm
	cvta.to.global.u64 %rd248, %rd249;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r287,%r288,%r289,%r290}, [%rd248];
	// end inline asm
	add.s64 	%rd252, %rd237, 64;
	// begin inline asm
	cvta.to.global.u64 %rd251, %rd252;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r291,%r292,%r293,%r294}, [%rd251];
	// end inline asm
	add.s64 	%rd255, %rd237, 80;
	// begin inline asm
	cvta.to.global.u64 %rd254, %rd255;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r295,%r296,%r297,%r298}, [%rd254];
	// end inline asm
	add.s64 	%rd258, %rd237, 96;
	// begin inline asm
	cvta.to.global.u64 %rd257, %rd258;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r299,%r300,%r301,%r302}, [%rd257];
	// end inline asm
	add.s64 	%rd261, %rd237, 112;
	// begin inline asm
	cvta.to.global.u64 %rd260, %rd261;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r303,%r304,%r305,%r306}, [%rd260];
	// end inline asm
	mov.b32 	%f1060, %r278;
	mov.b32 	%f1061, %r279;
	and.b32  	%r319, %r277, 65535;
	add.s32 	%r320, %r319, -1;
	cvt.rn.f32.s32 	%f1062, %r320;
	sub.f32 	%f1063, %f956, %f1060;
	mul.f32 	%f1064, %f1063, %f1062;
	sub.f32 	%f1065, %f1061, %f1060;
	div.rn.f32 	%f1066, %f1064, %f1065;
	min.f32 	%f1067, %f1062, %f1066;
	mov.f32 	%f1068, 0f00000000;
	max.f32 	%f1069, %f1068, %f1067;
	cvt.rmi.f32.f32 	%f1070, %f1069;
	sub.f32 	%f258, %f1069, %f1070;
	cvt.rzi.s32.f32 	%r321, %f1070;
	cvt.s64.s32 	%rd17, %r321;
	mul.wide.s32 	%rd272, %r321, 48;
	add.s64 	%rd264, %rd246, %rd272;
	// begin inline asm
	cvta.to.global.u64 %rd263, %rd264;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r307,%r308,%r309,%r310}, [%rd263];
	// end inline asm
	mov.b32 	%f1803, %r307;
	mov.b32 	%f1804, %r308;
	mov.b32 	%f1805, %r309;
	add.s64 	%rd267, %rd264, 16;
	// begin inline asm
	cvta.to.global.u64 %rd266, %rd267;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r311,%r312,%r313,%r314}, [%rd266];
	// end inline asm
	mov.b32 	%f1800, %r311;
	mov.b32 	%f1801, %r312;
	mov.b32 	%f1802, %r313;
	add.s64 	%rd270, %rd264, 32;
	// begin inline asm
	cvta.to.global.u64 %rd269, %rd270;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r315,%r316,%r317,%r318}, [%rd269];
	// end inline asm
	mov.b32 	%f1797, %r315;
	mov.b32 	%f1798, %r316;
	mov.b32 	%f1799, %r317;
	setp.leu.f32 	%p19, %f258, 0f00000000;
	@%p19 bra 	$L__BB14_38;

	mov.f32 	%f1071, 0f3F800000;
	sub.f32 	%f1072, %f1071, %f258;
	mul.lo.s64 	%rd282, %rd17, 48;
	add.s64 	%rd283, %rd237, %rd282;
	add.s64 	%rd274, %rd283, 80;
	// begin inline asm
	cvta.to.global.u64 %rd273, %rd274;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r322,%r323,%r324,%r325}, [%rd273];
	// end inline asm
	mov.b32 	%f1073, %r322;
	mov.b32 	%f1074, %r323;
	mov.b32 	%f1075, %r324;
	mul.f32 	%f1076, %f258, %f1073;
	mul.f32 	%f1077, %f258, %f1074;
	mul.f32 	%f1078, %f258, %f1075;
	fma.rn.f32 	%f1803, %f1072, %f1803, %f1076;
	fma.rn.f32 	%f1804, %f1072, %f1804, %f1077;
	fma.rn.f32 	%f1805, %f1072, %f1805, %f1078;
	add.s64 	%rd277, %rd283, 96;
	// begin inline asm
	cvta.to.global.u64 %rd276, %rd277;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r326,%r327,%r328,%r329}, [%rd276];
	// end inline asm
	mov.b32 	%f1079, %r326;
	mov.b32 	%f1080, %r327;
	mov.b32 	%f1081, %r328;
	mul.f32 	%f1082, %f258, %f1079;
	mul.f32 	%f1083, %f258, %f1080;
	mul.f32 	%f1084, %f258, %f1081;
	fma.rn.f32 	%f1800, %f1072, %f1800, %f1082;
	fma.rn.f32 	%f1801, %f1072, %f1801, %f1083;
	fma.rn.f32 	%f1802, %f1072, %f1802, %f1084;
	add.s64 	%rd280, %rd283, 112;
	// begin inline asm
	cvta.to.global.u64 %rd279, %rd280;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r330,%r331,%r332,%r333}, [%rd279];
	// end inline asm
	mov.b32 	%f1085, %r330;
	mov.b32 	%f1086, %r331;
	mov.b32 	%f1087, %r332;
	mul.f32 	%f1088, %f258, %f1085;
	mul.f32 	%f1089, %f258, %f1086;
	mul.f32 	%f1090, %f258, %f1087;
	fma.rn.f32 	%f1797, %f1072, %f1797, %f1088;
	fma.rn.f32 	%f1798, %f1072, %f1798, %f1089;
	fma.rn.f32 	%f1799, %f1072, %f1799, %f1090;
	bra.uni 	$L__BB14_38;

$L__BB14_27:
	mov.f32 	%f1806, 0f00000000;
	mov.f32 	%f1808, 0f3F800000;
	setp.eq.s32 	%p15, %r186, 4;
	@%p15 bra 	$L__BB14_30;

	setp.ne.s32 	%p16, %r186, 1;
	mov.f32 	%f1807, %f1806;
	mov.f32 	%f1809, %f1806;
	mov.f32 	%f1810, %f1808;
	mov.f32 	%f1811, %f1806;
	mov.f32 	%f1812, %f1808;
	mov.f32 	%f1813, %f1806;
	mov.f32 	%f1814, %f1806;
	@%p16 bra 	$L__BB14_39;

	// begin inline asm
	call (%rd167), _optix_get_static_transform_from_handle, (%rd165);
	// end inline asm
	add.s64 	%rd631, %rd167, 64;
	bra.uni 	$L__BB14_31;

$L__BB14_33:
	// begin inline asm
	call (%rd180), _optix_get_srt_motion_transform_from_handle, (%rd165);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd182, %rd180;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r200,%r201,%r202,%r203}, [%rd182];
	// end inline asm
	add.s64 	%rd186, %rd180, 16;
	// begin inline asm
	cvta.to.global.u64 %rd185, %rd186;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r204,%r205,%r206,%r207}, [%rd185];
	// end inline asm
	add.s64 	%rd189, %rd180, 32;
	// begin inline asm
	cvta.to.global.u64 %rd188, %rd189;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r208,%r209,%r210,%r211}, [%rd188];
	// end inline asm
	add.s64 	%rd192, %rd180, 48;
	// begin inline asm
	cvta.to.global.u64 %rd191, %rd192;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r212,%r213,%r214,%r215}, [%rd191];
	// end inline asm
	add.s64 	%rd195, %rd180, 64;
	// begin inline asm
	cvta.to.global.u64 %rd194, %rd195;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r216,%r217,%r218,%r219}, [%rd194];
	// end inline asm
	add.s64 	%rd198, %rd180, 80;
	// begin inline asm
	cvta.to.global.u64 %rd197, %rd198;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r220,%r221,%r222,%r223}, [%rd197];
	// end inline asm
	add.s64 	%rd201, %rd180, 96;
	// begin inline asm
	cvta.to.global.u64 %rd200, %rd201;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r224,%r225,%r226,%r227}, [%rd200];
	// end inline asm
	add.s64 	%rd204, %rd180, 112;
	// begin inline asm
	cvta.to.global.u64 %rd203, %rd204;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r228,%r229,%r230,%r231}, [%rd203];
	// end inline asm
	add.s64 	%rd207, %rd180, 128;
	// begin inline asm
	cvta.to.global.u64 %rd206, %rd207;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r232,%r233,%r234,%r235}, [%rd206];
	// end inline asm
	add.s64 	%rd210, %rd180, 144;
	// begin inline asm
	cvta.to.global.u64 %rd209, %rd210;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r236,%r237,%r238,%r239}, [%rd209];
	// end inline asm
	mov.b32 	%f968, %r203;
	mov.b32 	%f969, %r204;
	and.b32  	%r256, %r202, 65535;
	add.s32 	%r257, %r256, -1;
	cvt.rn.f32.s32 	%f970, %r257;
	sub.f32 	%f971, %f956, %f968;
	mul.f32 	%f972, %f971, %f970;
	sub.f32 	%f973, %f969, %f968;
	div.rn.f32 	%f974, %f972, %f973;
	min.f32 	%f975, %f970, %f974;
	mov.f32 	%f976, 0f00000000;
	max.f32 	%f977, %f976, %f975;
	cvt.rmi.f32.f32 	%f978, %f977;
	sub.f32 	%f218, %f977, %f978;
	cvt.rzi.s32.f32 	%r258, %f978;
	mul.wide.s32 	%rd224, %r258, 64;
	add.s64 	%rd213, %rd189, %rd224;
	// begin inline asm
	cvta.to.global.u64 %rd212, %rd213;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r240,%r241,%r242,%r243}, [%rd212];
	// end inline asm
	mov.b32 	%f1787, %r240;
	mov.b32 	%f1788, %r241;
	mov.b32 	%f1789, %r242;
	add.s64 	%rd216, %rd213, 16;
	// begin inline asm
	cvta.to.global.u64 %rd215, %rd216;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r244,%r245,%r246,%r247}, [%rd215];
	// end inline asm
	mov.b32 	%f1790, %r244;
	mov.b32 	%f1791, %r245;
	mov.b32 	%f1792, %r247;
	add.s64 	%rd219, %rd213, 32;
	// begin inline asm
	cvta.to.global.u64 %rd218, %rd219;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r248,%r249,%r250,%r251}, [%rd218];
	// end inline asm
	mov.b32 	%f1793, %r249;
	mov.b32 	%f1794, %r250;
	mov.b32 	%f1795, %r251;
	add.s64 	%rd222, %rd213, 48;
	// begin inline asm
	cvta.to.global.u64 %rd221, %rd222;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r252,%r253,%r254,%r255}, [%rd221];
	// end inline asm
	mov.b32 	%f1796, %r252;
	setp.leu.f32 	%p18, %f218, 0f00000000;
	@%p18 bra 	$L__BB14_35;

	mov.f32 	%f979, 0f3F800000;
	sub.f32 	%f980, %f979, %f218;
	add.s64 	%rd226, %rd213, 64;
	// begin inline asm
	cvta.to.global.u64 %rd225, %rd226;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r259,%r260,%r261,%r262}, [%rd225];
	// end inline asm
	mov.b32 	%f981, %r259;
	mov.b32 	%f982, %r260;
	mov.b32 	%f983, %r261;
	mul.f32 	%f984, %f218, %f981;
	mul.f32 	%f985, %f218, %f982;
	mul.f32 	%f986, %f218, %f983;
	fma.rn.f32 	%f1787, %f980, %f1787, %f984;
	fma.rn.f32 	%f1788, %f980, %f1788, %f985;
	fma.rn.f32 	%f1789, %f980, %f1789, %f986;
	add.s64 	%rd229, %rd213, 80;
	// begin inline asm
	cvta.to.global.u64 %rd228, %rd229;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r263,%r264,%r265,%r266}, [%rd228];
	// end inline asm
	mov.b32 	%f987, %r263;
	mov.b32 	%f988, %r264;
	mov.b32 	%f989, %r266;
	mul.f32 	%f990, %f218, %f987;
	mul.f32 	%f991, %f218, %f988;
	mul.f32 	%f992, %f218, %f989;
	fma.rn.f32 	%f1790, %f980, %f1790, %f990;
	fma.rn.f32 	%f1791, %f980, %f1791, %f991;
	fma.rn.f32 	%f1792, %f980, %f1792, %f992;
	add.s64 	%rd232, %rd213, 96;
	// begin inline asm
	cvta.to.global.u64 %rd231, %rd232;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r267,%r268,%r269,%r270}, [%rd231];
	// end inline asm
	mov.b32 	%f993, %r268;
	mov.b32 	%f994, %r269;
	mov.b32 	%f995, %r270;
	mul.f32 	%f996, %f218, %f993;
	mul.f32 	%f997, %f218, %f994;
	mul.f32 	%f998, %f218, %f995;
	fma.rn.f32 	%f999, %f980, %f1793, %f996;
	fma.rn.f32 	%f1000, %f980, %f1794, %f997;
	fma.rn.f32 	%f1001, %f980, %f1795, %f998;
	add.s64 	%rd235, %rd213, 112;
	// begin inline asm
	cvta.to.global.u64 %rd234, %rd235;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r271,%r272,%r273,%r274}, [%rd234];
	// end inline asm
	mov.b32 	%f1002, %r271;
	mul.f32 	%f1003, %f218, %f1002;
	fma.rn.f32 	%f1004, %f980, %f1796, %f1003;
	mul.f32 	%f1005, %f1000, %f1000;
	fma.rn.f32 	%f1006, %f999, %f999, %f1005;
	fma.rn.f32 	%f1007, %f1001, %f1001, %f1006;
	fma.rn.f32 	%f1008, %f1004, %f1004, %f1007;
	sqrt.rn.f32 	%f1009, %f1008;
	rcp.rn.f32 	%f1010, %f1009;
	mul.f32 	%f1793, %f999, %f1010;
	mul.f32 	%f1794, %f1000, %f1010;
	mul.f32 	%f1795, %f1001, %f1010;
	mul.f32 	%f1796, %f1010, %f1004;

$L__BB14_35:
	mul.f32 	%f1011, %f1794, %f1794;
	fma.rn.f32 	%f1012, %f1793, %f1793, %f1011;
	fma.rn.f32 	%f1013, %f1795, %f1795, %f1012;
	fma.rn.f32 	%f1014, %f1796, %f1796, %f1013;
	rcp.rn.f32 	%f1015, %f1014;
	mul.f32 	%f1016, %f1793, %f1015;
	mul.f32 	%f1017, %f1794, %f1015;
	mul.f32 	%f1018, %f1795, %f1015;
	mul.f32 	%f1019, %f1796, %f1015;
	mul.f32 	%f1020, %f1793, %f1016;
	mul.f32 	%f1021, %f1794, %f1017;
	mul.f32 	%f1022, %f1795, %f1018;
	mul.f32 	%f1023, %f1793, %f1017;
	mul.f32 	%f1024, %f1795, %f1019;
	mul.f32 	%f1025, %f1793, %f1018;
	mul.f32 	%f1026, %f1794, %f1019;
	mul.f32 	%f1027, %f1794, %f1018;
	mul.f32 	%f1028, %f1793, %f1019;
	sub.f32 	%f1029, %f1020, %f1021;
	sub.f32 	%f1030, %f1029, %f1022;
	fma.rn.f32 	%f1031, %f1796, %f1019, %f1030;
	sub.f32 	%f1032, %f1023, %f1024;
	add.f32 	%f1033, %f1032, %f1032;
	add.f32 	%f1034, %f1025, %f1026;
	add.f32 	%f1035, %f1034, %f1034;
	add.f32 	%f1036, %f1023, %f1024;
	add.f32 	%f1037, %f1036, %f1036;
	sub.f32 	%f1038, %f1021, %f1020;
	sub.f32 	%f1039, %f1038, %f1022;
	fma.rn.f32 	%f1040, %f1796, %f1019, %f1039;
	sub.f32 	%f1041, %f1027, %f1028;
	add.f32 	%f1042, %f1041, %f1041;
	sub.f32 	%f1043, %f1025, %f1026;
	add.f32 	%f1044, %f1043, %f1043;
	add.f32 	%f1045, %f1027, %f1028;
	add.f32 	%f1046, %f1045, %f1045;
	neg.f32 	%f1047, %f1020;
	sub.f32 	%f1048, %f1047, %f1021;
	add.f32 	%f1049, %f1022, %f1048;
	fma.rn.f32 	%f1050, %f1796, %f1019, %f1049;
	mul.f32 	%f1051, %f1789, %f1031;
	fma.rn.f32 	%f1052, %f1791, %f1033, %f1051;
	fma.rn.f32 	%f1805, %f1792, %f1035, %f1052;
	mul.f32 	%f1053, %f1791, %f1040;
	fma.rn.f32 	%f1054, %f1789, %f1037, %f1053;
	fma.rn.f32 	%f1802, %f1792, %f1042, %f1054;
	mul.f32 	%f1055, %f1791, %f1046;
	fma.rn.f32 	%f1056, %f1789, %f1044, %f1055;
	fma.rn.f32 	%f1799, %f1792, %f1050, %f1056;
	mul.f32 	%f1057, %f1788, %f1031;
	fma.rn.f32 	%f1804, %f1790, %f1033, %f1057;
	mul.f32 	%f1058, %f1790, %f1040;
	fma.rn.f32 	%f1801, %f1788, %f1037, %f1058;
	mul.f32 	%f1059, %f1790, %f1046;
	fma.rn.f32 	%f1798, %f1788, %f1044, %f1059;
	mul.f32 	%f1803, %f1787, %f1031;
	mul.f32 	%f1800, %f1787, %f1037;
	mul.f32 	%f1797, %f1787, %f1044;

$L__BB14_38:
	mul.f32 	%f1091, %f1798, %f1802;
	mul.f32 	%f1092, %f1799, %f1801;
	sub.f32 	%f1093, %f1092, %f1091;
	mul.f32 	%f1094, %f1803, %f1093;
	mul.f32 	%f1095, %f1797, %f1802;
	mul.f32 	%f1096, %f1799, %f1800;
	sub.f32 	%f1097, %f1096, %f1095;
	mul.f32 	%f1098, %f1097, %f1804;
	sub.f32 	%f1099, %f1094, %f1098;
	mul.f32 	%f1100, %f1797, %f1801;
	mul.f32 	%f1101, %f1798, %f1800;
	sub.f32 	%f1102, %f1101, %f1100;
	fma.rn.f32 	%f1103, %f1102, %f1805, %f1099;
	rcp.rn.f32 	%f1104, %f1103;
	mul.f32 	%f1812, %f1093, %f1104;
	mul.f32 	%f1105, %f1799, %f1804;
	mul.f32 	%f1106, %f1798, %f1805;
	sub.f32 	%f1107, %f1106, %f1105;
	mul.f32 	%f1813, %f1107, %f1104;
	mul.f32 	%f1108, %f1801, %f1805;
	mul.f32 	%f1109, %f1802, %f1804;
	sub.f32 	%f1110, %f1109, %f1108;
	mul.f32 	%f1814, %f1110, %f1104;
	sub.f32 	%f1111, %f1095, %f1096;
	mul.f32 	%f1809, %f1111, %f1104;
	mul.f32 	%f1112, %f1797, %f1805;
	mul.f32 	%f1113, %f1799, %f1803;
	sub.f32 	%f1114, %f1113, %f1112;
	mul.f32 	%f1810, %f1114, %f1104;
	mul.f32 	%f1115, %f1802, %f1803;
	mul.f32 	%f1116, %f1800, %f1805;
	sub.f32 	%f1117, %f1116, %f1115;
	mul.f32 	%f1811, %f1117, %f1104;
	mul.f32 	%f1806, %f1102, %f1104;
	mul.f32 	%f1118, %f1798, %f1803;
	mul.f32 	%f1119, %f1797, %f1804;
	sub.f32 	%f1120, %f1119, %f1118;
	mul.f32 	%f1807, %f1120, %f1104;
	mul.f32 	%f1121, %f1800, %f1804;
	mul.f32 	%f1122, %f1801, %f1803;
	sub.f32 	%f1123, %f1122, %f1121;
	mul.f32 	%f1808, %f1123, %f1104;
	bra.uni 	$L__BB14_39;

$L__BB14_30:
	// begin inline asm
	call (%rd631), _optix_get_instance_inverse_transform_from_handle, (%rd165);
	// end inline asm

$L__BB14_31:
	// begin inline asm
	cvta.to.global.u64 %rd171, %rd631;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r188,%r189,%r190,%r191}, [%rd171];
	// end inline asm
	mov.b32 	%f1812, %r188;
	mov.b32 	%f1813, %r189;
	mov.b32 	%f1814, %r190;
	add.s64 	%rd175, %rd631, 16;
	// begin inline asm
	cvta.to.global.u64 %rd174, %rd175;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r192,%r193,%r194,%r195}, [%rd174];
	// end inline asm
	mov.b32 	%f1809, %r192;
	mov.b32 	%f1810, %r193;
	mov.b32 	%f1811, %r194;
	add.s64 	%rd178, %rd631, 32;
	// begin inline asm
	cvta.to.global.u64 %rd177, %rd178;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r196,%r197,%r198,%r199}, [%rd177];
	// end inline asm
	mov.b32 	%f1806, %r196;
	mov.b32 	%f1807, %r197;
	mov.b32 	%f1808, %r198;

$L__BB14_39:
	setp.eq.s32 	%p20, %r643, 0;
	@%p20 bra 	$L__BB14_41;

	mul.f32 	%f1124, %f1783, %f1813;
	fma.rn.f32 	%f1125, %f1780, %f1812, %f1124;
	fma.rn.f32 	%f304, %f1786, %f1814, %f1125;
	mul.f32 	%f1126, %f1782, %f1813;
	fma.rn.f32 	%f1127, %f1779, %f1812, %f1126;
	fma.rn.f32 	%f305, %f1785, %f1814, %f1127;
	mul.f32 	%f1128, %f1781, %f1813;
	fma.rn.f32 	%f1129, %f1778, %f1812, %f1128;
	fma.rn.f32 	%f1814, %f1784, %f1814, %f1129;
	mul.f32 	%f1130, %f1783, %f1810;
	fma.rn.f32 	%f1131, %f1780, %f1809, %f1130;
	fma.rn.f32 	%f307, %f1786, %f1811, %f1131;
	mul.f32 	%f1132, %f1782, %f1810;
	fma.rn.f32 	%f1133, %f1779, %f1809, %f1132;
	fma.rn.f32 	%f308, %f1785, %f1811, %f1133;
	mul.f32 	%f1134, %f1781, %f1810;
	fma.rn.f32 	%f1135, %f1778, %f1809, %f1134;
	fma.rn.f32 	%f1811, %f1784, %f1811, %f1135;
	mul.f32 	%f1136, %f1783, %f1807;
	fma.rn.f32 	%f1137, %f1780, %f1806, %f1136;
	fma.rn.f32 	%f310, %f1786, %f1808, %f1137;
	mul.f32 	%f1138, %f1782, %f1807;
	fma.rn.f32 	%f1139, %f1779, %f1806, %f1138;
	fma.rn.f32 	%f311, %f1785, %f1808, %f1139;
	mul.f32 	%f1140, %f1781, %f1807;
	fma.rn.f32 	%f1141, %f1778, %f1806, %f1140;
	fma.rn.f32 	%f1808, %f1784, %f1808, %f1141;
	mov.f32 	%f1806, %f310;
	mov.f32 	%f1807, %f311;
	mov.f32 	%f1809, %f307;
	mov.f32 	%f1810, %f308;
	mov.f32 	%f1812, %f304;
	mov.f32 	%f1813, %f305;

$L__BB14_41:
	add.s32 	%r643, %r643, 1;
	setp.lt.u32 	%p21, %r643, %r183;
	mov.f32 	%f1778, %f1814;
	mov.f32 	%f1779, %f1813;
	mov.f32 	%f1780, %f1812;
	mov.f32 	%f1781, %f1811;
	mov.f32 	%f1782, %f1810;
	mov.f32 	%f1783, %f1809;
	mov.f32 	%f1784, %f1808;
	mov.f32 	%f1785, %f1807;
	mov.f32 	%f1786, %f1806;
	@%p21 bra 	$L__BB14_26;

$L__BB14_42:
	mul.f32 	%f1142, %f1834, %f1813;
	fma.rn.f32 	%f1143, %f1833, %f1812, %f1142;
	mul.f32 	%f1144, %f1834, %f1810;
	fma.rn.f32 	%f1145, %f1833, %f1809, %f1144;
	mul.f32 	%f1146, %f1834, %f1807;
	fma.rn.f32 	%f1147, %f1833, %f1806, %f1146;
	fma.rn.f32 	%f1835, %f955, %f1808, %f1147;
	fma.rn.f32 	%f1834, %f955, %f1811, %f1145;
	fma.rn.f32 	%f1833, %f955, %f1814, %f1143;
	bra.uni 	$L__BB14_44;

$L__BB14_43:
	mov.f32 	%f1835, %f955;

$L__BB14_44:
	// begin inline asm
	call (%f1149), _optix_get_ray_tmax, ();
	// end inline asm
	fma.rn.f32 	%f1984, %f1149, %f1835, %f1777;
	add.s64 	%rd18, %rd3, 320;
	ld.f32 	%f346, [%rd3+320];
	setp.eq.f32 	%p22, %f1984, %f346;
	@%p22 bra 	$L__BB14_49;

	ld.f32 	%f1151, [%rd18+4];
	setp.eq.f32 	%p23, %f1984, %f1151;
	@%p23 bra 	$L__BB14_49;
	bra.uni 	$L__BB14_46;

$L__BB14_49:
	mov.f32 	%f1175, 0f00000000;
	fma.rn.f32 	%f358, %f1175, %f1175, %f1175;
	@%p22 bra 	$L__BB14_51;
	bra.uni 	$L__BB14_50;

$L__BB14_51:
	mov.f32 	%f1180, 0fBF800000;
	fma.rn.f32 	%f1181, %f1180, %f1180, %f358;
	sqrt.rn.f32 	%f1182, %f1181;
	div.rn.f32 	%f1837, %f1175, %f1182;
	div.rn.f32 	%f1836, %f1180, %f1182;
	mov.f32 	%f1838, %f1837;
	bra.uni 	$L__BB14_52;

$L__BB14_50:
	mov.f32 	%f1176, 0f3F800000;
	fma.rn.f32 	%f1177, %f1176, %f1176, %f358;
	sqrt.rn.f32 	%f1178, %f1177;
	div.rn.f32 	%f1837, %f1175, %f1178;
	rcp.rn.f32 	%f1836, %f1178;
	mov.f32 	%f1838, %f1837;

$L__BB14_52:
	fma.rn.f32 	%f1982, %f1149, %f1833, %f1775;
	fma.rn.f32 	%f1983, %f1149, %f1834, %f1776;
	ld.u64 	%rd19, [%rd45];
	ld.const.u64 	%rd284, [params+344];
	cvta.to.global.u64 	%rd285, %rd284;
	cvt.u64.u32 	%rd20, %r1;
	mul.wide.u32 	%rd286, %r1, 4;
	add.s64 	%rd21, %rd285, %rd286;
	ld.global.u32 	%r10, [%rd21];
	setp.eq.s32 	%p26, %r10, 0;
	mov.f32 	%f1970, 0f00000000;
	mov.f32 	%f1971, 0f00000000;
	mov.f32 	%f1972, 0f00000000;
	mov.f32 	%f1973, 0f00000000;
	mov.f32 	%f1974, 0f00000000;
	mov.f32 	%f1975, 0f00000000;
	mov.f32 	%f1979, %f1838;
	mov.f32 	%f1980, %f1837;
	mov.f32 	%f1981, %f1836;
	@%p26 bra 	$L__BB14_100;

	// begin inline asm
	call (%r334), _optix_read_instance_id, ();
	// end inline asm
	setp.ge.u32 	%p27, %r334, %r10;
	mov.f32 	%f1979, %f1838;
	mov.f32 	%f1980, %f1837;
	mov.f32 	%f1981, %f1836;
	@%p27 bra 	$L__BB14_100;

	// begin inline asm
	call (%r335), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p28, %r335, 0;
	mov.f32 	%f1938, 0f00000000;
	mov.f32 	%f1937, 0f3F800000;
	mov.f32 	%f1875, %f1937;
	mov.f32 	%f1876, %f1938;
	mov.f32 	%f1877, %f1938;
	mov.f32 	%f1878, %f1938;
	mov.f32 	%f1871, %f1938;
	mov.f32 	%f1872, %f1937;
	mov.f32 	%f1873, %f1938;
	mov.f32 	%f1874, %f1938;
	mov.f32 	%f1867, %f1938;
	mov.f32 	%f1868, %f1938;
	mov.f32 	%f1869, %f1937;
	mov.f32 	%f1870, %f1938;
	@%p28 bra 	$L__BB14_72;

	// begin inline asm
	call (%r336), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1208), _optix_get_ray_time, ();
	// end inline asm
	setp.lt.s32 	%p29, %r336, 1;
	@%p29 bra 	$L__BB14_72;

	add.s32 	%r644, %r336, 1;
	mov.u32 	%r645, 1;

$L__BB14_57:
	.pragma "nounroll";
	add.s32 	%r338, %r644, -2;
	// begin inline asm
	call (%rd287), _optix_get_transform_list_handle, (%r338);
	// end inline asm
	// begin inline asm
	call (%r339), _optix_get_transform_type_from_handle, (%rd287);
	// end inline asm
	or.b32  	%r340, %r339, 1;
	setp.eq.s32 	%p30, %r340, 3;
	@%p30 bra 	$L__BB14_63;
	bra.uni 	$L__BB14_58;

$L__BB14_63:
	setp.eq.s32 	%p33, %r339, 2;
	@%p33 bra 	$L__BB14_67;
	bra.uni 	$L__BB14_64;

$L__BB14_67:
	// begin inline asm
	call (%rd359), _optix_get_matrix_motion_transform_from_handle, (%rd287);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd361, %rd359;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r428,%r429,%r430,%r431}, [%rd361];
	// end inline asm
	add.s64 	%rd365, %rd359, 16;
	// begin inline asm
	cvta.to.global.u64 %rd364, %rd365;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r432,%r433,%r434,%r435}, [%rd364];
	// end inline asm
	add.s64 	%rd368, %rd359, 32;
	// begin inline asm
	cvta.to.global.u64 %rd367, %rd368;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r436,%r437,%r438,%r439}, [%rd367];
	// end inline asm
	add.s64 	%rd371, %rd359, 48;
	// begin inline asm
	cvta.to.global.u64 %rd370, %rd371;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r440,%r441,%r442,%r443}, [%rd370];
	// end inline asm
	add.s64 	%rd374, %rd359, 64;
	// begin inline asm
	cvta.to.global.u64 %rd373, %rd374;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r444,%r445,%r446,%r447}, [%rd373];
	// end inline asm
	add.s64 	%rd377, %rd359, 80;
	// begin inline asm
	cvta.to.global.u64 %rd376, %rd377;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r448,%r449,%r450,%r451}, [%rd376];
	// end inline asm
	add.s64 	%rd380, %rd359, 96;
	// begin inline asm
	cvta.to.global.u64 %rd379, %rd380;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r452,%r453,%r454,%r455}, [%rd379];
	// end inline asm
	add.s64 	%rd383, %rd359, 112;
	// begin inline asm
	cvta.to.global.u64 %rd382, %rd383;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r456,%r457,%r458,%r459}, [%rd382];
	// end inline asm
	mov.b32 	%f1336, %r431;
	mov.b32 	%f1337, %r432;
	and.b32  	%r472, %r430, 65535;
	add.s32 	%r473, %r472, -1;
	cvt.rn.f32.s32 	%f1338, %r473;
	sub.f32 	%f1339, %f1208, %f1336;
	mul.f32 	%f1340, %f1339, %f1338;
	sub.f32 	%f1341, %f1337, %f1336;
	div.rn.f32 	%f1342, %f1340, %f1341;
	min.f32 	%f1343, %f1338, %f1342;
	mov.f32 	%f1344, 0f00000000;
	max.f32 	%f1345, %f1344, %f1343;
	cvt.rmi.f32.f32 	%f1346, %f1345;
	sub.f32 	%f454, %f1345, %f1346;
	cvt.rzi.s32.f32 	%r474, %f1346;
	cvt.s64.s32 	%rd28, %r474;
	mul.wide.s32 	%rd394, %r474, 48;
	add.s64 	%rd386, %rd368, %rd394;
	// begin inline asm
	cvta.to.global.u64 %rd385, %rd386;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r460,%r461,%r462,%r463}, [%rd385];
	// end inline asm
	mov.b32 	%f1875, %r460;
	mov.b32 	%f1876, %r461;
	mov.b32 	%f1877, %r462;
	mov.b32 	%f1878, %r463;
	add.s64 	%rd389, %rd386, 16;
	// begin inline asm
	cvta.to.global.u64 %rd388, %rd389;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r464,%r465,%r466,%r467}, [%rd388];
	// end inline asm
	mov.b32 	%f1871, %r464;
	mov.b32 	%f1872, %r465;
	mov.b32 	%f1873, %r466;
	mov.b32 	%f1874, %r467;
	add.s64 	%rd392, %rd386, 32;
	// begin inline asm
	cvta.to.global.u64 %rd391, %rd392;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r468,%r469,%r470,%r471}, [%rd391];
	// end inline asm
	mov.b32 	%f1867, %r468;
	mov.b32 	%f1868, %r469;
	mov.b32 	%f1869, %r470;
	mov.b32 	%f1870, %r471;
	setp.leu.f32 	%p35, %f454, 0f00000000;
	@%p35 bra 	$L__BB14_69;

	mov.f32 	%f1347, 0f3F800000;
	sub.f32 	%f1348, %f1347, %f454;
	mul.lo.s64 	%rd404, %rd28, 48;
	add.s64 	%rd405, %rd359, %rd404;
	add.s64 	%rd396, %rd405, 80;
	// begin inline asm
	cvta.to.global.u64 %rd395, %rd396;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r475,%r476,%r477,%r478}, [%rd395];
	// end inline asm
	mov.b32 	%f1349, %r475;
	mov.b32 	%f1350, %r476;
	mov.b32 	%f1351, %r477;
	mov.b32 	%f1352, %r478;
	mul.f32 	%f1353, %f454, %f1349;
	mul.f32 	%f1354, %f454, %f1350;
	mul.f32 	%f1355, %f454, %f1351;
	mul.f32 	%f1356, %f454, %f1352;
	fma.rn.f32 	%f1875, %f1348, %f1875, %f1353;
	fma.rn.f32 	%f1876, %f1348, %f1876, %f1354;
	fma.rn.f32 	%f1877, %f1348, %f1877, %f1355;
	fma.rn.f32 	%f1878, %f1348, %f1878, %f1356;
	add.s64 	%rd399, %rd405, 96;
	// begin inline asm
	cvta.to.global.u64 %rd398, %rd399;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r479,%r480,%r481,%r482}, [%rd398];
	// end inline asm
	mov.b32 	%f1357, %r479;
	mov.b32 	%f1358, %r480;
	mov.b32 	%f1359, %r481;
	mov.b32 	%f1360, %r482;
	mul.f32 	%f1361, %f454, %f1357;
	mul.f32 	%f1362, %f454, %f1358;
	mul.f32 	%f1363, %f454, %f1359;
	mul.f32 	%f1364, %f454, %f1360;
	fma.rn.f32 	%f1871, %f1348, %f1871, %f1361;
	fma.rn.f32 	%f1872, %f1348, %f1872, %f1362;
	fma.rn.f32 	%f1873, %f1348, %f1873, %f1363;
	fma.rn.f32 	%f1874, %f1348, %f1874, %f1364;
	add.s64 	%rd402, %rd405, 112;
	// begin inline asm
	cvta.to.global.u64 %rd401, %rd402;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r483,%r484,%r485,%r486}, [%rd401];
	// end inline asm
	mov.b32 	%f1365, %r483;
	mov.b32 	%f1366, %r484;
	mov.b32 	%f1367, %r485;
	mov.b32 	%f1368, %r486;
	mul.f32 	%f1369, %f454, %f1365;
	mul.f32 	%f1370, %f454, %f1366;
	mul.f32 	%f1371, %f454, %f1367;
	mul.f32 	%f1372, %f454, %f1368;
	fma.rn.f32 	%f1867, %f1348, %f1867, %f1369;
	fma.rn.f32 	%f1868, %f1348, %f1868, %f1370;
	fma.rn.f32 	%f1869, %f1348, %f1869, %f1371;
	fma.rn.f32 	%f1870, %f1348, %f1870, %f1372;
	bra.uni 	$L__BB14_69;

$L__BB14_58:
	mov.f32 	%f1867, 0f00000000;
	mov.f32 	%f1869, 0f3F800000;
	setp.eq.s32 	%p31, %r339, 4;
	@%p31 bra 	$L__BB14_61;

	setp.ne.s32 	%p32, %r339, 1;
	mov.f32 	%f1868, %f1867;
	mov.f32 	%f1870, %f1867;
	mov.f32 	%f1871, %f1867;
	mov.f32 	%f1872, %f1869;
	mov.f32 	%f1873, %f1867;
	mov.f32 	%f1874, %f1867;
	mov.f32 	%f1875, %f1869;
	mov.f32 	%f1876, %f1867;
	mov.f32 	%f1877, %f1867;
	mov.f32 	%f1878, %f1867;
	@%p32 bra 	$L__BB14_69;

	// begin inline asm
	call (%rd289), _optix_get_static_transform_from_handle, (%rd287);
	// end inline asm
	add.s64 	%rd632, %rd289, 16;
	bra.uni 	$L__BB14_62;

$L__BB14_64:
	// begin inline asm
	call (%rd302), _optix_get_srt_motion_transform_from_handle, (%rd287);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd304, %rd302;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r353,%r354,%r355,%r356}, [%rd304];
	// end inline asm
	add.s64 	%rd308, %rd302, 16;
	// begin inline asm
	cvta.to.global.u64 %rd307, %rd308;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r357,%r358,%r359,%r360}, [%rd307];
	// end inline asm
	add.s64 	%rd311, %rd302, 32;
	// begin inline asm
	cvta.to.global.u64 %rd310, %rd311;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r361,%r362,%r363,%r364}, [%rd310];
	// end inline asm
	add.s64 	%rd314, %rd302, 48;
	// begin inline asm
	cvta.to.global.u64 %rd313, %rd314;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r365,%r366,%r367,%r368}, [%rd313];
	// end inline asm
	add.s64 	%rd317, %rd302, 64;
	// begin inline asm
	cvta.to.global.u64 %rd316, %rd317;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r369,%r370,%r371,%r372}, [%rd316];
	// end inline asm
	add.s64 	%rd320, %rd302, 80;
	// begin inline asm
	cvta.to.global.u64 %rd319, %rd320;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r373,%r374,%r375,%r376}, [%rd319];
	// end inline asm
	add.s64 	%rd323, %rd302, 96;
	// begin inline asm
	cvta.to.global.u64 %rd322, %rd323;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r377,%r378,%r379,%r380}, [%rd322];
	// end inline asm
	add.s64 	%rd326, %rd302, 112;
	// begin inline asm
	cvta.to.global.u64 %rd325, %rd326;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r381,%r382,%r383,%r384}, [%rd325];
	// end inline asm
	add.s64 	%rd329, %rd302, 128;
	// begin inline asm
	cvta.to.global.u64 %rd328, %rd329;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r385,%r386,%r387,%r388}, [%rd328];
	// end inline asm
	add.s64 	%rd332, %rd302, 144;
	// begin inline asm
	cvta.to.global.u64 %rd331, %rd332;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r389,%r390,%r391,%r392}, [%rd331];
	// end inline asm
	mov.b32 	%f1223, %r356;
	mov.b32 	%f1224, %r357;
	and.b32  	%r409, %r355, 65535;
	add.s32 	%r410, %r409, -1;
	cvt.rn.f32.s32 	%f1225, %r410;
	sub.f32 	%f1226, %f1208, %f1223;
	mul.f32 	%f1227, %f1226, %f1225;
	sub.f32 	%f1228, %f1224, %f1223;
	div.rn.f32 	%f1229, %f1227, %f1228;
	min.f32 	%f1230, %f1225, %f1229;
	mov.f32 	%f1231, 0f00000000;
	max.f32 	%f1232, %f1231, %f1230;
	cvt.rmi.f32.f32 	%f1233, %f1232;
	sub.f32 	%f393, %f1232, %f1233;
	cvt.rzi.s32.f32 	%r411, %f1233;
	mul.wide.s32 	%rd346, %r411, 64;
	add.s64 	%rd335, %rd311, %rd346;
	// begin inline asm
	cvta.to.global.u64 %rd334, %rd335;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r393,%r394,%r395,%r396}, [%rd334];
	// end inline asm
	mov.b32 	%f1851, %r393;
	mov.b32 	%f1852, %r394;
	mov.b32 	%f1853, %r395;
	mov.b32 	%f1854, %r396;
	add.s64 	%rd338, %rd335, 16;
	// begin inline asm
	cvta.to.global.u64 %rd337, %rd338;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r397,%r398,%r399,%r400}, [%rd337];
	// end inline asm
	mov.b32 	%f1855, %r397;
	mov.b32 	%f1856, %r398;
	mov.b32 	%f1857, %r399;
	mov.b32 	%f1858, %r400;
	add.s64 	%rd341, %rd335, 32;
	// begin inline asm
	cvta.to.global.u64 %rd340, %rd341;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r401,%r402,%r403,%r404}, [%rd340];
	// end inline asm
	mov.b32 	%f1859, %r401;
	mov.b32 	%f1860, %r402;
	mov.b32 	%f1861, %r403;
	mov.b32 	%f1862, %r404;
	add.s64 	%rd344, %rd335, 48;
	// begin inline asm
	cvta.to.global.u64 %rd343, %rd344;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r405,%r406,%r407,%r408}, [%rd343];
	// end inline asm
	mov.b32 	%f1863, %r405;
	mov.b32 	%f1864, %r406;
	mov.b32 	%f1865, %r407;
	mov.b32 	%f1866, %r408;
	setp.leu.f32 	%p34, %f393, 0f00000000;
	@%p34 bra 	$L__BB14_66;

	mov.f32 	%f1234, 0f3F800000;
	sub.f32 	%f1235, %f1234, %f393;
	add.s64 	%rd348, %rd335, 64;
	// begin inline asm
	cvta.to.global.u64 %rd347, %rd348;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r412,%r413,%r414,%r415}, [%rd347];
	// end inline asm
	mov.b32 	%f1236, %r412;
	mov.b32 	%f1237, %r413;
	mov.b32 	%f1238, %r414;
	mov.b32 	%f1239, %r415;
	mul.f32 	%f1240, %f393, %f1236;
	mul.f32 	%f1241, %f393, %f1237;
	mul.f32 	%f1242, %f393, %f1238;
	mul.f32 	%f1243, %f393, %f1239;
	fma.rn.f32 	%f1851, %f1235, %f1851, %f1240;
	fma.rn.f32 	%f1852, %f1235, %f1852, %f1241;
	fma.rn.f32 	%f1853, %f1235, %f1853, %f1242;
	fma.rn.f32 	%f1854, %f1235, %f1854, %f1243;
	add.s64 	%rd351, %rd335, 80;
	// begin inline asm
	cvta.to.global.u64 %rd350, %rd351;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r416,%r417,%r418,%r419}, [%rd350];
	// end inline asm
	mov.b32 	%f1244, %r416;
	mov.b32 	%f1245, %r417;
	mov.b32 	%f1246, %r418;
	mov.b32 	%f1247, %r419;
	mul.f32 	%f1248, %f393, %f1244;
	mul.f32 	%f1249, %f393, %f1245;
	mul.f32 	%f1250, %f393, %f1246;
	mul.f32 	%f1251, %f393, %f1247;
	fma.rn.f32 	%f1855, %f1235, %f1855, %f1248;
	fma.rn.f32 	%f1856, %f1235, %f1856, %f1249;
	fma.rn.f32 	%f1857, %f1235, %f1857, %f1250;
	fma.rn.f32 	%f1858, %f1235, %f1858, %f1251;
	add.s64 	%rd354, %rd335, 96;
	// begin inline asm
	cvta.to.global.u64 %rd353, %rd354;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r420,%r421,%r422,%r423}, [%rd353];
	// end inline asm
	mov.b32 	%f1252, %r420;
	mov.b32 	%f1253, %r421;
	mov.b32 	%f1254, %r422;
	mov.b32 	%f1255, %r423;
	mul.f32 	%f1256, %f393, %f1252;
	mul.f32 	%f1257, %f393, %f1253;
	mul.f32 	%f1258, %f393, %f1254;
	mul.f32 	%f1259, %f393, %f1255;
	fma.rn.f32 	%f1859, %f1235, %f1859, %f1256;
	fma.rn.f32 	%f1260, %f1235, %f1860, %f1257;
	fma.rn.f32 	%f1261, %f1235, %f1861, %f1258;
	fma.rn.f32 	%f1262, %f1235, %f1862, %f1259;
	add.s64 	%rd357, %rd335, 112;
	// begin inline asm
	cvta.to.global.u64 %rd356, %rd357;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r424,%r425,%r426,%r427}, [%rd356];
	// end inline asm
	mov.b32 	%f1263, %r424;
	mov.b32 	%f1264, %r425;
	mov.b32 	%f1265, %r426;
	mov.b32 	%f1266, %r427;
	mul.f32 	%f1267, %f393, %f1263;
	mul.f32 	%f1268, %f393, %f1264;
	mul.f32 	%f1269, %f393, %f1265;
	mul.f32 	%f1270, %f393, %f1266;
	fma.rn.f32 	%f1271, %f1235, %f1863, %f1267;
	fma.rn.f32 	%f1864, %f1235, %f1864, %f1268;
	fma.rn.f32 	%f1865, %f1235, %f1865, %f1269;
	fma.rn.f32 	%f1866, %f1235, %f1866, %f1270;
	mul.f32 	%f1272, %f1261, %f1261;
	fma.rn.f32 	%f1273, %f1260, %f1260, %f1272;
	fma.rn.f32 	%f1274, %f1262, %f1262, %f1273;
	fma.rn.f32 	%f1275, %f1271, %f1271, %f1274;
	sqrt.rn.f32 	%f1276, %f1275;
	rcp.rn.f32 	%f1277, %f1276;
	mul.f32 	%f1860, %f1260, %f1277;
	mul.f32 	%f1861, %f1261, %f1277;
	mul.f32 	%f1862, %f1262, %f1277;
	mul.f32 	%f1863, %f1277, %f1271;

$L__BB14_66:
	mul.f32 	%f1278, %f1861, %f1861;
	fma.rn.f32 	%f1279, %f1860, %f1860, %f1278;
	fma.rn.f32 	%f1280, %f1862, %f1862, %f1279;
	fma.rn.f32 	%f1281, %f1863, %f1863, %f1280;
	rcp.rn.f32 	%f1282, %f1281;
	mul.f32 	%f1283, %f1860, %f1282;
	mul.f32 	%f1284, %f1861, %f1282;
	mul.f32 	%f1285, %f1862, %f1282;
	mul.f32 	%f1286, %f1863, %f1282;
	mul.f32 	%f1287, %f1860, %f1283;
	mul.f32 	%f1288, %f1861, %f1284;
	mul.f32 	%f1289, %f1862, %f1285;
	mul.f32 	%f1290, %f1860, %f1284;
	mul.f32 	%f1291, %f1862, %f1286;
	mul.f32 	%f1292, %f1860, %f1285;
	mul.f32 	%f1293, %f1861, %f1286;
	mul.f32 	%f1294, %f1861, %f1285;
	mul.f32 	%f1295, %f1860, %f1286;
	sub.f32 	%f1296, %f1287, %f1288;
	sub.f32 	%f1297, %f1296, %f1289;
	fma.rn.f32 	%f1298, %f1863, %f1286, %f1297;
	sub.f32 	%f1299, %f1290, %f1291;
	add.f32 	%f1300, %f1299, %f1299;
	add.f32 	%f1301, %f1292, %f1293;
	add.f32 	%f1302, %f1301, %f1301;
	add.f32 	%f1303, %f1290, %f1291;
	add.f32 	%f1304, %f1303, %f1303;
	sub.f32 	%f1305, %f1288, %f1287;
	sub.f32 	%f1306, %f1305, %f1289;
	fma.rn.f32 	%f1307, %f1863, %f1286, %f1306;
	sub.f32 	%f1308, %f1294, %f1295;
	add.f32 	%f1309, %f1308, %f1308;
	sub.f32 	%f1310, %f1292, %f1293;
	add.f32 	%f1311, %f1310, %f1310;
	add.f32 	%f1312, %f1294, %f1295;
	add.f32 	%f1313, %f1312, %f1312;
	neg.f32 	%f1314, %f1287;
	sub.f32 	%f1315, %f1314, %f1288;
	add.f32 	%f1316, %f1289, %f1315;
	fma.rn.f32 	%f1317, %f1863, %f1286, %f1316;
	mul.f32 	%f1318, %f1854, %f1298;
	fma.rn.f32 	%f1319, %f1857, %f1300, %f1318;
	fma.rn.f32 	%f1320, %f1859, %f1302, %f1319;
	sub.f32 	%f1878, %f1864, %f1320;
	mul.f32 	%f1321, %f1857, %f1307;
	fma.rn.f32 	%f1322, %f1854, %f1304, %f1321;
	fma.rn.f32 	%f1323, %f1859, %f1309, %f1322;
	sub.f32 	%f1874, %f1865, %f1323;
	mul.f32 	%f1324, %f1857, %f1313;
	fma.rn.f32 	%f1325, %f1854, %f1311, %f1324;
	fma.rn.f32 	%f1326, %f1859, %f1317, %f1325;
	sub.f32 	%f1870, %f1866, %f1326;
	mul.f32 	%f1327, %f1853, %f1298;
	fma.rn.f32 	%f1328, %f1856, %f1300, %f1327;
	fma.rn.f32 	%f1877, %f1858, %f1302, %f1328;
	mul.f32 	%f1329, %f1856, %f1307;
	fma.rn.f32 	%f1330, %f1853, %f1304, %f1329;
	fma.rn.f32 	%f1873, %f1858, %f1309, %f1330;
	mul.f32 	%f1331, %f1856, %f1313;
	fma.rn.f32 	%f1332, %f1853, %f1311, %f1331;
	fma.rn.f32 	%f1869, %f1858, %f1317, %f1332;
	mul.f32 	%f1333, %f1852, %f1298;
	fma.rn.f32 	%f1876, %f1855, %f1300, %f1333;
	mul.f32 	%f1334, %f1855, %f1307;
	fma.rn.f32 	%f1872, %f1852, %f1304, %f1334;
	mul.f32 	%f1335, %f1855, %f1313;
	fma.rn.f32 	%f1868, %f1852, %f1311, %f1335;
	mul.f32 	%f1875, %f1851, %f1298;
	mul.f32 	%f1871, %f1851, %f1304;
	mul.f32 	%f1867, %f1851, %f1311;
	bra.uni 	$L__BB14_69;

$L__BB14_61:
	// begin inline asm
	call (%rd632), _optix_get_instance_transform_from_handle, (%rd287);
	// end inline asm

$L__BB14_62:
	// begin inline asm
	cvta.to.global.u64 %rd293, %rd632;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r341,%r342,%r343,%r344}, [%rd293];
	// end inline asm
	mov.b32 	%f1875, %r341;
	mov.b32 	%f1876, %r342;
	mov.b32 	%f1877, %r343;
	mov.b32 	%f1878, %r344;
	add.s64 	%rd297, %rd632, 16;
	// begin inline asm
	cvta.to.global.u64 %rd296, %rd297;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r345,%r346,%r347,%r348}, [%rd296];
	// end inline asm
	mov.b32 	%f1871, %r345;
	mov.b32 	%f1872, %r346;
	mov.b32 	%f1873, %r347;
	mov.b32 	%f1874, %r348;
	add.s64 	%rd300, %rd632, 32;
	// begin inline asm
	cvta.to.global.u64 %rd299, %rd300;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r349,%r350,%r351,%r352}, [%rd299];
	// end inline asm
	mov.b32 	%f1867, %r349;
	mov.b32 	%f1868, %r350;
	mov.b32 	%f1869, %r351;
	mov.b32 	%f1870, %r352;

$L__BB14_69:
	setp.eq.s32 	%p36, %r645, 1;
	@%p36 bra 	$L__BB14_71;

	mul.f32 	%f1373, %f1846, %f1876;
	fma.rn.f32 	%f1374, %f1842, %f1875, %f1373;
	fma.rn.f32 	%f491, %f1850, %f1877, %f1374;
	mul.f32 	%f1375, %f1845, %f1876;
	fma.rn.f32 	%f1376, %f1841, %f1875, %f1375;
	fma.rn.f32 	%f492, %f1849, %f1877, %f1376;
	mul.f32 	%f1377, %f1844, %f1876;
	fma.rn.f32 	%f1378, %f1840, %f1875, %f1377;
	fma.rn.f32 	%f493, %f1848, %f1877, %f1378;
	mul.f32 	%f1379, %f1843, %f1876;
	fma.rn.f32 	%f1380, %f1839, %f1875, %f1379;
	fma.rn.f32 	%f1381, %f1847, %f1877, %f1380;
	add.f32 	%f1878, %f1878, %f1381;
	mul.f32 	%f1382, %f1846, %f1872;
	fma.rn.f32 	%f1383, %f1842, %f1871, %f1382;
	fma.rn.f32 	%f495, %f1850, %f1873, %f1383;
	mul.f32 	%f1384, %f1845, %f1872;
	fma.rn.f32 	%f1385, %f1841, %f1871, %f1384;
	fma.rn.f32 	%f496, %f1849, %f1873, %f1385;
	mul.f32 	%f1386, %f1844, %f1872;
	fma.rn.f32 	%f1387, %f1840, %f1871, %f1386;
	fma.rn.f32 	%f497, %f1848, %f1873, %f1387;
	mul.f32 	%f1388, %f1843, %f1872;
	fma.rn.f32 	%f1389, %f1839, %f1871, %f1388;
	fma.rn.f32 	%f1390, %f1847, %f1873, %f1389;
	add.f32 	%f1874, %f1874, %f1390;
	mul.f32 	%f1391, %f1846, %f1868;
	fma.rn.f32 	%f1392, %f1842, %f1867, %f1391;
	fma.rn.f32 	%f499, %f1850, %f1869, %f1392;
	mul.f32 	%f1393, %f1845, %f1868;
	fma.rn.f32 	%f1394, %f1841, %f1867, %f1393;
	fma.rn.f32 	%f500, %f1849, %f1869, %f1394;
	mul.f32 	%f1395, %f1844, %f1868;
	fma.rn.f32 	%f1396, %f1840, %f1867, %f1395;
	fma.rn.f32 	%f501, %f1848, %f1869, %f1396;
	mul.f32 	%f1397, %f1843, %f1868;
	fma.rn.f32 	%f1398, %f1839, %f1867, %f1397;
	fma.rn.f32 	%f1399, %f1847, %f1869, %f1398;
	add.f32 	%f1870, %f1870, %f1399;
	mov.f32 	%f1867, %f499;
	mov.f32 	%f1868, %f500;
	mov.f32 	%f1869, %f501;
	mov.f32 	%f1871, %f495;
	mov.f32 	%f1872, %f496;
	mov.f32 	%f1873, %f497;
	mov.f32 	%f1875, %f491;
	mov.f32 	%f1876, %f492;
	mov.f32 	%f1877, %f493;

$L__BB14_71:
	add.s32 	%r645, %r645, -1;
	add.s32 	%r644, %r644, -1;
	setp.gt.s32 	%p37, %r644, 1;
	mov.f32 	%f1839, %f1878;
	mov.f32 	%f1840, %f1877;
	mov.f32 	%f1841, %f1876;
	mov.f32 	%f1842, %f1875;
	mov.f32 	%f1843, %f1874;
	mov.f32 	%f1844, %f1873;
	mov.f32 	%f1845, %f1872;
	mov.f32 	%f1846, %f1871;
	mov.f32 	%f1847, %f1870;
	mov.f32 	%f1848, %f1869;
	mov.f32 	%f1849, %f1868;
	mov.f32 	%f1850, %f1867;
	@%p37 bra 	$L__BB14_57;

$L__BB14_72:
	// begin inline asm
	call (%r487), _optix_get_transform_list_size, ();
	// end inline asm
	setp.eq.s32 	%p38, %r487, 0;
	mov.f32 	%f1939, %f1938;
	mov.f32 	%f1934, %f1938;
	mov.f32 	%f1935, %f1937;
	mov.f32 	%f1936, %f1938;
	mov.f32 	%f1931, %f1938;
	mov.f32 	%f1932, %f1938;
	mov.f32 	%f1933, %f1937;
	@%p38 bra 	$L__BB14_91;

	// begin inline asm
	call (%r488), _optix_get_transform_list_size, ();
	// end inline asm
	// begin inline asm
	call (%f1409), _optix_get_ray_time, ();
	// end inline asm
	setp.eq.s32 	%p39, %r488, 0;
	@%p39 bra 	$L__BB14_91;

	mov.u32 	%r646, 0;

$L__BB14_75:
	.pragma "nounroll";
	// begin inline asm
	call (%rd406), _optix_get_transform_list_handle, (%r646);
	// end inline asm
	// begin inline asm
	call (%r491), _optix_get_transform_type_from_handle, (%rd406);
	// end inline asm
	or.b32  	%r492, %r491, 1;
	setp.eq.s32 	%p40, %r492, 3;
	@%p40 bra 	$L__BB14_81;
	bra.uni 	$L__BB14_76;

$L__BB14_81:
	setp.eq.s32 	%p43, %r491, 2;
	@%p43 bra 	$L__BB14_85;
	bra.uni 	$L__BB14_82;

$L__BB14_85:
	// begin inline asm
	call (%rd478), _optix_get_matrix_motion_transform_from_handle, (%rd406);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd480, %rd478;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r580,%r581,%r582,%r583}, [%rd480];
	// end inline asm
	add.s64 	%rd484, %rd478, 16;
	// begin inline asm
	cvta.to.global.u64 %rd483, %rd484;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r584,%r585,%r586,%r587}, [%rd483];
	// end inline asm
	add.s64 	%rd487, %rd478, 32;
	// begin inline asm
	cvta.to.global.u64 %rd486, %rd487;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r588,%r589,%r590,%r591}, [%rd486];
	// end inline asm
	add.s64 	%rd490, %rd478, 48;
	// begin inline asm
	cvta.to.global.u64 %rd489, %rd490;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r592,%r593,%r594,%r595}, [%rd489];
	// end inline asm
	add.s64 	%rd493, %rd478, 64;
	// begin inline asm
	cvta.to.global.u64 %rd492, %rd493;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r596,%r597,%r598,%r599}, [%rd492];
	// end inline asm
	add.s64 	%rd496, %rd478, 80;
	// begin inline asm
	cvta.to.global.u64 %rd495, %rd496;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r600,%r601,%r602,%r603}, [%rd495];
	// end inline asm
	add.s64 	%rd499, %rd478, 96;
	// begin inline asm
	cvta.to.global.u64 %rd498, %rd499;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r604,%r605,%r606,%r607}, [%rd498];
	// end inline asm
	add.s64 	%rd502, %rd478, 112;
	// begin inline asm
	cvta.to.global.u64 %rd501, %rd502;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r608,%r609,%r610,%r611}, [%rd501];
	// end inline asm
	mov.b32 	%f1513, %r583;
	mov.b32 	%f1514, %r584;
	and.b32  	%r624, %r582, 65535;
	add.s32 	%r625, %r624, -1;
	cvt.rn.f32.s32 	%f1515, %r625;
	sub.f32 	%f1516, %f1409, %f1513;
	mul.f32 	%f1517, %f1516, %f1515;
	sub.f32 	%f1518, %f1514, %f1513;
	div.rn.f32 	%f1519, %f1517, %f1518;
	min.f32 	%f1520, %f1515, %f1519;
	mov.f32 	%f1521, 0f00000000;
	max.f32 	%f1522, %f1521, %f1520;
	cvt.rmi.f32.f32 	%f1523, %f1522;
	sub.f32 	%f586, %f1522, %f1523;
	cvt.rzi.s32.f32 	%r626, %f1523;
	cvt.s64.s32 	%rd35, %r626;
	mul.wide.s32 	%rd513, %r626, 48;
	add.s64 	%rd505, %rd487, %rd513;
	// begin inline asm
	cvta.to.global.u64 %rd504, %rd505;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r612,%r613,%r614,%r615}, [%rd504];
	// end inline asm
	mov.b32 	%f1928, %r612;
	mov.b32 	%f1929, %r613;
	mov.b32 	%f1930, %r614;
	add.s64 	%rd508, %rd505, 16;
	// begin inline asm
	cvta.to.global.u64 %rd507, %rd508;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r616,%r617,%r618,%r619}, [%rd507];
	// end inline asm
	mov.b32 	%f1925, %r616;
	mov.b32 	%f1926, %r617;
	mov.b32 	%f1927, %r618;
	add.s64 	%rd511, %rd505, 32;
	// begin inline asm
	cvta.to.global.u64 %rd510, %rd511;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r620,%r621,%r622,%r623}, [%rd510];
	// end inline asm
	mov.b32 	%f1922, %r620;
	mov.b32 	%f1923, %r621;
	mov.b32 	%f1924, %r622;
	setp.leu.f32 	%p45, %f586, 0f00000000;
	@%p45 bra 	$L__BB14_87;

	mov.f32 	%f1524, 0f3F800000;
	sub.f32 	%f1525, %f1524, %f586;
	mul.lo.s64 	%rd523, %rd35, 48;
	add.s64 	%rd524, %rd478, %rd523;
	add.s64 	%rd515, %rd524, 80;
	// begin inline asm
	cvta.to.global.u64 %rd514, %rd515;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r627,%r628,%r629,%r630}, [%rd514];
	// end inline asm
	mov.b32 	%f1526, %r627;
	mov.b32 	%f1527, %r628;
	mov.b32 	%f1528, %r629;
	mul.f32 	%f1529, %f586, %f1526;
	mul.f32 	%f1530, %f586, %f1527;
	mul.f32 	%f1531, %f586, %f1528;
	fma.rn.f32 	%f1928, %f1525, %f1928, %f1529;
	fma.rn.f32 	%f1929, %f1525, %f1929, %f1530;
	fma.rn.f32 	%f1930, %f1525, %f1930, %f1531;
	add.s64 	%rd518, %rd524, 96;
	// begin inline asm
	cvta.to.global.u64 %rd517, %rd518;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r631,%r632,%r633,%r634}, [%rd517];
	// end inline asm
	mov.b32 	%f1532, %r631;
	mov.b32 	%f1533, %r632;
	mov.b32 	%f1534, %r633;
	mul.f32 	%f1535, %f586, %f1532;
	mul.f32 	%f1536, %f586, %f1533;
	mul.f32 	%f1537, %f586, %f1534;
	fma.rn.f32 	%f1925, %f1525, %f1925, %f1535;
	fma.rn.f32 	%f1926, %f1525, %f1926, %f1536;
	fma.rn.f32 	%f1927, %f1525, %f1927, %f1537;
	add.s64 	%rd521, %rd524, 112;
	// begin inline asm
	cvta.to.global.u64 %rd520, %rd521;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r635,%r636,%r637,%r638}, [%rd520];
	// end inline asm
	mov.b32 	%f1538, %r635;
	mov.b32 	%f1539, %r636;
	mov.b32 	%f1540, %r637;
	mul.f32 	%f1541, %f586, %f1538;
	mul.f32 	%f1542, %f586, %f1539;
	mul.f32 	%f1543, %f586, %f1540;
	fma.rn.f32 	%f1922, %f1525, %f1922, %f1541;
	fma.rn.f32 	%f1923, %f1525, %f1923, %f1542;
	fma.rn.f32 	%f1924, %f1525, %f1924, %f1543;
	bra.uni 	$L__BB14_87;

$L__BB14_76:
	mov.f32 	%f1931, 0f00000000;
	mov.f32 	%f1933, 0f3F800000;
	setp.eq.s32 	%p41, %r491, 4;
	@%p41 bra 	$L__BB14_79;

	setp.ne.s32 	%p42, %r491, 1;
	mov.f32 	%f1932, %f1931;
	mov.f32 	%f1934, %f1931;
	mov.f32 	%f1935, %f1933;
	mov.f32 	%f1936, %f1931;
	mov.f32 	%f1937, %f1933;
	mov.f32 	%f1938, %f1931;
	mov.f32 	%f1939, %f1931;
	@%p42 bra 	$L__BB14_88;

	// begin inline asm
	call (%rd408), _optix_get_static_transform_from_handle, (%rd406);
	// end inline asm
	add.s64 	%rd633, %rd408, 64;
	bra.uni 	$L__BB14_80;

$L__BB14_82:
	// begin inline asm
	call (%rd421), _optix_get_srt_motion_transform_from_handle, (%rd406);
	// end inline asm
	// begin inline asm
	cvta.to.global.u64 %rd423, %rd421;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r505,%r506,%r507,%r508}, [%rd423];
	// end inline asm
	add.s64 	%rd427, %rd421, 16;
	// begin inline asm
	cvta.to.global.u64 %rd426, %rd427;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r509,%r510,%r511,%r512}, [%rd426];
	// end inline asm
	add.s64 	%rd430, %rd421, 32;
	// begin inline asm
	cvta.to.global.u64 %rd429, %rd430;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r513,%r514,%r515,%r516}, [%rd429];
	// end inline asm
	add.s64 	%rd433, %rd421, 48;
	// begin inline asm
	cvta.to.global.u64 %rd432, %rd433;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r517,%r518,%r519,%r520}, [%rd432];
	// end inline asm
	add.s64 	%rd436, %rd421, 64;
	// begin inline asm
	cvta.to.global.u64 %rd435, %rd436;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r521,%r522,%r523,%r524}, [%rd435];
	// end inline asm
	add.s64 	%rd439, %rd421, 80;
	// begin inline asm
	cvta.to.global.u64 %rd438, %rd439;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r525,%r526,%r527,%r528}, [%rd438];
	// end inline asm
	add.s64 	%rd442, %rd421, 96;
	// begin inline asm
	cvta.to.global.u64 %rd441, %rd442;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r529,%r530,%r531,%r532}, [%rd441];
	// end inline asm
	add.s64 	%rd445, %rd421, 112;
	// begin inline asm
	cvta.to.global.u64 %rd444, %rd445;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r533,%r534,%r535,%r536}, [%rd444];
	// end inline asm
	add.s64 	%rd448, %rd421, 128;
	// begin inline asm
	cvta.to.global.u64 %rd447, %rd448;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r537,%r538,%r539,%r540}, [%rd447];
	// end inline asm
	add.s64 	%rd451, %rd421, 144;
	// begin inline asm
	cvta.to.global.u64 %rd450, %rd451;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r541,%r542,%r543,%r544}, [%rd450];
	// end inline asm
	mov.b32 	%f1421, %r508;
	mov.b32 	%f1422, %r509;
	and.b32  	%r561, %r507, 65535;
	add.s32 	%r562, %r561, -1;
	cvt.rn.f32.s32 	%f1423, %r562;
	sub.f32 	%f1424, %f1409, %f1421;
	mul.f32 	%f1425, %f1424, %f1423;
	sub.f32 	%f1426, %f1422, %f1421;
	div.rn.f32 	%f1427, %f1425, %f1426;
	min.f32 	%f1428, %f1423, %f1427;
	mov.f32 	%f1429, 0f00000000;
	max.f32 	%f1430, %f1429, %f1428;
	cvt.rmi.f32.f32 	%f1431, %f1430;
	sub.f32 	%f546, %f1430, %f1431;
	cvt.rzi.s32.f32 	%r563, %f1431;
	mul.wide.s32 	%rd465, %r563, 64;
	add.s64 	%rd454, %rd430, %rd465;
	// begin inline asm
	cvta.to.global.u64 %rd453, %rd454;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r545,%r546,%r547,%r548}, [%rd453];
	// end inline asm
	mov.b32 	%f1912, %r545;
	mov.b32 	%f1913, %r546;
	mov.b32 	%f1914, %r547;
	add.s64 	%rd457, %rd454, 16;
	// begin inline asm
	cvta.to.global.u64 %rd456, %rd457;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r549,%r550,%r551,%r552}, [%rd456];
	// end inline asm
	mov.b32 	%f1915, %r549;
	mov.b32 	%f1916, %r550;
	mov.b32 	%f1917, %r552;
	add.s64 	%rd460, %rd454, 32;
	// begin inline asm
	cvta.to.global.u64 %rd459, %rd460;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r553,%r554,%r555,%r556}, [%rd459];
	// end inline asm
	mov.b32 	%f1918, %r554;
	mov.b32 	%f1919, %r555;
	mov.b32 	%f1920, %r556;
	add.s64 	%rd463, %rd454, 48;
	// begin inline asm
	cvta.to.global.u64 %rd462, %rd463;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r557,%r558,%r559,%r560}, [%rd462];
	// end inline asm
	mov.b32 	%f1921, %r557;
	setp.leu.f32 	%p44, %f546, 0f00000000;
	@%p44 bra 	$L__BB14_84;

	mov.f32 	%f1432, 0f3F800000;
	sub.f32 	%f1433, %f1432, %f546;
	add.s64 	%rd467, %rd454, 64;
	// begin inline asm
	cvta.to.global.u64 %rd466, %rd467;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r564,%r565,%r566,%r567}, [%rd466];
	// end inline asm
	mov.b32 	%f1434, %r564;
	mov.b32 	%f1435, %r565;
	mov.b32 	%f1436, %r566;
	mul.f32 	%f1437, %f546, %f1434;
	mul.f32 	%f1438, %f546, %f1435;
	mul.f32 	%f1439, %f546, %f1436;
	fma.rn.f32 	%f1912, %f1433, %f1912, %f1437;
	fma.rn.f32 	%f1913, %f1433, %f1913, %f1438;
	fma.rn.f32 	%f1914, %f1433, %f1914, %f1439;
	add.s64 	%rd470, %rd454, 80;
	// begin inline asm
	cvta.to.global.u64 %rd469, %rd470;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r568,%r569,%r570,%r571}, [%rd469];
	// end inline asm
	mov.b32 	%f1440, %r568;
	mov.b32 	%f1441, %r569;
	mov.b32 	%f1442, %r571;
	mul.f32 	%f1443, %f546, %f1440;
	mul.f32 	%f1444, %f546, %f1441;
	mul.f32 	%f1445, %f546, %f1442;
	fma.rn.f32 	%f1915, %f1433, %f1915, %f1443;
	fma.rn.f32 	%f1916, %f1433, %f1916, %f1444;
	fma.rn.f32 	%f1917, %f1433, %f1917, %f1445;
	add.s64 	%rd473, %rd454, 96;
	// begin inline asm
	cvta.to.global.u64 %rd472, %rd473;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r572,%r573,%r574,%r575}, [%rd472];
	// end inline asm
	mov.b32 	%f1446, %r573;
	mov.b32 	%f1447, %r574;
	mov.b32 	%f1448, %r575;
	mul.f32 	%f1449, %f546, %f1446;
	mul.f32 	%f1450, %f546, %f1447;
	mul.f32 	%f1451, %f546, %f1448;
	fma.rn.f32 	%f1452, %f1433, %f1918, %f1449;
	fma.rn.f32 	%f1453, %f1433, %f1919, %f1450;
	fma.rn.f32 	%f1454, %f1433, %f1920, %f1451;
	add.s64 	%rd476, %rd454, 112;
	// begin inline asm
	cvta.to.global.u64 %rd475, %rd476;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r576,%r577,%r578,%r579}, [%rd475];
	// end inline asm
	mov.b32 	%f1455, %r576;
	mul.f32 	%f1456, %f546, %f1455;
	fma.rn.f32 	%f1457, %f1433, %f1921, %f1456;
	mul.f32 	%f1458, %f1453, %f1453;
	fma.rn.f32 	%f1459, %f1452, %f1452, %f1458;
	fma.rn.f32 	%f1460, %f1454, %f1454, %f1459;
	fma.rn.f32 	%f1461, %f1457, %f1457, %f1460;
	sqrt.rn.f32 	%f1462, %f1461;
	rcp.rn.f32 	%f1463, %f1462;
	mul.f32 	%f1918, %f1452, %f1463;
	mul.f32 	%f1919, %f1453, %f1463;
	mul.f32 	%f1920, %f1454, %f1463;
	mul.f32 	%f1921, %f1463, %f1457;

$L__BB14_84:
	mul.f32 	%f1464, %f1919, %f1919;
	fma.rn.f32 	%f1465, %f1918, %f1918, %f1464;
	fma.rn.f32 	%f1466, %f1920, %f1920, %f1465;
	fma.rn.f32 	%f1467, %f1921, %f1921, %f1466;
	rcp.rn.f32 	%f1468, %f1467;
	mul.f32 	%f1469, %f1918, %f1468;
	mul.f32 	%f1470, %f1919, %f1468;
	mul.f32 	%f1471, %f1920, %f1468;
	mul.f32 	%f1472, %f1921, %f1468;
	mul.f32 	%f1473, %f1918, %f1469;
	mul.f32 	%f1474, %f1919, %f1470;
	mul.f32 	%f1475, %f1920, %f1471;
	mul.f32 	%f1476, %f1918, %f1470;
	mul.f32 	%f1477, %f1920, %f1472;
	mul.f32 	%f1478, %f1918, %f1471;
	mul.f32 	%f1479, %f1919, %f1472;
	mul.f32 	%f1480, %f1919, %f1471;
	mul.f32 	%f1481, %f1918, %f1472;
	sub.f32 	%f1482, %f1473, %f1474;
	sub.f32 	%f1483, %f1482, %f1475;
	fma.rn.f32 	%f1484, %f1921, %f1472, %f1483;
	sub.f32 	%f1485, %f1476, %f1477;
	add.f32 	%f1486, %f1485, %f1485;
	add.f32 	%f1487, %f1478, %f1479;
	add.f32 	%f1488, %f1487, %f1487;
	add.f32 	%f1489, %f1476, %f1477;
	add.f32 	%f1490, %f1489, %f1489;
	sub.f32 	%f1491, %f1474, %f1473;
	sub.f32 	%f1492, %f1491, %f1475;
	fma.rn.f32 	%f1493, %f1921, %f1472, %f1492;
	sub.f32 	%f1494, %f1480, %f1481;
	add.f32 	%f1495, %f1494, %f1494;
	sub.f32 	%f1496, %f1478, %f1479;
	add.f32 	%f1497, %f1496, %f1496;
	add.f32 	%f1498, %f1480, %f1481;
	add.f32 	%f1499, %f1498, %f1498;
	neg.f32 	%f1500, %f1473;
	sub.f32 	%f1501, %f1500, %f1474;
	add.f32 	%f1502, %f1475, %f1501;
	fma.rn.f32 	%f1503, %f1921, %f1472, %f1502;
	mul.f32 	%f1504, %f1914, %f1484;
	fma.rn.f32 	%f1505, %f1916, %f1486, %f1504;
	fma.rn.f32 	%f1930, %f1917, %f1488, %f1505;
	mul.f32 	%f1506, %f1916, %f1493;
	fma.rn.f32 	%f1507, %f1914, %f1490, %f1506;
	fma.rn.f32 	%f1927, %f1917, %f1495, %f1507;
	mul.f32 	%f1508, %f1916, %f1499;
	fma.rn.f32 	%f1509, %f1914, %f1497, %f1508;
	fma.rn.f32 	%f1924, %f1917, %f1503, %f1509;
	mul.f32 	%f1510, %f1913, %f1484;
	fma.rn.f32 	%f1929, %f1915, %f1486, %f1510;
	mul.f32 	%f1511, %f1915, %f1493;
	fma.rn.f32 	%f1926, %f1913, %f1490, %f1511;
	mul.f32 	%f1512, %f1915, %f1499;
	fma.rn.f32 	%f1923, %f1913, %f1497, %f1512;
	mul.f32 	%f1928, %f1912, %f1484;
	mul.f32 	%f1925, %f1912, %f1490;
	mul.f32 	%f1922, %f1912, %f1497;

$L__BB14_87:
	mul.f32 	%f1544, %f1923, %f1927;
	mul.f32 	%f1545, %f1924, %f1926;
	sub.f32 	%f1546, %f1545, %f1544;
	mul.f32 	%f1547, %f1928, %f1546;
	mul.f32 	%f1548, %f1922, %f1927;
	mul.f32 	%f1549, %f1924, %f1925;
	sub.f32 	%f1550, %f1549, %f1548;
	mul.f32 	%f1551, %f1550, %f1929;
	sub.f32 	%f1552, %f1547, %f1551;
	mul.f32 	%f1553, %f1922, %f1926;
	mul.f32 	%f1554, %f1923, %f1925;
	sub.f32 	%f1555, %f1554, %f1553;
	fma.rn.f32 	%f1556, %f1555, %f1930, %f1552;
	rcp.rn.f32 	%f1557, %f1556;
	mul.f32 	%f1937, %f1546, %f1557;
	mul.f32 	%f1558, %f1924, %f1929;
	mul.f32 	%f1559, %f1923, %f1930;
	sub.f32 	%f1560, %f1559, %f1558;
	mul.f32 	%f1938, %f1560, %f1557;
	mul.f32 	%f1561, %f1926, %f1930;
	mul.f32 	%f1562, %f1927, %f1929;
	sub.f32 	%f1563, %f1562, %f1561;
	mul.f32 	%f1939, %f1563, %f1557;
	sub.f32 	%f1564, %f1548, %f1549;
	mul.f32 	%f1934, %f1564, %f1557;
	mul.f32 	%f1565, %f1922, %f1930;
	mul.f32 	%f1566, %f1924, %f1928;
	sub.f32 	%f1567, %f1566, %f1565;
	mul.f32 	%f1935, %f1567, %f1557;
	mul.f32 	%f1568, %f1927, %f1928;
	mul.f32 	%f1569, %f1925, %f1930;
	sub.f32 	%f1570, %f1569, %f1568;
	mul.f32 	%f1936, %f1570, %f1557;
	mul.f32 	%f1931, %f1555, %f1557;
	mul.f32 	%f1571, %f1923, %f1928;
	mul.f32 	%f1572, %f1922, %f1929;
	sub.f32 	%f1573, %f1572, %f1571;
	mul.f32 	%f1932, %f1573, %f1557;
	mul.f32 	%f1574, %f1925, %f1929;
	mul.f32 	%f1575, %f1926, %f1928;
	sub.f32 	%f1576, %f1575, %f1574;
	mul.f32 	%f1933, %f1576, %f1557;
	bra.uni 	$L__BB14_88;

$L__BB14_79:
	// begin inline asm
	call (%rd633), _optix_get_instance_inverse_transform_from_handle, (%rd406);
	// end inline asm

$L__BB14_80:
	// begin inline asm
	cvta.to.global.u64 %rd412, %rd633;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r493,%r494,%r495,%r496}, [%rd412];
	// end inline asm
	mov.b32 	%f1937, %r493;
	mov.b32 	%f1938, %r494;
	mov.b32 	%f1939, %r495;
	add.s64 	%rd416, %rd633, 16;
	// begin inline asm
	cvta.to.global.u64 %rd415, %rd416;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r497,%r498,%r499,%r500}, [%rd415];
	// end inline asm
	mov.b32 	%f1934, %r497;
	mov.b32 	%f1935, %r498;
	mov.b32 	%f1936, %r499;
	add.s64 	%rd419, %rd633, 32;
	// begin inline asm
	cvta.to.global.u64 %rd418, %rd419;
	// end inline asm
	// begin inline asm
	ld.global.v4.u32 {%r501,%r502,%r503,%r504}, [%rd418];
	// end inline asm
	mov.b32 	%f1931, %r501;
	mov.b32 	%f1932, %r502;
	mov.b32 	%f1933, %r503;

$L__BB14_88:
	setp.eq.s32 	%p46, %r646, 0;
	@%p46 bra 	$L__BB14_90;

	mul.f32 	%f1577, %f1908, %f1938;
	fma.rn.f32 	%f1578, %f1905, %f1937, %f1577;
	fma.rn.f32 	%f632, %f1911, %f1939, %f1578;
	mul.f32 	%f1579, %f1907, %f1938;
	fma.rn.f32 	%f1580, %f1904, %f1937, %f1579;
	fma.rn.f32 	%f633, %f1910, %f1939, %f1580;
	mul.f32 	%f1581, %f1906, %f1938;
	fma.rn.f32 	%f1582, %f1903, %f1937, %f1581;
	fma.rn.f32 	%f1939, %f1909, %f1939, %f1582;
	mul.f32 	%f1583, %f1908, %f1935;
	fma.rn.f32 	%f1584, %f1905, %f1934, %f1583;
	fma.rn.f32 	%f635, %f1911, %f1936, %f1584;
	mul.f32 	%f1585, %f1907, %f1935;
	fma.rn.f32 	%f1586, %f1904, %f1934, %f1585;
	fma.rn.f32 	%f636, %f1910, %f1936, %f1586;
	mul.f32 	%f1587, %f1906, %f1935;
	fma.rn.f32 	%f1588, %f1903, %f1934, %f1587;
	fma.rn.f32 	%f1936, %f1909, %f1936, %f1588;
	mul.f32 	%f1589, %f1908, %f1932;
	fma.rn.f32 	%f1590, %f1905, %f1931, %f1589;
	fma.rn.f32 	%f638, %f1911, %f1933, %f1590;
	mul.f32 	%f1591, %f1907, %f1932;
	fma.rn.f32 	%f1592, %f1904, %f1931, %f1591;
	fma.rn.f32 	%f639, %f1910, %f1933, %f1592;
	mul.f32 	%f1593, %f1906, %f1932;
	fma.rn.f32 	%f1594, %f1903, %f1931, %f1593;
	fma.rn.f32 	%f1933, %f1909, %f1933, %f1594;
	mov.f32 	%f1931, %f638;
	mov.f32 	%f1932, %f639;
	mov.f32 	%f1934, %f635;
	mov.f32 	%f1935, %f636;
	mov.f32 	%f1937, %f632;
	mov.f32 	%f1938, %f633;

$L__BB14_90:
	add.s32 	%r646, %r646, 1;
	setp.lt.u32 	%p47, %r646, %r488;
	mov.f32 	%f1903, %f1939;
	mov.f32 	%f1904, %f1938;
	mov.f32 	%f1905, %f1937;
	mov.f32 	%f1906, %f1936;
	mov.f32 	%f1907, %f1935;
	mov.f32 	%f1908, %f1934;
	mov.f32 	%f1909, %f1933;
	mov.f32 	%f1910, %f1932;
	mov.f32 	%f1911, %f1931;
	@%p47 bra 	$L__BB14_75;

$L__BB14_91:
	fma.rn.f32 	%f1595, %f1982, %f1875, %f1878;
	fma.rn.f32 	%f1596, %f1983, %f1876, %f1595;
	fma.rn.f32 	%f1597, %f1982, %f1871, %f1874;
	fma.rn.f32 	%f1598, %f1983, %f1872, %f1597;
	fma.rn.f32 	%f1599, %f1982, %f1867, %f1870;
	fma.rn.f32 	%f1600, %f1983, %f1868, %f1599;
	fma.rn.f32 	%f1982, %f1984, %f1877, %f1596;
	fma.rn.f32 	%f1983, %f1984, %f1873, %f1598;
	fma.rn.f32 	%f1984, %f1984, %f1869, %f1600;
	ld.const.u64 	%rd525, [params+112];
	setp.eq.s64 	%p48, %rd525, 0;
	mov.f32 	%f1958, %f1838;
	mov.f32 	%f1959, %f1837;
	mov.f32 	%f1960, %f1836;
	@%p48 bra 	$L__BB14_93;

	mul.f32 	%f1601, %f1838, %f1937;
	fma.rn.f32 	%f1602, %f1837, %f1934, %f1601;
	mul.f32 	%f1603, %f1838, %f1938;
	fma.rn.f32 	%f1604, %f1837, %f1935, %f1603;
	mul.f32 	%f1605, %f1838, %f1939;
	fma.rn.f32 	%f1606, %f1837, %f1936, %f1605;
	fma.rn.f32 	%f1607, %f1836, %f1931, %f1602;
	fma.rn.f32 	%f1608, %f1836, %f1932, %f1604;
	fma.rn.f32 	%f1609, %f1836, %f1933, %f1606;
	mul.f32 	%f1610, %f1607, %f1607;
	fma.rn.f32 	%f1611, %f1608, %f1608, %f1610;
	fma.rn.f32 	%f1612, %f1609, %f1609, %f1611;
	sqrt.rn.f32 	%f1613, %f1612;
	div.rn.f32 	%f1958, %f1607, %f1613;
	div.rn.f32 	%f1959, %f1608, %f1613;
	div.rn.f32 	%f1960, %f1609, %f1613;

$L__BB14_93:
	ld.const.u64 	%rd526, [params+136];
	setp.eq.s64 	%p49, %rd526, 0;
	@%p49 bra 	$L__BB14_95;

	mul.f32 	%f1614, %f1838, %f1937;
	fma.rn.f32 	%f1615, %f1837, %f1934, %f1614;
	mul.f32 	%f1616, %f1838, %f1938;
	fma.rn.f32 	%f1617, %f1837, %f1935, %f1616;
	mul.f32 	%f1618, %f1838, %f1939;
	fma.rn.f32 	%f1619, %f1837, %f1936, %f1618;
	fma.rn.f32 	%f1620, %f1836, %f1931, %f1615;
	fma.rn.f32 	%f1621, %f1836, %f1932, %f1617;
	fma.rn.f32 	%f1622, %f1836, %f1933, %f1619;
	mul.f32 	%f1623, %f1620, %f1620;
	fma.rn.f32 	%f1624, %f1621, %f1621, %f1623;
	fma.rn.f32 	%f1625, %f1622, %f1622, %f1624;
	sqrt.rn.f32 	%f1626, %f1625;
	div.rn.f32 	%f1838, %f1620, %f1626;
	div.rn.f32 	%f1837, %f1621, %f1626;
	div.rn.f32 	%f1836, %f1622, %f1626;

$L__BB14_95:
	mov.f32 	%f1981, %f1836;
	mov.f32 	%f1980, %f1837;
	mov.f32 	%f1979, %f1838;
	ld.const.u64 	%rd527, [params+184];
	setp.eq.s64 	%p50, %rd527, 0;
	mov.f32 	%f1970, 0f00000000;
	mov.f32 	%f1973, %f1970;
	mov.f32 	%f1974, %f1970;
	mov.f32 	%f1975, %f1970;
	@%p50 bra 	$L__BB14_97;

	mul.f32 	%f1630, %f1875, 0f00000000;
	mov.f32 	%f1631, 0f00000000;
	fma.rn.f32 	%f1632, %f1631, %f1876, %f1630;
	mul.f32 	%f1633, %f1871, 0f00000000;
	fma.rn.f32 	%f1634, %f1631, %f1872, %f1633;
	mul.f32 	%f1635, %f1867, 0f00000000;
	fma.rn.f32 	%f1636, %f1631, %f1868, %f1635;
	fma.rn.f32 	%f1973, %f1631, %f1877, %f1632;
	fma.rn.f32 	%f1974, %f1631, %f1873, %f1634;
	fma.rn.f32 	%f1975, %f1631, %f1869, %f1636;

$L__BB14_97:
	ld.const.u64 	%rd528, [params+232];
	ld.const.u64 	%rd529, [params+280];
	or.b64  	%rd530, %rd528, %rd529;
	setp.eq.s64 	%p51, %rd530, 0;
	mov.f32 	%f1971, %f1970;
	mov.f32 	%f1972, %f1970;
	@%p51 bra 	$L__BB14_99;

	mul.f32 	%f1640, %f1979, %f1875;
	fma.rn.f32 	%f1641, %f1980, %f1871, %f1640;
	mul.f32 	%f1642, %f1979, %f1876;
	fma.rn.f32 	%f1643, %f1980, %f1872, %f1642;
	mul.f32 	%f1644, %f1979, %f1877;
	fma.rn.f32 	%f1645, %f1980, %f1873, %f1644;
	fma.rn.f32 	%f1646, %f1981, %f1867, %f1641;
	fma.rn.f32 	%f1647, %f1981, %f1868, %f1643;
	fma.rn.f32 	%f1648, %f1981, %f1869, %f1645;
	mul.f32 	%f1649, %f1646, %f1646;
	fma.rn.f32 	%f1650, %f1647, %f1647, %f1649;
	fma.rn.f32 	%f1651, %f1648, %f1648, %f1650;
	sqrt.rn.f32 	%f1652, %f1651;
	div.rn.f32 	%f1653, %f1646, %f1652;
	div.rn.f32 	%f1654, %f1647, %f1652;
	div.rn.f32 	%f1655, %f1648, %f1652;
	mul.f32 	%f1656, %f1653, %f1937;
	mul.f32 	%f1657, %f1653, %f1938;
	mul.f32 	%f1658, %f1653, %f1939;
	fma.rn.f32 	%f1659, %f1654, %f1934, %f1656;
	fma.rn.f32 	%f1660, %f1654, %f1935, %f1657;
	fma.rn.f32 	%f1661, %f1654, %f1936, %f1658;
	fma.rn.f32 	%f1662, %f1655, %f1931, %f1659;
	fma.rn.f32 	%f1663, %f1655, %f1932, %f1660;
	fma.rn.f32 	%f1664, %f1655, %f1933, %f1661;
	mul.f32 	%f1665, %f1662, %f1662;
	fma.rn.f32 	%f1666, %f1663, %f1663, %f1665;
	fma.rn.f32 	%f1667, %f1664, %f1664, %f1666;
	sqrt.rn.f32 	%f1668, %f1667;
	rcp.rn.f32 	%f1669, %f1668;
	mul.f32 	%f1670, %f1669, %f1662;
	mul.f32 	%f1671, %f1669, %f1663;
	mul.f32 	%f1672, %f1669, %f1664;
	mul.f32 	%f1673, %f1937, 0f00000000;
	mov.f32 	%f1674, 0f00000000;
	fma.rn.f32 	%f1675, %f1674, %f1934, %f1673;
	mul.f32 	%f1676, %f1938, 0f00000000;
	fma.rn.f32 	%f1677, %f1674, %f1935, %f1676;
	mul.f32 	%f1678, %f1939, 0f00000000;
	fma.rn.f32 	%f1679, %f1674, %f1936, %f1678;
	fma.rn.f32 	%f1680, %f1674, %f1931, %f1675;
	fma.rn.f32 	%f1681, %f1674, %f1932, %f1677;
	fma.rn.f32 	%f1682, %f1674, %f1933, %f1679;
	mul.f32 	%f1683, %f1680, %f1669;
	mul.f32 	%f1684, %f1681, %f1669;
	mul.f32 	%f1685, %f1682, %f1669;
	mul.f32 	%f1686, %f1670, %f1683;
	fma.rn.f32 	%f1687, %f1671, %f1684, %f1686;
	fma.rn.f32 	%f1688, %f1672, %f1685, %f1687;
	mul.f32 	%f1689, %f1670, %f1688;
	mul.f32 	%f1690, %f1671, %f1688;
	mul.f32 	%f1691, %f1672, %f1688;
	sub.f32 	%f1970, %f1683, %f1689;
	sub.f32 	%f1971, %f1684, %f1690;
	sub.f32 	%f1972, %f1685, %f1691;

$L__BB14_99:
	st.global.u32 	[%rd21], %r334;
	mov.f32 	%f1838, %f1958;
	mov.f32 	%f1837, %f1959;
	mov.f32 	%f1836, %f1960;

$L__BB14_100:
	ld.const.u64 	%rd531, [params+328];
	cvta.to.global.u64 	%rd532, %rd531;
	shl.b64 	%rd533, %rd20, 3;
	add.s64 	%rd534, %rd532, %rd533;
	st.global.u64 	[%rd534], %rd19;
	ld.const.u64 	%rd535, [params+336];
	cvta.to.global.u64 	%rd536, %rd535;
	shl.b64 	%rd537, %rd20, 2;
	add.s64 	%rd538, %rd536, %rd537;
	mov.u32 	%r639, 0;
	st.global.u32 	[%rd538], %r639;
	ld.const.u64 	%rd539, [params+160];
	cvta.to.global.u64 	%rd540, %rd539;
	add.s64 	%rd541, %rd540, %rd537;
	st.global.f32 	[%rd541], %f1982;
	ld.const.u64 	%rd542, [params+168];
	cvta.to.global.u64 	%rd543, %rd542;
	add.s64 	%rd544, %rd543, %rd537;
	st.global.f32 	[%rd544], %f1983;
	ld.const.u64 	%rd545, [params+176];
	cvta.to.global.u64 	%rd546, %rd545;
	add.s64 	%rd547, %rd546, %rd537;
	st.global.f32 	[%rd547], %f1984;
	ld.const.u64 	%rd548, [params+72];
	cvta.to.global.u64 	%rd549, %rd548;
	add.s64 	%rd550, %rd549, %rd537;
	st.global.f32 	[%rd550], %f1149;
	ld.const.u64 	%rd36, [params+96];
	setp.eq.s64 	%p52, %rd36, 0;
	@%p52 bra 	$L__BB14_102;

	cvta.to.global.u64 	%rd551, %rd36;
	add.s64 	%rd553, %rd551, %rd537;
	st.global.u32 	[%rd553], %r639;
	ld.const.u64 	%rd554, [params+104];
	cvta.to.global.u64 	%rd555, %rd554;
	add.s64 	%rd556, %rd555, %rd537;
	st.global.u32 	[%rd556], %r639;

$L__BB14_102:
	ld.const.u64 	%rd37, [params+112];
	setp.eq.s64 	%p53, %rd37, 0;
	@%p53 bra 	$L__BB14_104;

	cvta.to.global.u64 	%rd557, %rd37;
	add.s64 	%rd559, %rd557, %rd537;
	st.global.f32 	[%rd559], %f1838;
	ld.const.u64 	%rd560, [params+120];
	cvta.to.global.u64 	%rd561, %rd560;
	add.s64 	%rd562, %rd561, %rd537;
	st.global.f32 	[%rd562], %f1837;
	ld.const.u64 	%rd563, [params+128];
	cvta.to.global.u64 	%rd564, %rd563;
	add.s64 	%rd565, %rd564, %rd537;
	st.global.f32 	[%rd565], %f1836;

$L__BB14_104:
	ld.const.u64 	%rd38, [params+136];
	setp.eq.s64 	%p54, %rd38, 0;
	@%p54 bra 	$L__BB14_106;

	cvta.to.global.u64 	%rd566, %rd38;
	add.s64 	%rd568, %rd566, %rd537;
	st.global.f32 	[%rd568], %f1979;
	ld.const.u64 	%rd569, [params+144];
	cvta.to.global.u64 	%rd570, %rd569;
	add.s64 	%rd571, %rd570, %rd537;
	st.global.f32 	[%rd571], %f1980;
	ld.const.u64 	%rd572, [params+152];
	cvta.to.global.u64 	%rd573, %rd572;
	add.s64 	%rd574, %rd573, %rd537;
	st.global.f32 	[%rd574], %f1981;

$L__BB14_106:
	ld.const.u64 	%rd39, [params+184];
	setp.eq.s64 	%p55, %rd39, 0;
	@%p55 bra 	$L__BB14_108;

	cvta.to.global.u64 	%rd575, %rd39;
	add.s64 	%rd577, %rd575, %rd537;
	st.global.f32 	[%rd577], %f1973;
	ld.const.u64 	%rd578, [params+192];
	cvta.to.global.u64 	%rd579, %rd578;
	add.s64 	%rd580, %rd579, %rd537;
	st.global.f32 	[%rd580], %f1974;
	ld.const.u64 	%rd581, [params+200];
	cvta.to.global.u64 	%rd582, %rd581;
	add.s64 	%rd583, %rd582, %rd537;
	st.global.f32 	[%rd583], %f1975;
	ld.const.u64 	%rd584, [params+208];
	cvta.to.global.u64 	%rd585, %rd584;
	add.s64 	%rd586, %rd585, %rd537;
	st.global.f32 	[%rd586], %f1973;
	ld.const.u64 	%rd587, [params+216];
	cvta.to.global.u64 	%rd588, %rd587;
	add.s64 	%rd589, %rd588, %rd537;
	st.global.f32 	[%rd589], %f1974;
	ld.const.u64 	%rd590, [params+224];
	cvta.to.global.u64 	%rd591, %rd590;
	add.s64 	%rd592, %rd591, %rd537;
	st.global.f32 	[%rd592], %f1975;

$L__BB14_108:
	ld.const.u64 	%rd40, [params+232];
	setp.eq.s64 	%p56, %rd40, 0;
	@%p56 bra 	$L__BB14_110;

	cvta.to.global.u64 	%rd593, %rd40;
	add.s64 	%rd595, %rd593, %rd537;
	st.global.f32 	[%rd595], %f1970;
	ld.const.u64 	%rd596, [params+240];
	cvta.to.global.u64 	%rd597, %rd596;
	add.s64 	%rd598, %rd597, %rd537;
	st.global.f32 	[%rd598], %f1971;
	ld.const.u64 	%rd599, [params+248];
	cvta.to.global.u64 	%rd600, %rd599;
	add.s64 	%rd601, %rd600, %rd537;
	st.global.f32 	[%rd601], %f1972;
	ld.const.u64 	%rd602, [params+256];
	cvta.to.global.u64 	%rd603, %rd602;
	add.s64 	%rd604, %rd603, %rd537;
	st.global.f32 	[%rd604], %f1970;
	ld.const.u64 	%rd605, [params+264];
	cvta.to.global.u64 	%rd606, %rd605;
	add.s64 	%rd607, %rd606, %rd537;
	st.global.f32 	[%rd607], %f1971;
	ld.const.u64 	%rd608, [params+272];
	cvta.to.global.u64 	%rd609, %rd608;
	add.s64 	%rd610, %rd609, %rd537;
	st.global.f32 	[%rd610], %f1972;

$L__BB14_110:
	ld.const.u64 	%rd41, [params+280];
	setp.eq.s64 	%p57, %rd41, 0;
	@%p57 bra 	$L__BB14_112;

	cvta.to.global.u64 	%rd611, %rd41;
	add.s64 	%rd613, %rd611, %rd537;
	st.global.f32 	[%rd613], %f1970;
	ld.const.u64 	%rd614, [params+288];
	cvta.to.global.u64 	%rd615, %rd614;
	add.s64 	%rd616, %rd615, %rd537;
	st.global.f32 	[%rd616], %f1971;
	ld.const.u64 	%rd617, [params+296];
	cvta.to.global.u64 	%rd618, %rd617;
	add.s64 	%rd619, %rd618, %rd537;
	st.global.f32 	[%rd619], %f1972;
	ld.const.u64 	%rd620, [params+304];
	cvta.to.global.u64 	%rd621, %rd620;
	add.s64 	%rd622, %rd621, %rd537;
	st.global.f32 	[%rd622], %f1970;
	ld.const.u64 	%rd623, [params+312];
	cvta.to.global.u64 	%rd624, %rd623;
	add.s64 	%rd625, %rd624, %rd537;
	st.global.f32 	[%rd625], %f1971;
	ld.const.u64 	%rd626, [params+320];
	cvta.to.global.u64 	%rd627, %rd626;
	add.s64 	%rd628, %rd627, %rd537;
	st.global.f32 	[%rd628], %f1972;

$L__BB14_112:
	ret;

$L__BB14_46:
	fma.rn.f32 	%f1152, %f1149, %f1833, %f1775;
	ld.f32 	%f1153, [%rd18+-32];
	sub.f32 	%f347, %f1152, %f1153;
	ld.f32 	%f1154, [%rd18+-28];
	fma.rn.f32 	%f1155, %f1149, %f1834, %f1776;
	sub.f32 	%f348, %f1155, %f1154;
	ld.f32 	%f1156, [%rd18+-24];
	sub.f32 	%f1157, %f1984, %f1156;
	mul.f32 	%f1158, %f1157, 0f00000000;
	mul.f32 	%f349, %f347, %f347;
	fma.rn.f32 	%f350, %f348, %f348, %f349;
	fma.rn.f32 	%f1159, %f1158, %f1158, %f350;
	sqrt.rn.f32 	%f1160, %f1159;
	ld.v4.f32 	{%f1161, %f1162, %f1163, %f1164}, [%rd18+-16];
	fma.rn.f32 	%f1167, %f1163, 0f3F000000, %f1161;
	setp.gt.f32 	%p24, %f1160, %f1167;
	mul.f32 	%f351, %f1158, 0f00000000;
	@%p24 bra 	$L__BB14_48;
	bra.uni 	$L__BB14_47;

$L__BB14_48:
	fma.rn.f32 	%f1173, %f351, %f351, %f350;
	sqrt.rn.f32 	%f1174, %f1173;
	div.rn.f32 	%f1838, %f347, %f1174;
	div.rn.f32 	%f1837, %f348, %f1174;
	div.rn.f32 	%f1836, %f351, %f1174;
	bra.uni 	$L__BB14_52;

$L__BB14_47:
	neg.f32 	%f1168, %f347;
	neg.f32 	%f1169, %f348;
	fma.rn.f32 	%f1170, %f1169, %f1169, %f349;
	fma.rn.f32 	%f1171, %f351, %f351, %f1170;
	sqrt.rn.f32 	%f1172, %f1171;
	div.rn.f32 	%f1838, %f1168, %f1172;
	div.rn.f32 	%f1837, %f1169, %f1172;
	div.rn.f32 	%f1836, %f351, %f1172;
	bra.uni 	$L__BB14_52;

}
	// .globl	__raygen__rg
.visible .entry __raygen__rg()
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<5>;
	.reg .f32 	%f<28>;
	.reg .b32 	%r<20>;
	.reg .b64 	%rd<44>;


	// begin inline asm
	call (%r1), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r2), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r4), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r5), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r6), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r7, %r6, %r2, %r5;
	mad.lo.s32 	%r8, %r7, %r1, %r4;
	ld.const.u64 	%rd3, [params+8];
	cvta.to.global.u64 	%rd4, %rd3;
	cvt.u64.u32 	%rd1, %r8;
	mul.wide.u32 	%rd5, %r8, 4;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f32 	%f1, [%rd6];
	ld.const.u64 	%rd7, [params+16];
	cvta.to.global.u64 	%rd8, %rd7;
	add.s64 	%rd9, %rd8, %rd5;
	ld.global.f32 	%f2, [%rd9];
	ld.const.u64 	%rd10, [params+24];
	cvta.to.global.u64 	%rd11, %rd10;
	add.s64 	%rd12, %rd11, %rd5;
	ld.global.f32 	%f3, [%rd12];
	ld.const.u64 	%rd13, [params+32];
	cvta.to.global.u64 	%rd14, %rd13;
	add.s64 	%rd15, %rd14, %rd5;
	ld.global.f32 	%f4, [%rd15];
	ld.const.u64 	%rd16, [params+40];
	cvta.to.global.u64 	%rd17, %rd16;
	add.s64 	%rd18, %rd17, %rd5;
	ld.global.f32 	%f5, [%rd18];
	ld.const.u64 	%rd19, [params+48];
	cvta.to.global.u64 	%rd20, %rd19;
	add.s64 	%rd21, %rd20, %rd5;
	ld.global.f32 	%f6, [%rd21];
	ld.const.u64 	%rd22, [params+56];
	cvta.to.global.u64 	%rd23, %rd22;
	add.s64 	%rd24, %rd23, %rd5;
	ld.global.f32 	%f7, [%rd24];
	ld.const.u64 	%rd25, [params+64];
	cvta.to.global.u64 	%rd26, %rd25;
	add.s64 	%rd27, %rd26, %rd5;
	ld.global.f32 	%f9, [%rd27];
	setp.eq.f32 	%p1, %f9, 0f7F800000;
	selp.f32 	%f8, 0f7F7FFFFF, %f9, %p1;
	ld.const.u64 	%rd2, [params+352];
	setp.eq.s64 	%p2, %rd2, 0;
	ld.const.u64 	%rd28, [params];
	cvta.to.global.u64 	%rd29, %rd28;
	add.s64 	%rd30, %rd29, %rd1;
	ld.global.u8 	%rs1, [%rd30];
	@%p2 bra 	$L__BB15_4;

	setp.eq.s16 	%p3, %rs1, 0;
	@%p3 bra 	$L__BB15_3;

	ld.const.u64 	%rd31, [params+360];
	mov.f32 	%f18, 0f00000000;
	mov.u32 	%r10, 4;
	mov.u32 	%r12, 1;
	mov.u32 	%r13, 0;
	// begin inline asm
	call _optix_trace_0, (%rd31, %f1, %f2, %f3, %f4, %f5, %f6, %f7, %f8, %f18, %r12, %r10, %r13, %r12, %r13);
	// end inline asm
	bra.uni 	$L__BB15_7;

$L__BB15_4:
	setp.eq.s16 	%p4, %rs1, 0;
	@%p4 bra 	$L__BB15_6;

	ld.const.u64 	%rd34, [params+360];
	mov.f32 	%f27, 0f00000000;
	mov.u32 	%r17, 1;
	mov.u32 	%r18, 0;
	// begin inline asm
	call _optix_trace_0, (%rd34, %f1, %f2, %f3, %f4, %f5, %f6, %f7, %f8, %f27, %r17, %r18, %r18, %r17, %r18);
	// end inline asm
	bra.uni 	$L__BB15_7;

$L__BB15_3:
	cvta.to.global.u64 	%rd32, %rd2;
	add.s64 	%rd33, %rd32, %rd1;
	mov.u16 	%rs3, 0;
	st.global.u8 	[%rd33], %rs3;
	bra.uni 	$L__BB15_7;

$L__BB15_6:
	mov.u64 	%rd35, 0;
	ld.const.u64 	%rd36, [params+328];
	cvta.to.global.u64 	%rd37, %rd36;
	shl.b64 	%rd38, %rd1, 3;
	add.s64 	%rd39, %rd37, %rd38;
	st.global.u64 	[%rd39], %rd35;
	ld.const.u64 	%rd40, [params+72];
	cvta.to.global.u64 	%rd41, %rd40;
	shl.b64 	%rd42, %rd1, 2;
	add.s64 	%rd43, %rd41, %rd42;
	mov.u32 	%r19, 2139095040;
	st.global.u32 	[%rd43], %r19;

$L__BB15_7:
	ret;

}
	// .globl	__miss__ms
.visible .entry __miss__ms()
{
	.reg .pred 	%p<2>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<14>;


	// begin inline asm
	call (%r1), _optix_get_launch_dimension_x, ();
	// end inline asm
	// begin inline asm
	call (%r2), _optix_get_launch_dimension_y, ();
	// end inline asm
	// begin inline asm
	call (%r4), _optix_get_launch_index_x, ();
	// end inline asm
	// begin inline asm
	call (%r5), _optix_get_launch_index_y, ();
	// end inline asm
	// begin inline asm
	call (%r6), _optix_get_launch_index_z, ();
	// end inline asm
	mad.lo.s32 	%r7, %r6, %r2, %r5;
	mad.lo.s32 	%r8, %r7, %r1, %r4;
	ld.const.u64 	%rd1, [params+352];
	setp.eq.s64 	%p1, %rd1, 0;
	cvt.u64.u32 	%rd2, %r8;
	@%p1 bra 	$L__BB16_2;

	cvta.to.global.u64 	%rd3, %rd1;
	add.s64 	%rd4, %rd3, %rd2;
	mov.u16 	%rs1, 0;
	st.global.u8 	[%rd4], %rs1;
	bra.uni 	$L__BB16_3;

$L__BB16_2:
	mov.u64 	%rd5, 0;
	ld.const.u64 	%rd6, [params+328];
	cvta.to.global.u64 	%rd7, %rd6;
	shl.b64 	%rd8, %rd2, 3;
	add.s64 	%rd9, %rd7, %rd8;
	st.global.u64 	[%rd9], %rd5;
	ld.const.u64 	%rd10, [params+72];
	cvta.to.global.u64 	%rd11, %rd10;
	shl.b64 	%rd12, %rd2, 2;
	add.s64 	%rd13, %rd11, %rd12;
	mov.u32 	%r9, 2139095040;
	st.global.u32 	[%rd13], %r9;

$L__BB16_3:
	ret;

}
	// .globl	__exception__err
.visible .entry __exception__err()
{
	.local .align 16 .b8 	__local_depot17[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<9>;


	mov.u64 	%SPL, __local_depot17;
	cvta.local.u64 	%SP, %SPL;
	add.u64 	%rd1, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	// begin inline asm
	call (%r1), _optix_get_exception_code, ();
	// end inline asm
	mul.wide.s32 	%rd3, %r1, 16;
	mov.u64 	%rd4, exceptions;
	add.s64 	%rd5, %rd4, %rd3;
	ld.const.u64 	%rd6, [%rd5+8];
	st.local.u32 	[%rd2], %r1;
	st.local.u64 	[%rd2+8], %rd6;
	mov.u64 	%rd7, $str$6;
	cvta.global.u64 	%rd8, %rd7;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32 	%r2, [retval0+0];
	} // callseq 0
	ret;

}

